# Para 0 1
CHI 2008 Proceedings · Visualization to Support Information Work	April 5-10, 2008 · Florence, Italy
# Para 1 1
An Exploratory Study of Visual Information Analysis
# Para 2 1
Petra Isenberg	Anthony Tang	Sheelagh Carpendale
# Para 3 1
Dept. of Computer Science	HCT Lab	Dept. of Computer Science
# Para 4 1
University of Calgary	University of British Columbia	University of Calgary
# Para 5 1
Calgary, AB, Canada	Vancouver, BC, Canada	Calgary, AB, Canada
# Para 6 1
petra.isenberg@ucalgary.ca	tonyt@ece.ubc.ca	sheelagh@ucalgary.ca
# Para 7 1
ABSTRACT
# Para 8 11
To design information visualization tools for collaborative 
use, we need to understand how teams engage with visual-
izations during their information analysis process. We re-
port on an exploratory study of individuals, pairs, and triples 
engaged in information analysis tasks using paper-based vi-
sualizations. From our study results, we derive a framework 
that captures the analysis activities of co-located teams and 
individuals. Comparing this framework with existing mod-
els of the information analysis process suggests that informa-
tion visualization tools may benefit from providing a flexible 
temporal flow of analysis actions.
# Para 19 1
Author Keywords
# Para 20 1
Information Visualization, analysis process, collaboration.
# Para 21 2
ACM Classification Keywords 
[H.5.2]Information Interfaces and Presentation
# Para 23 1
INTRODUCTION
# Para 24 19
Interactive information visualization (infovis) tools are often 
the center of many complex information analysis tasks [20]. 
In everyday practice, data is frequently interpreted and an-
alyzed not only by individuals but by teams of individuals 
working in concert to make decisions. Imagine a team of 
geologists looking at test results to plan an upcoming expe-
dition, a group of city planners examining census data and its 
influence on future development, or a team of businessmen 
looking at current data and forecasts of their industry sec-
tor. While many researchers have explored the information 
analysis process (e. g. [3, 9, 16]), little has emerged on the na-
ture of this process in a collaborative context [10, 12]. How 
a single doctor would analyze biomedical visualizations, for 
example, might differ from how a team of doctors might ana-
lyze the same data. If teams make use of visual information 
to solve problems differently than individuals, we need to 
understand what these differences are so we can redesign in-
fovis tools to support their activity. To address this problem, 
we designed an exploratory study to understand the flow and
# Para 43 6
Permission to make digital or hard copies of all or part of this work for 
personal or classroom use is granted without fee provided that copies are 
not made or distributed for profit or commercial advantage and that copies 
bear this notice and the full citation on the first page. To copy otherwise, 
or republish, to post on servers or to redistribute to lists, requires prior spe-
cific permission and/or a fee.
# Para 49 1
CHI 2008, April 5–10, 2008, Florence, Italy.
# Para 50 1
Copyright 2008 ACM 978-1-60558-011-1/08/04... $5.00.
# Para 51 11
nature of this collaborative process and its relation to indi-
vidual analysis practices. To derive practical guidelines for 
information visualization tool design, we focused on analyz-
ing how participants engage with the workspace and their 
collaborators. Teams in our study were given paper-based 
visualizations to solve tasks, allowing us to view their pro-
cess independently of the confounds of a specific infovis sys-
tem. The analytic framework that we have derived from our 
observations allows us to deconstruct and understand this vi-
sual information analysis process for the purpose of design, 
heuristic evaluation, and analysis of infovis tools.
# Para 62 7
Our work makes three primary contributions: we present an 
exploratory study to examine the information analysis pro-
cess for individuals and small groups in the context of visual 
data; second, we present an analytic framework that allows 
researchers to understand this analysis process in other con-
texts, and finally, we provide three concrete design implica-
tions for digital infovis tools derived from our findings.
# Para 69 1
BACKGROUND AND RELATED WORK
# Para 70 1
Collaborative Information Visualization Tools
# Para 71 18
Most collaborative information visualization systems have 
been developed for distributed data analysis: Many Eyes 
[21] and Swivel (http://www.swivel.com/) are two systems 
that are targeted at an internet-scale audience and both sup-
port asynchronous distributed collaborative sharing and ex-
ploration of data by letting users upload data, create visual-
izations, and comment on available visualizations. The Co- 
Motion environment has been used for information analysis 
and decision-support applications using shared views of the 
data on which all users can interact synchronously from re-
mote desktops [11]. A collaborative tree comparison system 
and a set of design guidelines for co-located data analysis 
has been presented in [8]. In relation to this work, our focus 
is to gain an understanding of the processes of co-located col-
laboration around information visualizations using a single 
shared workspace. This work particularly relates to previ-
ous studies that have also resulted in information processing 
frameworks as outlined in the next sections.
# Para 89 1
Collaborative Visual Information Processing
# Para 90 4
Both Park et al.’s study of pairs using distributed CAVE en-
vironments [12], and Mark et al.’s study of pairs sharing an 
infovis software tool that had been designed for single per-
son use [10], resulted in similar but not identical information
# Para 94 1
1217
# Para 95 1
CHI 2008 Proceedings · Visualization to Support Information Work	April 5-10, 2008 · Florence, Italy
# Para 96 6
processing frameworks. These two studies are most related, 
but our results differ in that by studying non-digital infor-
mation processing, our framework does not reflect the pro-
cessing constraints built into existing software. A detailed 
comparison of these frameworks with ours is included in the 
discussion section.
# Para 102 30
Several researchers have modeled an individual user’s in-
volvement in visual information processing as an iterative 
sequence of components; however, each model is unique in 
terms of its focus, and how it abstracts the process. One 
perspective has been concerned specifically with the design 
of digital information visualization tools, focusing on how 
a person manipulates view and visualization transformation 
parameters, e. g., [5, 9]. Jankun-Kelly et al. [9] propose a 
model of visual exploration for analyzing one person’s inter-
action with a digital visualization system. A core proposition 
of this work is that a fundamental operation in the visual 
exploration process is the manipulation of visualization pa-
rameters. This model is effective in capturing the temporal 
aspects of visual parameter manipulation; however, it does 
not capture the higher-level semantics of a person’s interac-
tion (i. e., why was a parameter changed?). Chi and Riedl 
[5] address this aspect, basing their semantic operator frame-
work on a person’s intention of action (i. e., view filtering vs. 
value filtering), classifying and organizing operators in the 
analysis process. At the other end of the spectrum, Amar 
and Stasko [1] name higher-level analytic activities that a 
person using a visualization system would typically perform, 
such as complex decision-making, learning a domain, iden-
tifying the nature of trends, and predicting the future. Shnei-
derman [15] outlines a two-step process (“overview then de-
tail”), that addresses a task-centric perspective on the analy-
sis process. He suggests seven different operations that in-
formation visualization tools should support to facilitate the 
problem solving process: overview, zoom, filter, details-on-
demand, relate, history, and extract.
# Para 132 12
A model by Russell et al. [13], derived from studying col-
laborative information consolidation activities, describes a 
“Learning Loop Complex,” a cyclic process of searching for 
representations and encoding information. Indirectly, these 
observations have led to Card et al.’s sense making cycle 
[3] (extended in [20]). A number of research directions in 
other domains have asked questions about how collabora-
tors share and coordinate their efforts to work together (see 
[4]). While these models relate to our research question, 
most have a stronger cognitive focus. We will later revisit 
the sense-making cycle by Card et al. [3] as it shares some 
processes defined in our framework.
# Para 144 10
Instead of focusing on either task driven or meta-cognitive 
processes, we are interested in the general processes that oc-
cur during collaborative information analysis (independent 
of the confines of a computer-based infovis tool), as well as 
the interactions with visualizations and those between team 
members. We are interested in general processes that form 
the basis of collaborative information visualization as the 
low-level mechanics of interacting with an infovis tool are 
probably not indicative of how teams would solve a visual 
information problem.
# Para 154 1
Choosing a Methodology
# Para 155 10
When developing software tools to augment work practices, 
at least three fundamentally different approaches exist. One 
is to study possible improvements for support of the process 
through studying the current software support or tools in use. 
Another is to hypothesize about improvements to existing 
tools, to develop a promising tool and study it in compar-
ison to the existing tools. A third is to work towards an 
improved understanding of the process in order to develop 
a better match between the natural human process and its 
software support.
# Para 165 37
Our approach falls into the third class. It begins with the 
premise that through observations of people’s interactions 
with physical artefacts, we can develop a richer understand-
ing of basic work processes that can be used to inform in-
terface design. Other researchers (e. g. [14, 19]) have taken 
this approach, studying how groups accomplish tasks in non- 
digital contexts in order to understand what activities digital 
tools should support. The reasoning behind this choice is 
that people’s physical interactions with these familiar arte-
facts and tools would closely reflect how they understand 
and think about the problem at hand. For instance, Tang’s 
study of group design activities around shared tabletop work-
spaces [ 19] revealed the importance of gestures and the work-
space itself in mediating and coordinating collaborative work. 
Similarly, Scott et al. [14] studied traditional tabletop game- 
play and collaborative design, focusing on the use of table-
top space and the sharing of items on the table. While these 
authors studied traditional physical contexts, ultimately their 
goal was to understand how to design digital tabletop tools. 
Both studies contributed to a better understanding of collab-
orative work practices involving tables in general. The ap-
proach taken in these two studies works well when address-
ing a design area where the critical issues are poorly under-
stood. For instance, we are uncertain how groups will work 
together with information visualizations if given the ability 
to do so freely (e. g. prior efforts involved systems where in-
dividuals could not work in parallel [12, 10]). Furthermore, 
we do not know how teams will share and make use of inter-
mediate results, or indeed whether they will even share and 
work together from the same views or artefacts of the data. 
Our work builds on prior efforts in developing frameworks 
to understand the visual information analysis process, and 
the work of researchers attempting to understand collabora-
tive behaviour. The study we describe here takes a first step 
toward building our understanding of collaborative visual in-
formation analysis. We can then leverage this understanding 
to build infovis tools that support collaboration.
# Para 202 4
A STUDY OF THE INFORMATION ANALYSIS PROCESS 
We conducted an exploratory study to understand the visual 
analysis process. The study focused on examining individu-
als and small groups in this process.
# Para 206 1
Participants
# Para 207 4
We recruited 24 paid participants from the university popula-
tion, 14 female, 10 male. The mean age of the participants 
was 26 years. We had 4 groups each of singles, pairs, and 
triples. With one exception, all pairs and triples were known
# Para 211 1
1218
# Para 212 1
CHI 2008 Proceedings · Visualization to Support Information Work	April 5-10, 2008 · Florence, Italy
# Para 213 1
Scenario	Task	Type
# Para 214 1
1) Give a short description of the participants’ characteristics.
# Para 215 1
2) Who should each breakfast option be advertised to?
# Para 216 1
3) Do more females prefer oatmeal than active people prefer cereal.
# Para 217 2
4) Do more inactive people prefer oatmeal than people over 60? Do you think there might be a relationship 
between lifestyle and age in terms of preference for oatmeal?
# Para 219 2
C 
(Cereal)
# Para 221 4
open 
open 
focused 
focused
# Para 225 1
1) Find pairs of behaviours that have similar ratings in at least three different situations.
# Para 226 1
2) Choose three situations and describe behaviours most appropriate for that situation.
# Para 227 1
3) Find two situations that have at least five behaviours with similar ratings.
# Para 228 1
4) Is it more appropriate to argue or belch in a park?
# Para 229 1
5) Where was it most appropriate to laugh.
# Para 230 1
6) What behaviour in which situation was most appropriate and which was most inappropriate.
# Para 231 2
B 
(Behaviour)
# Para 233 6
open 
open 
open 
focused 
focused 
focused
# Para 239 1
Table 1. Study questions and type per scenario.
# Para 240 4
to each other beforehand. For group details refer to Figure 1. 
Our sample size was informed by emerging results. After 
four pilot studies and 12 groups we were confident that fur-
ther observations would result in redundant data.
# Para 244 1
Singles	Pairs	Triples
# Para 245 2
Figure 1. Participants’ gender, chart familiarity, and data
analysis frequency.
# Para 247 1
Apparatus
# Para 248 11
Participants worked on a large table (90 × 150 cm) and were 
given 15 × 10 cm cards, each showing one data chart. The 
table was covered with a large paper sheet, and several pens, 
pencils, rulers, erasers, scissors, and sticky notes were pro-
vided. Six different types of charts were used. These charts 
showed different subsets of the data and each data subset 
was shown in at least two different representations (e. g., line 
chart and bar chart). Figure 2 gives an overview of the charts 
used and shows how many participants reported themselves 
to be unfamiliar with a given chart; however, data was al-
ways redundantly encoded in familiar charts.
# Para 259 1
Figure 2. Unfamiliarity of participants with study charts.
# Para 260 1
Tasks
# Para 261 2
Participants worked on two task scenarios, each composed 
of a different data set with its own representations. The data
# Para 263 18
sets used in the study are part of the sample files provided 
with the analysis software SPSS 14.0. The behaviour data 
set (Scenario B, behavior.sav in SPSS) included 32 charts (1 
stacked area, 1 line, 15 scatter plots, 15 bar charts). The data 
shown in these charts was about ratings for the appropriate-
ness of 15 behaviours in 15 different situations (e. g., running 
in church). The cereal data set (Scenario C, cereal.sav in 
SPSS) which included 30 charts (3 pie, 9 bar, 9 stacked bar, 
9 line charts) was about an imagined study of preferences for 
certain breakfast options. No specialized knowledge about 
the data was required to solve the tasks and high task en-
gagement was evident throughout the observations. The pre-
sentation order of these scenarios was counter-balanced be-
tween groups. Similar to the design used in [10], our sce-
narios each contained an equal number of open discovery 
tasks, where tasks could have several possible solutions, and 
focused question tasks which had only one correct answer. 
An overview of all tasks can be found in Table 1.
# Para 281 1
Procedure
# Para 282 16
Participants were greeted and then seated themselves around 
the table. Next, a short tutorial was provided on the types 
of charts, tasks, and scenarios used in the study. Partici-
pants were told that they could use any of the tools (pens, 
rulers, etc.) to work with the charts, and that they could 
write on anything as they saw fit (e. g., cards, scrap paper, 
table, etc.). Participants were then given an example task 
scenario to clarify the process. Once it was clear how to 
proceed, each task scenario was given in turn, and the partic-
ipants were instructed to work on the tasks in any way they 
felt comfortable. Upon completing both task scenarios, par-
ticipants filled out a questionnaire asking them about their 
experiences during the study and to collect demographic in-
formation. The groups of two and three participants natu-
rally discussed their tasks and progress and single partici-
pants were asked to use a “talk aloud” protocol.
# Para 298 1
Data Collection and Analysis
# Para 299 2
During each session two observers were always present. Both 
observers collected notes, and each session was video or au-
# Para 301 7
dio taped. 610 minutes of video data was collected (,: 50
minutes for each session). Our multi-pass open coding anal-
ysis was based on both the collected notes and the video data.
Both observers used notes and video samples to form initial
coding categories. These were used by one observer for the
first video coding pass and were refined through subsequent
study of the videos and the second coding pass.
# Para 308 1
B
# Para 309 1
S
# Para 310 1
O
# Para 311 1
S
# Para 312 1
SS
# Para 313 1
S
# Para 314 1
SC
# Para 315 1
S
# Para 316 1
AA
# Para 317 1
A
# Para 318 1
OO
# Para 319 1
x
# Para 320 1
O
# Para 321 1
S
# Para 322 1
S
# Para 323 1
S
# Para 324 1
MM
# Para 325 1
SS
# Para 326 1
S
# Para 327 2
Pie 
Chart
# Para 329 1
0 0
# Para 330 1
Unfamiliarity w/ Chart
# Para 331 2
Bar 
Chart
# Para 333 2
Scatter
Plot
# Para 335 1
1
# Para 336 2
Line 
Chart
# Para 338 1
2
# Para 339 2
Stacked
Bar
# Para 341 1
3
# Para 342 2
Stacked
Area
# Para 344 1
7
# Para 345 1
Sample Charts
# Para 346 1
100 100.00 00
# Para 347 1
80.00 80 00
# Para 348 1
60.00 60 00
# Para 349 1
40.00 40 00
# Para 350 1
20.00 20 00
# Para 351 1
0 000.00
# Para 352 1
0
# Para 353 1
C ass
# Para 354 1
Date
# Para 355 5
400 
300 
200 
100 
0
# Para 360 1
Bus
# Para 361 1
D nner
# Para 362 1
Park
# Para 363 1
nact ve
# Para 364 1
Lifestyle
# Para 365 2
nterv ew 
Church
# Para 367 1
Mov es
# Para 368 1
S dewa k	Bar
# Para 369 1
Act ve
# Para 370 1
E evator
# Para 371 2
Room 
Restroom
# Para 373 1
Game
# Para 374 1
Lounge
# Para 375 1
Gender
# Para 376 1
Ma e
# Para 377 2
Shout 
Laugh
# Para 379 1
	analysis frequency	(daily, weekly, monthly, yearly, never
# Para 380 1
gender (female, male
# Para 381 2
background (science, stats, business, social sci., communication, a 
familiar with all graph (yes, no)
# Para 383 1
SMBOCA
# Para 384 1
1219
# Para 385 1
CHI 2008 Proceedings · Visualization to Support Information Work	April 5-10, 2008 · Florence, Italy
# Para 386 1
FINDINGS
# Para 387 7
In this section, we outline our understanding of the collabora-
tive and individual visual analysis process we uncovered dur-
ing our analysis. We follow this by illustrating how the pro-
cesses themselves were not temporally organized in a consis-
tent way across groups. In the next section, we relate these 
findings to prior work, and discuss how they can inform the 
design of information visualization tools.
# Para 394 1
Processes in Visual Information Analysis
# Para 395 8
Our analysis revealed eight processes common to how par-
ticipants completed the tasks in our study (summarized in 
Table 2). We describe each process using real examples 
drawn from our study, discussing participants’ interactions 
with one another and the workspace, and elaborate on how 
the processes differed between group types. Where average 
process times are reported these are an aggregation of sev-
eral instances of particular processes during both scenarios.
# Para 403 1
Browse:
# Para 404 17
The browsing process comprises activities involving scan-
ning through data to get a feel for the available informa-
tion. Browsing activities do not involve a specific search 
related to a task; instead, the main goal is to gain some un-
derstanding of the data set. For example, we observed par-
ticipants quickly glancing through or scanning the informa-
tion artefacts—likely to see what types of charts were avail-
able and the variables in the charts. Five participants took 
the complete pile of charts and flipped through them in their 
hands, while 11 others created an elaborate layout of cards 
on the table. Figure 3 shows an example in which two par-
ticipants use two very different browsing strategies. One par-
ticipant (bottom of image) lays the two overview charts out 
in front of him, flipping through the remaining cards in his 
hand, while the other participant creates a small-multiples 
overview of the cards on the table as he browses through 
them one at a time. Groups were slightly more efficient than
# Para 421 1
individuals (average browsing times were ,: 30s for groups,
# Para 422 6
and ;::Li 60s for individuals), perhaps indicating that, for indi-
viduals, having a completely clear sense of the data is more 
important, whereas groups can rely on others. In one case, 
we observed one participant in a group of three who did not 
browse through the data himself; instead, he watched as his 
partners laid their cards out on the table.
# Para 428 1
(a) Start of a browsing session. (b) End of a browsing session.
# Para 429 4
Figure 3. Different browsing strategies: the participant on the
right creates an overview layout; the participant on the bottom
laid out the overview charts and is flipping through the
remaining data charts in his hands.
# Para 433 1
Parse:
# Para 434 18
The parsing process captures the reading or re-reading of the 
task description in an attempt to understand how to solve the 
problem. Participants read the task description both quietly 
or aloud, and in teams, this choice reflected the collabora-
tion style that teams adopted. For instance, teams working 
closely together would read task descriptions aloud, facilitat-
ing joint awareness of the state of the activity, and discus-
sion of how to interpret the question. On average, pairs and 
triples spent 2.5 min reading and re-reading the task descrip-
tion; however, individuals referred to the task sheet more fre-
quently (10 times vs. 9 times in pairs and 7 times for triples 
in total). While many real-world information analysis sce-
narios may not have a concrete problem description sheet, 
an assessment of the given problem(s) and the required vari-
ables can certainly still occur and would be considered part 
of this process. The problem sheet can be seen as external 
textual information that is not part of the current dataset but 
provides meta information on the problem, tasks, or data.
# Para 452 1
Discuss Collaboration Style:
# Para 453 2
Five teams explicitly discussed their overall task division 
strategy. We observed three main collaboration strategies:
# Para 455 5
•	Complete task division. Participants divided tasks between 
themselves to avoid duplicating work. Each participant 
worked alone with his or her information artefacts on a sep-
arate subset of the problems. Results would be combined 
at the end without much further group validation.
# Para 460 7
•	Independent, parallel work. Participants worked concur-
rently on the same tasks but independently of each other. 
When one participant had found an answer, solution and 
approach were compared and discussed. Other participants 
might then validate the solution by retracing the approach 
with their own artefacts, or by carefully examining a part-
ner’s information artefacts.
# Para 467 6
•	Joint work. Participants talked early about strategies on 
how to solve the task, and then participants went on to 
work closely together (in terms of conversation and provid-
ing assistance) using primarily their own information arte-
facts. When one person found a solution, information arte-
facts were shared and solutions were validated together.
# Para 473 17
Interestingly, while teams might explicitly discuss a collabo-
ration style, all 8 teams changed their collaboration strategy 
midway through a task scenario or between scenarios. A 
combination of parallel and joint work strategies was used 
by six teams and two others used a combination of task di-
vision/parallel and task division/joint work. Six of the eight 
teams started with a loose definition of doing the tasks “to-
gether.” Strategy discussions were brief: &lt; 1 min on average 
per scenario. Most of the changes in task strategy were quite 
seamless, and did not require any formal re-negotiation. This 
is echoed in the post-session questionnaire in which two par-
ticipants reported to have chosen their strategy “intuitively” 
and “by chance.” In general, teams showed a strong ten-
dency for parallel work: all eight groups solved at least parts 
of one scenario in parallel. 14 of 15 participants reported 
that the main reason they divided tasks this way was for per-
ceived efficiency.
# Para 490 1
1220
# Para 491 1
CHI 2008 Proceedings · Visualization to Support Information Work	April 5-10, 2008 · Florence, Italy
# Para 492 1
Process	Description	Goal
# Para 493 1
Browse
# Para 494 1
Parse
# Para 495 3
Discuss Collaboration Style 
Establish Task Strategy 
Clarify
# Para 498 1
Select
# Para 499 1
Operate
# Para 500 1
Validate
# Para 501 1
scan through the data
# Para 502 2
reading and interpretation of the task description 
discuss task division strategy
# Para 504 2
establish how to solve a task with given data &amp; tools 
understand a visualization
# Para 506 3
pick out visualizations relevant to a particular task 
higher-level cognitive work on specific data view 
confirm a partial or complete solution to a task
# Para 509 5
get a feel for the available information 
determine required variables for the task 
determine how to solve the tasks as a team 
find an efficient way to solve the problem 
avoid mis-interpretation of the data
# Para 514 2
minimize the number of visualizations to read 
solve task or sub-task
# Para 516 1
avoid errors in completing the task
# Para 517 1
Table 2. The eight processes in information analysis. “Discuss Collaboration Style” only applies to collaborative analysis scenarios.
# Para 518 1
Establish Task Strategy:
# Para 519 29
In this process, participants searched for the best way to 
solve a specific task using the given data and tools. The 
goal of establishing such a strategy was to determine the 
next views or interactions required to extract variables or 
patterns from the data to solve the problem efficiently. As 
a team activity, this discussion occurred 22 times with the 
help of individual information artefacts for all groups and 
tasks; one participant would present a possible approach to 
the other participant(s) using examples. For example, Fig-
ure 4 illustrates an instance where two participants are dis-
cussing how to solve a particular task using a specific chart 
they had chosen. The team frequently flipped between look-
ing at a shared chart and the chart in their own hand. This 
explicit strategy discussion was more common when teams 
worked in a joint work collaboration style. When partici-
pants worked independently or in parallel, the determination 
of strategy seemed to occur silently (perhaps in parallel to 
the parsing process). For instance, participants might articu-
late their strategies without discussing the explicit reasoning 
for it: “I am now going to look for the highest peak.” During 
the video analysis, we only observed on average 1–2 minutes 
per scenario in which teams specifically discussed their strat-
egy to solve a task. At the end of this process—depending 
on the chosen strategy—participants often reorganized their 
information artefacts in the space to create an adequate start-
ing position for solving the task. For example, if the strategy 
was to find two data charts, then the workspace might be or-
ganized to facilitate the finding of these two data charts (as 
in Figure 3).
# Para 548 2
Figure 4. Discussing a strategy on how to solve a task using the
chosen chart. Information artefacts are used as aids.
# Para 550 1
Clarify:
# Para 551 5
Clarification activities involve efforts to understand an in-
formation artefact. While we provided users common bar, 
pie, and line charts, we also provided less commonly used 
stacked bar charts and an area chart. The unfamiliar charts re-
quired more careful scrutiny by participants. For individual
# Para 556 13
participants, ambiguities in the data display were resolved 
twice using other charts as aids. Others did not attempt a 
clarification but chose alternative representations leaving out 
the one that was unclear. In teams, the need for clarification 
involved discussion with other participants to decipher and 
understand the charts and sharing of information artefacts. 
Overall clarification required less than 1 min for Scenario B 
and no clarification was required for Scenario C. The clar-
ification times for Scenario B were higher for each group 
as this scenario contained the most unfamiliar stacked area 
chart. Only those triples that included participants which 
were unfamiliar with certain charts required longer than av-
erage (1 min, 2 min) for clarification in Scenario B.
# Para 569 1
Select:
# Para 570 6
Selection activities involved finding and picking out infor-
mation artefacts relevant to a particular task. We observed 
several different forms of selection, often dependent on the 
organization of data that was established during browsing. 
We characterized these styles of selection by how artefacts 
were spatially separated from one another:
# Para 576 7
•	Selection from an overview layout. Beginning with an 
overview layout (e. g., small-multiples overview from Fig-
ure 3), relevant cards are picked out. Selection of cards 
from this layout involved either a re-arrangement of the 
organization scheme so that relevant cards were placed 
within close proximity or marking by either placing hands 
or fingers on the cards, or using pens.
# Para 583 6
•	Selection from a categorization layout. Starting from a 
pile-based categorization of information artefacts, piles are 
scanned and relevant cards picked out. These cards are 
then placed in new piles that carry semantic meaning (e. g., 
relevant, irrelevant). Previously existing piles might change 
their meaning, location, and structure in the process.
# Para 589 14
How users organized these selected data cards was depen-
dent on how they intended to operate on (or use) them. The 
left of Figure 5 illustrates an instance where two cards were 
relocated and placed side-by-side for comparison. Figure 5 
shows an example on the right where a variable was to be 
measured, so the card was relocated closer in the individ-
ual person’s workspace. The spatial organization of cards 
relative to piles of data could carry semantic meaning. For 
example, when an operation on a data card was to be brief, 
a single card was drawn out, operated upon, and then re-
placed. Similarly, the organization scheme might reflect the 
perceived importance of a set of cards: we observed piles of 
information artefacts that were clearly discarded (Figure 6). 
Temporally, we also observed different selection strategies,
# Para 603 1
1221
# Para 604 1
CHI 2008 Proceedings · Visualization to Support Information Work	April 5-10, 2008 · Florence, Italy
# Para 605 6
which could be loosely classified as “depth-first” or “breadth- 
first.” A “depth-first” approach involved selecting a single 
card, operating on it for a period of time, and then selecting 
the next card (e. g., Figure 6, left). “Breadth-first” strategies 
selected all cards deemed relevant in a single pass and then 
operated on them afterwards (see Figure 6, right). On av-
# Para 611 1
erage, participants spent ,: 4min selecting data, the second
# Para 612 1
most common process in our study.
# Para 613 12
of tools to aid comparison: marking individual values, bend-
ing or cutting individual charts (to facilitate placing values 
physically side-by-side), or on 7 occasions we noted overlay-
ing of charts atop one another in an attempt to see through 
the top chart. The operation process typically generated a 
set of results which were synthesized with previous results 
and/or written down. During team activity, results were re-
ported to the team if other tasks depended on these results 
(e. g., during joint activity). Operation was the most time- 
consuming activity in our study. On average participants 
spent almost half of their time (11 min) on operations per 
scenario. 64% of operations followed a selection process.
# Para 625 5
Figure 5. Chart organization during selection depending on 
their intended usage. Left: a participant selected four cards 
for comparison placing them side by side in her hand. Right: 
three participants selected individual charts and placed them 
in the center of their workspace to measure a specific value.
# Para 630 5
Figure 6. Changing categorization during selection. Left: a
participant placed irrelevant cards to her left and picks single
cards to operate on from the working set. Right: a participant
picked out relevant cards, placed them close to himself, and
put irrelevant cards in a pile further away.
# Para 635 1
Operate:
# Para 636 21
Operation activities involved higher-level cognitive work on 
a specific view of the data with the goal of extracting infor-
mation from the view to solve the task. Figure 7 illustrates 
the two most common types of operation activities: extract-
ing a data value, and comparing data values. To extract a 
data value from a card, participants often used rulers or some 
other form of measuring tool (e. g., edge of a piece of pa-
per). To aid recall of these values, participants made annota-
tions: sometimes on the charts themselves, and other times 
on spare pieces of papers. During the course of both scenar-
ios each participant on average annotated at least three infor-
mation artefacts (2 during Scenario B, 1 during Scenario C). 
Comparing values on a specific chart or values across charts 
was also extremely frequent. Every participant in our study 
compared charts on at least one occasion. The most frequent 
comparison involved just two charts but we also noted 15 oc-
casions of participants comparing three or more charts. In 
our study, participants arranged the charts for a comparison 
during selection: cards would be placed in close proximity 
to facilitate easier reading of either individual values or pat-
terns (Figure 6). Participants were quite creative in their use
# Para 657 4
Figure 7. Two participants showing two different types of
operations on the information. The participant on the right is
comparing two cards using a ruler while the participant on the
top is measuring a particular value.
# Para 661 1
Validate:
# Para 662 22
Validation activities involved confirming a partial or com-
plete solution to a task. Beyond confirming the correctness 
of a solution, teams also ensured the correctness of the pro-
cess or approach that was taken. In teams, the validation 
process often included discussion coupled with sharing of 
information artefacts: on 47 occasions participants validated 
others’ solutions by looking carefully at the solution using 
shared representations, while other times they searched for 
the solution by using their own information artefacts (i. e., 
the process or approach was shared instead of the artefacts 
themselves). When working more independently, the vali-
dation process only involved the presentation of a solution 
by the group member who had it. In groups where collab-
orators worked more closely, the collaborators would often 
ensure that the other participants had understood the process 
with which a solution was found. For individual participants, 
the validation process involved looking at other data cards 
(i. e., different representations) for the same answer. Of in-
terest is that individuals appear to be concerned about the 
“correctness” of their solution/approach based on other infor-
mation artefacts, while teams also rely on a collective valida-
tion from the social group. On average groups of three spent
# Para 684 2
the longest time validating their answers (,: 3 min), pairs 
spent ,: 2 min validating, and individuals spent less than one
# Para 686 1
minute validating their answers.
# Para 687 1
Temporal “Sequence” of Processes
# Para 688 5
To understand how the processes related to one another in 
terms of a temporal relationship, we analyzed the video data 
from our study, coding each individual’s activities using these 
process labels. This analysis revealed three aspects of partic-
ipants’ activity: first, while certain processes frequently oc-
# Para 693 1
1222
# Para 694 1
CHI 2008 Proceedings · Visualization to Support Information Work	April 5-10, 2008 · Florence, Italy
# Para 695 7
curred before others (e. g., select most frequently appeared 
before operate), no common overall pattern appeared; sec-
ond, individuals varied in how they approached each task, 
and finally, teams also varied drastically in how they spent 
their time. For brevity, we present a few example charts. All 
charts for singles, pairs, and triples exhibit this same extreme 
variability of approach.
# Para 702 7
Figure 8 shows the coded temporal sequence of analytic pro-
cesses during Scenario B for three pairs. Notice how the 
sequence of processes was quite different for each pair, even 
though participants worked on the same tasks using the same 
tools, representations, and views of the data. Even within 
teams participants did not show the same temporal occur-
rences of processes. On average, participants in pairs were
# Para 709 1
concurrently working in the same process for ,: 70% of the
# Para 710 18
time. For Scenario B (Figure 8), P2 has a 65% co-occurrence 
of the same processes, P3 80%, and P4 69%. This reflects 
the collaboration strategies participants had chosen. P3 had 
switched from a complete task division to joint work in this 
scenario while P2 and P4 were working mostly in parallel. 
Participants in groups of three only showed a 40% co-occur-
rence of processes on average. In both charts in Figure 8, 
Tasks 1–3 were open discovery tasks and Tasks 4–6 were 
focused question tasks. We noticed that both individuals 
and teams solved focused question problems quicker than 
open discovery tasks. Teams had a better understanding of 
the tasks (established during the task strategy process) and 
solved them (both focused and open discovery tasks) more 
correctly. This result echoes findings in [10] that suggest that 
groups perform more accurately, albeit slower. Of course, 
teams also exhibit establishing a task strategy more so than 
individuals, again in order to establish common ground [6], 
or to ensure a correct or agreed-upon approach.
# Para 728 5
Figure 9 shows a detail view of a specific task, charting in-
dividual participants and three of the participant pairs. No-
tice that even for a single task occurring over a roughly five 
minute sequence, how the participants engaged in the task, 
and the temporal distribution of process time varied.
# Para 733 4
Figure 9. Temporal sequence of processes for one open
discovery task. The top row shows timelines for individual
participants (S1–S4). The bottom row holds timelines for
participants in groups of two (P2–P4).
# Para 737 1
DISCUSSION
# Para 738 15
To this point, we have introduced a set of processes that oc-
cur within the context of collaborative and individual visual 
information analysis. These processes apparent from our 
study form an eight-process framework. The framework is 
unique from prior work in that it provides an understanding 
of how teams and individuals use information artefacts in the 
workspace to solve visual information analysis tasks and of 
how team members engage with each other during this pro-
cess. In this section, we discuss how our framework relates 
to other information analysis/information visualization mod-
els. This discussion reveals that while individual processes 
relate closely to existing models, our temporal analysis sug-
gests that with appropriate tools, both the collaborative and 
individual information analysis processes may naturally be 
more fluid and benefit from temporal flexibility.
# Para 753 1
Comparing Frameworks
# Para 754 1
Comparison with the Sense-Making Cycle
# Para 755 6
Card et al. [3, pp. 10] provide a high-level model of human 
activity called the “Knowledge Crystallization” or “Sense- 
Making Cycle” where the goal is to gain insights from data 
relative to some task. This model includes five main compo-
nents: foraging for data, searching for a schema (or repre-
sentational framework), instantiating a schema, problem
# Para 761 1
solving, and authoring, deciding or acting. It builds on
# Para 762 2
work by Russell et al. [13] which involved observations of 
collaborative work, and an extension can be found in [20].
# Para 764 1
The Sense-Making Cycle has several components related to QS C b	dl
# Para 765 9
our model. It outlines a process called “foraging for data” 
that includes our browse process. Spence [16] specifically 
explores the “foraging for data” component in terms of vi-
sual navigation. In particular, he relates visual navigation to 
cognitive activities (such as internal model formation and in-
formation interpretation), thereby arguing that how users can 
navigate, explore, and visualize a data space will shape how 
users think about the data. Spence distinguishes three dif-
ferent browsing activities [17]: exploratory browsing where
# Para 774 1
Task:
# Para 775 1
0:0(time)
# Para 776 1
55 4	3 6 3 6
# Para 777 1
0:5
# Para 778 1
3
# Para 779 1
0:10
# Para 780 1
2
# Para 781 1
0:15
# Para 782 1
0:0(time)
# Para 783 1
0:5
# Para 784 1
0:10
# Para 785 1
0:15
# Para 786 1
5
# Para 787 1
4	3 6 36
# Para 788 1
Task:
# Para 789 1
0:0(time)
# Para 790 1
Task:
# Para 791 1
0:0(time)
# Para 792 1
0:5
# Para 793 1
0:5
# Para 794 1
2
# Para 795 1
2
# Para 796 1
0:10
# Para 797 1
0:10
# Para 798 1
4	6
# Para 799 1
4
# Para 800 1
0:15
# Para 801 1
0:15
# Para 802 1
6
# Para 803 1
Task:
# Para 804 1
0:0(time)
# Para 805 1
Task:
# Para 806 1
0:0(time)
# Para 807 1
0:5
# Para 808 1
0:5
# Para 809 1
2
# Para 810 1
0:10
# Para 811 1
0:10
# Para 812 1
0:15
# Para 813 1
4	5 6
# Para 814 1
0:15
# Para 815 1
4
# Para 816 1
5 6
# Para 817 2
Task 5 
left out
# Para 819 1
P2:
# Para 820 1
Task:
# Para 821 1
5 min
# Para 822 1
5 min
# Para 823 1
5 min
# Para 824 1
P3
# Para 825 1
P2
# Para 826 1
Individuals:
# Para 827 1
S3
# Para 828 1
Groups of Two:
# Para 829 1
P4
# Para 830 1
S4
# Para 831 1
5 min	5 min
# Para 832 7
Legend: 
Select 
Parse 
Clarify 
Operate 
Idle 
Validate
# Para 839 1
S1
# Para 840 1
S2
# Para 841 1
5 min
# Para 842 1
5 min
# Para 843 1
Legend:
# Para 844 1
Browse	Select	Operate Parse	Clarify	Strategy	Collab Validate Idle
# Para 845 2
Figure 8. Temporal sequence of processes for three pairs
during one complete scenario.
# Para 847 1
1223
# Para 848 1
CHI 2008 Proceedings · Visualization to Support Information Work	April 5-10, 2008 · Florence, Italy
# Para 849 14
the goal is to accumulate an internal model of part of the 
viewable scene; opportunistic browsing to see what is there 
rather than to model what is seen; and involuntary browsing 
which is undirected or unconscious. We primarily observed 
exploratory browsing, and saw that, as part of this process, 
participants established a layout of cards, or put cards in ob-
servable categories (e. g., by variables or graph types). It 
seemed that those participants who created a specific lay-
out of cards in their work area created a type of overview 
by imposing an organization (even if a loose one) on the in-
formation artefacts. Thus, we saw a physical manifestation 
of the creation of an “internal model of the data.” Further-
more, these physical layouts (a consequence of the browsing 
phase) clearly relate to Shneiderman’s “overview” task [15].
# Para 863 25
“Search for schema” seems to involve activities that we char-
acterize as being a part of parsing, specifically the identifica-
tion of attributes on which to operate later. The activity of 
identifying attributes to look for in the data described in this 
model is augmented in our parse component by additional ac-
tivities of discussion, and note taking. “Search for a schema” 
and “instantiate schema” involve activities that help in the 
search for the best way to solve the given problem with the 
provided visualization tool and therefore relate to our task 
strategy process, albeit being more tool-centered than our 
definition. Clarification is not an explicit component in this 
model but the need for clarification would typically arise dur-
ing the searching for and instantiating a schema components. 
Our selection process is most closely related to the “foraging 
for data” component but can extend into the “searching for 
and instantiating a schema” components when participants 
have ended their browsing activities and are ready to select 
specific information important to solving the task. This may 
include activities that we see as part of an operation process: 
problem-solving, including Bertin’s three levels of reading: 
read fact, read compare, read pattern [2]. Validation is not 
directly represented in Card et al.’s model [3]; perhaps, as 
we have also observed, because validation seemed to be of-
ten omitted or quite brief for individual participants and their 
model focuses on a single user.
# Para 888 16
The Sense-Making Cycle is the most highly coupled and in-
teractive of the three models we are comparing to. It makes 
a strong temporal (cyclical) suggestion but does allow for 
loops within this cycle over defined forward and backward 
connections between components. In general, the Sense- 
Making Cycle is not identical to our model but predicts some 
of our findings in terms of temporal flexibility and shares 
some components with our model. An adaptation of the 
Sense-Making Cycle by Pirolli and Card is presented in [20] 
for some type of analysis work. This extension includes two 
main components: A Sense-Making Loop in which a mental 
model of the data is iteratively developed and a Data For-
aging Loop in which information is searched, read, filtered, 
and extracted. This model tries to cover most aspects of intel-
ligent analysis work and our processes mostly relate to those 
parts within the Sense-Making Loop as discussed above.
# Para 904 1
Collaborative Analysis Models
# Para 905 2
In studying pairs using distributed CAVE environments, Park 
et al. [12] articulate a five-stage pattern of behaviour: prob-
# Para 907 2
lem interpretation, agreement on vis tool to use, search 
for a trend, discovery reporting, and negotiation of dis-
# Para 909 4
coveries. Mark et al. [10] also provide a five-stage collabora 
tive information visualization model: parse question, map 
1 variable to program, finding correct visualization, val-
idating the visualization, and validation of the entire an-
# Para 913 1
swer. A loop is included for additional variables from stages
# Para 914 10
four back to stage two. The temporal sequence of stages in 
this model was derived from a study of pairs solving both 
free data discovery and focused question tasks in both dis-
tributed and co-located settings. These two models share 
some similarities, but are clearly not identical. A possible 
explanation for the disparity is that Mark et al.’s model [10] 
focuses on a context where the pair negotiates exploration 
through a shared tool (i. e., they could not work in a decou-
pled fashion [18]) whereas Park et al.’s model [12] allows 
for more loosely coupled work.
# Para 924 24
Both models share some similarity in the processes discov-
ered in our study. Our parsing process relates closely to 
Mark et al.’s “parse question” [10] and Park et al.’s “prob-
lem interpretation” [12] stages. We augment these stages 
with activities that might not have been part of the specific 
environment under study in both models: note taking and fre-
quent discussion about how to interpret a certain task. The 
discussion of the collaboration style is not explicitly covered 
in either model. However, similar to Park et al.’s study we 
observed a strong tendency in all group conditions for partic-
ipants to do at least part of the work using their own views 
and information artefacts. Similar differences in work styles 
for spatially fixed information visualization tasks (e. g., maps 
that cover the whole workspace) have been described in [18], 
but they have not been put in a greater context of other pro-
cesses of visual analysis. According to Mark et al.’s model, 
“map 1 variable to program” is closely related to our task 
strategy process in that it would also involve a collaborative 
agreement on the most appropriate visualizations, parame-
ters, or views to solve the problem [10], like Park et al.’s 
“agreement on visualization tools to use” [12]. However, our 
description of this process discusses the activities involved 
in establishing a strategy rather than describing it in the con-
text of a specific tool.
# Para 948 11
In contexts where new visualizations are introduced, or in-
dividuals are brought in without prior training on particu-
lar visualizations, the need for clarification would be com-
mon. Specifically, beyond providing users with aid in de-
veloping an understanding of a particular visualization, we 
would expect individuals to ask for collaborators’ interpreta-
tions of that visualization or interaction technique or to put 
their own views and interpretations up for discussion. Con-
sidering clarification as a process of analysis is important 
for designing and evaluating visualization tools but it is not 
a specific part of the two collaborative analysis models.
# Para 959 6
Our articulation of the selection process is related to parts of 
the activities covered by Mark et al.’s “find correct visualiza-
tion” stage and Park et al.’s “search for trend.” Our descrip-
tion of selection, however, more broadly captures the notion 
of picking out important information beyond operations in a 
specific visualization system.
# Para 965 1
1224
# Para 966 1
CHI 2008 Proceedings · Visualization to Support Information Work	April 5-10, 2008 · Florence, Italy
# Para 967 12
“Independent search for a trend including some adjustments 
to viewing parameters” and “report discovery” include op-
erations as defined in our model. Operation is not an indi-
vidual stage in Mark et al.’s model but is integrated in the 
“find correct visualization” stage [10]. In groups, the vali-
dation stage was much more visible and it is also included 
in these two models as the last stage of information analy-
sis [10, 12]. Mark et al. noticed differences in validation 
between the free discovery and focused question tasks; a re-
sult that was echoed in our study. During more open-ended 
questions, validation was usually longer and involved more 
discussion than for focused tasks.
# Para 979 3
In general, both these models are related to ours in that they 
share some of the processes discovered in our study but are 
quite different in their suggestion of a fixed temporal order.
# Para 982 1
Temporality and Process-Free Tools
# Para 983 17
Many of the existing models suggest a typical temporal order 
of components; however, our analysis of the temporal occur-
rence of the framework processes suggests that this typical 
temporal ordering was not evident. We argue that our find-
ing of a lack of a common temporal ordering reflects the 
design of our study; in particular, the stipulation that partic-
ipants would use a paper-based “information visualization” 
tool along with traditional tools such as pens, paper and 
notepaper. Traditional tools have no specific flow in terms of 
which tools should be used first or for what purpose. Similar 
observations have been made by Heiser et al. [7] in a study of 
non-digital co-located and remote sketching activities. The 
flexibility afforded by traditional tools allowed individuals 
to approach tasks differently. As a consequence, they also 
allowed groups to transition between multiple stages of inde-
pendent and closely coupled work rather than regimenting 
particular work process.
# Para 1000 11
In summary then, the processes in our analytic framework 
map to related models, yet our analysis suggests that the tem-
poral ordering of these components is by no means universal. 
In many digital information visualization systems, the flow 
of interaction is regimented by structure; in contrast, the use 
of traditional tools in our study allowed participants to freely 
choose how to approach and solve problems. On this basis, 
we believe this analytic framework can be used as a means to 
understand information visualization tools: for example, to 
asses temporal or procedural work processes that a particular 
system might impose.
# Para 1011 1
IMPLICATIONS FOR DESIGN
# Para 1012 10
Most information visualization systems have been designed 
for a single user, but co-located collaborative analysis of in-
formation is also common. Until relatively recently people 
have had to rely on physical prints of information for co- 
located collaborative analysis. The emergence of large, inter-
active displays opens new possibilities for the development 
of interfaces to support collaborative analysis using informa-
tion visualizations. In this section, we discuss implications 
for the design of single-user and co-located multi-user infor-
mation visualization systems based on our findings.
# Para 1022 1
Support Flexible Temporal Sequence of Work Processes:
# Para 1023 19
Individuals have unique information analysis practices based 
on their prior experiences, successes, and failures. These 
well-established work practices should be supported by dig-
ital systems. Our study showed that all participants worked 
differently in terms of the order and length of individual 
work processes they engaged in, suggesting the need for dig-
ital systems to be relatively unrestricting. The temporality of 
work processes suggested by previous models of the analytic 
process could imply that common information visualization 
tools require a specific process-flow. Our study, however, 
suggests that users of digital systems may benefit if a flex-
ible order of operations can be performed. Co-located col-
laborative systems, in which more than one user may work 
and interact at the same time, should possibly allow group 
members to be engaged in different types ofprocesses at the 
same time and also allow them to work together adopting the 
same processes. For example, one person should be able to 
select data from or browse a database while another already 
works on previously selected information.
# Para 1042 1
Support Changing Work Strategies:
# Para 1043 23
In group settings, our participants dynamically switched be-
tween closely coupled and more independent work. The 
browse, parse, operate, and select processes were most of-
ten done on individual views of the data in a more loosely 
coupled fashion. Discussion of collaboration style and estab-
lish task-specific strategy, clarify, and verify often happened 
in closer cooperation with the other partner(s) and often in-
cluded shared views of the data. To support these chang-
ing work strategies information visualization tools for co- 
located work need to be designed to support individual and 
shared views of and interactions on the data. Each collabora-
tor should be able to perform individual operations on these 
views unaffected by his or her team members’ actions. How-
ever, the tool should also help to share these individual views 
and, thus, provide awareness of one team member’s actions 
to the other collaborators. To support individual views of the 
data, interaction with the underlying data structures (deletion 
of nodes in a tree, change of query parameters, etc.) should 
be designed so as to not influence others’ views of the same 
data. However, to support shared views of the data, these pre-
vious operations should be transferable to group views, for 
example, to combine highlights, annotations, or other parts 
of an interaction history.
# Para 1066 1
Support Flexible Workspace Organization:
# Para 1067 12
Information artefacts were re-arranged on the table by all of 
our participants. We observed that participants had quite dis-
tinct individual workspaces on the table in which they laid 
out their cards. These workspaces were quite flexible and 
would change depending on tasks as well as, in group set-
tings, on team members’ spatial needs. This observation is 
echoed by the studies of collaborative behavior reported in 
[14] that call for co-located collaborative systems to provide 
appropriate functionality in these personal workspaces (ter-
ritories). We refer to their paper for further guidelines of 
how to support personal territories for co-located collabora-
tive work.
# Para 1079 1
1225
# Para 1080 1
CHI 2008 Proceedings · Visualization to Support Information Work	April 5-10, 2008 · Florence, Italy
# Para 1081 16
Participants also seemed to frequently impose categorizations 
on data items by organizing them spatially in the workspace. 
During browsing, overview layouts were often created in 
which the cards were spread across the whole workspace. 
Mainly during selection and at the end of an operation pro-
cess, information artefacts were organized in piles in the 
workspace. These piles seemed to have inherent categories 
and varied greatly in size, lifespan, and semantic. Allow-
ing users to impose a spatial organization of the informa-
tion artefacts in the workspace should be considered in the 
design of information visualization systems. These spatial 
organizations can help users support their mental model of 
the available information. Systems like CoMotion [11] are 
already taking a step in this direction but the typical informa-
tion visualization system still relies on a fixed set of windows 
and controls that can rarely be changed, piled, or relocated.
# Para 1097 1
CONCLUSION
# Para 1098 28
Several researchers have contributed to creating a theoretical 
understanding of how individuals make use of information 
visualizations to gain insight into data and solve problems. 
In this paper, we have continued our evolving theoretical un-
derstanding of this process by presenting a framework for 
visual information analysis. Our framework is based on find-
ings from an observational study that was designed to un-
cover the processes involved in collaborative and individual 
activities around information visualizations in a non-digital 
setting. We identified eight processes as part of this frame-
work: Browse, Parse, Discuss Collaboration Style, Establish 
Task-Specific Strategy, Clarify, Select, Operate, and Validate 
and described differences in team and individual work dur-
ing these processes. We have shown how these eight pro-
cesses relate to other models of information analysis, and 
provided insights on differences and commonalities between 
them. Yet, while others have posited a general temporal flow 
of information analysis, our results suggest this temporal 
flow may simply reflect an assumption in the design of ex-
isting information visualization tools. Thus, we argue that 
designers should allow for individuals’ unique approaches 
toward analysis, and support a more flexible temporal flow 
of activity. These eight processes can, therefore, be seen as 
an analytic framework that has implications for the design, 
heuristic evaluation, and analysis of individual and collabo-
rative information visualization systems. We have also given 
concrete design implications for digital information visual-
ization systems derived from our findings.
# Para 1126 1
ACKNOWLEDGEMENTS
# Para 1127 5
This work was supported in part by Alberta Ingenuity, iCORE, 
NSERC, NECTAR, and Smart Technologies. We would also 
like to thank Stacey Scott and our co-workers in the ilab for 
important feedback on this work and Bob Spence for discus-
sions about navigation in information spaces.
# Para 1132 1
REFERENCES
# Para 1133 4
1. R. A. Amar and J. T. Stasko. Knowledge Precepts for Design 
and Evaluation of Information Visualizations. IEEE 
Transactions on Visualization and Computer Graphics, 
11(4):432–442, July/August 2005.
# Para 1137 2
2. J. Bertin. Semiology of Graphics: Diagrams Networks Maps. 
The University of Wisconsin Press, Madison, WI, USA, 1983.
# Para 1139 4
3. S. Card, J. D. Mackinlay, and B. Shneiderman, editors. 
Readings In Information Visualization: Using Vision To 
Think. Morgan Kauffman Publishers, Inc., San Francisco, 
USA, 1999.
# Para 1143 4
4. J. M. Carroll, M. B. Rosson, G. Convertino, and C. H. Ganoe. 
Awareness and Teamwork in Computer-Supported 
Collaborations. Interacting with Computers, 18(1):21–46, 
2006.
# Para 1147 4
5. E. H.-H. Chi and J. T. Riedl. An Operator Interaction 
Framework for Visualization Systems. In Proc. of the 
Symposium on Information Visualization (InfoVis), pages 
63–70, Los Alamitos, USA, 1998. IEEE Comp. Society.
# Para 1151 2
6. H. H. Clark. Using Language. Cambridge University Press, 
Cambridge, UK, 1996.
# Para 1153 3
7. J. Heiser, B. Tversky, and M. Silverman. Sketches For and 
From Collaboration. In Visual and spatial reasoning in design 
III. Key Centre for Design Research, Sydney, 2004.
# Para 1156 4
8. P. Isenberg and S. Carpendale. Interactive Tree Comparison 
for Co-located Collaborative Information Visualization. IEEE 
Transactions on Visualization and Computer Graphics, 
12(5):1232–1238, Nov./Dec. 2007.
# Para 1160 4
9. T. Jankun-Kelly, K.-L. Ma, and M. Gertz. A Model and 
Framework for Visualization Exploration. IEEE Transactions 
on Visualization and Computer Graphics, 13(2):357–369, 
March/April 2007.
# Para 1164 3
10. G. Mark and A. Kobsa. The Effects of Collaboration and 
System Transparency on CIVE Usage: An Empirical Study 
and Model. Presence, 14(1):60–80, February 2005.
# Para 1167 2
11. MayaViz. CoMotion®. Website, 2007. 
http://www.mayaviz.com/ (accessed March 2007).
# Para 1169 5
12. K. S. Park, A. Kapoor, and J. Leigh. Lessons Learned from 
Employing Multiple Perspectives In a Collaborative Virtual 
Environment for Visualizing Scientific Data. In Proc. of the 
Conference on Collaborative Virtual Environments (CVE), 
pages 73–82, New York, USA, 2000. ACM Press.
# Para 1174 4
13. D. M. Russell, M. J. Stefik, P. Pirolli, and S. K. Card. The 
Cost Structure of Sensemaking. In Proc. of the Conference on 
Human Factors in Computing Systems (CHI), pages 269–276, 
New York, NY, USA, 1993. ACM Press.
# Para 1178 4
14. S. D. Scott, M. S. T. Carpendale, and K. M. Inkpen. 
Territoriality in Collaborative Tabletop Workspaces. In Proc. 
of the Conference on Computer-Supported Cooperative Work 
(CSCW), pages 294–303, New York, USA, 2004. ACM Press.
# Para 1182 4
15. B. Shneiderman. The Eyes Have It: A Task by Data Type 
Taxonomy for Information Visualizations. In Proc. of the 
Symp. on Visual Languages, pages 336–343, Los Alamitos, 
USA, 1996. IEEE Computer Society.
# Para 1186 3
16. R. Spence. A Framework for Navigation. International 
Journal of Human-Computer Studies, 51(5):919–945, 
November 1999.
# Para 1189 2
17. R. Spence. Information Visualization. Pearson Education 
Limited, Harlow, England, 2nd edition, 2007.
# Para 1191 4
18. A. Tang, M. Tory, B. Po, P. Neumann, and S. Carpendale. 
Collaborative Coupling over Tabletop Displays. In Proc. of 
the Conference on Human Factors in Computing Systems 
(CHI), pages 1181–1290, New York, USA, 2006. ACM Press.
# Para 1195 3
19. J. C. Tang. Findings from Observational Studies of 
Collaborative Work. International Journal of Man-Machine 
Studies, 34(2):143–160, February 1991.
# Para 1198 3
20. J. J. Thomas and K. A. Cook, editors. Illuminating the Path: 
The Research and Development Agenda for Visual Analytics. 
National Visualization and Analytics Center, August 2005.
# Para 1201 1
21. F. B. Vi´egas, M. Wattenberg, F. van Ham, J. Kriss, and
# Para 1202 4
M. McKeon. Many Eyes: A Site for Visualization at Internet 
Scale. IEEE Transactions on Visualization and Computer 
Graphics (Proceedings Visualization /Information 
Visualization 2007), 12(5):1121–1128, Nov./Dec. 2007.
# Para 1206 1
1226
