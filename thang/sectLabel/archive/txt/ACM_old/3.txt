A Computational Approach to Reflective Meta-Reasoning about
Languages with Bindings *
Aleksey Nogin Alexei Kopylov Xin Yu Jason Hickey
Department of Computer Science
California Institute of Technology
M/C 256-80, Pasadena, CA 91125
{nogin,kopylov,xiny,jyh}@cs.caltech.edu
Abstract
We present a foundation for a computational meta-theory of lan- +L+ guages with bindings implemented in a computer-aided formal rea- +L+ soning environment. Our theory provides the ability to reason ab- +L+ stractly about operators, languages, open-ended languages, classes +L+ of languages, etc. The theory is based on the ideas of higher-order +L+ abstract syntax, with an appropriate induction principle parameter- +L+ ized over the language (i. e. a set of operators) being used. In our ap- +L+ proach, both the bound and free variables are treated uniformly and +L+ this uniform treatment extends naturally to variable-length bind- +L+ ings. The implementation is reflective, namely there is a natural +L+ mapping between the meta-language of the theorem-prover and the +L+ object language of our theory. The object language substitution op- +L+ eration is mapped to the meta-language substitution and does not +L+ need to be defined recursively. Our approach does not require de- +L+ signing a custom type theory; in this paper we describe the im- +L+ plementation of this foundational theory within a general-purpose +L+ type theory. This work is fully implemented in the MetaPRL the- +L+ orem prover, using the pre-existing NuPRL-like Martin-L¨of-style +L+ computational type theory. Based on this implementation, we lay +L+ out an outline for a framework for programming language experi- +L+ mentation and exploration as well as a general reflective reasoning +L+ framework. This paper also includes a short survey of the existing +L+ approaches to syntactic reflection.
Categories and Subject Descriptors D.3.1 [Programming Lan- +L+ guages]: Formal Definitions and Theory—Syntax; F.4.3 [Math- +L+ ematical Logic and Formal Languages]: Formal Languages— +L+ Operations on languages
General Terms Languages, Theory, Verification
Keywords Higher-Order Abstract Syntax, Reflection, Type The- +L+ ory, Meta PRL, N uPRL, Programming Language Experimentation, +L+ Languages with Bindings.
* An extended version of this paper is available as Caltech Technical Report +L+ CaltechCSTR:2005.003 [NKYH05]
Permission to make digital or hard copies of all or part of this work for personal or +L+ classroom use is granted without fee provided that copies are not made or distributed +L+ for profit or commercial advantage and that copies bear this notice and the full citation +L+ on the first page. To copy otherwise, to republish, to post on servers or to redistribute +L+ to lists, requires prior specific permission and/or a fee.
MERLIN’05 September 30, 2005, Tallinn, Estonia.
Copyright �c 2005 ACM 1-59593-072-8/05/0009...$5.00.
1. Introduction
1.1 Reflection
Very generally, reflection is the ability of a system to be “self- +L+ aware” in some way. More specifically, by reflection we mean the +L+ property of a computational or formal system to be able to access +L+ and internalize some of its own properties.
There are many areas of computer science where reflection +L+ plays or should play a major role. When exploring properties of +L+ programming languages (and other languages) one often realizes +L+ that languages have at least two kinds of properties — semantic +L+ properties that have to do with the meaning of what the language’s +L+ constructs express and syntactic properties of the language itself.
Suppose for example that we are exploring some language that +L+ contains arithmetic operations. And in particular, in this language +L+ one can write polynomials like x2 +2x + 1. In this case the number +L+ of roots of a polynomial is a semantic property since it has to do +L+ with the valuation of the polynomial. On the other hand, the degree +L+ of a polynomial could be considered an example of a syntactic +L+ property since the most natural way to define it is as a property of +L+ the expression that represents that polynomial. Of course, syntactic +L+ properties often have semantic consequences, which is what makes +L+ them especially important. In this example, the number of roots of +L+ a polynomial is bounded by its degree.
Another area where reflection plays an important role is run- +L+ time code generation — in most cases, a language that supports +L+ run-time code generation is essentially reflective, as it is capable +L+ of manipulating its own syntax. In order to reason about run-time +L+ code generation and to express its semantics and properties, it is +L+ natural to use a reasoning system that is reflective as well.
There are many different flavors of reflection. The syntactic +L+ reflection we have seen in the examples above, which is the ability +L+ of a system to internalize its own syntax, is just one of these +L+ many flavors. Another very important kind of reflection is logical +L+ reflection, which is the ability of a reasoning system or logic to +L+ internalize and reason about its own logical properties. A good +L+ example of a logical reflection is reasoning about knowledge — +L+ since the result of reasoning about knowledge is knowledge itself, +L+ the logic of knowledge is naturally reflective [Art04].
In most cases it is natural for reflection to be iterated. In the +L+ case of syntactic reflection we might care not only about the syntax +L+ of our language, but also about the syntax used for expressing the +L+ syntax, the syntax for expressing the syntax for expressing the +L+ syntax and so forth. In the case of the logic of knowledge it is +L+ natural to have iterations of the form “I know that he knows that
I know ...”.
When a formal system is used to reason about properties of pro- +L+ gramming languages, iterated reflection magnifies the power of the
2
system, making it more natural to reason not just about individual +L+ languages, but also about classes of languages, language schemas, +L+ and so on. More generally, reflection adds a lot of additional power +L+ to a formal reasoning system [GS89, Art99]. In particular, it is +L+ well-known [G¨od36, Mos52, EM71, Par71] that reflection allows +L+ a super-exponential reduction in the size of certain proofs. In addi- +L+ tion, reflection could be a very useful mechanism for implement- +L+ ing proof search algorithms [ACU93, GWZ00, CFW04]. See also +L+ [Har95] for a survey of reflection in theorem proving.
1.2 Uniform Reflection Framework
For each of the examples in the previous section there are many +L+ ad-hoc ways of achieving the specific benefits of a specific fla- +L+ vor of reflection. This work aims at creating a unifying reflective +L+ framework that would allow achieving most of these benefits in a +L+ uniform manner, without having to reinvent and re-implement the +L+ basic reflective methodology every time. We believe that such a +L+ framework will increase the power of the formal reasoning tools, +L+ and it may also become an invaluable tool for exploring the proper- +L+ ties of novel programming languages, for analyzing run-time code +L+ generation, and for formalizing logics of knowledge.
This paper establishes a foundation for the development of this +L+ framework — a new approach to reflective meta-reasoning about +L+ languages with bindings. We present a theory of syntax that:
•	in a natural way provides both a higher-order abstract syntax +L+ (HOAS) approach to bindings and a de Bruijn-style approach +L+ to bindings, with easy and natural translation between the two;
•	provides a uniform HOAS-style approach to both bound and +L+ free variables that extends naturally to variable-length “vectors” +L+ of binders;
•	permits meta-reasoning about languages — in particular, the +L+ operators, languages, open-ended languages, classes of lan- +L+ guages etc. are all first-class objects that can be reasoned about +L+ both abstractly and concretely;
•	comes with a natural induction principle for syntax that can be +L+ parameterized by the language being used;
•	provides a natural mapping between the object syntax and meta- +L+ syntax that is free of exotic terms, and allows mapping the +L+ object-level substitution operation directly to the meta-level one +L+ (i.e. P-reduction);
•	is fully derived in a pre-existing type theory in a theorem +L+ prover;
•	is designed to serve as a foundation for a general reflective +L+ reasoning framework in a theorem prover;
•	is designed to serve as a foundation for a programming lan- +L+ guage experimentation framework.
The paper is structured as follows. Our work inherits a large +L+ number of ideas from previous efforts and we start in Section 2 +L+ with a brief survey of existing techniques for formal reasoning +L+ about syntax. Next in Section 3 we outline our approach to rea- +L+ soning about syntax and in Section 4 we present a formal account +L+ of our theory based on a Martin-L¨of style computational type the- +L+ ory [CAB+86, HAB+] and the implementation of that account in +L+ the MetaPRL theorem prover [Hic97, Hic99, Hic01, HNC+03, +L+ HNK+, HAB+]. Then in Section 5 we outline our plan for building +L+ a uniform reflection framework based on the syntactic reflection. +L+ Finally, in Section 6 we resume the discussion of related work that +L+ was started in Section 2. +L+ 1.3 Notation and Terminology
We believe that our approach to reasoning about syntax is fairly +L+ general and does not rely on any special features of the theo- +L+ rem prover we use. However, since we implement this theory in +L+ MetaPRL, we introduce some basic knowledge about MetaPRL +L+ terms.
A MetaPRL term consists of:
1. An operator name (like “sum”), which is a unique name indi- +L+ cating the logic and component of a term;
2. A list of parameters representing constant values; and +L+ 3. A set of subterms with possible variable bindings.
We use the following syntax to describe terms, based on the N u P R L +L+ definition [ACHA90]:
In addition, MetaPRL has a meta-syntax somewhat similar to +L+ the higher-order abstract syntax presented in Pfenning and Elliott +L+ [PE88]. MetaPRL uses the second-order variables in the style of +L+ Huet and Lang [HL78] to describe term schemas. For example, +L+ Xx.V [x], where V is a second-order variable of arity 1, is a schema +L+ that stands for an arbitrary term whose top-level operator is X.
This meta-syntax requires that every time a binding occurrence +L+ is explicitly specified in a schema, all corresponding bound occur- +L+ rences have to be specified as well. This requirement makes it very +L+ easy to specify free variable restrictions — for example, Xx.V, +L+ where V is a second-order meta-variable of arity 0, is a schema +L+ that stands for an arbitrary term whose top-level operator is X and +L+ whose body does not have any free occurrences of the variable +L+ bound by that X. In particular, the schema Xx. V matches the term +L+ Xy.1, but not the term Xx.x.
In addition, this meta-language allows specifying certain term +L+ transformations, including implicit substitution specifications. For +L+ example, a beta reduction transformation may be specified using +L+ the following schema:
(Xx.V1 [x]) V2 H V1 [V2]
Here the substitution of V2 for x in V1 is specified implicitly.
Throughout this paper we will use this second-order notation to +L+ denote arbitrary terms — namely, unless stated otherwise, when we +L+ write “Xx.t[x]” we mean an arbitrary term of this form, not a term +L+ containing a concrete second-order variable named “t”.
As in LF [HHP93] we assume that object level variables (i.e. +L+ the variables of the language whose syntax we are expressing) +L+ are directly mapped to meta-theory variables (i.e. the variable of +L+ the language that we use to express the syntax). Similarly, we +L+ assume that the object-level binding structure is mapped to the +L+ meta-level binding structure. In other words, the object-level notion +L+ of the “binding/bound occurrence” is a subset of that in the meta- +L+ language. We also consider a-equal terms — both on the object +L+ level and on the meta-level — to be identical and we assume that +L+ substitution avoids capture by renaming.
The sequent schema language we use [NH02] contains a num- +L+ ber of more advanced features in addition to those outlined here. +L+ However, for the purposes of this presentation, the basic features +L+ outlined above are sufficient.
2. Previous Models of Reflection
In 1931 G¨odel used reflection to prove his famous incompleteness +L+ theorem [G¨od31]. To express arithmetic in arithmetic itself, he +L+ assigned a unique number (a G¨odel number) to each arithmetic
opname
�- J 
operator name
[p1; .. .; pn] f�v1.t1; . . . ; �vm.tm}
Y	Y	J
parameters	subterms
3
formula. A G¨odel number of a formula is essentially a numeric +L+ code of a string of symbols used to represent that formula.
A modern version of the G¨odel’s approach was used by Aitken +L+ et al. [ACHA90, AC92, ACU93, Con94] to implement reflection +L+ in the NuPRL theorem prover [CAB+86, ACE+00]. A large part +L+ of this effort was essentially a reimplementation of the core of the +L+ NuPRL prover inside NuPRL’s logical theory.
In G¨odel’s approach and its variations (including Aitken’s one), +L+ a general mechanism that could be used for formalizing one logical +L+ theory in another is applied to formalizing a logical theory in itself. +L+ This can be very convenient for reasoning about reflection, but for +L+ our purposes it turns out to be extremely impractical. First, when +L+ formalizing a theory in itself using generic means, the identity +L+ between the theory being formalized and the one in which the +L+ formalization happens becomes very obfuscated, which makes it +L+ almost impossible to relate the reflected theory back to the original +L+ one. Second, when one has a theorem proving system that already +L+ implements the logical theory in question, creating a completely +L+ new implementation of this logical theory inside itself is a very +L+ tedious redundant effort. Another practical disadvantage of the +L+ G¨odel numbers approach is that it tends to blow up the size of +L+ the formulas; and iterated reflection would cause the blow-up to +L+ be iterated as well, making it exponential or worse.
A much more practical approach is being used in some pro- +L+ gramming languages, such as Lisp and Scheme. There, the com- +L+ mon solution is for the implementation to expose its internal syntax +L+ representation to user-level code by the quote constructor (where +L+ quote (t) prevents the evaluation of the expression t). The prob- +L+ lems outlined above are solved instantly by this approach: there is +L+ no blow-up, there is no repetition of structure definitions, there is +L+ even no need for verifying that the reflected part is equivalent to the +L+ original implementation since they are identical. Most Scheme im- +L+ plementations take this even further: the eval function is the inter- +L+ nal function for evaluating a Scheme expression, which is exposed +L+ to the user-level; Smith [Smi84] showed how this approach can +L+ achieve an infinite tower of processors. A similar language with the +L+ quotation and antiquotation operators was introduced in [GMO03].
This approach, however, violates the congruence property with +L+ respect to computation: if two terms are computationally equal then +L+ one can be substituted for the other in any context. For instance, +L+ although 2 * 2 is equal to 4, the expressions “2*2” and “4” are +L+ syntactically different, thus we can not substitute 2*2 by 4 in +L+ the expression quote(2*2). The congruence property is essential +L+ in many logical reasoning systems, including the NuPRL system +L+ mentioned above and the MetaPRL system [HNC+03, HNK+, +L+ HAB+] that our group uses.
A possible way to expose the internal syntax without violat- +L+ ing the congruence property is to use the so-called “quoted” or +L+ “shifted” operators [AA99, Bar01, Bar05] rather than quoting the +L+ whole expression at once. For any operator op in the original lan- +L+ guage, we add the quoted operator (denoted as op) to represent a +L+ term built with the operator op. For example, if the original lan- +L+ guage contains the constant “0” (which, presumably, represents the +L+ number 0), then in the reflected language, 0 would stand for the +L+ term that denotes the expression “0”. Generally, the quoted opera- +L+ tor has the same arity as the original operator, but it is defined on +L+ syntactic terms rather than on semantic objects. For instance, while +L+ * is a binary operator on numbers, * is a binary operator on terms. +L+ Namely, if t1 and t2 are syntactic terms that stand for expressions +L+ e1 and e2 respectively, then t1 *t2 is a new syntactic term that stands +L+ for the expression e1 *e2. Thus, the quotation of the expression 1 *2 +L+ would be 1 * 2.
In general, the well-formedness (typing) rule for a quoted oper- +L+ ator is the following:
t1 E Term	...	tn E Term
op{t1; ... ; tn} E Term
where Term is a type of terms.
Note that quotations can be iterated arbitrarily many times, +L+ allowing us to quote quoted terms. For instance, 1 stands for the +L+ term that denotes the term that denotes the numeral 1.
Problems arise when quoting expressions that contain binding +L+ variables. For example, what is the quotation of Xx.x? There are +L+ several possible ways of answering this question. A commonly +L+ used approach [PE88, DH94, DFH95, ACM02, ACM03] in logical +L+ frameworks such as Elf [Pfe89], LF [HHP93], and Isabelle [PN90, +L+ Pau94] is to construct an object logic with a concrete X operator +L+ that has a type like
(Term -+ Term) -+ Term or (Var -+ Term) -+ Term.
In this approach, the quoted Xx.x might look like X(Xx.x) and the +L+ quoted Xx.1 might look like X(Xx.1). Note that in these examples +L+ the quoted terms have to make use of both the syntactic (i. e. quoted) +L+ operator X and the semantic operator X.
Exotic Terms. Naive implementations of the above approach +L+ suffer from the well-known problem of exotic terms [DH95, +L+ DFH95]. The issue is that in general we can not allow applying +L+ the X operator to an arbitrary function that maps terms to terms (or +L+ variables to terms) and expect the result of such an application to +L+ be a “proper” reflected term.
Consider for example the following term:
X(Xx. if x = 1 then 1 else 2)
It is relatively easy to see that it is not a real syntactic term and +L+ can not be obtained by quoting an actual term. (For comparison, +L+ consider X(Xx. if x = 1 then 1 else 2), which is a quotation of +L+ Xx. if x = 1 then 1 else 2).
How can one ensure that Xe denotes a “real” term and not an +L+ “exotic” one? That is, is it equal to a result of quoting an actual +L+ term of the object language? One possibility is to require e to be +L+ a substitution function; in other words it has to be equal to an +L+ expression of the form Xx.t[x] where t is composed entirely of term +L+ constructors (i.e. quoted operators) and x, while using destructors +L+ (such as case analysis, the if operator used in the example above, +L+ etc) is prohibited.
There are a number of approaches to enforcing the above restric- +L+ tion. One of them is the usage of logical frameworks with restricted +L+ function spaces [PE88, HHP93], where X-terms may only con- +L+ tain constructors. Another is to first formalize the larger type that +L+ does include exotic terms and then to define recursively a predicate +L+ describing the “validity” or “well-formedness” of a term [DH94, +L+ DFH95] thus removing the exotic terms from consideration. Yet +L+ another approach is to create a specialized type theory that com- +L+ bines the idea of restricted function spaces with a modal type oper- +L+ ator [DPS97, DL99, DL01]. There the case analysis is disallowed +L+ on objects of “pure” type T, but is allowed on objects of a special
type ❑T. This allows expressing both the restricted function space
“T1 -+ T2” and the unrestricted one “(�T1) -+ T2” within a single +L+ type theory.
Another way of regarding the problem of exotic terms is that it +L+ is caused by the attempt to give a semantic definition to a primarily +L+ syntactic property. A more syntax-oriented approach was used by +L+ Barzilay et al. [BA02, BAC03, Bar05]. In Barzilay’s approach, the +L+ quoted version of an operator that introduces a binding has the +L+ same shape (i.e. the number of subterms and the binding structure) +L+ as the original one and the variables (both the binding and the
(1)
4
bound occurrences) are unaffected by the quotation. For instance, +L+ the quotation of Xx.x is just Xx.x.
The advantages of this approach include:
•	This approach is simple and clear.
•	Quoted terms have the same structure as original ones, inherit- +L+ ing a lot of properties of the object syntax.
•	In all the above approaches, the a-equivalence relation for +L+ quoted terms is inherited “for free”. For example, Xx.x and +L+ Xy.y are automatically considered to be the same term.
•	Substitution is also easy: we do not need to re-implement the +L+ substitution that renames binding variables to avoid the capture +L+ of free variables; we can use the substitution of the original +L+ language instead.
To prune exotic terms, Barzilay says that Xx.t[x] is a valid term +L+ when Xx.t[x] is a substitution function. He demonstrates that it is +L+ possible to formalize this notion in a purely syntactical fashion. In +L+ this setting, the general well-formedness rule for quoted terms with +L+ bindings is the following:
is substk {x1, · · · , xk.t[&quot;x]}	· · ·	is substl {z 1, · · · , zl.s[&quot;z]}
op{x1, · · · , xk.t[&quot;x]; · · · ; z1, · · · , zl.s[&quot;z]} E Term
(2) +L+ where is substn {x1 , · · · , xn.t[&quot;x]} is the proposition that t is a sub- +L+ stitution function over variables x1 , · · · , xn (in other words, it is a +L+ syntactic version of the Valid predicate of [DH94, DFH95]). This +L+ proposition is defined syntactically by the following two rules:
is substn {x1, · · · , xn . xi}
and
is substn+k{x1, · · · , xn,y1, · · · , yk.t[&quot;x;&quot;y]}
...
is substn+l {x1, · · · , xn, z1, ··· , zl.s[&quot;x; &quot;z]}}
is substn {x1 · · ·xn.op{y1 · · ·yk.t[&quot;x; &quot;y]; · · · ; z1 · · ·zl.s[&quot;x; &quot;z]}}
In this approach the is substn {} and X operators are essentially +L+ untyped (in NuPRL type theory, the computational properties of +L+ untyped terms are at the core of the semantics; types are added on +L+ top of the untyped computational system).
Recursive Definition and Structural Induction Principle. A +L+ difficulty shared by both the straightforward implementations of +L+ the (Term -+ Term) -+ Term approach and by the Barzilay’s one +L+ is the problem of recursively defining the Term type. We want to +L+ define the Term type as the smallest set satisfying rules (1) and (2). +L+ Note, however, that unlike rule (1), rule (2) is not monotonic in the +L+ sense that is substk {x1, · · · , xk.t[&quot;x]} depends non-monotonically +L+ on the Term type. For example, to say whether Xx.t[x] is a term, we +L+ should check whether t is a substitution function over x. It means at +L+ least thatfor every x in Term, t[x] should be in Term as well. Thus +L+ we need to define the whole type Term before using (2), which +L+ produces a logical circle. Moreover, since X has type (Term -+ +L+ Term) -+ Term, it is hard to formulate the structural induction +L+ principle for terms built with the X term constructor.
Variable-Length Lists of Binders. In Barzilay’s approach, for +L+ each number n, is substn {} is considered to be a separate operator +L+ — there is no way to quantify over n, and there is no way to +L+ express variable-length lists of binders. This issue of expressing the +L+ unbounded-length lists of binders is common to some of the other +L+ approaches as well.
Meta-Reasoning. Another difficulty that is especially apparent +L+ in Barzilay’s approach is that it only allows reasoning about con- +L+ crete operators in concrete languages. This approach does not pro- +L+ vide the ability to reason about operators abstractly; in particular, +L+ there is no way to state and prove meta-theorems that quantify over +L+ operators or languages, much less classes of languages.
3. Higher-Order Abstract Syntax +L+ with Inductive Definitions
Although it is possible to solve the problems outlined in the previ- +L+ ous Section (and we will return to the discussion of some of those +L+ solutions in Section 6), our desire is to avoid these difficulties from +L+ the start. We propose a natural model of reflection that manages to +L+ work around those difficulties. We will show how to give a sim- +L+ ple recursive definition of terms with binding variables, which does +L+ not allow the construction of exotic terms and does allow structural +L+ induction on terms.
In this Section we provide a conceptual overview of our ap- +L+ proach; details are given in Section 4.
3.1 Bound Terms
One of the key ideas of our approach is how we deal with terms +L+ containing free variables. We extend to free variables the principle +L+ that variable names do not really matter. In fact, we model free +L+ variables as bindings that can be arbitrarily a-renamed. Namely, +L+ we will write bterm{x1, · · · , xn.t[&quot;x]} for a term t over variables +L+ x1, · · ·, xn. For example, instead of term x*y we will use the +L+ term bterm{x, y.x*y} when it is considered over variables x and +L+ y and bterm{x, y, z.x*y} when it is considered over variables x, +L+ y and z. Free occurrences of xi in t[&quot;x] are considered bound +L+ in bterm{x1, · · · , xn.t[&quot;x]} and two a-equal bterm{} expressions +L+ (“bterms”) are considered to be identical.
Not every bterm is necessarily well-formed. We will define the +L+ type of terms in such a way as to eliminate exotic terms. Consider +L+ for example a definition of lambda-terms.
EXAMPLE 1. We can define a set of reflected lambda-terms as the +L+ smallest set such that
•	bterm{x1, · · · , xn.xi}, where 1 &lt; i &lt; n, is a lambda-term (a +L+ variable);
•	ifbterm{x1, · · · , xn, xn+1.t[&quot;x] ) is a lambda-term, then
bterm{x1 , · · · , xn .Xxn+1 .t[&quot;x])
is also a lambda-term (an abstraction);
•	if bterm{x1, · · · , xn.t1 [&quot;x]} and bterm{x1, · · · , xn.t2[&quot;x]} are +L+ lambda-terms, then
bterm{x1; · · · ; xn.apply{t1 [&quot;x]; t2[&quot;x]}}
is also a lambda-term (an application).
In a way, bterms could be understood as an explicit coding for +L+ Barzilay’s substitution functions. And indeed, some of the basic +L+ definitions are quite similar. The notion of bterms is also very +L+ similar to that of local variable contexts [FPT99].
3.2 Terminology
Before we proceed further, we need to define some terminology.
DEFINITION 1. We change the notion of subterm so that the sub- +L+ terms of a bterm are also bterms. For example, the immediate sub- +L+ terms of bterm{x, y.x*y} are bterm{x, y.x} and bterm{x, y.y}; the +L+ immediate subterm ofbterm{x.Xy.x} is bterm{x, y.x}.
DEFINITION 2. We call the number of outer binders in a bterm +L+ expression its binding depth. Namely, the binding depth of the +L+ bterm bterm{x1, · · · , xn.t[&quot;x]} is n.
DEFINITION 3. Throughout the rest of the paper we use the notion +L+ of operator shape. The shape ofan operator is a list ofnatural num- +L+ bers each stating how many new binders the operator introduces on
5
the corresponding subterm. The length of the shape list is therefore +L+ the arity of the operator. For example, the shape of the + operator +L+ is [0; 0] and the shape of the X operator is [1].
The mapping from operators to shapes is also sometimes called +L+ a binding signature of a language [FPT99, Plo90].
DEFINITION 4. Let op be an operator with shape [d1; · · · ; dN], +L+ and let btl be a list of bterms [b1; · · · ; bM]. We say that btl is +L+ compatible with op at depth n when,
1. N=M;
2. the binding depth of bterm bj is n + dj for each 1 &lt; j &lt; N.
3.3 Abstract Operators
Expressions of the form bterm{&quot;x.op{· · · }} can only be used to ex- +L+ press syntax with concrete operators. In other words, each expres- +L+ sion of this form contains a specific constant operator op. However, +L+ we would like to reason about operators abstractly; in particular, +L+ we want to make it possible to have variables of the type “Op” that +L+ can be quantified over and used in the same manner as operator +L+ constants. In order to address this we use explicit term constructors +L+ in addition to bterm{&quot;x.op{· · · }} constants.
The expression mk bterm{n; “op”; btl}, where “op” is some en-
coding of the quoted operator op, stands for a bterm with binding
depth n, operator op and subterms btl. Namely,
mk bterm{n; op; bterm{x1 , · · · , xn, &quot;y1 .t1 [&quot;x; &quot;y1]} :: · · · ::
bterm{x1, · · · ,xn,&quot;yk.tk[&quot;x; &quot;yk]} :: nil}
is bterm{x1, · · · , xn.op {&quot;y1 .t1 [&quot;x; &quot;y1]; · · · ; &quot;yk.tk[&quot;x; &quot;yk]}}. Here, +L+ nil is the empty list and :: is the list cons operator and there- +L+ fore the expression b1 :: · · · :: bn :: nil represents the concrete list +L+ [b1; ··· ; bn].
Note that if we know the shape of the operator op and we know +L+ that the mk bterm expression is well-formed (or, more specifically, +L+ if we know that btl is compatible with op at depth n), then it +L+ would normally be possible to deduce the value of n (since n is +L+ the difference between the binding depth of any element of the list +L+ btl and the corresponding element of the shape(op) list). There are +L+ two reasons, however, for supplying n explicitly:
•	When btl is empty (in other words, when the arity of op is 0), +L+ the value of n can not be deduced this way and still needs to be +L+ supplied somehow. One could consider 0-arity operators to be a +L+ special case, but this results in a significant loss of uniformity.
•	When we do not know whether an mk bterm expression is +L+ necessarily well-formed (and as we will see it is often useful +L+ to allow this to happen), then a lot of definitions and proofs +L+ are greatly simplified when the binding depth of mk bterm +L+ expressions is explicitly specified.
Using the mk bterm constructor and a few other similar con- +L+ structors that will be introduced later, it becomes easy to reason ab- +L+ stractly about operators. Indeed, the second argument to mk bterm +L+ can now be an arbitrary expression, not just a constant. This has a +L+ cost of making certain definitions slightly more complicated. For +L+ example, the notion of “compatible with op at depth n” now be- +L+ comes an important part of the theory and will need to be explicitly +L+ formalized. However, this is a small price to pay for the ability to +L+ reason abstractly about operators, which easily extends to reason- +L+ ing abstractly about languages, classes of languages and so forth.
3.4 Inductively Defining the Type of Well-Formed Bterms
There are two equivalent approaches to inductively defining the +L+ general type (set) of all well-formed bterms. The first one follows +L+ the same idea as in Example 1:
•	bterm{x1 , · · · , xn.xi } is a well-formed bterm for 1 &lt; i &lt; n;
•	mk bterm{n; op; btl} is a well-formed bterm when op is a well- +L+ formed quoted operator and btl is a list of well-formed bterms +L+ that is compatible with op at some depth n.
If we denote bterm{x1, · · · , xl, y, z1, · · · , zr.y} as var{l; r}, +L+ we can restate the base case of the above definition as “var{l; r}, +L+ where l and r are arbitrary natural numbers, is a well-formed +L+ bterm”. Once we do this it becomes apparent that the above def- +L+ inition has a lot of similarities with de Bruijn-style indexing of +L+ variables [dB72]. Indeed, one might call the numbers l and r the +L+ left and right indices of the variable var{l; r}.
It is possible to provide an alternate definition that is closer to +L+ pure HOAS:
•	bnd{x.t[x]}, where t is a well-formed substitution function, is +L+ a well-formed bterm (the bnd operation increases the binding +L+ depth of t by one by adding x to the beginning of the list of t’s +L+ outer binders).
•	mk term{op; btl}, where op is a well-formed quoted operator, +L+ and btl is a list of well-formed bterms that is compatible with +L+ op at depth 0, is a well-formed bterm (of binding depth 0).
Other than better capturing the idea of HOAS, the latter defini- +L+ tion also makes it easier to express the reflective correspondence +L+ between the meta-syntax (the syntax used to express the theory of +L+ syntax, namely the one that includes the operators mk bterm, bnd, +L+ etc.) and the meta-meta-syntax (the syntax that is used to express +L+ the theory of syntax and the underlying theory, in other words, the +L+ syntax that includes the second-order notations.) Namely, provided +L+ that we define the subst{bt; t} operation to compute the result of +L+ substituting a closed term t for the first outer binder of the bterm +L+ bt, we can state that
subst{bnd{x.t1 [x]} ; t2} ≡ t1 [t2] (3)
(where t1 and t2 are literal second-order variables). In other words, +L+ we can state that the substitution operator subst and the implicit +L+ second-order substitution in the “meta-meta-” language are equiv- +L+ alent.
The downside of the alternate definition is that it requires defin- +L+ ing the notion of “being a substitution function”.
3.5 Our Approach
In our work we try to combine the advantages of both approaches +L+ outlined above. In the next Section we present a theory that includes +L+ both the HOAS-style operations (bnd, mk term) and the de Bruijn- +L+ style ones (var, mk bterm). Our theory also allows deriving the +L+ equivalence (3). In our theory the definition of the basic syntactic +L+ operations is based on the HOAS-style operators; however, the +L+ recursive definition of the type of well-formed syntax is based on +L+ the de Bruijn-style operations. Our theory includes also support for +L+ variable-length lists of binders.
4. Formal Implementation in a Theorem Prover
In this Section we describe how the foundations of our theory are +L+ formally defined and derived in the NuPRL-style Computational +L+ Type Theory in the MetaPRL Theorem Prover. For brevity, we +L+ will present a slightly simplified version of our implementation; +L+ full details are available in the extended version of this paper +L+ [NKYH05, Appendix].
4.1 Computations and Types
In our work we make heavy usage of the fact that our type theory +L+ allows us to define computations without stating upfront (or even +L+ knowing) what the relevant types are. In NuPRL-style type theo-
6
ries (which some even dubbed “untyped type theory”), one may de- +L+ fine arbitrary recursive functions (even potentially nonterminating +L+ ones). Only when proving that such function belongs to a particular +L+ type, one may have to prove termination. See [All87a, All87b] for +L+ a semantics that justifies this approach.
The formal definition of the syntax of terms consists of two +L+ parts:
•	The definition of untyped term constructors and term oper- +L+ ations, which includes both HOAS-style operations and de +L+ Bruijn-style operations. As it turns out, we can establish most +L+ of the reduction properties without explicitly giving types to all +L+ the operations.
•	The definition of the type of terms. We will define the type of +L+ terms as the type that contains all terms that can be legitimately +L+ constructed by the term constructors.
4.2 HOAS Constructors
At the core of our term syntax definition are two basic HOAS-style +L+ constructors:
•	bnd{x.t[x]} is meant to represent a term with a free variable x. +L+ The intended semantics (which will not become explicit until +L+ later) is that bnd{x.t[x]} will only be considered well-formed +L+ when t is a substitution function.
Internally, bnd{x.t[x]} is implemented simply as the pair +L+ (0, Xx.t[x]). This definition is truly internal and is used only +L+ to prove the properties of the two destructors presented below; +L+ it is never used outside of this Section (Section 4.2).
•	mk term{op; ts} pairs op with ts. The intended usage of this +L+ operation (which, again, will only become explicit later) is that +L+ it represents a closed term (i.e. a bterm of binding depth 0) with +L+ operator op and subterms ts. It will be considered well-formed +L+ when op is an operator and ts is a list of terms that is compatible
with op at depth 0. For example, mk term{X; bnd{x.x}} is Xx.x.
Internally, mk term{op; ts} is implemented as the nested pair +L+ (1, (op, ts)). Again, this definition is never used outside of this +L+ Section.
We also implement two destructors:
•	subst{bt; t} is meant to represent the result of substituting term +L+ t for the first variable of the bterm bt. Internally, subst{bt; t} +L+ is defined simply as an application (bt.2) t (where bt.2 is the +L+ second element of the pair bt).
We derive the following property of this substitution operation:
subst{bnd{x.t1 [x]} ; t2} ≡ t1 [t2]
where “≡” is the computational equality relation1 and t1 and +L+ t2 may be absolutely arbitrary, even ill-typed. This derivation +L+ is the only place where the internal definition of subst{bt; t} is +L+ used.
Note that the above equality is exactly the “reflective property +L+ of substitution” (3) that was one of the design goals for our +L+ theory.
•	weak dest {bt; bcase; op, ts.mkt case[op; ts]} is designed to +L+ provide a way to find out whether bt is a bnd{} or a mk term{op; ts}
1 In NuPRL-style type theories the computational equality relation (which +L+ is also sometimes called “squiggle equality” and is sometimes denoted
as“∼” or “←-+”) is the finest-grained equality relation in the theory.
When a ≡ b is true, a may be replaced with b in an arbitrary context. +L+ Examples of computational equality include beta-reduction Xx.a[x]b ≡ +L+ a[b], arithmetical equalities (1 + 2 ≡ 3), and definitional equality (an +L+ abstraction is considered to be computationally equal to its definition).
and to “extract” the op and ts in the latter case. In the rest of +L+ this paper we will use the “pretty-printed” form for weak dest +L+ — “match bt with bnd{ } -+ bcase I mk term{op; ts} -+ +L+ mkt case[op; ts]”. Internally, it is defined as
if bt.1 = 0 then bcase else mkt case[bt.2.1; bt.2.2].
From this internal definition we derive the following properties +L+ of weak dest:
⎛	⎞
matchbnd{x.t[x]} with
⎝bnd{ } -+ bcase	⎠
bcase
mk term{op; ts} -+ mkt case[op; ts]≡
⎛
matchmk term{op; ts} with
⎝bnd{ } -+ bcase +L+ Imk term{o; t} -+ mkt case[o; t] +L+ 4.3 Vector HOAS Operations
As we have mentioned at the end of Section 2, some approaches to +L+ reasoning about syntax make it hard or even impossible to express +L+ arbitrary-length lists of binders. In our approach, we address this +L+ challenge by allowing operators where a single binding in the meta- +L+ language stands for a list of object-level bindings. In particular, we +L+ allow representing bnd{x1.bnd{x2. · · · bnd{xn.t[x1; ... ; xn]} · · ·}} +L+ as
vbnd{n; x.t[nth{1; x}; . . . ; nth{n; x}]}, where “nth{i; l}” is the “i- +L+ th element of the list l” function.
We define the following vector-style operations:
•	vbnd{n; x.t[x]} represents a “telescope” of nested bnd opera- +L+ tions. It is defined by induction2 on the natural number n as +L+ follows:
vbnd{0; x.t[x]}:= t[nil]
vbnd{n + 1; x.t[x]}:= bnd{v.vbnd{n; x.t[v :: x]}}
We also introduce vbnd{n; t} as a simplified notation for +L+ vbnd{n; x.t} when t does not have free occurrences of x.
•	vsubst{bt; ts} is a “vector” substitution operation that is meant +L+ to represent the result of simultaneous substitution of the terms +L+ in the ts list for the first ItsI variables of the bterm bt (here IlI is +L+ the length of the list l). vsubst{bt; ts} is defined by induction on +L+ the list ts as follows:
vsubst{bt; nil}:= bt
vsubst{bt; t :: ts}:= vsubst{subst{bt; t} ; ts}
Below are some of the derived properties of these operations:
	bnd{v.t[v]} ≡ vbnd{1; hd(v)}	(4)
Vm , n E N.
�vbnd{m +n; x.t[x]} ≡ vbnd{m; y.vbnd{n; z.t[y@z]}}) (5)
	Vl E List. (vsubst{vbnd{Il I; v.t[v]} ;l} ≡ t[l])	(6)
Vl E List.Vn E N. �(n ≥ IlI) ⇒	(7)
(vsubst{vbnd{n; v.t[v]} ;l} ≡ vbnd{n − IlI; v.bt[l@v]}))
Vn E N.	(8)
vbnd{n; l.vsubst{vbnd{n; v.t[v]} ;l}} ≡ vbnd{n; l.t[l]})
where “hd” is the list “head” operation, “@” is the list append +L+ operation, “List” is the type of arbitrary lists (the elements of a list +L+ do not have to belong to any particular type), N is the type of natural +L+ numbers, and all the variables that are not explicitly constrained to +L+ a specific type stand for arbitrary expressions.
2 Our presentation of the inductive definitions is slightly simplified by +L+ omitting some minor technical details. See [NKYH05, Appendix] for +L+ complete details.
⎞⎠ ≡mkt case[op; ts]
7
Equivalence (5) allows the merging and splitting of vector bnd +L+ operations. Equivalence (6) is a vector variant of equivalence (3). +L+ Equivalence (8) is very similar to equivalence (6) applied in the +L+ vbnd{n; l. · · ·} context, except that (8) does not require l to be a +L+ member of any special type.
4.4 De Bruijn-style Operations
Based on the HOAS constructors defined in the previous two sec- +L+ tions, we define two de Bruijn-style constructors.
•	var{i; j} is defined as vbnd{i; bnd{v.vbnd{j; v}}}. It is easy to +L+ see that this definition indeed corresponds to the informal
bterm{x1,··· ,xl, y, z1,··· , zr .y} +L+ definition given in Section 3.4.
•	mk bterm{n; op; ts} is meant to compute a bterm of binding +L+ depth n, with operator op, and with ts as its subterms. This op- +L+ eration is defined by induction on natural number n as follows:
mk bterm{0; op; ts}:= mk term{op; ts} +L+ mk bterm{n + 1; op; ts}:=
bnd{v.mk bterm{n; op; map Xt.subst{t; v} ts}}
Note that, if ts is a list of bnd expressions (which is the intended +L+ usage of the mk bterm operation), then the
bnd{v. · · · map Xt.subst{t; v} ts · · ·}
has the effect of stripping the outer bnd from each of the mem- +L+ bers of the ts list and “moving” them into a single “merged” bnd +L+ on the outside.
We also define a number of de Bruijn-style destructors, i.e., op- +L+ erations that compute various de Bruijn-style characteristics of a +L+ bterm. Since the var and mk bterm constructors are defined in terms +L+ of the HOAS constructors, the destructors have to be defined in +L+ terms of HOAS operations as well. Because of this, these defini- +L+ tions are often far from straightforward.
It is important to emphasize that the tricky definitions that we +L+ use here are only needed to establish the basic properties of the +L+ operations we defined. Once the basic theory is complete, we can +L+ raise the level of abstraction and no usage of this theory will +L+ ever require using any of these definitions, being aware of these +L+ definitions, or performing similar tricks again.
•	bdepth{t} computes the binding depth of term t. It is defined +L+ recursively using the Y combinator as
rXb.matchb with
Y	bnd{ } -+ 1 + f (subst{b; mk term{0; 0}})
|mkterm{ ; }-+0
In effect, this recursive function strips the outer binders from a +L+ bterm one by one using substitution (note that here we can use +L+ an arbitrary mk bterm expression as a second argument for the +L+ substitution function; the arguments to mk bterm do not have +L+ to have the “correct” type) and counts the number of times it +L+ needs to do this before the outermost mk bterm is exposed.
We derive the following properties of bdepth:
Vl, r E ICY. (bdepth {var{l; r}} ≡ (l +r + 1)); +L+ Vn E ICY.(bdepth{mk bterm{n; op; ts}} ≡ n).
Note that the latter equivalence only requires n to have the +L+ “correct” type, while op and ts may be arbitrary. Since the +L+ bdepth operator is needed for defining the type of Term of well- +L+ formed bterms, at this point we would not have been able to +L+ express what the “correct” type for ts would be.
•	left{t} is designed to compute the “left index” of a var expres- +L+ sion. It is defined as
	�	�
Xf.Xb.Xl.
match b with	�
	Y	bnd{ } -+
�1 + f (subst{b; mk term {l; 0}})(l + 1) � � +L+ |mk term{lf; ) -+ lf
In effect, this recursive function substitutes mk term{0; 0} +L+ for the first binding of t, mk term{1; 0} for the second one, +L+ mk term{2; 0} for the next one and so forth. Once all the binders +L+ are stripped and a mk term{l; 0} is exposed, l is the index +L+ we were looking for. Note that here we intentionally supply +L+ mk term with an argument of a “wrong” type (ICY instead of +L+ Op); we could have avoided this, but then the definition would +L+ have been significantly more complicated.
As expected, we derive that
Vl, r E ICY.(left{var{l; r}} ≡ l).
•	right{t} computes the “right index” of a var expression. It +L+ is trivial to define in terms of the previous two operators: +L+ right{t}:= bdepth{t} − left{t} − 1.
•	get op{t; op} is an operation such that
Vn E ICY.(get op{mk bterm{n; op; ts} ; opf) ≡ op),
Vl, r E ICY. ((get op{var{i; j} ; op} ≡ op).
Its definition is similar to that of left{}.
•	subterms{t} is designed to recover the last argument of a +L+ mk bterm expression. The definition is rather technical and +L+ complicated, so we omit it; see [NKYH05, Appendix C] for +L+ details. The main property of the subterms operation that we +L+ derive is
Vn E ICY.Vbtl E List.(subterms{mk bterm{n; op; btl}} ≡ +L+ map Xb.vbnd{n; v.vsubst{b; v}} btl)
The right-hand side of this equivalence is not quite the plain +L+ “btl” that one might have hoped to see here. However, when +L+ btl is a list of bterms with binding depths at least n, which is +L+ necessarily the case for any well-formed mk bterm{n; op; btl}, +L+ equivalence (8) would allow simplifying this right-hand side to +L+ the desired btl.
4.5 Operators
For this basic theory the exact representation details for operators +L+ are not essential and we define the type of operators Op abstractly. +L+ We only require that operators have decidable equality and that +L+ there exist a function of the type Op -+ ICY List that computes +L+ operators’ shapes.
Using this shape function and the bdepth function from Sec- +L+ tion 4.4, it is trivial to formalize the “ts is compatible with op at +L+ depth n” predicate of Definition 4. We denote this predicate as +L+ shape compat{n; op; ts} and define it as
|shape{op}| = |btl|A
Vi E 1..|btl|.bdepth{nth{btl; i}} = n +nth{shape{op}; i}
4.6 The Type of Terms
In this section we will define the type of terms (i.e. well-formed +L+ bterms), Term, as the type of all terms that can be constructed by +L+ the de Bruijn constructors from Section 4.4. That is, the Term type +L+ contains all expressions of the forms:
•	var{i; j} for all natural numbers i, j; or
)t
t0
8
• mk bterm{n; op; ts} for any natural number n, operator op, and +L+ list of terms ts that is compatible with op at depth n.
The Term type is defined as a fixpoint of the following function +L+ from types to types:
Iter(X) := Image(dom(X); x.mk(x)),
where
•	Image is a type constructor such that Image(T; x. f [xl) is the +L+ type of all the f [tl for t e T (for it to be well-formed, T must +L+ be a well-formed type and f must not have any free variables +L+ except for x);
•	dom(X) is a type defined as
(N×N)+(n:N× op:Op× {ts:X List I shape compat{n; op; ts}});
•	and mk(x) (where x is presumably a member of the type +L+ dom(X)) is defined as
matchx with
inl (i, j) -+ var{i ; j}
Iinr (n, op, ts) -+ mk bterm{n; op; ts} .
The fixpoint of Iter is reached by defining
•	Term0 := Void (an empty type)
•	Termn+1 := Iter(Termn)
•	Term := U Termn
neN
We derive the intended introduction rules for the Term type:
i eN	j eN
var{i ; j} e Term
and
n e N op e Op ts e TermList shape compat{n; op; ts}
.
mk bterm{n; op; ts} e Term
Also, the structural induction principle is derived for the Term +L+ type. Namely, we show that to prove that some property P[tl holds +L+ for any term t, it is sufficient to prove
•	(Base case) P holds for all variables, that is, P[var{i ; j}l holds +L+ for all natural numbers i and j;
•	(Induction step) P[mk bterm{n; op; ts}l is true for any natural +L+ number n, any operator op, and any list of terms ts that is +L+ compatible with op at depth n, provided P[tl is true for any +L+ element t of the list ts.
Note that the type of “terms over n variables” (where n = 0 cor- +L+ responds to closed terms) may be trivially defined using the Term +L+ type and the “subset” type constructor — {t : Term II bdepth{t} = +L+ n}.
5. Conclusions and Future Work
In Sections 3 and 4 we have presented a basic theory of syntax +L+ that is fully implemented in a theorem prover. As we mentioned in +L+ the introduction, the approach is both natural and expressive, and +L+ provides a foundation for reflective reasoning about classes of lan- +L+ guages and logics. However, we consider this theory to be only +L+ the first step towards building a user-accessible uniform reflection +L+ framework and a user-accessible uniform framework for program- +L+ ming language reasoning and experimentation, where tasks similar +L+ to the ones presented in the POPLMARK challenge [ABF+05] can +L+ be performed easily and naturally. In this section we provide an out- +L+ line of our plans for building such frameworks on top of the basic +L+ syntactic theory.
5.1 Higher-Level User Interface
One obvious shortcoming of the theory presented in Sections 3 +L+ and 4 is that it provides only the basic low-level operations such +L+ as bnd, var, subterms, etc. It presents a very low-level account of +L+ syntax in a way that would often fail to abstract away the details +L+ irrelevant to the user.
To address this problem we are planning to provide user in- +L+ terface functionality capable of mapping the high-level concepts +L+ to the low-level ones. In particular, we are going to provide an +L+ interface that would allow instantiating general theorems to spe- +L+ cific collections of operators and specific languages. Thus, the user +L+ will be able to write something like “reflect language [Xx..; +L+ apply{.; .}] ” and the system will create all the components outlined +L+ in Example 1:
•	It will create a definition for the type
Language[Xx..; apply{.; .}l
of reflected lambda-terms (where Language[ll is a general def- +L+ inition of a language over a list of operators l);
•	It will state and derive the introduction rules for this type;
•	It will state and derive the elimination rule for this type (the +L+ induction principle).
Moreover, we are planning to support even more complicated lan- +L+ guage declarations, such as
t := int I t -+ t; e := v I Xx : t.e[xl I apply{e; e}
that would cause the system to create mutually recursive type +L+ definitions and appropriate rules.
Finally, we are also planning to support “pattern bindings” that +L+ are needed for a natural encoding of ML-like pattern matching +L+ (such as the one sketched in the POPLMARK challenge [ABF+05]). +L+ As far as the underlying theory goes, we believe that the mecha- +L+ nisms very similar to the “vector bindings” presented in Section 4.3 +L+ will be sufficient here.
5.2 “Dereferencing” Quoted Terms
As in Barzilay’s work, the quoted operator approach makes it easy +L+ to define the “unquoting” (or “dereferencing”) operator [lunq. If t +L+ is a syntactic term, then [tllunq is the value represented by t. By +L+ definition,
[op{t1; ... ; tn}lunq = op{[t1lunq; ... ; [tnllunq}.
For instance, [2 * 3lunq is 2 * 3 (i.e. 6).
In order to define unquoting on terms with bindings, we need to +L+ introduce the “guard” operation hp pi such that [bt)llunq is t for an +L+ arbitrary expression t. Then [lunq can be defined as follows:
[op{x1, ..., xk.t[x1; ... ; xkl; ... ;z1, ..., zl.s[z1; ... ; zll}lunq = +L+ op{x1, . . . ,xk.[[t[(ix1 ; ... ; Ixk�llunq;
. . .	;
z1, . . . , zl.[s[(z1�� ; ... ; (1zl�llunq}.
For example, [[Xx.2*xlunq = Xx.[2*��x�llunq = Xx.[2lunq * +L+ [bx)lunq =Xx.2 * x.
The unquote operation establishes the identity between the orig- +L+ inal syntax and the reflected syntax, making it a “true” reflection.
Note that the type theory (which ensures, in particular, that +L+ only terminating functions may be shown to belong to a function +L+ type) would keep the [ llunq operation from introducing logical +L+ paradoxes.3
3 This is, obviously, not a proper argument. While a proper argument can be +L+ made here, it is outside of the scope of this particular paper.
9
Also, since the notion of the quoted operators is fully open- +L+ ended, each new language added to the system will automatically +L+ get to use the Q lunq operation for all its newly introduced opera- +L+ tors.
5.3 Logical Reflection
After defining syntactic reflection, it is easy to define logical reflec- +L+ tion. If we consider the proof system open-ended, then the logical +L+ reflection is trivial — when P is a quotation of a proposition, we +L+ can regard “QPlunq” as meaning “P is true”. The normal modal +L+ rules for the Qlunq modality are trivially derivable. For example +L+ modus ponens
QP  =:�  Qlunq =:� QPlunq =:� QQQlunq
is trivially true because if we evaluate the first Qllunq (remember,
QP =:� Qlunq = (QPlunq =:� QQlunq)
by definition of Qlunq), we get an obvious tautology +L+ (QPlunq =:� QQQlunq) =:� QPlunq =:� QQlunq.
In order to consider a closed proof system (in other words, if +L+ we want to be able to do induction over derivations), we would +L+ need to define a provability predicate for that system. We are +L+ planning to provide user interface functionality that would allow +L+ users to describe a set of proof rules and the system would generate +L+ appropriate proof predicate definitions and derive appropriate rules +L+ (in a style similar to the one outlined in Section 5.1 for the case of +L+ language descriptions).
6. Related Work
In Section 2 we have already discussed a number of approaches +L+ that we consider ourselves inheriting from. Here we would like to +L+ revisit some of them and mention a few other related efforts.
Our work has a lot in common with the HOAS implemented in +L+ Coq by Despeyroux and Hirschowitz [DH94]. In both cases, the +L+ more general space of terms (that include the exotic ones) is later +L+ restricted in a recursive manner. In both cases, the higher-order +L+ analogs of first-order de Bruijn operators are defined and used as a +L+ part of the “well-formedness” specification for the terms. Despey- +L+ roux and Hirschowitz use functions over infinite lists of variables +L+ to define open terms, which is similar to our vector bindings.
There are a number of significant differences as well. Our ap- +L+ proach is sufficiently syntactical, which allows eliminating all ex- +L+ otic terms, even those that are extensionally equal to the well- +L+ formed ones, while the more semantic approach of [DH94, +L+ DFH95] has to accept such exotic terms (their solution to this prob- +L+ lem is to consider an object term to be represented by the whole +L+ equivalence class of extensionally equal terms); more generally +L+ while [DH94] states that “this problem of extensionality is recur- +L+ rent all over our work”, most of our lemmas establish identity and +L+ not just equality, thus avoiding most of the issues of extensional +L+ equality. In our implementation, the substitution on object terms is +L+ mapped directly to P-reduction, while Despeyroux et al. [DFH95] +L+ have to define it recursively. In addition, we provide a uniform ap- +L+ proach to both free and bound variables that naturally extends to +L+ variable-length “vector” bindings.
While our approach is quite different from the modal X-calculus +L+ one [DPS97, DL99, DL01], there are some similarities in the in- +L+ tuition behind it. Despeyroux et al. [DPS97] says “Intuitively, we
interpret ❑B as the type of closed objects of type B. We can iter-
ate or distinguish cases over closed objects, since all constructors +L+ are statically known and can be provided for.” The intuition be- +L+ hind our approach is in part based on the canonical model of the +L+ NuPRL type theory [All87a, All87b], where each type is mapped +L+ to an equivalence relations over the closed terms of that type.
Gordon and Melham [GM96] define the type of X-terms as a +L+ quotient of the type of terms with concrete binding variables over +L+ a-equivalence. Michael Norrish [Nor04] builds upon this work by +L+ replacing certain variable “freshness” requirements with variable +L+ “swapping”. This approach has a number of attractive properties; +L+ however, we believe that the level of abstraction provided by the +L+ HOAS-style approaches makes the HOAS style more convenient +L+ and accessible.
Ambler, Crole, and Momigliano [ACM02] have combined the +L+ HOAS with the induction principle using an approach which in +L+ some sense is opposite to ours. Namely, they define the HOAS +L+ operators on top of the de Bruijn definition of terms using higher +L+ order pattern matching. In a later work [ACM03] they have de- +L+ scribed the notion of “terms-in-infinite-context” which is quite sim- +L+ ilar to our approach to vector binding. While our vector bindings +L+ presented in Section 4.3 are finite length, the exact same approach +L+ would work for the infinite-length “vectors” as well.
Acknowledgments
The authors are grateful to Eli Barzilay whose ideas were an in- +L+ spiration for some of the work that lead to this paper. We are also +L+ grateful for his comments on an early draft of this paper.
We are grateful to the anonymous reviewers for their very thor- +L+ ough and fair feedback and many helpful suggestions.
References
[AA99] Eric Aaron and Stuart Allen. Justifying calculational logic
by a conventional metalinguistic semantics. Technical Report +L+ TR99-1771, Cornell University, Ithaca, New York, September +L+ 1999.
[ABF+05] Brian E. Aydemir, Aaron Bohannon, Matthew Fairbairn, +L+ J. Nathan Foster, Benjamin C. Pierce, Peter Sewell, Dimitrios +L+ Vytiniotis, Geoffrey Washburn, Stephanie Weirich, and Steve +L+ Zdancewic. Mechanized metatheory for the masses: The +L+ POPLmark challenge. Available fromhttp://www.cis. +L+ upenn.edu/group/proj/plclub/mmm/,2005.
[AC92] William Aitken and Robert L. Constable. Reflecting on
NuPRL : Lessons 1–4. Technical report, Cornell University, +L+ Computer Science Department, Ithaca, NY, 1992.
[ACE+00] Stuart Allen, Robert Constable, Richard Eaton, Christoph +L+ Kreitz, and Lori Lorigo. The NuPRL open logical envi- +L+ ronment. In David McAllester, editor, Proceedings of the +L+ 17th International Conference on Automated Deduction, vol- +L+ ume 1831 of Lecture Notes in Artificial Intelligence, pages +L+ 170–176. Springer Verlag, 2000.
[ACHA90] Stuart F. Allen, Robert L. Constable, Douglas J. Howe, +L+ and William Aitken. The semantics of reflected proof. In +L+ Proceedings of the 5th Symposium on Logic in Computer +L+ Science, pages 95–197. IEEE Computer Society Press, June +L+ 1990.
[ACM02] Simon Ambler, Roy L. Crole, and Alberto Momigliano.
Combining higher order abstract syntax with tactical theorem +L+ proving and (co)induction. In TPHOLs ’02: Proceedings +L+ of the 15th International Conference on Theorem Proving +L+ in Higher Order Logics, pages 13–30, London, UK, 2002. +L+ Springer-Verlag.
[ACM03] S. J. Ambler, R. L. Crole, and Alberto Momigliano. A
definitional approach to primitive recursion over higher +L+ order abstract syntax. In Proceedings of the 2003 workshop +L+ on Mechanized reasoning about languages with variable +L+ binding, pages 1–11. ACM Press, 2003.
[ACU93] William Aitken, Robert L. Constable, and Judith Underwood.
Metalogical Frameworks II: Using reflected decision pro- +L+ cedures.Journal of Automated Reasoning, 22(2):171–221, +L+ 1993.
10
[All87a]	Stuart F. Allen. A Non-type-theoretic Definition of Martin-
L¨of’s Types. In D. Gries, editor, Proceedings ofthe 2nd IEEE +L+ Symposium on Logic in Computer Science, pages 215–224. +L+ IEEE Computer Society Press, June 1987.
[All87b]	Stuart F. Allen. A Non-Type-Theoretic Semantics for Type-
Theoretic Language. PhD thesis, Cornell University, 1987.
[Art99]	Sergei Artemov. On explicit reflection in theorem proving
and formal verification. In Ganzinger [Gan99], pages 267– +L+ 281.
[Art04]	Sergei Artemov. Evidence-based common knowledge.
Technical Report TR-2004018, CUNY Ph.D. Program in +L+ Computer Science Technical Reports, November 2004.
[BA02]	Eli Barzilay and Stuart Allen. Reflecting higher-order abstract
syntax in NuPRL. In Victor A. Carre˜no, C´ezar A. Mu˜noz, +L+ and Sophi`ene Tahar, editors, Theorem Proving in Higher +L+ Order Logics; Track B Proceedings of the 15th International +L+ Conference on Theorem Proving in Higher Order Logics +L+ (TPHOLs 2002), Hampton, VA, August 2002, pages 23–32. +L+ National Aeronautics and Space Administration, 2002.
[BAC03]	Eli Barzilay, Stuart Allen, and Robert Constable. Practical
reflection in NuPRL. Short paper presented at 18th Annual +L+ IEEE Symposium on Logic in Computer Science, June 22– +L+ 25, Ottawa, Canada, 2003.
[Bar01]	Eli Barzilay. Quotation and reflection in NuPRL and Scheme.
Technical Report TR2001-1832, Cornell University, Ithaca, +L+ New York, January 2001.
[Bar05]	Eli Barzilay. Implementing Reflection in NuPRL. PhD thesis,
Cornell University, 2005. In preparation.
[CAB+86] Robert L. Constable, Stuart F. Allen, H. M. Bromley, W. R. +L+ Cleaveland, J. F. Cremer, R. W. Harper, Douglas J. Howe, +L+ T. B. Knoblock, N. P. Mendler, P. Panangaden, James T. +L+ Sasaki, and Scott F. Smith. Implementing Mathematics with +L+ the NuPRL ProofDevelopment System. Prentice-Hall, NJ, +L+ 1986.
[CFW04]	Luis Crus-Filipe and Freek Weidijk. Hierarchical reflection.
In Slind et al. [SBG04], pages 66–81.
[Con94]	Robert L. Constable. Using reflection to explain and enhance
type theory. In Helmut Schwichtenberg, editor, Proof and +L+ Computation, volume 139 of NATO Advanced Study Insti- +L+ tute, International Summer School held in Marktoberdorf, +L+ Germany, July 20-August 1, NATO Series F, pages 65–100. +L+ Springer, Berlin, 1994.
[dB72]	N. G. de Bruijn. Lambda calculus notation with nameless
dummies, a tool for automatic formula manipulation, with +L+ application to the Church-Rosser theorem. Indagaciones +L+ Mathematische, 34:381–392, 1972. This also appeared in the +L+ Proceedings of the Koninklijke Nederlandse Akademie van +L+ Wetenschappen, Amsterdam, series A, 75, No. 5.
[DFH95]	Jo¨elle Despeyroux, Amy Felty, and Andr´e Hirschowitz.
Higher-order abstract syntax in Coq. In M. Dezani- +L+ Ciancaglini and G. Plotkin, editors, Proceedings of the +L+ International Conference on Typed Lambda Calculus and +L+ its Applications, volume 902 of Lecture Notes in Computer +L+ Science, pages 124–138. Springer-Verlag, April 1995. Also +L+ appears as INRIA research report RR-2556.
[DH94]	Jo¨elle Despeyroux and Andr´e Hirschowitz. Higher-order
abstract syntax with induction in Coq. In LPAR ’94: +L+ Proceedings of the 5th International Conference on Logic +L+ Programming and Automated Reasoning, volume 822 +L+ of Lecture Notes in Computer Science, pages 159–173. +L+ Springer-Verlag, 1994. Also appears as INRIA research +L+ report RR-2292.
[DH95]	James Davis and Daniel Huttenlocher. Shared annotations for
cooperative learning. In Proceedings of the ACM Conference +L+ on Computer Supported Cooperative Learning, September +L+ 1995.
[DL99]	Jo¨elle Despeyroux and Pierre Leleu. A modal lambda
calculus with iteration and case constructs. In T. Altenkirch, +L+ W. Naraschewski, and B. Reus, editors, Types for Proofs +L+ and Programs: International Workshop, TYPES ’98, Kloster +L+ Irsee, Germany, March 1998, volume 1657 of Lecture Notes +L+ in Computer Science, pages 47–61, 1999.
[DL01]	Jo¨elle Despeyroux and Pierre Leleu. Recursion over objects
of functional type. Mathematical Structures in Computer +L+ Science, 11(4):555–572, 2001.
[DPS97]	Jo¨elle Despeyroux, Frank Pfenning, and Carsten Sch¨urmann.
Primitive recursion for higher–order abstract syntax. In +L+ R. Hindley, editor, Proceedings of the Third International +L+ Conference on Typed Lambda Calculus and Applications +L+ (TLCA’97), volume 1210 of Lecture Notes in Computer +L+ Science, pages 147–163. Springer-Verlag, April 1997. An +L+ extended version is available as Technical Report CMU-CS- +L+ 96-172, Carnegie Mellon University.
[EM71]	Andrzej Ehrenfeucht and Jan Mycielski. Abbreviating
proofs by adding new axioms. Bulletin of the American +L+ Mathematical Society, 77:366–367, 1971.
[F+86]	Solomon Feferman et al., editors. Kurt G¨odel Collected
Works, volume 1. Oxford University Press, Oxford, +L+ Clarendon Press, New York, 1986.
[FPT99]	Marcelo Fiore, Gordon Plotkin, and Daniele Turi. Abstract
syntax and variable binding. In Proceedings of 14th IEEE +L+ Symposium on Logic in Computer Science, pages 193+. IEEE +L+ Computer Society Press, 1999.
[Gan99]	Harald Ganzinger, editor. Proceedings of the 16th Interna-
tional Conference on Automated Deduction, volume 1632 +L+ of Lecture Notes in Artificial Intelligence, Berlin, July 7–10 +L+ 1999. Trento, Italy.
[GM96]	A. D. Gordon and T. Melham. Five axioms of alpha-
conversion. In J. von Wright, J. Grundy, and J. Harrison, +L+ editors, Theorem Proving in Higher Order Logics: 9th +L+ International Conference, Turku, Finland, August 1996: +L+ Proceedings, volume 1125 of Lecture Notes in Computer +L+ Science, pages 173–190. Springer-Verlag, 1996.
[GMO03] Jim Grundy, Tom Melham, and John O’Leary. A reflective +L+ functional language for hardware design and theorem +L+ proving. Technical Report PRG-RR-03-16, Oxford Univerity, +L+ Computing Laboratory, 2003.
[G¨od31 ]	Kurt G¨odel. ¨Uber formal unentscheidbare s¨atze der principia
mathematica und verwandter systeme I. Monatshefte f¨ur +L+ Mathematik und Physik, 38:173–198, 1931. English version +L+ in [vH67].
[G¨od36]	K. G¨odel. ¨Uber die L¨ange von beweisen. Ergebnisse
eines mathematischen Kolloquiums, 7:23–24, 1936. English +L+ translation in [F+86], pages 397–399.
[GS89]	F. Giunchiglia and A. Smaill. Reflection in constructive
and non-constructive automated reasoning. In H. Abramson +L+ and M. H. Rogers, editors, Meta-Programming in Logic +L+ Programming, pages 123–140. MIT Press, Cambridge, +L+ Mass., 1989.
[GWZ00] H. Geuvers, F. Wiedijk, and J. Zwanenburg. Equational rea- +L+ soning via partial reflection. In J. Harrison and M. Aagaard, +L+ editors, Theorem Proving in Higher Order Logics: 13th Inter- +L+ national Conference, TPHOLs 2000, volume 1869 of Lecture +L+ Notes in Computer Science, pages 162–178. Springer-Verlag, +L+ 2000.
[HAB+]	Jason J. Hickey, Brian Aydemir, Yegor Bryukhov, Alexei
Kopylov, Aleksey Nogin, and Xin Yu. A listing of Meta PRL +L+ theories. http://metaprl.org/theories.pdf.
[Har95]	J. Harrison. Metatheory and reflection in theorem proving:
A survey and critique. Technical Report CRC-53, SRI +L+ International, Cambridge Computer Science Research +L+ Centre, Millers Yard, Cambridge, UK, February 1995.
11
[HHP93]	Robert Harper, Furio Honsell, and Gordon Plotkin. A
framework for defining logics. Journal of the Association +L+ for Computing Machinery, 40(1):143–184, January 1993. A +L+ revised and expanded verion of ’87 paper.
[Hic97]	Jason J. Hickey. NuPRL-Light: An implementation
framework for higher-order logics. In William McCune, +L+ editor, Proceedings of the 14th International Conference +L+ on Automated Deduction, volume 1249 of Lecture Notes in +L+ Artificial Intelligence, pages 395–399. Springer, July 13–17 +L+ 1997. An extended version of the paper can be found at +L+ http://www.cs.caltech.edu/~jyh/papers/cade14_ +L+ nl/default.html.
[Hic99]	Jason J. Hickey. Fault-tolerant distributed theorem proving.
In Ganzinger [Gan99], pages 227–231.
[Hic01]	Jason J. Hickey. The MetaPRL Logical Programming
Environment. PhD thesis, Cornell University, Ithaca, NY, +L+ January 2001.
[HL78]	G´erard P. Huet and Bernard Lang. Proving and applying
program transformations expressed with second-order +L+ patterns. Acta Informatica, 11:31–55,1978.
[HNC+03] Jason Hickey, Aleksey Nogin, Robert L. Constable, +L+ Brian E. Aydemir, Eli Barzilay, Yegor Bryukhov, Richard +L+ Eaton, Adam Granicz, Alexei Kopylov, Christoph Kreitz, +L+ Vladimir N. Krupski, Lori Lorigo, Stephan Schmitt, Carl +L+ Witty, and Xin Yu. MetaPRL — A modular logical en- +L+ vironment. In David Basin and Burkhart Wolff, editors, +L+ Proceedings of the 16th International Conference on Theo- +L+ rem Proving in Higher OrderLogics (TPHOLs 2003), volume +L+ 2758 of Lecture Notes in Computer Science, pages 287–303. +L+ Springer-Verlag, 2003.
[HNK+]	Jason J. Hickey, Aleksey Nogin, Alexei Kopylov, et al.
MetaPRL home page. http://metaprl.org/.
[Mos52]	Andrzej Mostowski. Sentences undecidable in formalized
arithmetic: an exposition of the theory of Kurt G¨odel. +L+ Amsterdam: North-Holland, 1952.
[NH02]	Aleksey Nogin and Jason Hickey. Sequent schema for
derived rules. In Victor A. Carre˜no, C´ezar A. Mu˜noz, +L+ and Sophi`ene Tahar, editors, Proceedings of the 15th +L+ International Conference on Theorem Proving in Higher +L+ Order Logics (TPHOLs 2002), volume 2410 of Lecture Notes +L+ in Computer Science, pages 281–297. Springer-Verlag, 2002.
[NKYH05] Aleksey Nogin, Alexei Kopylov, Xin Yu, and Jason Hickey. +L+ A computational approach to reflective meta-reasoning +L+ about languages with bindings. Technical Report Cal- +L+ techCSTR:2005.003, California Institure of Technology, +L+ 2005. Available at http://resolver.caltech.edu/ +L+ CaltechCSTR:2005.003.
[Nor04]	Michael Norrish. Recursive function definition for types with
binders. In Slind et al. [SBG04], pages 241–256.
[Par71]	R. Parikh. Existence and feasibility in arithmetic. The Journal
ofSymbolic Logic, 36:494–508,1971.
[Pau94]	Lawrence C. Paulson. Isabelle: A Generic Theorem Prover,
volume 828 of Lecture Notes in Computer Science. Springer- +L+ Verlag, New York, 1994.
[PE88]	Frank Pfenning and Conal Elliott. Higher-order abstract
syntax. In Proceedings oftheACMSIGPLAN’88 Conference +L+ on Programming Language Design and Implementation +L+ (PLDI), volume 23(7) of SIGPLANNotices, pages 199–208, +L+ Atlanta, Georgia, June 1988. ACM Press.
[Pfe89]	Frank Pfenning. Elf: a language for logic definition and
verified metaprogramming. In Proceedings of the 4th IEEE +L+ Symposium on Logic in Computer Science, pages 313–322, +L+ Asilomar Conference Center, Pacific Grove, California, June +L+ 1989. IEEE Computer Society Press.
[Plo90]	Gordon Plotkin. An illative theory of relations. In R. Cooper,
K. Mukai, and J. Perry, editors, Situation Theory and Its +L+ Applications, Volume 1, number 22 in CSLI Lecture Notes, +L+ pages 133–146. Centre for the Study of Language and +L+ Information, 1990.
[PN90]	L. Paulson and T. Nipkow. Isabelle tutorial and user’s man-
ual. Technical report, University of Cambridge Computing +L+ Laboratory, 1990.
[SBG04]	Konrad Slind, Annette Bunker, and Ganesh Gopalakrishnan,
editors. Proceedings of the 17th International Conference +L+ on Theorem Proving in Higher Order Logics (TPHOLs +L+ 2004), volume 3223 of Lecture Notes in Computer Science. +L+ Springer-Verlag, 2004.
[Sch01]	Carsten Sch¨urmann. Recursion for higher-order encodings.
In L. Fribourg, editor, Computer Science Logic, Proceedings +L+ of the 10th Annual Conference of the EACSL, volume 2142 +L+ of Lecture Notes in Computer Science, pages 585–599. +L+ Springer-Verlag, 2001.
[Smi84]	B.C. Smith. Reflection and semantics in Lisp. Principles of
Programming Languages, pages 23–35, 1984.
[vH67]	J. van Heijenoort, editor. From Frege to G¨odel: A Source
Book in Mathematical Logic, 1879–1931. Harvard University +L+ Press, Cambridge, MA, 1967.
12
