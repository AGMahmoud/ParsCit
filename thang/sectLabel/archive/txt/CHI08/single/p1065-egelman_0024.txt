CHI 2008 Proceedings · Am I Safe	April 5-10, 2008 · Florence, Italy
The SiteKey system was introduced in 2005 to simplify au-
thentication by not forcing the user to install additional soft-
ware. SiteKey uses a system of visual authentication images 
that are selected by the user at the time of enrollment. When 
the user enters his or her username, the image is displayed. 
If the user recognizes the image as the original shared secret, 
it is safe to enter the password [2]. However, a recent study 
found that 92% of participants still logged in to the website 
using their own credentials when the correct image was not 
present [19]. However, this sample may have been drawn 
from a biased population since others refused to participate, 
citing privacy and security concerns.
Some argue that the use of extended validation (EV) certifi-
cates may help users detect phishing websites. An EV cer-
tificate differs from a standard SSL certificate because the 
website owner must undergo background checks. A regular 
certificate only tells a user that the certificate was granted 
by a particular issuing authority, whereas an EV certificate 
also says that it belongs to a legally recognized company [4]. 
The newest version of Microsoft’s Internet Explorer sup-
ports EV certificates, coloring the URL bar green and dis-
playing the name of the company. However, a recent study 
found that EV certificates did not make users less likely to 
fall for phishing attacks. The study also found that after 
reading a help file, users were less suspicious of fraudulent 
websites that did not yield warning indicators [13].
Many web browser extensions for phishing detection cur-
rently exist. Unfortunately, a recent study on anti-phishing 
toolbar accuracy found that these tools fail to identify a sub-
stantial proportion of phishing websites [26]. A 2006 study 
by Wu et al. found that the usability of these tools is also 
lacking because many of them use passive indicators. Many 
users fail to notice the indicators, while others often do not 
trust them because they think the sites look trustworthy [23].
A MODEL FOR WARNINGS
In this paper we will analyze our user study results using 
a model from the warnings sciences. Computer scientists 
can benefit from studies in this field. Many studies have ex-
amined “hazard matching” and “arousal strength.” Hazard 
matching is defined as accurately using warning messages to 
convey risks—if a warning does not adequately convey risk, 
the user may not take heed of the warning. Arousal strength 
is defined as the perceived urgency of the warning [12].
To date, few studies have been conducted to evaluate the 
arousal strength of software warnings. In one study of warn-
ing messages used in Microsoft Windows, researchers found 
that using different combinations of icons and text greatly af-
fected participants’ risk perceptions. Participants were shown 
a series of dialog boxes with differing text and icons, and 
were instructed to estimate the severity of the warnings us-
ing a 10-point Likert scale. The choice of icons and words 
greatly affected how each participant ranked the severity. 
The researchers also examined the extent to which individu-
als will continue to pay attention to a warning after seeing it 
multiple times (“habituation”). They found that users dis-
missed the warnings without reading them after they had 
seen them multiple times. This behavior continued even
Figure 4. Diagram of the different phases of the C-HIP model [21].
when using a similar but different warning in a different sit-
uation. The only way of recapturing the user’s attention was 
to increase the arousal strength of the warning [1].
Wogalter proposed the Communication-Human Information 
Processing Model (C-HIP) for structuring warning research, 
as shown in Figure 4. He suggests that C-HIP be used to 
identify reasons that a particular warning is ineffective [21]. 
The C-HIP model begins with a source delivering a warning 
through a channel to a receiver, who receives it along with 
other environmental stimuli that may distract from the mes-
sage. The receiver goes through five information processing 
steps, which ultimately determine whether the warning re-
sults in any change in behavior.
We can ask the following questions to examine the different 
steps in Wogalter’s model [5]:
1. Attention Switch and Maintenance — Do users notice the 
indicators?
2. Comprehension/Memory — Do users know what the indi-
cators mean?
3. Comprehension/Memory — Do users know what they are 
supposed to do when they see the indicators?
4. Attitudes/Beliefs — Do they believe the indicators?
5. Motivation — Are they motivated to take the recommended 
actions?
6. Behavior — Will they actually perform those actions? 
7. Environmental Stimuli — How do the indicators interact 
with other indicators and other stimuli?
Observing users as they complete a task while thinking aloud 
provides insights into most of the above questions. Alterna-
tively, users can complete tasks and then fill out post-task 
questionnaires or participate in interviews, although these 
require users to remember why they did something and re-
port it afterwards, and users sometimes say what they think
Environmental
Stimuli
Comprehension
Memory
Attention 
Maintenance
Motivation
Attention 
Switch
Attitudes 
Beliefs
Behavior
Channel
Delivery
Source
1067
