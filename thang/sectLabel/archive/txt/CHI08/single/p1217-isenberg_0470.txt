CHI 2008 Proceedings · Visualization to Support Information Work	April 5-10, 2008 · Florence, Italy
FINDINGS
In this section, we outline our understanding of the collabora-
tive and individual visual analysis process we uncovered dur-
ing our analysis. We follow this by illustrating how the pro-
cesses themselves were not temporally organized in a consis-
tent way across groups. In the next section, we relate these 
findings to prior work, and discuss how they can inform the 
design of information visualization tools.
Processes in Visual Information Analysis
Our analysis revealed eight processes common to how par-
ticipants completed the tasks in our study (summarized in 
Table 2). We describe each process using real examples 
drawn from our study, discussing participants’ interactions 
with one another and the workspace, and elaborate on how 
the processes differed between group types. Where average 
process times are reported these are an aggregation of sev-
eral instances of particular processes during both scenarios.
Browse:
The browsing process comprises activities involving scan-
ning through data to get a feel for the available informa-
tion. Browsing activities do not involve a specific search 
related to a task; instead, the main goal is to gain some un-
derstanding of the data set. For example, we observed par-
ticipants quickly glancing through or scanning the informa-
tion artefacts—likely to see what types of charts were avail-
able and the variables in the charts. Five participants took 
the complete pile of charts and flipped through them in their 
hands, while 11 others created an elaborate layout of cards 
on the table. Figure 3 shows an example in which two par-
ticipants use two very different browsing strategies. One par-
ticipant (bottom of image) lays the two overview charts out 
in front of him, flipping through the remaining cards in his 
hand, while the other participant creates a small-multiples 
overview of the cards on the table as he browses through 
them one at a time. Groups were slightly more efficient than
individuals (average browsing times were ,: 30s for groups,
and ;::Li 60s for individuals), perhaps indicating that, for indi-
viduals, having a completely clear sense of the data is more 
important, whereas groups can rely on others. In one case, 
we observed one participant in a group of three who did not 
browse through the data himself; instead, he watched as his 
partners laid their cards out on the table.
(a) Start of a browsing session. (b) End of a browsing session.
Figure 3. Different browsing strategies: the participant on the
right creates an overview layout; the participant on the bottom
laid out the overview charts and is flipping through the
remaining data charts in his hands.
Parse:
The parsing process captures the reading or re-reading of the 
task description in an attempt to understand how to solve the 
problem. Participants read the task description both quietly 
or aloud, and in teams, this choice reflected the collabora-
tion style that teams adopted. For instance, teams working 
closely together would read task descriptions aloud, facilitat-
ing joint awareness of the state of the activity, and discus-
sion of how to interpret the question. On average, pairs and 
triples spent 2.5 min reading and re-reading the task descrip-
tion; however, individuals referred to the task sheet more fre-
quently (10 times vs. 9 times in pairs and 7 times for triples 
in total). While many real-world information analysis sce-
narios may not have a concrete problem description sheet, 
an assessment of the given problem(s) and the required vari-
ables can certainly still occur and would be considered part 
of this process. The problem sheet can be seen as external 
textual information that is not part of the current dataset but 
provides meta information on the problem, tasks, or data.
Discuss Collaboration Style:
Five teams explicitly discussed their overall task division 
strategy. We observed three main collaboration strategies:
•	Complete task division. Participants divided tasks between 
themselves to avoid duplicating work. Each participant 
worked alone with his or her information artefacts on a sep-
arate subset of the problems. Results would be combined 
at the end without much further group validation.
•	Independent, parallel work. Participants worked concur-
rently on the same tasks but independently of each other. 
When one participant had found an answer, solution and 
approach were compared and discussed. Other participants 
might then validate the solution by retracing the approach 
with their own artefacts, or by carefully examining a part-
ner’s information artefacts.
•	Joint work. Participants talked early about strategies on 
how to solve the task, and then participants went on to 
work closely together (in terms of conversation and provid-
ing assistance) using primarily their own information arte-
facts. When one person found a solution, information arte-
facts were shared and solutions were validated together.
Interestingly, while teams might explicitly discuss a collabo-
ration style, all 8 teams changed their collaboration strategy 
midway through a task scenario or between scenarios. A 
combination of parallel and joint work strategies was used 
by six teams and two others used a combination of task di-
vision/parallel and task division/joint work. Six of the eight 
teams started with a loose definition of doing the tasks “to-
gether.” Strategy discussions were brief: &lt; 1 min on average 
per scenario. Most of the changes in task strategy were quite 
seamless, and did not require any formal re-negotiation. This 
is echoed in the post-session questionnaire in which two par-
ticipants reported to have chosen their strategy “intuitively” 
and “by chance.” In general, teams showed a strong ten-
dency for parallel work: all eight groups solved at least parts 
of one scenario in parallel. 14 of 15 participants reported 
that the main reason they divided tasks this way was for per-
ceived efficiency.
1220
