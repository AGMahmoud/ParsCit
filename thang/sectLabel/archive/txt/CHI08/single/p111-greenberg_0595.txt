CHI 2008 Proceedings · Usability Evaluation Considered Harmful?	April 5-10, 2008 · Florence, Italy
4. The way innovations were taken up both in systems and 
by culture evolved considerably from the original vision 
of use: even our best visionaries had problems 
predicting how cultures would adopt technologies to 
their personal needs. Yet the vision was critical for 
stimulating work in the area.
5. Even if usability evaluations had occurred, they likely 
would have been meaningless. The underlying 
technology was immature, and any usability evaluation 
would highlight its limitations rather than its promise. 
As well, evaluations would have been based around user 
groups and task sets that would have little actual 
correspondence to how the technology would evolve in 
terms of its audience and actual uses.
Our argument is that using standard usability evaluation 
methods to validate innovations outside its culture of use is 
almost pointless (excepting for identifying slight usability 
problems). This leads to a dilemma: how can we create 
what could become culturally significant systems if we 
demand that the system be validated before a culture is 
formed around it? Indeed, this dilemma leads to a major 
frustration within CHI. We predominantly produce 
technology that is somewhat better than its antecedents, but 
these technologies rarely make it into the commercial world 
(although they may influence it somewhat). We also see 
innovative technologies that are highly successful but not 
developed by the CHI community, so we are left to evaluate 
its usability only after the fact. There is something wrong 
with this picture.
WHAT TO DO
We have argued that evaluation – while undeniably useful 
in many situations – can be harmful if applied 
inappropriately. There are several initiatives that we as a 
community can do to remedy this situation.
First, we need to recognize that usability evaluation is just 
one of the many methods that comprise our user-centered 
design toolkit, and that it should be used only when 
appropriate. As with any method, it should be brought into 
play only when the problem and the stage of UI 
development warrant it. There are many other aspects of 
user-centered design that are just as important: 
understanding requirements, considering cultural aspects, 
developing and showing clients design alternatives, 
affording new interface possibilities through technical 
innovations, and so on.
Second, we need to judge whether a usability evaluation at 
a particular point in our design cycle would produce 
anything meaningful. This means we need to continually 
reflect on our process, and consider the pros and cons. If the 
answer is ‘no’, then we should seek other methods to 
validate that stage of development. We outlined above 
several situations where this is likely: in very early design 
stages, in cases where usefulness overshadows usability, in 
instances where unpredictable cultural uptake dominates 
how an innovative system will actually be used.
Third, as a community we need to stop this blanket 
insistence on usability evaluation. This is not to say that we 
should accept hand-waving and slick demos as an 
alternative. As both an academic and practitioner 
community, we need to recognize that there are many other 
appropriate ways to validate one’s work. Examples include 
a design rationale, a vision of what could be, expected 
scenarios of use, reflections, case studies, participatory 
critique, and so on. At a minimum, authors should critique 
the design: why things were done, what else was 
considered, what they learned, expected problems, how it 
fits in the broader context of both prior art and situated 
context, what is to be done next, and so on. These are all 
criteria that would be expected in any respected design 
school or firm. There is a rigour. There is a discipline. It is 
just not the same rigour and discipline that we currently 
encourage, teach, practice or accept. Academic paper 
submissions or product descriptions should be judged by 
the question being asked, the type of system or situation 
that is being described and whether the method the 
inventors used to argue their points are reasonable.
Fourth, when usability evaluations are appropriate for 
validating research designs, we should recognize that the 
formulatic way we do our evaluations (or judge them as 
publishable) often results in weak science. We need to 
change our methods to favor rigorous science. For really 
novel innovations, existence proofs are likely appropriate. 
For mainstream systems or modest variations of established 
ideas, we should likely favor risky hypothesis testing. We 
certainly should be doing more to help others replicate our 
results (e.g., by publishing data and/or making software 
available), and we should be more open-minded about 
accepting and encouraging replications in our literature.
Fifth, we should look to other disciplines to consider how 
they judge design worthiness. One example is the practice 
of design as taught in disciplines such as architecture and 
industrial design. Both employ the notion of a design 
studio: a place where people develop ideas into artifacts, 
and where surrounding people are expected to engage in 
discussion about these artifacts as they are being formed. 
These fields recognize that early designs are just ‘sketches’ 
that illustrate an idea in flux. Sketches are meant to change 
over time, and active discussion can influence how they 
change. Early evaluation is usually through the Design 
Critique (or ‘Crit’). The designer presents the artifact to the 
group (typically a mix of senior and junior people), and 
explains why the design has unfolded the way it has. 
Members of the group respond: by articulating what they 
like and dislike about the idea, by challenging the 
designer’s assumptions through a series of probes and 
questions, and by offering concrete suggestions of ways to 
improve the design. This is a reflective and highly 
interactive process: constructive criticisms and probing 
demands that designer and criticizers alike develop and 
share a deep understanding of the design idea and how it
118
