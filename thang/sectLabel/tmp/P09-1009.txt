title ||| Unsupervised Multilingual Grammar Induction
author ||| Benjamin Snyder, Tahira Naseem, and Regina Barzilay
affiliation ||| Computer Science and Artificial Intelligence Laboratory
affiliation ||| Massachusetts Institute of Technology
email ||| {bsnyder, tahira, regina}@csail.mit.edu
sectionHeader ||| Abstract
bodyText ||| We investigate the task of unsupervised
bodyText ||| constituency parsing from bilingual par-
bodyText ||| allel corpora. Our goal is to use bilin-
bodyText ||| gual cues to learn improved parsing mod-
bodyText ||| els for each language and to evaluate these
bodyText ||| models on held-out monolingual test data.
bodyText ||| We formulate a generative Bayesian model
bodyText ||| which seeks to explain the observed par-
bodyText ||| allel data through a combination of bilin-
bodyText ||| gual and monolingual parameters. To this
bodyText ||| end, we adapt a formalism known as un-
bodyText ||| ordered tree alignment to our probabilistic
bodyText ||| setting. Using this formalism, our model
bodyText ||| loosely binds parallel trees while allow-
bodyText ||| ing language-specific syntactic structure.
bodyText ||| We perform inference under this model us-
bodyText ||| ing Markov Chain Monte Carlo and dy-
bodyText ||| namic programming. Applying this model
bodyText ||| to three parallel corpora (Korean-English,
bodyText ||| Urdu-English, and Chinese-English) we
bodyText ||| find substantial performance gains over
bodyText ||| the CCM model, a strong monolingual
bodyText ||| baseline. On average, across a variety of
bodyText ||| testing scenarios, our model achieves an
bodyText ||| 8.8 absolute gain in F-measure. 1
sectionHeader ||| 1 Introduction
bodyText ||| In this paper we investigate the task of unsuper-
bodyText ||| vised constituency parsing when bilingual paral-
bodyText ||| lel text is available. Our goal is to improve pars-
bodyText ||| ing performance on monolingual test data for each
bodyText ||| language by using unsupervised bilingual cues at
bodyText ||| training time. Multilingual learning has been suc-
bodyText ||| cessful for other linguistic induction tasks such as
bodyText ||| lexicon acquisition, morphological segmentation,
bodyText ||| and part-of-speech tagging (Genzel, 2005; Snyder
bodyText ||| and Barzilay, 2008; Snyder et al., 2008; Snyder
footnote ||| 1Code and the outputs of our experiments are available at
footnote ||| http://groups.csail.mit.edu/rbg/code/multiling induction.
bodyText ||| et al., 2009). We focus here on the unsupervised
bodyText ||| induction of unlabeled constituency brackets. This
bodyText ||| task has been extensively studied in a monolingual
bodyText ||| setting and has proven to be difficult (Charniak
bodyText ||| and Carroll, 1992; Klein and Manning, 2002).
bodyText ||| The key premise of our approach is that am-
bodyText ||| biguous syntactic structures in one language may
bodyText ||| correspond to less uncertain structures in the other
bodyText ||| language. For instance, the English sentence I
bodyText ||| saw [the student [from MIT]] exhibits the classic
bodyText ||| problem of PP-attachment ambiguity. However,
bodyText ||| its Urdu translation, literally glossed as I [[MIT of]
bodyText ||| student] saw, uses a genitive phrase that may only
bodyText ||| be attached to the adjacent noun phrase. Know-
bodyText ||| ing the correspondence between these sentences
bodyText ||| should help us resolve the English ambiguity.
bodyText ||| One of the main challenges of unsupervised
bodyText ||| multilingual learning is to exploit cross-lingual
bodyText ||| patterns discovered in data, while still allowing
bodyText ||| a wide range of language-specific idiosyncrasies.
bodyText ||| To this end, we adapt a formalism known as un-
bodyText ||| ordered tree alignment (Jiang et al., 1995) to
bodyText ||| a probabilistic setting. Under this formalism,
bodyText ||| any two trees can be embedded in an alignment
bodyText ||| tree. This alignment tree allows arbitrary parts
bodyText ||| of the two trees to diverge in structure, permitting
bodyText ||| language-specific grammatical structure to be pre-
bodyText ||| served. Additionally, a computational advantage
bodyText ||| of this formalism is that the marginalized probabil-
bodyText ||| ity over all possible alignments for any two trees
bodyText ||| can be efficiently computed with a dynamic pro-
bodyText ||| gram in linear time.
bodyText ||| We formulate a generative Bayesian model
bodyText ||| which seeks to explain the observed parallel data
bodyText ||| through a combination of bilingual and mono-
bodyText ||| lingual parameters. Our model views each pair
bodyText ||| of sentences as having been generated as fol-
bodyText ||| lows: First an alignment tree is drawn. Each
bodyText ||| node in this alignment tree contains either a soli-
bodyText ||| tary monolingual constituent or a pair of coupled
bodyText ||| bilingual constituents. For each solitary mono-
page ||| 73
note ||| Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 73–81,
note ||| Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP
bodyText ||| lingual constituent, a sequence of part-of-speech
bodyText ||| tags is drawn from a language-specific distribu-
bodyText ||| tion. For each pair of coupled bilingual con-
bodyText ||| stituents, a pair of part-of-speech sequences are
bodyText ||| drawn jointly from a cross-lingual distribution.
bodyText ||| Word-level alignments are then drawn based on
bodyText ||| the tree alignment. Finally, parallel sentences are
bodyText ||| assembled from these generated part-of-speech se-
bodyText ||| quences and word-level alignments.
bodyText ||| To perform inference under this model, we use
bodyText ||| a Metropolis-Hastings within-Gibbs sampler. We
bodyText ||| sample pairs of trees and then compute marginal-
bodyText ||| ized probabilities over all possible alignments us-
bodyText ||| ing dynamic programming.
bodyText ||| We test the effectiveness of our bilingual gram-
bodyText ||| mar induction model on three corpora of parallel
bodyText ||| text: English-Korean, English-Urdu and English-
bodyText ||| Chinese. The model is trained using bilingual
bodyText ||| data with automatically induced word-level align-
bodyText ||| ments, but is tested on purely monolingual data
bodyText ||| for each language. In all cases, our model out-
bodyText ||| performs a state-of-the-art baseline: the Con-
bodyText ||| stituent Context Model (CCM) (Klein and Man-
bodyText ||| ning, 2002), sometimes by substantial margins.
bodyText ||| On average, over all the testing scenarios that we
bodyText ||| studied, our model achieves an absolute increase
bodyText ||| in F-measure of 8.8 points, and a 19% reduction
bodyText ||| in error relative to a theoretical upper bound.
sectionHeader ||| 2 Related Work
bodyText ||| The unsupervised grammar induction task has
bodyText ||| been studied extensively, mostly in a monolin-
bodyText ||| gual setting (Charniak and Carroll, 1992; Stolcke
bodyText ||| and Omohundro, 1994; Klein and Manning, 2002;
bodyText ||| Seginer, 2007). While PCFGs perform poorly on
bodyText ||| this task, the CCM model (Klein and Manning,
bodyText ||| 2002) has achieved large gains in performance and
bodyText ||| is among the state-of-the-art probabilistic models
bodyText ||| for unsupervised constituency parsing. We there-
bodyText ||| fore use CCM as our basic model of monolingual
bodyText ||| syntax.
bodyText ||| While there has been some previous work on
bodyText ||| bilingual CFG parsing, it has mainly focused on
bodyText ||| improving MT systems rather than monolingual
bodyText ||| parsing accuracy. Research in this direction was
bodyText ||| pioneered by (Wu, 1997), who developed Inver-
bodyText ||| sion Transduction Grammars to capture cross-
bodyText ||| lingual grammar variations such as phrase re-
bodyText ||| orderings. More general formalisms for the same
bodyText ||| purpose were later developed (Wu and Wong,
bodyText ||| 1998; Chiang, 2005; Melamed, 2003; Eisner,
bodyText ||| 2003; Zhang and Gildea, 2005; Blunsom et al.,
bodyText ||| 2008). We know of only one study which eval-
bodyText ||| uates these bilingual grammar formalisms on the
bodyText ||| task of grammar induction itself (Smith and Smith,
bodyText ||| 2004). Both our model and even the monolingual
bodyText ||| CCM baseline yield far higher performance on the
bodyText ||| same Korean-English corpus.
bodyText ||| Our approach is closer to the unsupervised
bodyText ||| bilingual parsing model developed by Kuhn
bodyText ||| (2004), which aims to improve monolingual per-
bodyText ||| formance. Assuming that trees induced over paral-
bodyText ||| lel sentences have to exhibit certain structural reg-
bodyText ||| ularities, Kuhn manually specifies a set of rules
bodyText ||| for determining when parsing decisions in the two
bodyText ||| languages are inconsistent with GIZA++ word-
bodyText ||| level alignments. By incorporating these con-
bodyText ||| straints into the EM algorithm he was able to im-
bodyText ||| prove performance over a monolingual unsuper-
bodyText ||| vised PCFG. Still, the performance falls short of
bodyText ||| state-of-the-art monolingual models such as the
bodyText ||| CCM.
bodyText ||| More recently, there has been a body of work
bodyText ||| attempting to improve parsing performance by ex-
bodyText ||| ploiting syntactically annotated parallel data. In
bodyText ||| one strand of this work, annotations are assumed
bodyText ||| only in a resource-rich language and are projected
bodyText ||| onto a resource-poor language using the parallel
bodyText ||| data (Hwa et al., 2005; Xi and Hwa, 2005). In
bodyText ||| another strand of work, syntactic annotations are
bodyText ||| assumed on both sides of the parallel data, and a
bodyText ||| model is trained to exploit the parallel data at test
bodyText ||| time as well (Smith and Smith, 2004; Burkett and
bodyText ||| Klein, 2008). In contrast to this work, our goal
bodyText ||| is to explore the benefits of multilingual grammar
bodyText ||| induction in a fully unsupervised setting.
bodyText ||| We finally note a recent paper which uses pa-
bodyText ||| rameter tying to improve unsupervised depen-
bodyText ||| dency parse induction (Cohen and Smith, 2009).
bodyText ||| While the primary performance gains occur when
bodyText ||| tying related parameters within a language, some
bodyText ||| additional benefit is observed through bilingual ty-
bodyText ||| ing, even in the absence of a parallel corpus.
sectionHeader ||| 3 Model
bodyText ||| We propose an unsupervised Bayesian model for
bodyText ||| learning bilingual syntactic structure using paral-
bodyText ||| lel corpora. Our key premise is that difficult-to-
bodyText ||| learn syntactic structures of one language may cor-
bodyText ||| respond to simpler or less uncertain structures in
bodyText ||| the other language. We treat the part-of-speech
bodyText ||| tag sequences of parallel sentences, as well as their
page ||| 74
figure ||| (ii)
figure ||| (iii)
figure ||| (i)
figureCaption ||| Figure 1: A pair of trees (i) and two possible alignment trees. In (ii), no empty spaces are inserted, but
figureCaption ||| the order of one of the original tree’s siblings has been reversed. In (iii), only two pairs of nodes have
figureCaption ||| been aligned (indicated by arrows) and many empty spaces inserted.
bodyText ||| word-level alignments, as observed data. We ob-
bodyText ||| tain these word-level alignments using GIZA++
bodyText ||| (Och and Ney, 2003).
bodyText ||| Our model seeks to explain this observed data
bodyText ||| through a generative process whereby two aligned
bodyText ||| parse trees are produced jointly. Though they
bodyText ||| are aligned, arbitrary parts of the two trees are
bodyText ||| permitted to diverge, accommodating language-
bodyText ||| specific grammatical structure. In effect, our
bodyText ||| model loosely binds the two trees: node-to-node
bodyText ||| alignments need only be used where repeated
bodyText ||| bilingual patterns can be discovered in the data.
subsectionHeader ||| 3.1 Tree Alignments
bodyText ||| We achieve this loose binding of trees by adapting
bodyText ||| unordered tree alignment (Jiang et al., 1995) to a
bodyText ||| probabilistic setting. Under this formalism, any
bodyText ||| two trees can be aligned using an alignment tree.
bodyText ||| The alignment tree embeds the original two trees
bodyText ||| within it: each node is labeled by a pair (x, y),
bodyText ||| (A, y), or (x, A) where x is a node from the first
bodyText ||| tree, y is a node from the second tree, and A is an
bodyText ||| empty space. The individual structure of each tree
bodyText ||| must be preserved under the embedding with the
bodyText ||| exception of sibling order (to allow variations in
bodyText ||| phrase and word order).
bodyText ||| The flexibility of this formalism can be demon-
bodyText ||| strated by two extreme cases: (1) an alignment be-
bodyText ||| tween two trees may actually align none of their
bodyText ||| individual nodes, instead inserting an empty space
bodyText ||| A for each of the original two trees’ nodes. (2)
bodyText ||| if the original trees are isomorphic to one an-
bodyText ||| other, the alignment may match their nodes ex-
bodyText ||| actly, without inserting any empty spaces. See
bodyText ||| Figure 1 for an example.
subsectionHeader ||| 3.2 Model overview
bodyText ||| As our basic model of syntactic structure, we
bodyText ||| adopt the Constituent-Context Model (CCM) of
bodyText ||| Klein and Manning (2002). Under this model,
bodyText ||| the part-of-speech sequence of each span in a sen-
bodyText ||| tence is generated either as a constituent yield
bodyText ||| — if it is dominated by a node in the tree —
bodyText ||| or otherwise as a distituent yield. For example,
bodyText ||| in the bracketed sentence [John/NNP [climbed/VB
bodyText ||| [the/DT tree/NN]]], the sequence VB DT NN is gen-
bodyText ||| erated as a constituent yield, since it constitutes a
bodyText ||| complete bracket in the tree. On the other hand,
bodyText ||| the sequence VB DT is generated as a distituent,
bodyText ||| since it does not. Besides these yields, the con-
bodyText ||| texts (two surrounding POS tags) of constituents
bodyText ||| and distituents are generated as well. In this exam-
bodyText ||| ple, the context of the constituent VB DT NN would
bodyText ||| be (NNP, #), while the context of the distituent VB
bodyText ||| DT would be (NNP, NN). The CCM model em-
bodyText ||| ploys separate multinomial distributions over con-
bodyText ||| stituents, distituents, constituent contexts, and dis-
bodyText ||| tituent contexts. While this model is deficient —
bodyText ||| each observed subsequence of part-of-speech tags
bodyText ||| is generated many times over — its performance
bodyText ||| is far higher than that of unsupervised PCFGs.
bodyText ||| Under our bilingual model, each pair of sen-
bodyText ||| tences is assumed to have been generated jointly in
bodyText ||| the following way: First, an unlabeled alignment
bodyText ||| tree is drawn uniformly from the set of all such
bodyText ||| trees. This alignment tree specifies the structure
bodyText ||| of each of the two individual trees, as well as the
bodyText ||| pairs of nodes which are aligned and those which
bodyText ||| are not aligned (i.e. paired with a A).
bodyText ||| For each pair of aligned nodes, a correspond-
bodyText ||| ing pair of constituents and contexts are jointly
bodyText ||| drawn from a bilingual distribution. For unaligned
bodyText ||| nodes (i.e. nodes paired with a A in the alignment
page ||| 75
bodyText ||| tree), a single constituent and context are drawn,
bodyText ||| from language-specific distributions. Distituents
bodyText ||| and their contexts are also drawn from language-
bodyText ||| specific distributions. Finally, word-level align-
bodyText ||| ments are drawn based on the structure of the
bodyText ||| alignment tree.
bodyText ||| In the next two sections, we describe our model
bodyText ||| in more formal detail by specifying the parame-
bodyText ||| ters and generative process by which sentences are
bodyText ||| formed.
subsectionHeader ||| 3.3 Parameters
bodyText ||| Our model employs a number of multinomial dis-
bodyText ||| tributions:
listItem ||| •	7r�D : over constituent yields of language i,
listItem ||| •	7r�D : over distituent yields of language i,
listItem ||| •	��D : over constituent contexts of language i,
listItem ||| •	��D : over distituent contexts of language i,
listItem ||| •	w : over pairs of constituent yields, one from
listItem ||| the first language and the other from the sec-
listItem ||| ond language,
listItem ||| •	Gzpair : over a finite set of integer val-
listItem ||| ues {—m, ... , —2, —1, 0,1, 2, ... , m}, mea-
listItem ||| suring the Giza-score of aligned tree node
listItem ||| pairs (see below),
listItem ||| •	Gznode : over a finite set of integer values
listItem ||| {—m, . . ., —2, —1, 01, measuring the Giza-
listItem ||| score of unaligned tree nodes (see below).
bodyText ||| The first four distributions correspond exactly to
bodyText ||| the parameters of the CCM model. Parameter w is
bodyText ||| a “coupling parameter” which measures the com-
bodyText ||| patibility of tree-aligned constituent yield pairs.
bodyText ||| The final two parameters measure the compatibil-
bodyText ||| ity of syntactic alignments with the observed lexi-
bodyText ||| cal GIZA++ alignments. Intuitively, aligned nodes
bodyText ||| should have a high density of word-level align-
bodyText ||| ments between them, and unaligned nodes should
bodyText ||| have few lexical alignments.
bodyText ||| More formally, consider a tree-aligned node
bodyText ||| pair (n1, n2) with corresponding yields (y1, y2).
bodyText ||| We call a word-level alignment good if it aligns
bodyText ||| a word in y1 with a word in y2. We call a word-
bodyText ||| level alignment bad if it aligns a word in y1 with
bodyText ||| a word outside y2, or vice versa. The Giza-
bodyText ||| score for (n1, n2) is the number of good word
bodyText ||| alignments minus the number of bad word align-
bodyText ||| ments. For example, suppose the constituent my
bodyText ||| long name is node-aligned to its Urdu translation
bodyText ||| mera lamba naam. If only the word-pairs my/mera
bodyText ||| and name/naam are aligned, then the Giza-score
bodyText ||| for this node-alignment would be 2. If however,
bodyText ||| the English word long were (incorrectly) aligned
bodyText ||| under GIZA++ to some Urdu word outside the cor-
bodyText ||| responding constituent, then the score would drop
bodyText ||| to 1. This score could even be negative if the num-
bodyText ||| ber of bad alignments exceeds those that are good.
bodyText ||| Distribution Gzpair provides a probability for these
bodyText ||| scores (up to some fixed absolute value).
bodyText ||| For an unaligned node n with corresponding
bodyText ||| yield y, only bad GIZA++ alignments are possible,
bodyText ||| thus the Giza-score for these nodes will always be
bodyText ||| zero or negative. Distribution Gznode provides a
bodyText ||| probability for these scores (down to some fixed
bodyText ||| value). We want our model to find tree alignments
bodyText ||| such that both aligned node pairs and unaligned
bodyText ||| nodes have high Giza-score.
sectionHeader ||| 3.4 Generative Process
bodyText ||| Now we describe the stochastic process whereby
bodyText ||| the observed parallel sentences and their word-
bodyText ||| level alignments are generated, according to our
bodyText ||| model.
bodyText ||| As the first step in the Bayesian generative pro-
bodyText ||| cess, all the multinomial parameters listed in the
bodyText ||| previous section are drawn from their conjugate
bodyText ||| priors — Dirichlet distributions of appropriate di-
bodyText ||| mension. Then, each pair of word-aligned parallel
bodyText ||| sentences is generated through the following pro-
bodyText ||| cess:
listItem ||| 1. A pair of binary trees T1 and T2 along with
bodyText ||| an alignment tree A are drawn according to
bodyText ||| P(T1, T2, A). A is an alignment tree for T1
bodyText ||| and T2 if it can be obtained by the follow-
bodyText ||| ing steps: First insert blank nodes (labeled by
bodyText ||| A) into T1 and T2. Then permute the order
bodyText ||| of sibling nodes such that the two resulting
bodyText ||| trees T10 and T20 are identical in structure. Fi-
bodyText ||| nally, overlay T10 and T20 to obtain A. We ad-
bodyText ||| ditionally require that A contain no extrane-
bodyText ||| ous nodes – that is no nodes with two blank
bodyText ||| labels (A, A). See Figure 1 for an example.
bodyText ||| We define the distribution P(T1, T2, A) to be
bodyText ||| uniform over all pairs of binary trees and their
bodyText ||| alignments.
listItem ||| 2. For each node in A of the form (n1, A) (i.e.
listItem ||| nodes in T1 left unaligned by A), draw
listItem ||| (i) a constituent yield according to 7r�1 ,
listItem ||| 76
listItem ||| (ii) a constituent context according to 0C1,
listItem ||| (iii) a Giza-score according to Gznode.
listItem ||| 3. For each node in A of the form (A, n2) (i.e.
listItem ||| nodes in T2 left unaligned by A), draw
listItem ||| (i) a constituent yield according to 7rC2 ,
listItem ||| (ii) a constituent context according to 0C2,
listItem ||| (iii) a Giza-score according to Gznode.
listItem ||| 4. For each node in A of the form (n1, n2) (i.e.
listItem ||| tree-aligned node pairs), draw
listItem ||| (i) a pair of constituent yields (y1, y2) ac-
listItem ||| cording to:
equation ||| 0C1 (y1) - 0C2(y2) - W (y1, y2)	(1)
equation ||| Z
bodyText ||| which is a product of experts combining
bodyText ||| the language specific context-yield dis-
bodyText ||| tributions as well as the coupling distri-
bodyText ||| bution W with normalization constant Z,
listItem ||| (ii) a pair of contexts according to the ap-
listItem ||| propriate language-specific parameters,
listItem ||| (iii) a Giza-score according to Gzpair.
listItem ||| 5. For each span in TZ not dominated by a node
bodyText ||| (for each language i E 11, 2}), draw a dis-
bodyText ||| tituent yield according to 7r�Z and a distituent
bodyText ||| context according to 0�Z.
listItem ||| 6. Draw actual word-level alignments consis-
bodyText ||| tent with the Giza-scores, according to a uni-
bodyText ||| form distribution.
bodyText ||| In the next section we turn to the problem of
bodyText ||| inference under this model when only the part-
bodyText ||| of-speech tag sequences of parallel sentences and
bodyText ||| their word-level alignments are observed.
sectionHeader ||| 3.5 Inference
bodyText ||| Given a corpus of paired part-of-speech tag se-
bodyText ||| quences (s1, s2) and their GIZA++ alignments
bodyText ||| g, we would ideally like to predict the set of
bodyText ||| tree pairs (T1, T2) which have highest proba-
bodyText ||| bility when conditioned on the observed data:
bodyText ||| P(T1, T2Is1, s2, g). We could rewrite this by
bodyText ||| explicitly integrating over the yield, context, cou-
bodyText ||| pling, Giza-score parameters as well as the align-
bodyText ||| ment trees. However, since maximizing this in-
bodyText ||| tegral directly would be intractable, we resort to
bodyText ||| standard Markov chain sampling techniques. We
bodyText ||| use Gibbs sampling (Hastings, 1970) to draw trees
bodyText ||| for each sentence conditioned on those drawn for
bodyText ||| all other sentences. The samples form a Markov
bodyText ||| chain which is guaranteed to converge to the true
bodyText ||| joint distribution over all sentences.
bodyText ||| In the monolingual setting, there is a well-
bodyText ||| known tree sampling algorithm (Johnson et al.,
bodyText ||| 2007). This algorithm proceeds in top-down fash-
bodyText ||| ion by sampling individual split points using the
bodyText ||| marginal probabilities of all possible subtrees.
bodyText ||| These marginals can be efficiently pre-computed
bodyText ||| and form the “inside” table of the famous Inside-
bodyText ||| Outside algorithm. However, in our setting, trees
bodyText ||| come in pairs, and their joint probability crucially
bodyText ||| depends on their alignment.
bodyText ||| For the i1h parallel sentence, we wish to jointly
bodyText ||| sample the pair of trees (T1,T2)Z together with
bodyText ||| their alignment AZ. To do so directly would in-
bodyText ||| volve simultaneously marginalizing over all pos-
bodyText ||| sible subtrees as well as all possible alignments
bodyText ||| between such subtrees when sampling upper-level
bodyText ||| split points. We know of no obvious algorithm
bodyText ||| for computing this marginal. We instead first sam-
bodyText ||| ple the pair of trees (T1, T2)Z from a simpler pro-
bodyText ||| posal distribution Q. Our proposal distribution as-
bodyText ||| sumes that no nodes of the two trees are aligned
bodyText ||| and therefore allows us to use the recursive top-
bodyText ||| down sampling algorithm mentioned above. After
bodyText ||| a new tree pair T* _ (T1*, T2* )Z is drawn from Q,
bodyText ||| we accept the pair with the following probability:
equation ||| � �
equation ||| min 1,
equation ||| P(T* T—Z, A—Z) Q(TIT—Z, A—Z)
equation ||| P(T IT—Z, A—Z) Q(T* IT—Z, A—Z)
bodyText ||| where T is the previously sampled tree-pair for
bodyText ||| sentence i, P is the true model probability, and
bodyText ||| Q is the probability under the proposal distribu-
bodyText ||| tion. This use of a tractable proposal distribution
bodyText ||| and acceptance ratio is known as the Metropolis-
bodyText ||| Hastings algorithm and it preserves the conver-
bodyText ||| gence guarantee of the Gibbs sampler (Hastings,
bodyText ||| 1970). To compute the terms P(T*IT—Z,A—Z)
bodyText ||| and P(T IT—Z, A—Z) in the acceptance ratio above,
bodyText ||| we need to marginalize over all possible align-
bodyText ||| ments between tree pairs.
bodyText ||| Fortunately, for any given pair of trees T1 and
bodyText ||| T2 this marginalization can be computed using
bodyText ||| a dynamic program in time O (I T1 I I T2 I) . Here
bodyText ||| we provide a very brief sketch. For every pair
bodyText ||| of nodes n1 E T1, n2 E T2, a table stores the
bodyText ||| marginal probability of the subtrees rooted at n1
bodyText ||| and n2, respectively. A dynamic program builds
bodyText ||| this table from the bottom up: For each node pair
bodyText ||| n1, n2, we sum the probabilities of all local align-
bodyText ||| ment configurations, each multiplied by the appro-
page ||| 77
bodyText ||| priate marginals already computed in the table for
bodyText ||| lower-level node pairs. This algorithm is an adap-
bodyText ||| tation of the dynamic program presented in (Jiang
bodyText ||| et al., 1995) for finding minimum cost alignment
bodyText ||| trees (Fig. 5 of that publication).
bodyText ||| Once a pair of trees (T1, T2) has been sam-
bodyText ||| pled, we can proceed to sample an alignment tree
bodyText ||| AIT1, T2.2 We sample individual alignment deci-
bodyText ||| sions from the top down, at each step using the
bodyText ||| alignment marginals for the remaining subtrees
bodyText ||| (already computed using the afore-mentioned dy-
bodyText ||| namic program). Once the triple (T1, T2, A) has
bodyText ||| been sampled, we move on to the next parallel sen-
bodyText ||| tence.
bodyText ||| We avoid directly sampling parameter val-
bodyText ||| ues, instead using the marginalized closed forms
bodyText ||| for multinomials with Dirichlet conjugate-priors
bodyText ||| using counts and hyperparameter pseudo-counts
bodyText ||| (Gelman et al., 2004). Note that in the case of
bodyText ||| yield pairs produced according to Distribution 1
bodyText ||| (in step 4 of the generative process) conjugacy is
bodyText ||| technically broken, since the yield pairs are no
bodyText ||| longer produced by a single multinomial distribu-
bodyText ||| tion. Nevertheless, we count the produced yields
bodyText ||| as if they had been generated separately by each
bodyText ||| of the distributions involved in the numerator of
bodyText ||| Distribution 1.
sectionHeader ||| 4 Experimental setup
bodyText ||| We test our model on three corpora of bilin-
bodyText ||| gual parallel sentences: English-Korean, English-
bodyText ||| Urdu, and English-Chinese. Though the model is
bodyText ||| trained using parallel data, during testing it has ac-
bodyText ||| cess only to monolingual data. This set-up ensures
bodyText ||| that we are testing our model’s ability to learn bet-
bodyText ||| ter parameters at training time, rather than its abil-
bodyText ||| ity to exploit parallel data at test time. Following
bodyText ||| (Klein and Manning, 2002), we restrict our model
bodyText ||| to binary trees, though we note that the alignment
bodyText ||| trees do not follow this restriction.
bodyText ||| Data The Penn Korean Treebank (Han et al.,
bodyText ||| 2002) consists of 5,083 Korean sentences trans-
bodyText ||| lated into English for the purposes of language
bodyText ||| training in a military setting. Both the Korean
bodyText ||| and English sentences are annotated with syntactic
bodyText ||| trees. We use the first 4,000 sentences for training
bodyText ||| and the last 1,083 sentences for testing. We note
bodyText ||| that in the Korean data, a separate tag is given for
footnote ||| 2Sampling the alignment tree is important, as it provides
footnote ||| us with counts of aligned constituents for the coupling pa-
footnote ||| rameter.
bodyText ||| each morpheme. We simply concatenate all the
bodyText ||| morpheme tags given for each word and treat the
bodyText ||| concatenation as a single tag. This procedure re-
bodyText ||| sults in 199 different tags. The English-Urdu par-
bodyText ||| allel corpus3 consists of 4,325 sentences from the
bodyText ||| first three sections of the Penn Treebank and their
bodyText ||| Urdu translations annotated at the part-of-speech
bodyText ||| level. The Urdu side of this corpus does not pro-
bodyText ||| vide tree annotations so here we can test parse ac-
bodyText ||| curacy only on English. We use the remaining
bodyText ||| sections of the Penn Treebank for English test-
bodyText ||| ing. The English-Chinese treebank (Bies et al.,
bodyText ||| 2007) consists of 3,850 Chinese newswire sen-
bodyText ||| tences translated into English. Both the English
bodyText ||| and Chinese sentences are annotated with parse
bodyText ||| trees. We use the first 4/5 for training and the final
bodyText ||| 1/5 for testing.
bodyText ||| During preprocessing of the corpora we remove
bodyText ||| all punctuation marks and special symbols, fol-
bodyText ||| lowing the setup in previous grammar induction
bodyText ||| work (Klein and Manning, 2002). To obtain lex-
bodyText ||| ical alignments between the parallel sentences we
bodyText ||| employ GIZA++ (Och and Ney, 2003). We use in-
bodyText ||| tersection alignments, which are one-to-one align-
bodyText ||| ments produced by taking the intersection of one-
bodyText ||| to-many alignments in each direction. These one-
bodyText ||| to-one intersection alignments tend to have higher
bodyText ||| precision.
bodyText ||| We initialize the trees by making uniform split
bodyText ||| decisions recursively from the top down for sen-
bodyText ||| tences in both languages. Then for each pair of
bodyText ||| parallel sentences we randomly sample an initial
bodyText ||| alignment tree for the two sampled trees.
bodyText ||| Baseline We implement a Bayesian version of
bodyText ||| the CCM as a baseline. This model uses the same
bodyText ||| inference procedure as our bilingual model (Gibbs
bodyText ||| sampling). In fact, our model reduces to this
bodyText ||| Bayesian CCM when it is assumed that no nodes
bodyText ||| between the two parallel trees are ever aligned
bodyText ||| and when word-level alignments are ignored. We
bodyText ||| also reimplemented the original EM version of
bodyText ||| CCM and found virtually no difference in perfor-
bodyText ||| mance when using EM or Gibbs sampling. In both
bodyText ||| cases our implementation achieves F-measure in
bodyText ||| the range of 69-70% on WSJ10, broadly in line
bodyText ||| with the performance reported by Klein and Man-
bodyText ||| ning (2002).
bodyText ||| Hyperparameters Klein (2005) reports using
bodyText ||| smoothing pseudo-counts of 2 for constituent
footnote ||| 3 http://www.crulp.org
page ||| 78
figureCaption ||| Figure 2: The F-measure of the CCM baseline (dotted line) and bilingual model (solid line) plotted on
figureCaption ||| the y-axis, as the maximum sentence length in the test set is increased (x-axis). Results are averaged over
figureCaption ||| all training scenarios given in Table 1.
bodyText ||| yields and contexts and 8 for distituent yields and
bodyText ||| contexts. In our Bayesian model, these similar
bodyText ||| smoothing counts occur as the parameters of the
bodyText ||| Dirichlet priors. For Korean we found that the
bodyText ||| baseline performed well using these values. How-
bodyText ||| ever, on our English and Chinese data, we found
bodyText ||| that somewhat higher smoothing values worked
bodyText ||| best, so we utilized values of 20 and 80 for con-
bodyText ||| stituent and distituent smoothing counts, respec-
bodyText ||| tively.
bodyText ||| Our model additionally requires hyperparam-
bodyText ||| eter values for w (the coupling distribution for
bodyText ||| aligned yields), Gzpair and Gznode (the distribu-
bodyText ||| tions over Giza-scores for aligned nodes and un-
bodyText ||| aligned nodes, respectively). For w we used a
bodyText ||| symmetric Dirichlet prior with parameter 1. For
bodyText ||| Gzpair and Gznode, in order to create a strong bias
bodyText ||| towards high Giza-scores, we used non-symmetric
bodyText ||| Dirichlet priors. In both cases, we capped the ab-
bodyText ||| solute value of the scores at 3, to prevent count
bodyText ||| sparsity. In the case of Gzpair we gave pseudo-
bodyText ||| counts of 1,000 for negative values and zero, and
bodyText ||| pseudo-counts of 1,000,000 for positive scores.
bodyText ||| For Gznode we gave a pseudo-count of 1,000,000
bodyText ||| for a score of zero, and 1,000 for all nega-
bodyText ||| tive scores. This very strong prior bias encodes
bodyText ||| our intuition that syntactic alignments which re-
bodyText ||| spect lexical alignments should be preferred. Our
bodyText ||| method is not sensitive to these exact values and
bodyText ||| any reasonably strong bias gave similar results.
bodyText ||| In all our experiments, we consider the hyper-
bodyText ||| parameters fixed and observed values.
bodyText ||| Testing and evaluation As mentioned above,
bodyText ||| we test our model only on monolingual data,
bodyText ||| where the parallel sentences are not provided to
bodyText ||| the model. To predict the bracketings of these
bodyText ||| monolingual test sentences, we take the smoothed
bodyText ||| counts accumulated in the final round of sampling
bodyText ||| over the training data and perform a maximum
bodyText ||| likelihood estimate of the monolingual CCM pa-
bodyText ||| rameters. These parameters are then used to pro-
bodyText ||| duce the highest probability bracketing of the test
bodyText ||| set.
bodyText ||| To evaluate both our model as well as the base-
bodyText ||| line, we use (unlabeled) bracket precision, re-
bodyText ||| call, and F-measure (Klein and Manning, 2002).
bodyText ||| Following previous work, we include the whole-
bodyText ||| sentence brackets but ignore single-word brack-
bodyText ||| ets. We perform experiments on different subsets
bodyText ||| of training and testing data based on the sentence-
bodyText ||| length. In particular we experimented with sen-
bodyText ||| tence length limits of 10, 20, and 30 for both the
bodyText ||| training and testing sets. We also report the upper
bodyText ||| bound on F-measure for binary trees. We average
bodyText ||| the results over 10 separate sampling runs.
sectionHeader ||| 5 Results
bodyText ||| Table 1 reports the full results of our experiments.
bodyText ||| In all testing scenarios the bilingual model out-
bodyText ||| performs its monolingual counterpart in terms of
bodyText ||| both precision and recall. On average, the bilin-
bodyText ||| gual model gains 10.2 percentage points in preci-
bodyText ||| sion, 7.7 in recall, and 8.8 in F-measure. The gap
bodyText ||| between monolingual performance and the binary
bodyText ||| tree upper bound is reduced by over 19%.
bodyText ||| The extent of the gain varies across pairings.
bodyText ||| For instance, the smallest improvement is ob-
bodyText ||| served for English when trained with Urdu. The
bodyText ||| Korean-English pairing results in substantial im-
bodyText ||| provements for Korean and quite large improve-
bodyText ||| ments for English, for which the absolute gain
bodyText ||| reaches 28 points in F-measure. In the case of Chi-
bodyText ||| nese and English, the gains for English are fairly
bodyText ||| minimal whereas those for Chinese are quite sub-
page ||| 79
table ||| 	Max Sent. Length		Monolingual			Bilingual			Upper Bound
table ||| 	Test	Train	Precision	Recall	F1	Precision	Recall	F1	F1
table ||| 		10	52.74	39.53	45.19	57.76	43.30	49.50	85.6
table ||| 	10	20	41.87	31.38	35.87	61.66	46.22	52.83	85.6
table ||| 		30	33.43	25.06	28.65	64.41	48.28	55.19	85.6
table ||| 	20	20	35.12	25.12	29.29	56.96	40.74	47.50	83.3
table ||| 		30	26.26	18.78	21.90	60.07	42.96	50.09	83.3
table ||| 	30	30	23.95	16.81	19.76	58.01	40.73	47.86	82.4
table ||| 		10	71.07	62.55	66.54	75.63	66.56	70.81	93.6
table ||| 	10	20	71.35	62.79	66.80	77.61	68.30	72.66	93.6
table ||| 		30	71.37	62.81	66.82	77.87	68.53	72.91	93.6
table ||| 	20	20	64.28	54.73	59.12	70.44	59.98	64.79	91.9
table ||| 		30	64.29	54.75	59.14	70.81	60.30	65.13	91.9
table ||| 	30	30	63.63	54.17	58.52	70.11	59.70	64.49	91.9
table ||| 		10	50.09	34.18	40.63	37.46	25.56	30.39	81.0
table ||| 	10	20	58.86	40.17	47.75	50.24	34.29	40.76	81.0
table ||| 		30	64.81	44.22	52.57	68.24	46.57	55.36	81.0
table ||| 	20	20	41.90	30.52	35.31	38.64	28.15	32.57	84.3
table ||| 		30	52.83	38.49	44.53	58.50	42.62	49.31	84.3
table ||| 	30	30	46.35	33.67	39.00	51.40	37.33	43.25	84.1
table ||| 		10	39.87	27.71	32.69	40.62	28.23	33.31	81.9
table ||| 	10	20	43.44	30.19	35.62	47.54	33.03	38.98	81.9
table ||| 		30	43.63	30.32	35.77	54.09	37.59	44.36	81.9
table ||| 	20	20	29.80	23.46	26.25	36.93	29.07	32.53	88.0
table ||| 		30	30.05	23.65	26.47	43.99	34.63	38.75	88.0
table ||| 	30	30	24.46	19.41	21.64	39.61	31.43	35.05	88.4
table ||| 		10	57.98	45.68	51.10	73.43	57.85	64.71	88.1
table ||| 	10	20	70.57	55.60	62.20	80.24	63.22	70.72	88.1
table ||| 		30	75.39	59.40	66.45	79.04	62.28	69.67	88.1
table ||| 	20	20	57.78	43.86	49.87	67.26	51.06	58.05	86.3
table ||| 		30	63.12	47.91	54.47	64.45	48.92	55.62	86.3
table ||| 	30	30	57.36	43.02	49.17	57.97	43.48	49.69	85.7
tableCaption ||| Table 1: Unlabeled precision, recall and F-measure for the monolingual baseline and the bilingual model
tableCaption ||| on several test sets. We report results for different combinations of maximum sentence length in both the
tableCaption ||| training and test sets. The right most column, in all cases, contains the maximum F-measure achievable
tableCaption ||| using binary trees. The best performance for each test-length is highlighted in bold.
bodyText ||| stantial. This asymmetry should not be surprising,
bodyText ||| as Chinese on its own seems to be quite a bit more
bodyText ||| difficult to parse than English.
bodyText ||| We also investigated the impact of sentence
bodyText ||| length for both the training and testing sets. For
bodyText ||| our model, adding sentences of greater length to
bodyText ||| the training set leads to increases in parse accu-
bodyText ||| racy for short sentences. For the baseline, how-
bodyText ||| ever, adding this additional training data degrades
bodyText ||| performance in the case of English paired with Ko-
bodyText ||| rean. Figure 2 summarizes the performance of
bodyText ||| our model for different sentence lengths on sev-
bodyText ||| eral of the test-sets. As shown in the figure, the
bodyText ||| largest improvements tend to occur at longer sen-
bodyText ||| tence lengths.
sectionHeader ||| 6 Conclusion
bodyText ||| We have presented a probabilistic model for bilin-
bodyText ||| gual grammar induction which uses raw parallel
bodyText ||| text to learn tree pairs and their alignments. Our
bodyText ||| formalism loosely binds the two trees, using bilin-
bodyText ||| gual patterns when possible, but allowing substan-
bodyText ||| tial language-specific variation. We tested our
bodyText ||| model on three test sets and showed substantial
bodyText ||| improvement over a state-of-the-art monolingual
bodyText ||| baseline.4
footnote ||| 4The authors acknowledge the support of the NSF (CA-
footnote ||| REER grant IIS-0448168, grant IIS-0835445, and grant IIS-
footnote ||| 0835652). Thanks to Amir Globerson and members of the
footnote ||| MIT NLP group for their helpful suggestions. Any opinions,
footnote ||| findings, or conclusions are those of the authors, and do not
footnote ||| necessarily reflect the views of the funding organizations
page ||| 80
sectionHeader ||| References
reference ||| Ann Bies, Martha Palmer, Justin Mott, and Colin
reference ||| Warner. 2007. English Chinese translation treebank
reference ||| v 1.0. LDC2007T02.
reference ||| Phil Blunsom, Trevor Cohn, and Miles Osborne. 2008.
reference ||| Bayesian synchronous grammar induction. In Pro-
reference ||| ceedings of NIPS.
reference ||| David Burkett and Dan Klein. 2008. Two languages
reference ||| are better than one (for syntactic parsing). In Pro-
reference ||| ceedings of EMNLP, pages 877–886.
reference ||| Eugene Charniak and Glen Carroll. 1992. Two exper-
reference ||| iments on learning probabilistic dependency gram-
reference ||| mars from corpora. In Proceedings of the AAAI
reference ||| Workshop on Statistically-Based NLP Techniques,
reference ||| pages 1–13.
reference ||| David Chiang. 2005. A hierarchical phrase-based
reference ||| model for statistical machine translation. In Pro-
reference ||| ceedings of the ACL, pages 263–270.
reference ||| Shay B. Cohen and Noah A. Smith. 2009. Shared lo-
reference ||| gistic normal distributions for soft parameter tying
reference ||| in unsupervised grammar induction. In Proceedings
reference ||| of the NAACL/HLT.
reference ||| Jason Eisner. 2003. Learning non-isomorphic tree
reference ||| mappings for machine translation. In The Compan-
reference ||| ion Volume to the Proceedings of the ACL, pages
reference ||| 205–208.
reference ||| Andrew Gelman, John B. Carlin, Hal S. Stern, and
reference ||| Donald B. Rubin. 2004. Bayesian data analysis.
reference ||| Chapman and Hall/CRC.
reference ||| Dmitriy Genzel. 2005. Inducing a multilingual dictio-
reference ||| nary from a parallel multitext in related languages.
reference ||| In Proceedings of EMNLP/HLT, pages 875–882.
reference ||| C. Han, N.R. Han, E.S. Ko, H. Yi, and M. Palmer.
reference ||| 2002. Penn Korean Treebank: Development and
reference ||| evaluation. In Proc. Pacific Asian Conf. Language
reference ||| and Comp.
reference ||| W. K. Hastings. 1970. Monte carlo sampling meth-
reference ||| ods using Markov chains and their applications.
reference ||| Biometrika, 57:97–109.
reference ||| R. Hwa, P. Resnik, A. Weinberg, C. Cabezas, and
reference ||| O. Kolak. 2005. Bootstrapping parsers via syntactic
reference ||| projection across parallel texts. Journal of Natural
reference ||| Language Engineering, 11(3):311–325.
reference ||| T. Jiang, L. Wang, and K. Zhang. 1995. Alignment of
reference ||| trees – an alternative to tree edit. Theoretical Com-
reference ||| puter Science, 143(1):137–148.
reference ||| M. Johnson, T. Griffiths, and S. Goldwater. 2007.
reference ||| Bayesian inference for PCFGs via Markov chain
reference ||| Monte Carlo. In Proceedings of the NAACL/HLT,
reference ||| pages 139–146.
reference ||| Dan Klein and Christopher D. Manning. 2002. A
reference ||| generative constituent-context model for improved
reference ||| grammar induction. In Proceedings of the ACL,
reference ||| pages 128–135.
reference ||| D. Klein. 2005. The Unsupervised Learning of Natu-
reference ||| ral Language Structure. Ph.D. thesis, Stanford Uni-
reference ||| versity.
reference ||| Jonas Kuhn. 2004. Experiments in parallel-text based
reference ||| grammar induction. In Proceedings of the ACL,
reference ||| pages 470–477.
reference ||| I. Dan Melamed. 2003. Multitext grammars
reference ||| and synchronous parsers. In Proceedings of the
reference ||| NAACL/HLT, pages 79–86.
reference ||| Franz Josef Och and Hermann Ney. 2003. A sys-
reference ||| tematic comparison of various statistical alignment
reference ||| models. Computational Linguistics, 29(1):19–51.
reference ||| Yoav Seginer. 2007. Fast unsupervised incremental
reference ||| parsing. In Proceedings of the ACL, pages 384–391.
reference ||| David A. Smith and Noah A. Smith. 2004. Bilingual
reference ||| parsing with factored estimation: Using English to
reference ||| parse Korean. In Proceeding of EMNLP, pages 49–
reference ||| 56.
reference ||| Benjamin Snyder and Regina Barzilay. 2008. Un-
reference ||| supervised multilingual learning for morphological
reference ||| segmentation. In Proceedings of the ACL/HLT,
reference ||| pages 737–745.
reference ||| Benjamin Snyder, Tahira Naseem, Jacob Eisenstein,
reference ||| and Regina Barzilay. 2008. Unsupervised multi-
reference ||| lingual learning for POS tagging. In Proceedings of
reference ||| EMNLP, pages 1041–1050.
reference ||| Benjamin Snyder, Tahira Naseem, Jacob Eisenstein,
reference ||| and Regina Barzilay. 2009. Adding more languages
reference ||| improves unsupervised multilingual part-of-speech
reference ||| tagging: A Bayesian non-parametric approach. In
reference ||| Proceedings of the NAACL/HLT.
reference ||| Andreas Stolcke and Stephen M. Omohundro. 1994.
reference ||| Inducing probabilistic grammars by Bayesian model
reference ||| merging. In Proceedings of ICGI, pages 106–118.
reference ||| Dekai Wu and Hongsing Wong. 1998. Machine
reference ||| translation with a stochastic grammatical channel.
reference ||| In Proceedings of the ACL/COLING, pages 1408–
reference ||| 1415.
reference ||| Dekai Wu. 1997. Stochastic inversion transduction
reference ||| grammars and bilingual parsing of parallel corpora.
reference ||| Computational Linguistics, 23(3):377–403.
reference ||| Chenhai Xi and Rebecca Hwa. 2005. A backoff
reference ||| model for bootstrapping resources for non-english
reference ||| languages. In Proceedings of EMNLP, pages 851 –
reference ||| 858.
reference ||| Hao Zhang and Daniel Gildea. 2005. Stochastic lex-
reference ||| icalized inversion transduction grammar for align-
reference ||| ment. In Proceedings of the ACL, pages 475–482.
page ||| 81
