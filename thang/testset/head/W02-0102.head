<?xml version="1.0" encoding="UTF-8"?>
<file>
  <entry no="0">
    <variant no="0" confidence="1.0">
	<title>Interactive Spreadsheet for Teaching the Forward-Backward Algorithm +L+ </title>
	<author>Jason Eisner +L+ </author>
	<affiliation>Department of Computer Science +L+ Johns Hopkins University +L+ </affiliation>
	<address>Baltimore, MD, USA 21218-2691 +L+ </address>
	<email>jason@cs.jhu.edu +L+ </email>
	<abstract>Abstract +L+ This paper offers a detailed lesson plan on the forward- +L+ backward algorithm. The lesson is taught from a live, com- +L+ mented spreadsheet that implements the algorithm and graphs +L+ its behavior on a whimsical toy example. By experimenting +L+ with different inputs, one can help students develop intuitions +L+ about HMMs in particular and Expectation Maximization in +L+ general. The spreadsheet and a coordinated follow-up assign- +L+ ment are available. +L+ 1 Why Teach from a Spreadsheet? +L+ Algorithm animations are a wonderful teaching tool. +L+ They are concrete, visual, playful, sometimes inter- +L+ active, and remain available to students after the lec- +L+ ture ends. Unfortunately, they have mainly been lim- +L+ ited to algorithms that manipulate easy-to-draw data +L+ structures. +L+ Numerical algorithms can be “animated” by +L+ spreadsheets. Although current spreadsheets do not +L+ provide video, they can show “all at once” how a +L+ computation unfolds over time, displaying interme- +L+ diate results in successive rows of a table and on +L+ graphs. Like the best algorithm animations, they +L+ let the user manipulate the input data to see what +L+ changes. The user can instantly and graphically see +L+ the effect on the whole course of the computation. +L+ Spreadsheets are also transparent. In Figure 1, the +L+ user has double-clicked on a cell to reveal its un- +L+ derlying formula. The other cells that it depends on +L+ are automatically highlighted, with colors keyed to +L+ the references in the formula. There is no program- +L+ ming language to learn: spreadsheet programs are +L+ aimed at the mass market, with an intuitive design +L+ and plenty of online help, and today’s undergrad- +L+ uates already understand their basic operation. An +L+ adventurous student can even experiment with mod- +L+ ifying the formulas, or can instrument the spread- +L+ sheet with additional graphs. +L+ Finally, modern spreadsheet programs such as +L+ Microsoft Excel support visually attractive layouts +L+ with integrated comments, color, fonts, shading, and +L+ Figure 1: User has double-clicked on cell D29. +L+ drawings. This makes them effective for both class- +L+ room presentation and individual study. +L+ This paper describes a lesson plan that was cen- +L+ tered around a live spreadsheet, as well as a subse- +L+ quent programming assignment in which the spread- +L+ sheet served as a debugging aid. The materials are +L+ available for use by others. +L+ Students were especially engaged in class, appar- +L+ ently for the following reasons: +L+ Striking results (“It learned it!”) that could be im- +L+ mediately apprehended from the graphs. +L+ Live interactive demo. The students were eager +L+ to guess what the algorithm would do on partic- +L+ ular inputs and test their guesses. +L+ A whimsical toy example. +L+ The departure from the usual class routine. +L+ Novel use of spreadsheets. Several students who +L+ thought of them as mere bookkeeping tools were +L+ awed by this, with one calling it “the coolest-ass +L+ spreadsheet ever.” +L+ 2 How to Teach from a Spreadsheet? +L+ It is possible to teach from a live spreadsheet by us- +L+ ing an RGB projector. The spreadsheet’s zoom fea- +L+ ture can compensate for small type, although under- +L+ graduate eyes prove sharp enough that it may be un- +L+ necessary. (Invite the students to sit near the front.) +L+ Of course, interesting spreadsheets are much too +L+ big to fit on the screen, even with a “View / Full +L+ Screen” command. But scrolling is easy to follow +L+ if it is not too fast and if the class has previously +L+ </abstract>
	<date>July </date>
	<note>2002, pp. 10-18. Association for Computational Linguistics. +L+ Natural Language Processing and Computational Linguistics, Philadelphia, +L+ Proceedings of the Workshop on </note>
	<title>Effective Tools and Methodologies for Teaching +L+ </title>
	<abstract>been given a tour of the overall spreadsheet layout +L+ (by scrolling and/or zooming out). Split-screen fea- +L+ tures such as hide rows/columns, split panes, and +L+ freeze panes can be moderately helpful; so can com- +L+ mands to jump around the spreadsheet, or switch be- +L+ tween two windows that display different areas. It +L+ is a good idea to memorize key sequences for such +L+ commands rather than struggle with mouse menus +L+ or dialog boxes during class. +L+ </abstract>
	<note>3 The Subject Matter +L+ Among topics in natural language processing, +L+ the forward-backward or Baum-Welch algorithm +L+ (Baum, 1972) is particularly difficult to teach. +L+ </note>
	<title>The algorithm estimates the parameters of a +L+ Hidden Markov Model (HMM) by Expectation- +L+ Maximization (EM), using dynamic programming +L+ </title>
	<abstract>to carry out the expectation steps efficiently. +L+ HMMs have long been central in speech recog- +L+ nition (Rabiner, 1989). Their application to part- +L+ of-speech tagging (Church, 1988; DeRose, 1988) +L+ kicked off the era of statistical NLP, and they have +L+ found additional NLP applications to phrase chunk- +L+ ing, text segmentation, word-sense disambiguation, +L+ and information extraction. +L+ The algorithm is also important to teach for ped- +L+ agogical reasons, as the entry point to a family of +L+ EM algorithms for unsupervised parameter estima- +L+ tion. Indeed, it is an instructive special case of (1) +L+ the inside-outside algorithm for estimation of prob- +L+ abilistic context-free grammars; (2) belief propa- +L+ gation for training singly-connected Bayesian net- +L+ works and junction trees (Pearl, 1988; Lauritzen, +L+ 1995); (3) algorithms for learning alignment mod- +L+ els such as weighted edit distance; (4) general finite- +L+ state parameter estimation (Eisner, 2002). +L+ Before studying the algorithm, students should +L+ first have worked with some if not all of the key +L+ ideas in simpler settings. Markov models can be +L+ introduced through n-gram models or probabilistic +L+ finite-state automata. EM can be introduced through +L+ simpler tasks such as soft clustering. Global opti- +L+ mization through dynamic programming can be in- +L+ troduced in other contexts such as probabilistic CKY +L+ parsing or edit distance. Finally, the students should +L+ understand supervised training and Viterbi decod- +L+ ing of HMMs, for example in the context of part- +L+ of-speech tagging. +L+ Even with such preparation, however, the +L+ forward-backward algorithm can be difficult for be- +L+ ginning students to apprehend. It requires them to +L+ think about all of the above ideas at once, in com- +L+ bination, and to relate them to the nitty-gritty of the +L+ algorithm, namely +L+ the two-pass computation of mysterious and +L+ probabilities +L+ the conversion of these prior path probabilities to +L+ posterior expectations of transition and emission +L+ counts +L+ Just as important, students must develop an under- +L+ standing of the algorithm’s qualitative properties, +L+ which it shares with other EM algorithms: +L+ performs unsupervised learning (what is this and +L+ why is it possible?) +L+ alternates expectation and maximization steps +L+ maximizes p(observed training data) (i.e., total +L+ probability of all hidden paths that generate those +L+ data) +L+ finds only a local maximum, so is sensitive to +L+ initial conditions +L+ cannot escape zeroes or symmetries, so they +L+ should be avoided in initial conditions +L+ uses the states as it sees fit, ignoring the sugges- +L+ tive names that we may give them (e.g., part of +L+ speech tags) +L+ may overfit the training data unless smoothing is +L+ used +L+ The spreadsheet lesson was deployed in two 50- +L+ minute lectures at Johns Hopkins University, in an +L+ introductory NLP course aimed at upper-level un- +L+ dergraduates and first-year graduate students. A sin- +L+ gle lecture might have sufficed for a less interactive +L+ presentation. +L+ The lesson appeared in week 10 of 13, by which +L+ time the students had already been exposed to most +L+ of the preparatory topics mentioned above, includ- +L+ ing Viterbi decoding of a part-of-speech trigram tag- +L+ ging model. However, the present lesson was their +L+ first exposure to EM or indeed to any kind of unsu- +L+ pervised learning. +L+ Figure 2: Initial guesses of parameters. +L+ Figure 3: Diary data and reconstructed weather. +L+ 4 The Ice Cream Climatology Data +L+ [While the spreadsheet could be used in many ways, +L+ the next several sections offer one detailed lesson +L+ plan. Questions for the class are included; subse- +L+ quent points often depend on the answers, which are +L+ concealed here in footnotes. Some fragments of the +L+ full spreadsheet are shown in the figures.] +L+ The situation: You are climatologists in the year +L+ 2799, studying the history of global warming. You +L+ can’t find any records of Baltimore weather, but you +L+ do find my diary, in which I assiduously recorded +L+ how much ice cream I ate each day (see Figure 3). +L+ What can you figure out from this about the weather +L+ that summer? +L+ Let’s simplify and suppose there are only two +L+ kinds of days: C (cold) and H (hot). And let’s sup- +L+ pose you have guessed some probabilities as shown +L+ on the spreadsheet (Figure 2). +L+ Thus, you guess that on cold days, I usually ate +L+ only 1 ice cream cone: my probabilities of 1, 2, +L+ or 3 cones were 70%, 20% and 10%. That adds +L+ up to 100%. On hot days, the probabilities were +L+ reversed—I usually ate 3 ice creams. So other things +L+ equal, if you know I ate 3 ice creams, the odds are +L+ 7 to 1 that it was a hot day, but if I ate 2 ice creams, +L+ the odds are 1 to 1 (no information). +L+ You also guess (still Figure 2) that if today is cold, +L+ tomorrow is probably cold, and if today is hot, to- +L+ morrow is probably hot. (Q: How does this setup +L+ resemble part-of-speech tagging?1) +L+ We also have some boundary conditions. I only +L+ kept this diary for a while. If I was more likely to +L+ start or stop the diary on a hot day, then that is use- +L+ ful information and it should go in the table. (Q: Is +L+ there an analogy in part-of-speech tagging?2) For +L+ simplicity, let’s guess that I was equally likely to +L+ start or stop on a hot or cold day. So the first day I +L+ started writing was equally likely (50%) to be hot or +L+ cold, and any given day had the same chance (10%) +L+ of being the last recorded day, e.g., because on any +L+ day I wrote (regardless of temperature), I had a 10% +L+ chance of losing my diary. +L+ 5 The Trellis and Decoding +L+ [The notationpi(H) in this paper stands for the prob- +L+ ability ofHon dayi, given all the observed ice cream +L+ data. On the spreadsheet itself the subscript i is +L+ clear from context and is dropped; thus in Figure 3, +L+ p(H) denotes the conditional probabilitypi(H), not a +L+ prior. The spreadsheet likewise omits subscripts on +L+ i(H) and i(H).] +L+ Scroll down the spreadsheet and look at the lower +L+ line of Figure 3, which shows a weather reconstruc- +L+ tion under the above assumptions. It estimates the +L+ relative hot and cold probabilities for each day. Ap- +L+ parently, the summer was mostly hot with a cold +L+ spell in the middle; we are unsure about the weather +L+ on a few transitional days. +L+ We will now see how the reconstruction was ac- +L+ complished. Look at the trellis diagram on the +L+ spreadsheet (Figure 4). Consistent with visual intu- +L+ ition, arcs (lines) represent days and states (points) +L+ represent the intervening midnights. A cold day is +L+ represented by an arc that ends in a C state.3 (So +L+ 1A: This is a bigram tag generation model with tagsCandH. +L+ Each tag independently generates a word (1, 2, or 3); the word +L+ choice is conditioned on the tag. +L+ 2A: A tagger should know that sentences tend to start with +L+ determiners and end with periods. A tagging that ends with a +L+ determiner should be penalized because p(StopjDet) 0. +L+ 3These conventions are a compromise between a traditional +L+ view of HMMs and a finite-state view used elsewhere in the +L+ course. (The two views correspond to Moore vs. Mealy ma- +L+ chines.) In the traditional view, states would represent days and +L+ Figure 4: The - trellis. +L+ each arc effectively inherits the C or H label of its +L+ terminal state.) +L+ Q: According to the trellis, what is the a priori +L+ probability that the first three days of summer are +L+ H,H,C and I eat 2,3,3 cones respectively (as I did)?4 +L+ Q: Of the 8 ways to account for the 2,3,3 cones, +L+ which is most probable?5 Q: Why do all 8 paths +L+ have low probabilities?6 +L+ Recall that the Viterbi algorithm computes, at +L+ each state of the trellis, the maximum probability +L+ of any path from Start. Similarly, define at a +L+ state to be the total probability of all paths to that +L+ state from Start. Q: How would you compute it +L+ by dynamic programming?7 Q: Symmetrically, how +L+ would you compute at a state, which is defined to +L+ be the total probability of all paths to Stop? +L+ The and values are computed on the spread- +L+ sheet (Figure 1). Q: Are there any patterns in the +L+ values?8 +L+ Now for some important questions. Q: What is +L+ the total probability of all paths from Start to +L+ would bear emission probabilities such asp(3jH). In Figure 4, +L+ as in finite-state machines, this role is played by the arcs (which +L+ also carry transition probabilities such as p(HjC)); this allows +L+ and to be described more simply as sums of path probabili- +L+ ties. But we persist in a traditional labeling of the states as H or +L+ C so that the notation can refer to them. +L+ 4A: Consult the path Start ! H ! H ! C, which has +L+ probability (0:5 </abstract>
	<phone>0:2) (0:8 0:7) (0:1 0:1) = 0:1 0:56 0:01 </phone>
	<abstract>= +L+ 0:00056. Note that the trellis is specialized to these data. +L+ 5A: H,H,H gives probability 0:1 0:56 0:56 = 0:03136. +L+ (Starting with C would be as cheap as starting with H, but then +L+ getting from C to H would be expensive.) +L+ 6A: It was a priori unlikely that I’d eat exactly this sequence +L+ of ice creams. (A priori there were many more than 8 possible +L+ paths, but this trellis only shows the paths generating the actual +L+ data 2,3,3.) We’ll be interested in the relative probabilities of +L+ these 8 paths. +L+ 7A: In terms of at the predecessor states: just replace +L+ “max” with “+” in the Viterbi algorithm. +L+ 8A: probabilities decrease going down the column, and +L+ probabilities decrease going up, as they become responsible for +L+ generating more and more ice cream data. +L+ Figure 5: Computing expected counts and their totals. +L+ Stop in which day 3 is hot?9 It is shown in col- +L+ umn H of Figure 1. Q: Why is column I of Figure 1 +L+ constant at 9.13e-19 across rows?10 Q: What does +L+ that column tell us about ice cream or weather?11 +L+ Now the class may be able to see how to complete +L+ the reconstruction: +L+ p(day 3 hotj2;3;3;:::) = p(day 3 hot;2;3;3;:::)p(2;3;3;:::) +L+ = 3(H) 3(H) +L+ 3(C) 3(C)+ 3(H) 3(H) +L+ = 9:0e-199:8e-21+9:0e-19 +L+ which is 0.989, as shown in cell K29 of Figure 5. +L+ Figure 3 simply graphs column K. +L+ 6 Understanding the Reconstruction +L+ Notice that the lower line in Figure 3 has the same +L+ general shape as the upper line (the original data), +L+ but is smoother. For example, some 2-ice-cream +L+ days were tagged as probably cold and some as +L+ probably hot. Q: Why?12 Q: Since the first day has +L+ 2 ice creams and doesn’t follow a hot day, why was +L+ it tagged as hot?13 Q: Why was day 11, which has +L+ only 1 ice cream, tagged as hot?14 +L+ We can experiment with the spreadsheet (using +L+ the Undo command after each experiment). Q: What +L+ do you predict will happen to Figure 3 if we weaken +L+ 9A: By the distributive law, 3(H) 3(H). +L+ 10A: It is the total probability of all paths that go through ei- +L+ ther CorHon a given day. But all paths do that, so this is simply +L+ the total probability of all paths! The choice of day doesn’t mat- +L+ ter. +L+ 11A: It is the probability of my actual ice cream consumption: +L+ p(2;3;3;:::) = P~wp(~w;2;3;3;:::) = 9.13e-19, where ~w +L+ ranges over all 233 possible weather state sequences such as +L+ H,H,C,. . . . Each summand is the probability of a trellis path. +L+ 12A: Figure 2 assumed a kind of “weather inertia” in which +L+ a hot day tends to be followed by another hot day, and likewise +L+ for cold days. +L+ 13Because an apparently hot day follows it. (See footnote 5.) +L+ It is the factors that consider this information from the future, +L+ and make 1(H) 1(H) 1(C) 1(C). +L+ 14A: Switching from hot to cold and back (HCH) has proba- +L+ bility 0.01, whereas staying hot (HHH) has probability 0.64. So +L+ although the fact that I ate only one ice cream on day 11 favors +L+ Cby 7 to 1, the inferred “fact” that days 10 and 12 are hot favors +L+ H by 64 to 1. +L+ (a) +L+ (b) +L+ Figure 6: With (a) no inertia, and (b) anti-inertia. +L+ or remove the “weather inertia” in Figure 2?15 Q: +L+ What happens if we try “anti-inertia”?16 +L+ Even though the number of ice creams is not de- +L+ cisive (consider day 11), it is influential. Q: What +L+ do you predict will happen if the distribution of ice +L+ creams is the same on hot and cold days?17 Q: What +L+ if we also change p(HjStart) from 0.5 to 0?18 +L+ 7 Reestimating Emission Probabilities +L+ We originally assumed (Figure 2) that I had a 20% +L+ chance of eating 2 cones on either a hot or a cold +L+ day. But if our reconstruction is right (Figure 3), I +L+ actually ate 2 cones on 20% of cold days but 40+% +L+ of hot days. +L+ 15A: Changing p(C j C) = p(H j C) = p(C j H) = p(H j +L+ H) = 0:45 cancels the smoothing effect (Figure 6a). The lower +L+ line now tracks the upper line exactly. +L+ 16A: Setting p(C j H) = p(H j C) = 0:8 and p(C j C) = +L+ p(HjH) = 0:1, rather than vice-versa, yields Figure 6b. +L+ 17A: The ice cream data now gives us no information about +L+ the weather, so pi(H) = pi(C) = 0:5 on every day i. +L+ 18A: p1(H) = 0, but pi(H) increases toward an asymptote +L+ of 0.5 (the “limit distribution”). The weather is more likely to +L+ switch to hot than to cold if it was more likely cold to begin +L+ with; so pi(H) increases if it is &lt; 0:5. +L+ Figure 7: Parameters of Figure 2 updated by reestimation. +L+ So now that we “know” which days are hot and +L+ which days are cold, we should really update our +L+ probabilities to 0.2 and 0.4, not 0.2 and 0.2. After +L+ all, our initial probabilities were just guesses. +L+ Q: Where does the learning come from—isn’t this +L+ circular? Since our reconstruction was based on the +L+ guessed probabilities 0.2 and 0.2, why didn’t the re- +L+ construction perfectly reflect those guesses?19 +L+ Scrolling rightward on the spreadsheet, we find +L+ a table giving the updated probabilities (Figure 7). +L+ This table feeds into a second copy of the forward- +L+ backward calculation and graph. Q: The second +L+ graph of pi(H) (not shown here) closely resembles +L+ the first; why is it different on days 11 and 27?20 +L+ The updated probability table was computed by +L+ the spreadsheet. Q: When it calculated how often I +L+ ate 2 cones on a reconstructed hot day, do you think +L+ it counted day 27 as a hot day or </abstract>
	<note>a cold day?21 +L+ 8 Reestimating Transition Probabilities +L+ Notice that Figure 7 also updated the transition prob- +L+ abilities. This involved counting the 4 kinds of days +L+ distinguished by Figure 8:22 e.g., what fraction of H +L+ 19A: The reconstruction of the weather </note>
	<abstract>underlying the ob- +L+ served data was a compromise between the guessed probabili- +L+ ties (Figure 2) and the demands of the actual data. The model +L+ in Figure 2 disagreed with the data: it would not have predicted +L+ that 2-cone days actually accounted for more than 20% of all +L+ days, or that they were disproportionately likely to fall between +L+ 3-cone days. +L+ 20A: These days fall between hot and cold days, so smoothing +L+ has little effect: their temperature is mainly reconstructed from +L+ the number of ice creams. 1 ice cream is now better evidence of +L+ a cold day, and 2 ice creams of a hot day. Interestingly, days 11 +L+ and 14 can now conspire to “cool down” the intervening 3-ice- +L+ cream days. +L+ 21A: Half of each, since p27(H) 0:5! The actual compu- +L+ tation is performed in Figure 5 and should be discussed at this +L+ point. +L+ 22Notice how p(H ! C) and p(C ! H) spike when the +L+ weather changes, on day 14 and either day 27 or 28. +L+ Figure 8: Second-order weather reconstruction. +L+ days were followed by H? Again, fractional counts +L+ were used to handle uncertainty. +L+ Q: Does Figure 3 (first-order reconstruction) +L+ contain enough information to construct Figure 8 +L+ (second-order reconstruction)?23 +L+ Continuing with the probabilities from the end of +L+ footnote 23, suppose we increase p(HjStart) to +L+ 0.7. Q: What will happen to the first-order graph?24 +L+ Q: What if we switch from anti-inertia back to iner- +L+ tia (Figure 9)?25 +L+ Q: In this last case, what do you predict will hap- +L+ pen when we reestimate the probabilities?26 +L+ This reestimation (Figure 10) slightly improved +L+ the reconstruction. [Defer discussion of what “im- +L+ proved” means: the class still assumes that good re- +L+ constructions look like Figure 3.] Q: Now what? +L+ A: Perhaps we should do it again. And again, and +L+ again. . . Scrolling rightward past 10 successive rees- +L+ timations, we see that this arrives at the intuitively +L+ 23A: No. A dramatic way to see this is to make the dis- +L+ tribution of ice cream distribution the same on hot and cold +L+ days. This makes the first-order graph constant at 0.5 as in foot- +L+ note 17. But we can still get a range of behaviors in the second- +L+ order graph; e.g., if we switch from inertia to anti-inertia as in +L+ footnote 16, then we switch from thinking the weather is un- +L+ known but constant to thinking it is unknown but oscillating. +L+ 24A: pi(H) alternates and converges to 0.5 from both sides. +L+ 25A: pi(H) converges to 0.5 from above (cf. footnote 18), as +L+ shown in Figure 9. +L+ 26A: The first-order graph suggests that the early days of +L+ summer were slightly more likely to be hot than cold. Since +L+ we ate more ice cream on those days, the reestimated probabili- +L+ ties (unlike the initial ones) slightly favor eating more ice cream +L+ on hot days. So the new reconstruction based on these proba- +L+ bilities has a very shallow “U” shape (bottom of Figure 10), in +L+ which the low-ice-cream middle of the summer is slightly less +L+ likely to be hot. +L+ Figure 9: An initial poor reconstruction that will be improved +L+ by reestimation. +L+ correct answer (Figure 11)! +L+ Thus, starting from an uninformed probability ta- +L+ ble, the spreadsheet learned sensible probabilities +L+ (Figure 11) that enabled it to reconstruct the weather. +L+ The 3-D graph shows how the reconstruction im- +L+ proved over time. +L+ The only remaining detail is how the transition +L+ probabilities in Figure 8 were computed. Recall that +L+ to get Figure 3, we asked what fraction of paths +L+ passed through each state. This time we must ask +L+ what fraction of paths traversed each arc. (Q: How +L+ to compute this?27) Just as there were two possible +L+ states each day, there are four possible arcs each day, +L+ and the graph reflects their relative probabilities. +L+ 9 Reestimation Experiments +L+ We can check whether the algorithm still learns from +L+ other initial guesses. The following examples appear +L+ on the spreadsheet and can be copied over the table +L+ of initial probabilities. (Except for the pathologi- +L+ cally symmetric third case, they all learn the same +L+ structure.) +L+ 1. No weather inertia, but more ice cream on hot +L+ days. The model initially behaves as in foot- +L+ 27A: The total probability of all paths traversing q ! r is +L+ (q) p(q!r) (r). +L+ Figure 10: The effect of reestimation on Figure 9. +L+ note 15, but over time it learns that weather does +L+ have inertia. +L+ 2. Inertia, but only a very slight preference for more +L+ ice cream on hot days. The pi(H) graph is ini- +L+ tially almost as flat as in footnote 17. But over +L+ several passes the model learns that I eat a lot +L+ more ice cream on hot days. +L+ 3. A completely symmetric initial state: no inertia, +L+ and no preference at all for more ice cream on hot +L+ days. Q: What do you expect to happen under +L+ reestimation?28 +L+ 4. Like the previous case, but break the symmetry +L+ by giving cold days a slight preference to eat +L+ more ice cream (Figure 12). This initial state is +L+ almost perfectly symmetric. Q: Why doesn’t this +L+ case appear to learn the same structure as the pre- +L+ vious ones?29 +L+ The final case does not converge to quite the same +L+ result as the others: C and H are reversed. (It is +L+ 28A: Nothing changes, since the situation is too symmetric. +L+ As H and C behave identically, there is nothing to differentiate +L+ them and allow them to specialize. +L+ 29A: Actually it does; it merely requires more iterations to +L+ converge. (The spreadsheet is only wide enough to hold 10 iter- +L+ ations; to run for 10 more, just copy the final probabilities back +L+ over the initial ones. Repeat as necessary.) It learns both inertia +L+ and a preference for more ice cream on cold days. +L+ Figure 11: Nine more passes of forward-backward reestimation +L+ on Figures 9–10. Note that the final graph is even smoother than +L+ Figure 3. +L+ Figure 12: Breaking symmetry toward the opposite solution. +L+ Figure 13: If T is the sequence of 34 training observations +L+ (33 days plus Stop), then p(T) increases rapidly during rees- +L+ timation. To compress the range of the graph, we don’t plot +L+ p(T) but rather perplexity per observation = 1= 34 +L+ p +L+ p(T) = +L+ 2 (log2 p(T))=34. +L+ nowHthat is used for the low-ice-cream midsummer +L+ days.) Should you care about this difference? As +L+ climatologists, you might very well be upset that the +L+ spreadsheet reversed cold and hot days. But since C +L+ and H are ultimately just arbitrary labels, then per- +L+ haps the outcome is equally good in some sense. +L+ What does it mean for the outcome of this unsuper- +L+ vised learning procedure to be “good”? The dataset +L+ is just the ice cream diary, which makes no reference +L+ to weather. Without knowing the true weather, how +L+ can we tell whether we did a good job learning it? +L+ 10 Local Maximization of Likelihood +L+ The answer: A good model is one that predicts the +L+ dataset as accurately as possible. The dataset actu- +L+ ally has temporal structure, since I tended to have +L+ long periods of high and low ice cream consump- +L+ tion. That structure is what the algorithm discov- +L+ ered, regardless of whether weather was the cause. +L+ The state C or H distinguishes between the two kinds +L+ of periods and tends to persist over time. +L+ So did this learned model predict the dataset well? +L+ It was not always sure about the state sequence, +L+ but Figure 13 shows that the likelihood of the ob- +L+ served dataset (summed over all possible state se- +L+ quences) increased on every iteration. (Q: How is +L+ this found?30) +L+ That behavior is actually guaranteed: repeated +L+ 30It is the total probability of paths that explain the data, i.e., +L+ all paths in Figure 4, as given by column I of Figure 1; see +L+ footnote 10. +L+ forward-backward reestimation converges to a local +L+ maximum of likelihood. We have already discov- +L+ ered two symmetric local maxima, both with per- +L+ plexity of 2.827 per day: the model might use C to +L+ represent cold and H to represent hot, or vice versa. +L+ Q: How much better is 2.827 than a model with no +L+ temporal structure?31 +L+ Remember that maximizing the likelihood of the +L+ training data can lead to overfitting. Q: Do you see +L+ any evidence of this in the final probability table?32 +L+ Q: Is there a remedy?33 +L+ 11 A Trick Ending +L+ We get very different results if we slightly mod- +L+ ify Figure 12 by putting p(1 j H) = 0:3 with +L+ p(2 j H) = 0:4. The structure of the solution is +L+ very different (Figure 14). In fact, the final param- +L+ eters now show anti-inertia, giving a reconstruction +L+ similar to Figure 6b. Q: What went wrong?34 +L+ In the two previous local maxima, H meant “low +L+ ice-cream day” or “high ice-cream day.” Q: Accord- +L+ ing to Figure 14, what doesHmean here?35 Q: What +L+ does the low value of p(HjH) mean?36 +L+ So we see that there are actually two kinds of +L+ structure coexisting in this dataset: days with a lot +L+ (little) ice cream tend to repeat, and days with 2 ice +L+ creams tend not to repeat. The first kind of structure +L+ did a better job of lowering the perplexity, but both +L+ 31A: A model with no temporal structure is a unigram model. +L+ A good guess is that it will have perplexity 3, since it will be +L+ completely undecided between the 3 kinds of observations. (It +L+ so happens that they were equally frequent in the dataset.) How- +L+ ever, if we prevent the learning of temporal structure (by setting +L+ the initial conditions so that the model is always in state C, or is +L+ always equally likely to be in states C and H), we find that the +L+ perplexity is 3.314, reflecting the four-way unigram distribution +L+ p(1) = p(2) = p(3) = 11=34, p(Stop)=1/34. +L+ 32A: p(H j Start) ! 1 because we become increasingly +L+ sure that the training diary started on a hot day. But this single +L+ training observation, no matter how justifiably certain we are of +L+ it, might not generalize to next summer’s diary. +L+ 33A: Smoothing the fractional counts. Note: If a prior is used +L+ for smoothing, the algorithm is guaranteed to locally maximize +L+ the posterior (in place of the likelihood). +L+ 34A: This is a third local maximum of likelihood, unrelated +L+ to the others, with worse perplexity (3.059). Getting stuck in +L+ poor local maxima is an occupational hazard. +L+ 35A: H usually emits 2 ice creams, whereas C never does. So +L+ H stands for a 2-ice-cream day. +L+ 36A: That 2 ice creams are rarely followed by 2 ice creams. +L+ Looking at the dataset, this is true. So even this local maximum +L+ successfully discovered some structure: it discovered (to my +L+ surprise) that when I make up data, I tend not to repeat 2’s! +L+ Figure 14: A suboptimal local maximum. +L+ are useful. Q: How could we get our model to dis- +L+ cover both kinds of structure (thereby lowering the +L+ perplexity further)?37 +L+ Q: We have now seen three locally optimal mod- +L+ els in which the H state was used for 3 different +L+ things—even though we named it H for “Hot.” What +L+ does this mean for the application of this algorithm +L+ to part-of-speech tagging?38 +L+ 12 Follow-Up Assignment +L+ In a follow-up assignment, students applied Viterbi +L+ decoding and forward-backward reestimation to +L+ part-of-speech tagging.39 +L+ In the assignment, students were asked to test +L+ their code first on the ice cream data (provided as +L+ a small tagged corpus) before switching to real data. +L+ </abstract>
	<note>This cemented the analogy between the ice cream +L+ and tagging tasks, helping students connect the class +L+ to the assignment. +L+ 37A: Use more states. Four states would suffice to distinguish +L+ hot/2, cold/2, hot/not2, and cold/not2 days. +L+ 38A: There is no guarantee that N and V will continue to dis- +L+ tinguish nouns and verbs after reestimation. They will evolve to +L+ make whatever distinctions help to predict the word sequence. +L+ 39Advanced students might also want to read about a mod- +L+ ern supervised trigram tagger (Brants, 2000), or the mixed re- +L+ sults when one actually trains trigram taggers by EM (Merialdo, +L+ 1994). +L+ Furthermore, students could check their ice cream +L+ output against the spreadsheet, and track down basic +L+ bugs by comparing their intermediate results to the +L+ spreadsheet’s. They reported this to be very useful. +L+ Presumably it helps learning when students actually +L+ find their bugs before handing in the assignment, and +L+ when they are able to isolate their misconceptions +L+ on their own. It also made office hours and grading +L+ much easier for the teaching assistant. +L+ 13 Availability +L+ The spreadsheet (in Microsoft Excel) and assign- +L+ ment are available at http://www.cs.jhu. +L+ edu/˜jason/papers/#tnlp02. +L+ Also available is a second version of the spread- +L+ sheet, which uses the Viterbi approximation for de- +L+ coding and reestimation. The Viterbi algorithm is +L+ implemented in an unconventional way so that the +L+ two spreadsheets are almost identical; there is no +L+ need to follow backpointers. The probability of the +L+ best path through state H on day 3 is 3(H) 3(H), +L+ where and are computed like and but maxi- +L+ mizing rather than summing path probabilities. The +L+ Viterbi approximation treats p3(H) as 1 or 0 accord- +L+ ing to whether 3(H) 3(H) equals max( 3(C) +L+ 3(C); 3(H) 3(H)). +L+ Have fun! Comments are most welcome. +L+ References +L+ L. </note>
	<abstract>E. Baum. 1972. An inequality and associated max- +L+ imization technique in statistical estimation of proba- +L+ bilistic functions of a Markov process. Inequalities, 3. +L+ Thorsten Brants. 2000. TnT: A statistical part-of-speech +L+ tagger. In Proc. of ANLP, Seattle. +L+ K. W. Church. 1988. A stochastic parts program and noun +L+ phrase parser for unrestricted text. Proc. of ANLP. +L+ Steven J. DeRose. 1988. Grammatical category disam- +L+ biguation by statistical optimization. Computational +L+ Linguistics, 14(1):31–39. +L+ Jason Eisner. 2002. Parameter estimation for probabilis- +L+ tic finite-state transducers. In Proc. of ACL. +L+ Steffen L. Lauritzen. 1995. The EM algorithm for graph- +L+ ical association models with missing data. Computa- +L+ tional Statistics and Data Analysis, 19:191–201. +L+ Bernard Merialdo. 1994. Tagging English text with a +L+ probabilistic model. Comp. Ling., 20(2):155–172. +L+ Judea Pearl. 1988. Probabilistic Reasoning in Intelli- +L+ gent </abstract>
	<note>Systems: Networks of Plausible Inference. Mor- +L+ gan Kaufmann, San Mateo, California. +L+ L. R. Rabiner. 1989. A tutorial on hidden Markov mod- +L+ els and selected applications in speech recognition. +L+ Proceedings of IEEE, 77(2):257–285, February. +L+ </note>
  </variant>
  </entry>
  <entry no="1">
  </entry>
</file>
