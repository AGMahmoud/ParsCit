<?xml version="1.0" encoding="UTF-8"?>
<result>
<algorithm name="ParsHed" version="090625" confidence="0.916415">
<title confidence="0.9991785">Using Long Runs as Predictors of Semantic Coherence in a Partial Document Retrieval System</title>
<author confidence="0.99378">Hyopil Shin</author>
<affiliation confidence="0.992076">Computing Research Laboratory, NMSU</affiliation>
<address confidence="0.9769505">PO Box 30001 Las Cruces, NM, 88003</address>
<email confidence="0.999442">hshin@crl.nmsu.edu</email>
<author confidence="0.998672">Jerrold F Stach</author>
<affiliation confidence="0.989141">Computer Science Telecommunications, UMKC</affiliation>
<address confidence="0.9988995">5100 Rockhill Road Kansas City, MO, 64110</address>
<email confidence="0.991658">stach@cstp.umkc.edu</email>
<abstract confidence="0.999518913043478">We propose a method for dealing with semantic complexities occurring in information retrieval systems on the basis of linguistic observations. Our method follows from an analysis indicating that long runs of content words appear in a stopped document cluster, and our observation that these long runs predominately originate from the prepositional phrase and subject complement positions and as such, may be useful predictors of semantic coherence. From this linguistic basis, we test three statistical hypotheses over a small collection of documents from different genre. By coordinating thesaurus semantic categories (SEMCATs) of the long run words to the semantic categories of paragraphs, we conclude that for paragraphs containing both long runs and short runs, the SEMCAT weight of long runs of content words is a strong predictor of the semantic coherence of the paragraph</abstract>
</algorithm>
<algorithm name="ParsCit" version="090625">
<citationList>
<citation valid="true">
<authors>
<author>R Boyd</author>
<author>J Driscoll</author>
<author>I Syu</author>
</authors>
<title>Incorporating Semantics Within a Connectionist Model and a Vector Processing Model</title>
<date>1994</date>
<booktitle>In Proceedings of the TREC-2</booktitle>
<pages>NIST.</pages>
<contexts>
<context position="12623" citStr="Boyd et al. (1994)">ed out in Section 1, all terms are not known in partial text retrieval. Further, our approach is based on semantic weight rather than word frequency. Therefore any frequency based measures defined by Boyd et al. (1994) and Wendlandt (1991) need to be built from the probabilities of individual semantic categories. Those modifications are described below. As a simplifying assumption, we assume SEMCATs have a uniform </context>
<context position="23595" citStr="Boyd et al. (1994)">ar structures function as 12 minor predication and as such are loci of semantic intent or coherence. In order to facilitate the use of long runs as predictors, we modified the traditional measures of Boyd et al. (1994), Wendlandt (1991) to accommodate semantic categories and partial text retrieval. The revised metrics and the computational method we propose were used in the statistical experiments presented above. </context>
</contexts>
<marker>Boyd, Driscoll, Syu, 1994</marker>
<rawString>Boyd R., Driscoll J, and Syu I. (1994) Incorporating Semantics Within a Connectionist Model and a Vector Processing Model. In Proceedings of the TREC-2, NIST.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Deerwester</author>
<author>G Furnas</author>
<author>T Landauer</author>
<author>R Harshman</author>
</authors>
<title>Indexing by Latent Semantic Anaysis</title>
<date>1990</date>
<journal>Journal of the American Society of Information Science</journal>
<pages>41--6</pages>
<marker>Deerwester, Furnas, Landauer, Harshman, 1990</marker>
<rawString>Deerwester S., Furnas G., Landauer T., and Harshman R. (1990) Indexing by Latent Semantic Anaysis. Journal of the American Society of Information Science 41-6.</rawString>
</citation>
</citationList>
</algorithm>
</result>