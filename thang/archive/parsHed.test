<title> Protocols for Collecting Responses +L+ in Multi-hop Radio Networks +L+ </title> <author> Chungki Lee James E. Burns +L+ Mostafa H. Ammar +L+ </author> <pubnum> GIT-CC-92/28 +L+ </pubnum> <date> June 1992 +L+ </date> <abstract> Abstract +L+ The problem of collecting responses in multi-hop radio networks is considered. A given node, called the source, is to collect a specified number of +L+ responses from nodes in a radio network. The problem arises in several +L+ applications of distributed systems. A deterministic and a randomized protocol for the problem are presented. The two protocols are analyzed and +L+ their performance is compared. Conclusions are drawn about the suitability +L+ of our protocols in various network environments. +L+ </abstract> <affiliation> College of Computing +L+ Georgia Institute of Technology +L+ </affiliation> <address> Atlanta, Georgia 30332-0280 +L+ </address> <page> +PAGE+ </page> 
<title> Classes as Assertions +L+ </title> <author> Neelam Soundarajan +L+ </author> <affiliation> Computer and Information Science +L+ The Ohio State University +L+ </affiliation> <address> Columbus, OH 43210 +L+ </address> <email> e-mail: neelam@cis.ohio-state.edu +L+ </email> <abstract> Abstract: How do we formally specify the relation between a base class and a +L+ derived class? This question has two parts, a syntactic one, and a semantic one. +L+ The syntactic part is of course the easier of the two and the answer to that part is +L+ the standard contra/co- variance requirement on the arguments and result of any +L+ base class method redefined in the derived class. Our concern in the current paper +L+ is with the semantic part of the question, i.e., how do we specify the behavioral +L+ relation between the base class and the derived class? We show that the standard +L+ answer -which is the semantic counterpart of contra/co-variance- is too rigid, and +L+ does not allow some natural and common forms of inheritance. We then propose a +L+ more flexible way to specify the relation, and show how different types of behavioral relations between base classes and derived classes may be specified using our +L+ notation. +L+ </abstract> <page> +PAGE+ </page> 
<title> The SAMOS Active DBMS Prototype +L+ </title> <author> Stella Gatziu , Andreas Geppert , Klaus R. Dittrich +L+ </author> <affiliation> Institut fur Informatik, Universitat uZrich 1 +L+ </affiliation> <pubnum> Technical Report 94.16 +L+ </pubnum> <abstract> Abstract +L+ We describe SAMOS, an active object-oriented database management system prototype. SAMOS offers a powerful rule definition language, including a small yet powerful set of event definition facilities. It is able to detect primitive and composite events +L+ automatically and efficiently. Upon event detection, SAMOS executes rules attached +L+ to the occurred events. +L+ </abstract> <intro> 1 Introduction </intro> 
<title> Location Independent Names for Nomadic Computers +L+ </title> <author> David C. Steere , Mark Morrissey , Peter Geib , Calton Pu , and Jonathan Walpole +L+ </author> <affiliation> Department of Computer Science and Engineering +L+ Oregon Graduate Institute +L+ </affiliation> <abstract> Abstract +L+ Recent advances in the Domain Name System (DNS) and the Dynamic Host Configuration +L+ Protocol (DHCP) have enabled a new approach to supporting mobile users: location independent +L+ naming. In this approach, machines use the same hostname from any internet location, but use an +L+ IP address that corresponds to their current location. We describe a protocol that implements +L+ location independent naming for nomadic computers, i.e., machines that do not need transparent +L+ mobility. Our protocol allows hosts to move across security domains, uses existing protocols, and +L+ preserves existing trust relationships. Therefore, it preserves the performance and security of +L+ normal IP for nomadic computers at the expense of not providing the transparent mobility of +L+ Mobile IP. We contend that this is a reasonable tradeoff for nomadic computing. +L+ </abstract> <intro> 1 Introduction </intro> 
<title> Vertex heaviest paths and cycles in quasi-transitive +L+ digraphs +L+ </title> <author> Jtrgen Bang-Jensen +L+ Gregory Gutin +L+ </author> <affiliation> Department of Mathematics and Computer Science +L+ Odense University, </affiliation> <address> Denmark +L+ </address> <abstract> Abstract +L+ A digraph D is called a quasi-transitive digraph (QTD) if for any +L+ triple x; ; of distinct vertices of D such that (x; ) and (; ) are +L+ arcs of D there is at least one arc from x to or from to x. Solving +L+ a conjecture by J. Bang-Jensen and J. Huang (J. Graph Theory, to +L+ appear), G. Gutin (Australas. J. Combin., to appear) described polynomial algorithms for finding a Hamiltonian cycle and a Hamiltonian +L+ path (if it exists) in a QTD. The approach taken in that paper cannot +L+ be used to find a longest path or cycle in polynomial time. We present +L+ a principally new approach that leads to polynomial algorithms for +L+ finding vertex heaviest paths and cycles in QTD's with non-negative +L+ weights on the vertices. This, in particular, provides an answer to a +L+ question by N. Alon on longest paths and cycles in QTD's. +L+ </abstract> <intro> 1 Introduction </intro> 
<title> Shape Modeling with Front Propagation: A Level Set Approach +L+ </title> <author> Ravikanth Malladi , 1 James A. Sethian , 1 and Baba C. Vemuri 2 +L+ </author> <affiliation> 1 Lawrence Berkeley Laboratory +L+ and +L+ Department of Mathematics +L+ University of California, </affiliation> <address> Berkeley, CA 94720. +L+ </address> <affiliation> 2 Department of Computer & Information Sciences +L+ University of Florida, </affiliation> <address> Gainesville, FL 32611. +L+ </address> <abstract> Abstract +L+ Shape modeling is an important constituent of computer vision as well as computer graphics +L+ research. Shape models aid the tasks of object representation and recognition. This paper +L+ presents a new approach to shape modeling which retains some of the attractive features of +L+ existing methods, and overcomes some of their limitations. Our techniques can be applied to +L+ model arbitrarily complex shapes, which include shapes with significant protrusions, and to +L+ situations where no a priori assumption about the object's topology is made. A single instance +L+ of our model, when presented with an image having more than one object of interest, has the +L+ ability to split freely to represent each object. This method is based on the ideas developed +L+ by Osher and Sethian to model propagating solid/liquid interfaces with curvature-dependent +L+ speeds. The interface (front) is a closed, nonintersecting, hypersurface flowing along its gradient +L+ field with constant speed or a speed that depends on the curvature. It is moved by solving a +L+ "Hamilton-Jacobi" type equation written for a function in which the interface is a particular +L+ level set. A speed term synthesized from the image is used to stop the interface in the vicinity of +L+ object boundaries. The resulting equation of motion is solved by employing entropy-satisfying +L+ upwind finite difference schemes. We present a variety of ways of computing evolving front, +L+ including narrow bands, reinitializations, and different stopping criteria. The efficacy of the +L+ scheme is demonstrated with numerical experiments on some synthesized images and some low +L+ contrast medical images. +L+ </abstract> <note> fl1 Supported in part by the Applied Mathematical Sciences Subprogram of the Office of Energy Research, U.S. +L+ Dept. of Energy under Contract DE-AC03-76SD00098 and by the NSF ARPA under grant DMS-8919074. +L+ 2 Supported in part by NSF grant ECS-9210648. +L+ </note> <page> +PAGE+ </page> 
<title> Evolution of Recursive Transition Networks for +L+ Natural Language Recognition with Parallel +L+ Distributed Genetic Programming +L+ </title> <author> Riccardo Poli +L+ </author> <affiliation> School of Computer Science +L+ The University of Birmingham +L+ </affiliation> <email> E-mail: R.Poli@cs.bham.ac.uk +L+ </email> <pubnum> Technical Report: CSRP-96-19 +L+ </pubnum> <date> December 1996 +L+ </date> <abstract> Abstract +L+ This paper describes the application of Parallel Distributed Genetic Programming (PDGP) to the problem of inducing programs for natural language processing. +L+ PDGP is a new form of Genetic Programming (GP) which is suitable for the development of programs with a high degree of parallelism and an efficient and effective +L+ reuse of partial results. Programs are represented in PDGP as graphs with nodes +L+ representing functions and terminals, and links representing the flow of control and +L+ results. PDGP allows the exploration of a large space of possible programs including standard tree-like programs, logic networks, neural networks, finite state +L+ automata, Recursive Transition Networks (RTNs), etc. The paper describes the +L+ representations, the operators and the interpreters used in PDGP, and illustrates +L+ its behaviour on the problem of inducing RTN-based recognisers for natural lan +L+ guage from positive and negative examples. +L+ </abstract> <intro> 1 Introduction </intro> 
<title> Does Configuration Management Research Have a Future? +L+ </title> <author> Andre van der Hoek , Dennis Heimbigner , and Alexander L. Wolf +L+ </author> <affiliation> Department of Computer Science, CB 430 +L+ University of Colorado +L+ </affiliation> <address> Boulder, Colorado 80309 USA +L+ </address> <email> fandre,dennis,alwg@cs.colorado.edu +L+ </email> <abstract> Abstract +L+ In this position paper we raise the question of whether Configuration Management (CM) +L+ research has a future. The new standard in CM systems|typified by commercial products +L+ such as Adele, ADC, ClearCase, Continuus/CM, and CCC/Harvest|largely satisfies the CM +L+ functionality requirements posed by Dart. This implies that research in the area of CM is either +L+ unnecessary or that we must find new challenges in CM on which to focus. We believe that +L+ these challenges indeed exist. Here we present some areas that we feel are good opportunities +L+ for new or continued CM research, and therefore conclude that CM research does have a future. +L+ </abstract> <intro> Introduction </intro> 
<title> Numerical conformal mapping using cross-ratios +L+ and Delaunay triangulation +L+ </title> <author> Tobin A. Driscoll Stephen A. Vavasis +L+ </author> <date> January 23, 1996 +L+ </date> <abstract> Abstract +L+ We propose a new algorithm for computing the Riemann mapping of the +L+ unit disk to a polygon, also known as the Schwarz-Christoffel transformation. +L+ The new algorithm, CRDT, is based on cross-ratios of the prevertices, and also +L+ on cross-ratios of quadrilaterals in a Delaunay triangulation of the polygon. +L+ The CRDT algorithm produces an accurate representation of the Riemann +L+ mapping even in the presence of arbitrary long, thin regions in the polygon, +L+ unlike any previous conformal mapping algorithm. We believe that CRDT can +L+ never fail to converge to the correct Riemann mapping, but the correctness and +L+ convergence proof depend on conjectures that we have so far not been able to +L+ prove. We demonstrate convergence with computational experiments. +L+ The Riemann mapping has applications to problems in two-dimensional +L+ potential theory and to finite-difference mesh generation. We use CRDT to +L+ produce a mapping and solve a boundary value problem on long, thin regions +L+ for which no other algorithm can solve these problems. +L+ </abstract> <intro> 1 Conformal mapping </intro> 
<title> A Feedback Mechanism for Query by Navigation +L+ </title> <author> F.C. Berger +L+ Th.P. van der Weide n +L+ </author> <note> Published as: </note> <author> F.C. Berger and Th.P. van der +L+ Weide. </author> <title> A Feedback Mechanism for Query by +L+ Navigation. </title> <pubnum> Technical Report CSI-R9413, </pubnum> <affiliation> Computing Science Institute, University of Nijmegen, +L+ </affiliation> <address> Nijmegen, The Netherlands, </address> <date> October 1994. </date> +L+ <abstract> Abstract +L+ The Two-Level Hypermedia Paradigm sees an +L+ Information Retrieval System as consisting of +L+ a document network (the Hyperbase) and a +L+ descriptor (term) network (the Hyperindex). +L+ Query by Navigation is a process whereby the +L+ searcher gives a description of the Information Need by travelling through the descriptor +L+ network. This paper presents a formalism for +L+ expressing the effects of traversing the Hyper-index on the elements of the Hyperindex. This +L+ formalism makes use of probabilities for mod-elling the searcher's behavious. The events +L+ which can occur during the search process +L+ are discussed and modelled. Some important +L+ properties, which are reasonable to demand of +L+ a retrieval system, can be proven to be valid +L+ if this formalism is adopted. A mechanism +L+ for assigning a measure of relevance to documents is presented. This uses the formalism +L+ mentioned above. An example will show the +L+ effectiveness of The aspect of relevance feedback and its role in Query by Navigation is +L+ introduced by examining the different level on +L+ which the searcher can offer information for +L+ weeding out unwanted sections of the search +L+ space. In order to illustrate the workings of +L+ Query by Navigation a small example is included. +L+ </abstract> <affiliation> Dept. of Information Systems, Faculty of Mathematics and +L+ Informatics, University of Nijmegen, </affiliation> <address> Toernooiveld 1, 6525 ED +L+ Nijmegen, The Netherlands +L+ </address> <keyword> Keywords: information retrieval, relevance feedback, user modelling, query formulation +L+ </keyword> <note> Classification: AMS 68P20; CR H.3.3, H.5.1 +L+ </note> <intro> 1 Introduction </intro> 
<title> Tally NP Sets and Easy Census Functions +L+ </title> <author> Judy Goldsmith 1 +L+ </author> <affiliation> Department of Computer Science +L+ University of Kentucky +L+ </affiliation> <address> Lexington, KY 40506, USA +L+ </address> <email> goldsmit@cs.engr.uky.edu +L+ </email> <author> Mitsunori Ogihara 2 +L+ </author> <affiliation> Department of Computer Science +L+ University of Rochester +L+ </affiliation> <address> Rochester, NY 14627, USA +L+ </address> <email> ogihara@cs.rochester.edu +L+ </email> <author> Jorg Rothe 3 +L+ </author> <affiliation> Institut fur Informatik +L+ Friedrich-Schiller-Universitat Jena +L+ </affiliation> <address> 07740 Jena, Germany +L+ </address> <email> rothe@informatik.uni-jena.de +L+ </email> <date> March 19, 1998 +L+ </date> <note> 1 Supported in part by NSF grant CCR-9315354. +L+ 2 Supported in part by NSF CAREER Award CCR-9701911. +L+ 3 Supported in part by grants NSF-INT-9513368/DAAD-315-PRO-fo-ab and NSF-CCR-9322513 +L+ and by a NATO Postdoctoral Science Fellowship from the Deutscher Akademischer Austausch-dienst ("Gemeinsames Hochschulsonderprogramm III von Bund und Landern"). Current address: +L+ Department of Computer Science, University of Rochester, Rochester, NY 14627, USA. Work done +L+ in part while visiting the University of Kentucky and the University of Rochester. +L+ </note> <page> +PAGE+ </page> 
<title> Intra-Option Learning about Temporally Abstract Actions +L+ </title> <author> Richard S. Sutton +L+ </author> <affiliation> Department of Computer Science +L+ University of Massachusetts +L+ </affiliation> <address> Amherst, MA 01003-4610 +L+ </address> <email> rich@cs.umass.edu +L+ </email> <author> Doina Precup +L+ </author> <affiliation> Department of Computer Science +L+ University of Massachusetts +L+ </affiliation> <address> Amherst, MA 01003-4610 +L+ </address> <email> dprecup@cs.umass.edu +L+ </email> <author> Satinder Singh +L+ </author> <affiliation> Department of Computer Science +L+ University of Colorado +L+ </affiliation> <address> Boulder, CO 80309-0430 +L+ </address> <email> baveja@cs.colorado.edu +L+ </email> <abstract> Abstract +L+ Several researchers have proposed modeling +L+ temporally abstract actions in reinforcement +L+ learning by the combination of a policy and a termination condition, which we refer to as an option. Value functions over options and models of +L+ options can be learned using methods designed +L+ for semi-Markov decision processes (SMDPs). +L+ However, all these methods require an option to +L+ be executed to termination. In this paper we explore methods that learn about an option from +L+ small fragments of experience consistent with +L+ that option, even if the option itself is not executed. We call these methods intra-option learning methods because they learn from experience +L+ within an option. Intra-option methods are sometimes much more efficient than SMDP methods because they can use off-policy temporal-difference mechanisms to learn simultaneously +L+ about all the options consistent with an experience, not just the few that were actually executed. In this paper we present intra-option learning methods for learning value functions over options and for learning multi-time models of the +L+ consequences of options. We present computational examples in which these new methods +L+ learn much faster than SMDP methods and learn +L+ effectively when SMDP methods cannot learn at +L+ all. We also sketch a convergence proof for intra +L+ option value learning. +L+ </abstract> <intro> 1 Introduction </intro> 
<title> Hierarchical Inter-Domain Routing Protocol +L+ with On-Demand ToS and Policy Resolution +L+ </title> <author> Cengiz Alaettinoglu , A. Udaya Shankar +L+ </author> <affiliation> Institute for Advanced Computer Studies +L+ Department of Computer Science +L+ University of Maryland +L+ </affiliation> <address> College Park, Maryland 20742 +L+ </address> <pubnum> CS-TR-3299 +L+ </pubnum> <date> June 20, 1994 +L+ </date> <abstract> Abstract +L+ Traditional inter-domain routing protocols based on superdomains maintain either "strong" +L+ or "weak" ToS and policy constraints for each visible superdomain. With strong constraints, +L+ a valid path may not be found even though one exists. With weak constraints, an invalid +L+ domain-level path may be treated as a valid path. +L+ We present an inter-domain routing protocol based on superdomains, which always finds +L+ a valid path if one exists. Both strong and weak constraints are maintained for each visible +L+ superdomain. If the strong constraints of the superdomains on a path are satisfied, then the +L+ path is valid. If only the weak constraints are satisfied for some superdomains on the path, the +L+ source uses a query protocol to obtain a more detailed "internal" view of these superdomains, +L+ and searches again for a valid path. Our protocol handles topology changes, including node/link +L+ failures that partition superdomains. Evaluation results indicate our protocol scales well to large +L+ internetworks. +L+ </abstract> <keyword> Categories and Subject Descriptors: C.2.1 [Computer-Communication Networks]: Network Archi +L+ tecture and Design|packet networks; store and forward networks; C.2.2 [Computer-Communication Net +L+ works]: Network Protocols|protocol architecture; C.2.m [Routing Protocols]; F.2.m [Computer Network +L+ Routing Protocols]. +L+ </keyword> <note> This work is supported in part by ARPA and Philips Labs under contract DASG60-92-0055 to Department +L+ of Computer Science, University of Maryland, and by National Science Foundation Grant No. NCR 89-04590. The +L+ views, opinions, and/or findings contained in this report are those of the author(s) and should not be interpreted as +L+ representing the official policies, either expressed or implied, of the Advanced Research Projects Agency, PL, NSF, +L+ or the U.S. Government. Computer facilities were provided in part by NSF grant CCR-8811954. +L+ </note> <page> +PAGE+ </page> 
<note> Pages 61 to 70 of W. Daelemans, A. van den Bosch, and A. Weijters (Editors), +L+ Workshop Notes of the ECML/MLnet Workshop on Empirical Learning of Natural +L+ Language Processing Tasks, April 26, 1997, Prague, Czech Republic +L+ </note> <title> Automatic Phonetic Transcription of Words +L+ Based On Sparse Data +L+ </title> <author> Maria Wolters (i) and Antal van den Bosch (ii) +L+ </author> <affiliation> (i) Institut fur Kommunikationsforschung und Phonetik, Universitat Bonn </affiliation> +L+ <author> Poppelsdorfer Allee 47, 53113 Bonn, Germany </author> +L+ <email> mwo@asl1.ikp.uni-bonn.de +L+ </email> <affiliation> (ii) Department of Computer Science, Universiteit Maastricht </affiliation> +L+ <author> PO Box 616, 6200 MD Maastricht, The Netherlands </author> +L+ <email> antal@cs.unimaas.nl +L+ </email> <abstract> Abstract +L+ The relation between the orthography and the phonology of a language has +L+ traditionally been modelled by hand-crafted rule sets. Machine-learning (ML) +L+ approaches offer a means to gather this knowledge automatically. Problems +L+ arise when the training material is sparse. Generalising from sparse data +L+ is a well-known problem for many ML algorithms. We present experiments +L+ in which connectionist, instance-based, and decision-tree learning algorithms +L+ are applied to a small corpus of Scottish Gaelic. instance-based learning in the +L+ ib1-ig algorithm yields the best generalisation performance, and that most +L+ algorithms tested perform tolerably well. Given the availability of a lexicon, +L+ even if it is sparse, ML is a valuable and efficient tool for automatic phonetic +L+ transcription of written text. +L+ </abstract> <intro> 1 The Problem </intro> 
<title> Loop Optimizations for Acyclic Object-Oriented Queries +L+ </title> <author> Vasilis Samoladas Daniel P. Miranker +L+ </author> <affiliation> The University of Texas at Austin +L+ Department of Computer Sciences +L+ </affiliation> <address> Taylor Hall 2.124 +L+ Austin, TX 78712-1188 +L+ </address> <email> fvsam,mirankerg@cs.utexas.edu +L+ </email> <phone> Tel: (512)-471-9541 +L+ </phone> <abstract> Abstract +L+ Nested loop execution of object-oriented queries retains +L+ the promise of maintaining the full generality of the object paradigm, independent of the specifics of any single +L+ object model. Thus, from this starting point we have +L+ developed an object-oriented query optimizer and execution engine. The methods, developed to date for only +L+ acyclic queries, augment nested loops structures with a +L+ simple marking mechanism such that unnecessary loop +L+ iterations are not repeated. In the case of acyclic queries, +L+ the executions are asymptotically optimal. In contrast to +L+ optimal query methods based on semijoin reductions our +L+ method involves no preprocessing step and thus avoids +L+ the extra I/O associated with semijoins and prevents the +L+ formal benefits of semijoin reduction from appearing as a +L+ practical improvement. Empirical results comparing our +L+ query environment with a commercially available product +L+ demonstrate significant performance improvement. +L+ </abstract> <intro> 1 Introduction </intro> 
<title> Utility Models for Goal-Directed +L+ Decision-Theoretic Planners +L+ </title> <author> Peter Haddawy 1 , Steve Hanks +L+ </author> <affiliation> Department of Computer Science and Engineering +L+ University of Washington +L+ </affiliation> <address> Seattle, WA 98195 +L+ </address> <pubnum> Technical Report 93-06-04 +L+ </pubnum> <date> June 15, 1993 +L+ </date> 1 <affiliation> Department of EE & CS, University of Wisconsin-Milwaukee, </affiliation> <address> Milwaukee WI 53201 +L+ </address> <page> +PAGE+ </page> 
<note> Appears in Working Notes, Integrating Multiple Learned Models for Improving and Scaling Machine Learning Algorithms +L+ Workshop, Thirteenth National Conference on Artificial Intelligence, Portland, OR: AAAI Press (1996). +L+ </note> <title> Human Expert-Level Performance on a Scientific Image Analysis Task +L+ by a System Using Combined Artificial Neural Networks +L+ </title> <author> Kevin J. Cherkauer +L+ </author> <affiliation> Department of Computer Sciences +L+ University of Wisconsin-Madison +L+ </affiliation> <address> 1210 West Dayton Street +L+ Madison, WI 53706, USA +L+ </address> <email> cherkauer@cs.wisc.edu +L+ </email> <abstract> Abstract +L+ This paper presents the Plannett system, which +L+ combines artificial neural networks to achieve expert- +L+ level accuracy on the difficult scientific task of recognizing volcanos in radar images of the surface of the +L+ planet Venus. Plannett uses ANNs that vary along +L+ two dimensions: the set of input features used to train +L+ and the number of hidden units. The ANNs are combined simply by averaging their output activations. +L+ When Plannett is used as the classification module +L+ of a three-stage image analysis system called JAR- +L+ tool, the end-to-end accuracy (sensitivity and specificity) is as good as that of a human planetary geologist on a four-image test suite. JARtool-Plannett +L+ also achieves the best algorithmic accuracy on these +L+ images to date. +L+ </abstract> <intro> Introduction </intro> 
<title> What Tasks Can Be Performed with an Uncalibrated +L+ Stereo Vision System? +L+ </title> <author> J. P. Hespanha , Z. Dodds , G. D. Hager , and A. S. Morse +L+ </author> <affiliation> Center for Computational Vision and Control +L+ c/o Computer Science Department +L+ </affiliation> <address> P.O. Box 208285 +L+ Yale University +L+ New Haven, CT, 06520 +L+ </address> <phone> Phone: (203) 432-6432 +L+ </phone> <email> E-mail: (gregory.hager, joao.hespanha, zachary.dodds, as.morse)@yale.edu +L+ </email> <abstract> Abstract +L+ This article studies the following question: "When is it possible to decide, on the basis of images of point features observed by an imprecisely modeled two-camera stereo +L+ vision system, whether or not a prescribed robot positioning task has been accomplished with precision?" It is shown that for a stereo vision system with known epipo-lar geometry, whether or not such a positioning task has been accomplished can be +L+ decided with available data, just in case the task function which specifies the task is a +L+ projective invariant. +L+ </abstract> <note> Submitted to IJCV special issue on vision research at Yale. +L+ This research was supported by the National Science Foundation, the Army Research Office, and the +L+ Air Force Office of Scientific Research +L+ </note> <page> +PAGE+ </page> 
<title> An Evolving Algebra Abstract Machine +L+ </title> <author> Giuseppe Del Castillo 1 , Igor D - urd -anovic 2 , Uwe Glasser 1 +L+ </author> <affiliation> 1 Heinz Nixdorf Institut, Universitat-GH Paderborn, </affiliation> <address> Furstenallee 11, +L+ 33102 Paderborn, Germany, </address> <email> fgiusp,glaesserg@uni-paderborn.de </email> +L+ <affiliation> 2 FB Mathematik-Informatik, Universitat-GH Paderborn, </affiliation> <address> Warburger Str. 100, +L+ 33098 Paderborn, Germany, </address> <email> igor@uni-paderborn.de </email> +L+ <abstract> Abstract. Evolving algebras (EAs) as defined by Yuri Gurevich constitute the basis of a powerful and elegant specification and verification +L+ method which has successfully been applied to the design and analysis of +L+ various kinds of discrete dynamic systems. Aiming at the development +L+ of a comprehensive EA-based specification and design environment, we +L+ introduce the concept of an evolving algebra abstract machine (EAM ) as +L+ a platform for the systematic development of EA tools; for instance, as +L+ required for machine based analysis and execution of EA specifications. +L+ We give a formal definition of the EAM ground model in terms of a +L+ universal evolving algebra, where we validate the correctness of the relation between evolving algebras (their theoretical foundations) and their +L+ EAM representation and interpretation. Our approach covers sequential +L+ as well as distributed evolving algebras. +L+ </abstract> <intro> Introduction </intro> 
<title> Hierarchical Optimization of Optimal Path Finding for +L+ Transportation Applications +L+ </title> <author> Ning Jing +L+ </author> <affiliation> Changsha Institute of Technology +L+ </affiliation> <email> jning@eecs.umich.edu +L+ </email> <author> Yun-Wu Huang +L+ </author> <affiliation> University of Michigan +L+ </affiliation> <email> ywh@eecs.umich.edu +L+ </email> <author> Elke A. Rundensteiner +L+ </author> <affiliation> University of Michigan +L+ </affiliation> <email> rundenst@eecs.umich.edu +L+ </email> <abstract> Abstract +L+ Efficient path query processing is a key requirement for advanced +L+ database applications including GIS (Geographic Information Systems) and ITS (Intelligent Transportation Systems). We study the +L+ problem in the context of automobile navigation systems where a +L+ large number of path requests can be submitted over the transportation network within a short period of time. To guarantee efficient re-sponsefor path queries, we employ a path view materialization strategy for precomputing the best paths. We tackle the following three +L+ issues: (1) memory-resident solutions quickly exceed current computer storage capacity for networks of thousands of nodes, (2) disk-based solutions have been found inefficient to meet the stringent +L+ performance requirements, and (3) path views become too costly +L+ to update for large graphs. We propose the HEP V (Hierarchical +L+ Encoded Path View) approach that addresses these problems while +L+ guaranteeing the optimality of path retrieval. Our experimental results reveal that HEP V is more efficient than previously known +L+ path finding approaches. +L+ </abstract> <intro> 1 Introduction </intro> 
<title> Efficient PRAM Simulation on a +L+ Distributed Memory Machine +L+ </title> <author> Richard M. Karp +L+ </author> <affiliation> University of California at Berkeley and +L+ International Computer Science Institute, </affiliation> <address> Berkeley, CA </address> +L+ <author> Michael Luby +L+ </author> <affiliation> International Computer Science Institute, </affiliation> <address> Berkeley, CA </address>+L+ <affiliation> and UC Berkeley +L+ </affiliation> <author> Friedhelm Meyer auf der Heide +L+ </author> <affiliation> Heinz Nixdorf Institute and Computer Science Department, </affiliation> +L+ <affiliation> University of Paderborn, </affiliation> <address> Germany </address> +L+ <pubnum> TR-93-040 </pubnum> +L+ <date> August 1993 </date> +L+ <abstract> Abstract +L+ We present algorithms for the randomized simulation of a shared memory machine +L+ (PRAM) on a Distributed Memory Machine (DMM). In a PRAM, memory conflicts +L+ occur only through concurrent access to the same cell, whereas the memory of a +L+ DMM is divided into modules, one for each processor, and concurrent accesses to +L+ the same module create a conflict. The delay of a simulation is the time needed to +L+ simulate a parallel memory access of the PRAM. Any general simulation of an m +L+ processor PRAM on a n processor DMM will necessarily have delay at least m=n. A +L+ randomized simulation is called time-processor optimal if the delay is O(m=n) with +L+ high probability. Using a novel simulation scheme based on hashing we obtain a +L+ time-processor optimal simulation with delay O(loglog(n)log (n)). The best previous +L+ simulations use a simpler scheme based on hashing and have much larger delay: +L+ fi(log(n)= loglog(n)) for the simulation of an n processor PRAM on an n processor +L+ DMM, and fi(log(n)) in the case where the simulation is time-processor optimal. +L+ </abstract> <note> Research partially supported by NSF/DARPA Grant CCR-9005448 +L+ Research partially supported by NSF operating grant CCR-9016468 and by grant No. 89-00312 from +L+ the United States-Israel Binational Science Foundation (BSF), Jerusalem, Israel. +L+ Part of work was done during a visit at the International Computer Science Institute at Berkeley; +L+ supported in part by DFG-Forschergruppe "Effiziente Nutzung massiv paralleler Systeme, Teilprojekt 4", +L+ and by the Esprit Basic Research Action Nr. 7141 (ALCOM II). +L+ </note> <page> +PAGE+ </page> 
<title> Towards the Assessment of Logics for +L+ Concurrent Actions +L+ </title> <author> Choong-Ho Yi +L+ </author> <affiliation> Department of Computer and Information Science +L+ Linkoping University +L+ </affiliation> <address> 581 83 Linkoping, Sweden +L+ </address> <email> E-mail: choyi@ida.liu.se +L+ </email> <abstract> Abstract +L+ We have introduced concurrency into the framework of Sandewall. The resulting formalism is capable of reasoning about interdependent as well +L+ as independent concurrent actions. Following +L+ Sandewall's systematical method, we have then +L+ applied the entailment criterion PCM to selecting +L+ intended models of common sense theories where +L+ concurrent actions are allowed, and proved that +L+ the criterion leads to only intended models for a +L+ subset of such theories. +L+ </abstract> <intro> Introduction </intro> 
<title> Decision-Theoretic Troubleshooting: A Framework for +L+ Repair and Experiment +L+ </title> <author> John S. Breese +L+ David Heckerman +L+ </author> <email> &lt;breese|heckerma@microsoft.com&gt; +L+ </email> <date> March, 1996 +L+ (revised May 1996) +L+ </date> <pubnum> Technical Report +L+ MSR-TR-96-06 +L+ </pubnum> <affiliation> Microsoft Research +L+ Advanced Technology Division +L+ Microsoft Corporation +L+ </affiliation> <address> One Microsoft Way +L+ Redmond, WA 98052 +L+ </address> <note> Also appears in the Proceedings of the Twelfth Conference on Uncertainty in Artificial Intelligence, +L+ August, 1996 +L+ </note> <page> +PAGE+ </page> 
<title> Real-Time Reliable Multicast Using Proactive Forward Error Correction +L+ </title> <author> Dan Rubenstein , Jim Kurose , and Don Towsley +L+ </author> <affiliation> Computer Science Department +L+ University of Massachusetts +L+ </affiliation> <address> Amherst, MA 01003 +L+ </address> <email> fdrubenst, kurose, towsleyg@cs.umass.edu +L+ </email> <pubnum> Technical Report 98-19 +L+ </pubnum> <affiliation> Department of Computer Science +L+ </affiliation> <date> March 1998 +L+ </date> <abstract> Abstract +L+ Real-Time reliable multicast over a best-effort service network remains a challenging research problem. Most +L+ protocols for reliable multicast use repair techniques that result in significant and variable delay, which can lead to +L+ missed deadlines in real-time scenarios. This paper presents a repair technique that combines forward error correction +L+ (FEC) with automatic repeat request (ARQ). The novel aspect of the technique is its ability to reduce delay in reliable +L+ multicast delivery by sending repairs proactively (i.e., before they are required). The technique requires minimal +L+ state at senders and receivers, and no additional active router functionality beyond what is required by the current +L+ multicast service model. Furthermore, the technique uses only end-to-end mechanisms, where all data and repairs are +L+ transmitted by the data-originating source, leaving receivers free from any burden of sending repairs. We simulate +L+ a simple round-based version of a protocol embodying this technique to show its effectiveness in preventing repair +L+ request implosion, reducing the expected time of reliable delivery of data, and keeping bandwidth usage for repairs +L+ low. We show how a protocol using the technique can be adapted to provide delivery that is reliable before a real-time +L+ deadline with probabilities extremely close to one. Finally, we develop several variations of the protocol that use the +L+ technique in various fashions for high rate data streaming applications, and present results from additional simulations +L+ that examine performance in a variety of Internet-like heterogeneous networks. +L+ </abstract> <intro> 1 Introduction </intro> 
<title> Interpretable Neural Networks with BP-SOM +L+ </title> <author> Ton Weijters 1 , Antal van den Bosch 2 , and Jaap van den Herik 3 +L+ </author> <affiliation> 1 Information Technology, Eindhoven University of Technology, </affiliation> <address> The Netherlands +L+ </address> <affiliation> 2 ILK / Computational Linguistics, Tilburg University, </affiliation> <address> The Netherlands +L+ </address> <affiliation> 3 Department of Computer Science, Universiteit Maastricht, </affiliation> <address> The Netherlands +L+ </address> <abstract> Abstract. Interpretation of models induced by artificial neural networks is often a difficult task. In this paper we focus on a relatively +L+ novel neural network architecture and learning algorithm, bp-som, that +L+ offers possibilities to overcome this difficulty. It is shown that networks +L+ trained with bp-som show interesting regularities, in that hidden-unit +L+ activations become restricted to discrete values, and that the som part +L+ can be exploited for automatic rule extraction. +L+ </abstract> <intro> 1 Introduction </intro> 
<title> Visualisation of Large Networks in 3-D Space: +L+ Issues in +L+ Implementation and Experimental Evaluation +L+ </title> <author> Yan Xiao Paul Milgram +L+ </author> <abstract> Abstract +L+ Three dimensional visualisation has become a +L+ widespread scheme for helping users to access +L+ and manage large information network. In this +L+ report, various techniques for displaying depth +L+ information are reviewed, with an emphasis on +L+ stereoscopic displays. Input devices used to interact with a 3-D space are also examined. Issues in 3-D network visualisation are elicited from +L+ three viewpoints: psychological, task-related and +L+ implementational. Consideration of these issues +L+ leads to the design of a preliminary experimental +L+ programme for evaluating various network visu-alisation techniques. +L+ </abstract> <intro> 1 Introduction </intro> 
<title> Trust-region interior-point algorithms for minimization problems +L+ with simple bounds +L+ </title> <author> J. E. Dennis Lus N. Vicente +L+ </author> <abstract> Abstract +L+ Two trust-region interior-point algorithms for the solution of minimization problems +L+ with simple bounds are presented. The algorithms scale the local model in a way proposed +L+ by Coleman and Li [1], but they are new otherwise. The first algorithm is more usual in +L+ that the trust region and the local quadratic model are consistently scaled. The second +L+ algorithm proposed here uses an unscaled trust region. A first-order convergence result for +L+ these algorithms is given and dogleg and conjugate-gradient algorithms to compute trial +L+ steps are introduced. Some numerical examples that show the advantages of the the second +L+ algorithm are presented. +L+ </abstract> <keyword> Keywords. trust-region methods, interior-point algorithms, Dikin-Karmarkar ellipsoid, +L+ Coleman and Li scaling, simple bounds. +L+ </keyword> <note> AMS subject classification. 49M37, 90C20, 90C30 +L+ </note> <intro> 1 Introduction </intro> 
<title> Incoercible Multiparty Computation +L+ </title> <note> (Extended Abstract) +L+ </note> <author> Ran Canetti Rosario Gennaro +L+ </author> <date> May 17, 1996 +L+ </date> <abstract> Abstract +L+ Current secure multiparty protocols have the following deficiency. The public transcript of the communication can be used as an involuntary commitment of the parties to their inputs and outputs. Thus +L+ parties can be later coerced by some authority to reveal their private data. Previous work that has +L+ pointed this interesting problem out contained only partial treatment. +L+ In this work we present the first general and rigorous treatment of the coercion problem in secure computation. First we present a general definition of protocols that provide resilience to coercion. Our +L+ definition constitutes a natural extension of the general paradigm used for defining secure multiparty +L+ protocols. Next we show that if trapdoor permutations exist then any function can be incoercibly +L+ computed (i.e., computed by a protocol that provides resilience to coercion) in the presence of com-putationally bounded adversaries and only public communication channels. This holds as long as less +L+ than half the parties are coerced (or corrupted). In particular, ours are the first incoercible protocols +L+ without physical assumptions. Also, our protocols constitute an alternative solution to the recently +L+ solved adaptive security problem. +L+ Our techniques are quite surprising and include non-standard use of deniable encryptions. +L+ </abstract> <affiliation> Laboratory for Computer Science, Massachusetts Institute of Technology, </affiliation> <address> 545 Technology Square, Cambridge MA 02139, +L+ U.S.A. </address> <email> canetti,rosario@theory.lcs.mit.edu +L+ </email> <page> +PAGE+ </page> 
<title> On Algorithms for Simplicial Depth +L+ </title> <author> Andrew Y. Cheng +L+ </author> <affiliation> Department of Industrial Engineering +L+ </affiliation> <author> Ming Ouyang +L+ </author> <affiliation> Department of Computer Science +L+ Rutgers University +L+ </affiliation> <address> New Brunswick, New Jersey 08903 +L+ </address> <abstract> ABSTRACT +L+ Simplicial depth is a way to measure how deep a point is among a set of points. Efficient +L+ algorithms to compute it are important to the usefulness of its applications, such as in +L+ multivariate analysis in statistics. A straightforward method takes O(n d+1 ) time when the +L+ points are in d-dimensional space. We discuss an algorithm that takes O(n 2 ) time when the +L+ points are in three-dimensional space, and we generalize it to four-dimensional space with +L+ a time complexity of O(n 4 ). For spaces higher than four-dimensional, there are no known +L+ algorithms faster than the straightforward method. +L+ </abstract> <intro> 1 Simplicial depth </intro> 
<title> Unification and Polymorphism in Region Inference +L+ </title> <author> Mads Tofte, </author> <affiliation> Department of Computer Science, University of Copenhagen +L+ </affiliation> <author> Lars Birkedal, </author> <affiliation> School of Computer Science, Carnegie Mellon University +L+ </affiliation> <note> Dedicated to Robin Milner on the occasion of his 60th birthday. +L+ </note> <abstract> Abstract +L+ Region Inference is a technique for inferring lifetimes of values in strict, higher-order programming languages such as Standard ML. The purpose of this paper is to show how ideas +L+ from Milner's polymorphic type discipline can serve as a basis for region inference, even in the +L+ presence of a limited form of polymorphic recursion. +L+ </abstract> <intro> 1 Introduction </intro> 
<title> Distributed Simulation of DEVS-Based Multiformalism Models +L+ </title> <author> Herbert Praehofer and Gernot Reisinger +L+ </author> <affiliation> Institute of Systems Science +L+ Systems Theory and Information Engineering +L+ Johannes Kepler University Linz +L+ </affiliation> <address> A-4040 Linz, Austria +L+ </address> <abstract> Abstract +L+ In this paper we introduce a new approach for parallel, distributed simulation of modular, hierarchical +L+ DEVS and DEVS-based combined discrete/continuous +L+ multiformalism models. The algorithm combines +L+ conservative and optimistic distributed simulation +L+ strategies and is able to optimally exploit lookahead +L+ capabilities of the model. The object oriented implementation in C++ is intended to serve as a powerful +L+ simulator in the STIMS modeling and simulation environment. +L+ </abstract> <intro> 1 Introduction and Motivation </intro> 
<title> Transis: A Communication Sub-System +L+ for +L+ High Availability +L+ </title> <author> Yair Amir , Danny Dolev , Shlomo Kramer , Dalia Malki +L+ </author> <affiliation> Computer Science department +L+ The Hebrew University of Jerusalem +L+ </affiliation> <address> Jerusalem, Israel +L+ </address> <pubnum> Technical Report CS91-13 +L+ </pubnum> <date> April 30, 1992 +L+ </date> <page> +PAGE+ </page> 
<title> Constraint Based Design of ATM +L+ Networks, an Experimental Study +L+ </title> <author> Hongzhou Ma , Inderjeet Singh , Jonathan Turner +L+ </author> <pubnum> wucs-97-15 +L+ </pubnum> <date> April 97 +L+ </date> <affiliation> Department of Computer Science +L+ </affiliation> <address> Campus Box 1045 +L+ </address> <affiliation> Washington University +L+ </affiliation> <address> One Brookings Drive +L+ St. Louis, MO 63130-4899 +L+ </address> <abstract> Abstract +L+ This paper describes an experimental study of constraint-based network design. We used a +L+ novel network design tool, implemented in Java, to design representative networks joining +L+ major U.S. cities. The cost of three topologies: Best Star, Minimum Spanning Tree (MST), +L+ and Delaunay Triangulation, are compared, with and without localized traffic constraints. +L+ The best star network gives near optimal result when the traffic is only constrained by source +L+ and sink capacity of switches (flat traffic constraints). With localized traffic constraints, the +L+ most cost effective network has a structure similar to the MST. The cheapest network has a +L+ tree structure when there are only flat traffic constraints, but can have cycles when localized +L+ traffic constraints are present. +L+ </abstract> <page> +PAGE+ </page> 
<title> Theory and Design of Multidimensional QMF Sub-Band Filters From +L+ 1-D Filters and Polynomials Using Transforms +L+ </title> <author> I.A. Shah A.A.C. Kalker +L+ </author> <affiliation> Philips Research Laboratories, +L+ </affiliation> <address> P.O. Box 80.000, 5600 JA Eindhoven, The Netherlands +L+ </address> <email> Net: kalker@prl.philips.nl, shah@prl.philips.nl +L+ </email> <abstract> Abstract +L+ The paper presents the general theory of designing multidimensional Quadrature Mirror Filters (QMF), +L+ for use in sub-band coding (SBC) systems, using the McClellan transform [1]. It was recently shown that +L+ McClellan transform could be used to generate 2-D diamond shape QMF filters [2]. In this paper we will +L+ formalize the proofs of the diamond shape case, and generalize it to other shapes, sampling rasters and +L+ dimensions. +L+ Moreover we show that we do not really need the 1-D QMF filters: it is also possible and even more +L+ convenient to design QMF filter banks by performing transformations on a class of real valued polynomials. +L+ Examples are given of two dimensional diamond and fan-shape filters and three dimensional tetrad filters +L+ designed using this transformation technique. +L+ </abstract> <intro> 1 Introduction </intro> 
<title> Modeling and Optimization of a Multiresolution +L+ Image Retrieval System +L+ </title> <author> Antonio Ortega , +L+ </author> <affiliation> Dept. of Electrical Eng.-Systems +L+ University of Southern California +L+ </affiliation> <address> Los Angeles, California +L+ </address> <author> Zhensheng Zhang, +L+ </author> <affiliation> Dept. of Electrical Engineering and Center for Telecom. Research +L+ Columbia University, </affiliation> <address> New York +L+ </address> <author> Martin Vetterli +L+ </author> <affiliation> Dept. of Electrical Engineering and Computer Science +L+ University of California, +L+ </affiliation> <address> Berkeley, California +L+ </address> <date> July 15, 1994 +L+ </date> <note> IEEE/ACM Transactions on Networking, Submitted, July 1994 +L+ </note> <abstract> Abstract +L+ In this paper, we study the tradeoffs involved in choosing the bit allocation in a +L+ multiresolution remote image retrieval system. Such a system uses a multiresolution +L+ image coding scheme so that a user accessing the database will first see a coarse +L+ version of the images and will be able to accept or discard a given image faster, +L+ without needing to receive all the image data. We formalize the problem of choosing +L+ the bit allocation (e.g., in the two resolution case, how many bits should be given +L+ to the coarse image and the additional information, respectively?) so that the +L+ overall delay in the query is minimized. We provide analytical methods to find the +L+ optimal solution under different configurations and show how a good choice of the +L+ bit allocation results in a significant reduction of the overall delay in the query (by +L+ up to a factor of two in some cases). +L+ </abstract> <note> This work was presented in part at the IS&T/SPIE Symp. on Electronic Imaging Science & Tech +L+ nology '94, San Jose, CA, Feb. 94 and at Infocom '94, Toronto, Canada, Jun. 94. +L+ Work supported in part by the Fulbright Commission and the Ministry of Education of Spain. This +L+ work was done while at the Dept. of Electrical Eng. and Center for Telecom. Research, Columbia +L+ University. +L+ </note> <page> +PAGE+ </page> 
<title> Automated Decomposition of Model-based Learning Problems +L+ </title> <author> Brian C. Williams and Bill Millar +L+ </author> <affiliation> Recom Technologies, Caelum Research +L+ NASA Ames Research Center, </affiliation> <address> MS 269-2 +L+ Moffett Field, CA 94305 USA +L+ </address> <email> E-mail: williams, millar@ptolemy.arc.nasa.gov +L+ </email> <abstract> Abstract +L+ A new generation of sensor rich, massively distributed +L+ autonomous systems is being developed that has +L+ the potential for unprecedented performance, such +L+ as smart buildings, reconfigurable factories, adaptive +L+ traffic systems and remote earth ecosystem monitoring. To achieve high performance these massive systems will need to accurately model themselves and +L+ their environment from sensor information. Accomplishing this on a grand scale requires automating the +L+ art of large-scale modeling. This paper presents a +L+ formalization of decompositional, model-based learning +L+ (DML), a method developed by observing a modeler's +L+ expertise at decomposing large scale model estimation +L+ tasks. The method exploits a striking analogy between +L+ learning and consistency-based diagnosis. Moriarty, +L+ an implementation of DML, has been applied to thermal modeling of a smart building, demonstrating a +L+ significant improvement in learning rate. +L+ </abstract> <intro> Introduction </intro> 
<title> Path integral approach to no-Coriolis +L+ approximation in heavy-ion collisions +L+ </title> <author> K. Hagino , 1 N. Takigawa, 1 , A.B. Balantekin 2 , and J.R. Bennett 3 +L+ </author> <affiliation> 1 Department of Physics, Tohoku University, </affiliation> <address> 980-77 Sendai, Japan +L+ </address> <affiliation> 2 Physics Department, University of Wisconsin, </affiliation> +L+ <address> Madison, Wisconsin 53706, USA +L+ </address> <affiliation> 3 Department of Physics and Astronomy, +L+ University of North Carolina at Chapel Hill, </affiliation> <address> Chapel Hill, NC 27599-3255 +L+ </address> <date> June 26, 1995 +L+ </date> <abstract> Abstract +L+ We use the two time influence functional method of the path integral approach in +L+ order to reduce the dimension of the coupled-channels equations for heavy-ion reactions +L+ based on the no-Coriolis approximation. Our method is superior to other methods in that +L+ it easily enables us to study the cases where the initial spin of the colliding particle is not +L+ zero. It can also be easily applied to the cases where there is a spin-orbit force, and where +L+ the internal degrees of freedom are not necessarily collective coordinates. It also clarifies +L+ the underlying assumption of the approximation. +L+ </abstract> <page> +PAGE+ </page> 
<title> Digital Communication Over Rayleigh +L+ Fading Channels +L+ </title> <author> T. M. Parks +L+ </author> <date> 15 December 1992 +L+ </date> <abstract> Abstract +L+ The properties of Rayleigh fading channels are derived and their +L+ effects on various QAM signal constellations are explored. A simplified +L+ channel model for an urban radio environment is justified in order +L+ to simplify the analysis of error performance for the constellations. +L+ Finally, arguments are made for extending the results to more general +L+ channel models. +L+ </abstract> <page> +PAGE+ </page> 
<note> Appears in KDD-97 +L+ </note> <title> MineSet: An Integrated System for Data Mining +L+ </title> <author> Cliff Brunk James Kelly Ron Kohavi +L+ </author> <affiliation> Data Mining and Visualization +L+ Silicon Graphics, Inc. +L+ </affiliation> <address> 2011 N. Shoreline Blvd +L+ Mountain View, CA 94043-1389 +L+ </address> <email> fbrunk,jkelly,ronnykg@engr.sgi.com +L+ </email> <abstract> Abstract +L+ MineSet TM , Silicon Graphics' interactive system for +L+ data mining, integrates three powerful technologies: +L+ database access, analytical data mining, and data visualization. It supports the knowledge discovery process from data access and preparation through iterative analysis and visualization to deployment. Mine-Set is based on a client-server architecture that scales +L+ to large databases. The database access component +L+ provides a rich set of operators that can be used to +L+ preprocess and transform the stored data into forms +L+ appropriate for visualization and analytical mining. +L+ The 3D visualization capabilities allow direct data visualization for exploratory analysis, including tools +L+ for displaying high-dimensional data containing geographical and hierarchical information. The analytical mining algorithms help identify potentially interesting models of the data, which can be viewed using +L+ visualization tools specialized for the learned models. +L+ Third party vendors can interface to the MineSet tools +L+ for model deployment and for integration with other +L+ packages. +L+ </abstract> <intro> Introduction </intro> 
<date> 07/17/97 </date> <note> 10:13 1 of 8 +L+ </note> <title> The Abstract Class Pattern +L+ </title> <author> Bobby Woolf +L+ </author> <affiliation> Knowledge Systems Corp. +L+ </affiliation> <address> 4001 Weston Pkwy, Cary, NC 27513-2303 +L+ </address> <phone> 919-677-1119 x541, </phone> <email> bwoolf@ksccary.com +L+ </email> <title> ABSTRACT CLASS Class Behavioral +L+ </title> <abstract> Intent +L+ Define the interface for a hierarchy of classes while deferring the implementation to subclasses. +L+ Abstract Class lets subclasses redefine the implementation of an interface while preserving the +L+ polymorphism of those classes. +L+ Also Known As +L+ Liskov Substitution Principle [LW93], Design by Contract [Meyer91], Base Class [Auer95] , +L+ Template Class [Woolf97] +L+ </abstract> <intro> Motivation +L+ </intro> <page> +PAGE+ </page> 
<pubnum> M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 368 +L+ </pubnum> <note> Appears in: Fourth European Conference on Computer Vision, Cambridge, UK, April 1996. +L+ </note> <title> Generalized Image Matching: +L+ Statistical Learning of Physically-Based Deformations +L+ </title> <author> Chahab Nastar , Baback Moghaddam and Alex Pentland +L+ </author> <affiliation> Perceptual Computing Section, The Media Laboratory, +L+ Massachusetts Institute of Technology +L+ </affiliation> <address> 20 Ames Street, Cambridge MA 02139, U.S.A. +L+ </address> <abstract> Abstract +L+ We describe a novel approach for image matching +L+ based on deformable intensity surfaces. In this +L+ approach, the intensity surface of the image +L+ is modeled as a deformable 3D mesh in the +L+ (x; ; I(x; )) space. Each surface point has 3 +L+ degrees of freedom, thus capturing fine surface +L+ changes. A set of representative deformations +L+ within a class of objects (e.g. faces) are statistically learned through a Principal Components Analysis, thus providing a priori knowledge +L+ about object-specific deformations. We demonstrate the power of the approach by examples +L+ such as image matching and interpolation of +L+ missing data. Moreover this approach dramatically reduces the computational cost of solving +L+ the governing equation for the physically based +L+ system by approximately three orders of magni +L+ tude. +L+ </abstract> <intro> 1 Introduction </intro> 
<note> Kluwer Academic Publishers, Boston. Manufactured in The Netherlands. </note> +L+ <title> A Method for Automatic Design Error Location and +L+ Correction in Combinational Logic Circuits +L+ </title> <author> AYMAN M. WAHBA AND DOMINIQUE BORRIONE +L+ </author> <affiliation> Modelisation et Preuves de Circuits, TIMA Laboratory, </affiliation> <address> BP 53X, 38041 Grenoble Cedex FRANCE +L+ </address> <email> Ayman.Wahba@imag.fr, Dominique.Borrione@imag.fr +L+ </email> <note> Received ??. Revised ??. +L+ </note> <abstract> Abstract. We present a new diagnostic algorithm, based on backward-propagation, for localising design +L+ errors in combinational logic circuits. Three hypotheses are considered, that cover all single gate replacement and insertion errors. Diagnosis-oriented test patterns are generated in order to rapidly reduce the +L+ suspected area where the error lies. The originality of our method is the use of patterns which do not +L+ detect the error, in addition to detecting patterns. A theorem shows that, in favourable cases, only two +L+ patterns suffice to get a correction. We have implemented the test generation and diagnosis algorithms. +L+ Results obtained on benchmarks show that the error is always found, after the application of a small +L+ number of test patterns, with an execution time proportional to the circuit size. +L+ </abstract> <keyword> Keywords: design correctness, design debugging, design error diagnosis +L+ </keyword> <intro> 1. Introduction </intro> 
<title> Segregating Planners and Their Environments +L+ </title> <author> Scott D. Anderson +L+ Paul R. Cohen +L+ </author> <affiliation> Experimental Knowledge Systems Laboratory +L+ Computer Science Department, LGRC +L+ University of Massachusetts +L+ </affiliation> <address> Amherst MA 01003-4610 +L+ </address> <email> fanderson,coheng@cs.umass.edu +L+ </email> <note> To be published in the proceedings of the +L+ Spring Symposium on Integrated Planning Applications +L+ </note> <abstract> Abstract +L+ By implementing agents and environments using a domain-independent, extensible simulation substrate, described in this +L+ paper, agents will have clean interfaces to +L+ their environments. These makes it easier +L+ for agents to be plugged into other environments that have been similarly defined. If +L+ agents can interact with multiple environments, their behaviors and the associated +L+ experimental results will be more general +L+ and interesting. +L+ </abstract> <intro> 1 Introduction </intro> 
<title> Kin Recognition, Similarity, and Group Behavior +L+ </title> <author> Maja J Mataric +L+ </author> <affiliation> MIT Artificial Intelligence Laboratory +L+ </affiliation> <address> 545 Technology Square #721 +L+ Cambridge, MA 02139 +L+ </address> <phone> phone: (617) 253-8839 +L+ </phone> <phone> fax: (617) 253-0039 +L+ </phone> <email> maja@ai.mit.edu +L+ </email> <abstract> Abstract +L+ This paper presents an approach to describing +L+ group behavior using simple local interactions +L+ among individuals. We propose that for a given +L+ domain a set of basic interactions can be defined +L+ which describes a large variety of group behaviors. +L+ The methodology we present allows for simplified +L+ qualitative analysis of group behavior through the +L+ use of shared goals, kin recognition, and minimal +L+ communication. We also demonstrate how these +L+ basic interactions can be simply combined into +L+ more complex compound group behaviors. +L+ To validate our approach we implemented an array of basic group behaviors in the domain of spatial interactions among homogeneous agents. We +L+ describe some of the experimental results from two +L+ distinct domains: a software environment, and a +L+ collection of 20 mobile robots. We also describe +L+ a compound behavior involving a combination of +L+ the basic interactions. Finally, we compare the +L+ performance of homogeneous groups to those of +L+ dominance hierarchies on the same set of basic behaviors. +L+ </abstract> <intro> Introduction </intro> 
<title> Planning and Proof Planning +L+ </title> <author> Erica Melis 1 and Alan Bundy 2 +L+ </author> <abstract> Abstract. The paper adresses proof planning as a specific AI planning. It describes some peculiarities of proof planning and discusses +L+ some possible cross-fertilization of planning and proof planning. +L+ </abstract> <intro> 1 Introduction </intro> 
<title> A Data-Flow Graphical User Interface for Querying a Scientific +L+ Database +L+ </title> <author> Bosco S. Tjan , Leonard Breslow , Sait Dogru , Vijay Rajan, +L+ Keith Rieck , James R. Slagle , and Marius O. Poliac +L+ </author> <affiliation> Computer Science Department +L+ University of Minnesota, </affiliation> <address> Minneapolis MN 55455 +L+ </address> <abstract> Abstract +L+ We describe the design principles and functionality +L+ of a visual query language called SeeQL that represents data retrieval and analysis operations as a data-flow graph. A query is viewed as a sequence of relational algebra and other data transformation operations applied to database tables. The language is well-suited for large-scale scientific database applications, +L+ where data analysis is a major component and the typical queries or data retrieval patterns are unrestricted. +L+ The language provides a flexible yet easy-to-use environment for database access and data analysis for +L+ non-programmer research scientists. We have implemented this language in a system being used in a long-term data-intensive highway pavement research project +L+ (MnRoad) conducted by the Minnesota Department of +L+ Transportation. +L+ </abstract> <intro> 1 Introduction </intro> 
<title> Adaptive Markov Chain Monte Carlo through +L+ Regeneration +L+ </title> <author> Walter R. Gilks +L+ </author> <affiliation> Medical Research Council +L+ Biostatistics Unit +L+ </affiliation> <address> Cambridge, CB2 2SR, UK. +L+ </address> <author> Gareth O. Roberts +L+ </author> <affiliation> Statistical Laboratory +L+ University of Cambridge +L+ </affiliation> <address> Cambridge, CB2 1SB, UK. +L+ </address> <author> Sujit K. Sahu +L+ </author> <affiliation> School of Mathematics +L+ University of Wales, Cardiff +L+ </affiliation> <address> Cardiff, CF2 4YH, UK. +L+ </address> <date> January 26, 1998 +L+ </date> <abstract> Summary +L+ Markov chain Monte Carlo (MCMC) is used for evaluating expectations of functions of interest +L+ under a target distribution . This is done by calculating averages over the sample path of a +L+ Markov chain having as its stationary distribution. For computational efficiency, the Markov +L+ chain should be rapidly mixing. This can sometimes be achieved only by careful design of the +L+ transition kernel of the chain, on the basis of a detailed preliminary exploratory analysis of . An +L+ alternative approach might be to allow the transition kernel to adapt whenever new features of +L+ are encountered during the MCMC run. However, if such adaptation occurs infinitely often, the +L+ stationary distribution of the chain may be disturbed. We describe a framework, based on the +L+ concept of Markov chain regeneration, which allows adaptation to occur infinitely often, but which +L+ does not disturb the stationary distribution of the chain or the consistency of sample-path averages. +L+ </abstract> <keyword> Key Words: Adaptive method; Bayesian inference; Gibbs sampling; Markov chain Monte Carlo; +L+ </keyword> <page> +PAGE+ </page> 
<title> Measuring the Difficulty of Specific Learning Problems +L+ </title> <author> Chris Thornton +L+ </author> <affiliation> Cognitive and Computing Sciences +L+ University of Sussex +L+ </affiliation> <address> Brighton BN1 9QN +L+ </address> <email> Email: Chris.Thornton@cogs.susx.ac.uk +L+ </email> <phone> Tel: (44)273 606755 x 3239 +L+ </phone> <date> October 21, 1994 +L+ </date> <abstract> Abstract +L+ Existing complexity measures from contemporary learning theory cannot be conveniently applied to specific learning problems (e.g., training sets). Moreover, they are typically non-generic, +L+ i.e., they necessitate making assumptions about the way in which the learner will operate. The lack +L+ of a satisfactory, generic complexity measure for learning problems poses difficulties for researchers +L+ in various areas; the present paper puts forward an idea which may help to alleviate these. It +L+ shows that supervised learning problems fall into two, generic, complexity classes only one of which +L+ is associated with computational tractability. By determining which class a particular problem +L+ belongs to, we can thus effectively evaluate its degree of generic difficulty. +L+ </abstract> <intro> 1 Introduction </intro> 
<title> A Study of the Structure and Performance +L+ of MMU Handling Software +L+ </title> <author> Yousef A. Khalidi +L+ Vikram P. Joshi +L+ Dock Williams +L+ </author> <pubnum> SMLI TR-94-28 </pubnum> <date> June 1994 +L+ </date> <abstract> Abstract: +L+ Modern operating systems provide a rich set of interfaces for mapping, sharing, and protecting memory. Different +L+ memory management unit (MMU) architectures provide different mechanisms for managing memory translations. +L+ Since the same OS usually runs on different MMU architectures, a software hardware address translation (hat) +L+ layer that abstracts the MMU architecture is normally implemented between MMU hardware and the virtual memory system of the OS. In this paper, we study the impact of the OS and the MMU on the structure and performance +L+ of the hat layer. In particular, we concentrate on the role of the hat layer on the scalability of system performance +L+ on symmetric multiprocessors with 2-12 CPUs. The results show that, unlike single-user applications, multi-user +L+ applications require very careful multi-threading of the hat layer to achieve system performance that scales with +L+ the number of CPUs. In addition, multi-threading the hat can result in better performance in lesser amounts of +L+ physical memory. +L+ </abstract> <note> email addresses: +L+ </note> <email> yousef.khalidi@eng.sun.com +L+ vikram.joshi@eng.sun.com +L+ dock.williams@eng.sun.com +L+ </email> <address> M/S 29-01 +L+ 2550 Garcia Avenue +L+ Mountain View, CA 94043 +L+ </address> <page> +PAGE+ </page> 
<title> Dynamic Procedure Placement Through Cache Windowing +L+ </title> <author> Carleton Miyamoto +L+ </author> <pubnum> CS 252/265 </pubnum> <date> Spring 98 +L+ </date> <affiliation> University of California, Berkeley +L+ </affiliation> <abstract> Abstract +L+ The relative slowdown of DRAMs with respect to +L+ processor speeds and the widespread use of SMP +L+ machines have bolstered the reliance on processor caches +L+ to provide good performance. As a result, optimizing +L+ machines and software for caches have recently received +L+ more attention. In addition, with the popularity of +L+ extensible computing, which includes the object oriented +L+ programming style, shared libraries, and Java based +L+ computing, creating effective compilers has become +L+ more challenging, with an increased reliance on more +L+ dynamic techniques, such as profiling and runtime code +L+ generation. This paper proposes a dynamic optimization +L+ method called cache windowing to reduce conflict misses +L+ in L1 instruction caches. Using a combination of +L+ hardware and software support, cache windowing +L+ integrates a RollCache (a direct-mapped cache enhanced +L+ to support dynamic cache configuration) and a software +L+ implemented FIFO caching policy. Together, both allow +L+ a program to reposition procedures, dynamically and +L+ efficiently, to eliminate cache conflicts. Experiments +L+ show that this type of caching scheme can achieve miss +L+ rates competitive to a 2-way set associative cache for +L+ various programs. Currently, a high software overhead +L+ exists to support a software caching policy, though +L+ different compiler optimizations, such as inlining, may +L+ help to reduce this. Such a system provides a more robust +L+ runtime architecture that, potentially, may adapt better to +L+ a wider variety of environments. +L+ </abstract> <intro> 1 Introduction </intro> 
<title> Qualia Structure and the +L+ Compositional Interpretation of Compounds +L+ </title> <author> Michael Johnston x and Federica Busa +L+ </author> <affiliation> Research Lab for Linguistics and Computation, +L+ Computer Science Department, +L+ Volen Center for Complex Systems, +L+ Brandeis University, +L+ </affiliation> <address> Waltham, MA 02254 +L+ </address> <email> johnston@cs.brandeis.edu federica@cs.brandeis.edu +L+ </email> <abstract> Abstract +L+ The analysis of nominal compound constructions has proven to be a recalcitrant problem +L+ for linguistic semantics and poses serious challenges for natural language processing systems. +L+ We argue for a compositional treatment of compound constructions which limits the need for +L+ listing of compounds in the lexicon. We argue that the development of a practical model of +L+ compound interpretation crucially depends on issues of lexicon design. The Generative Lexicon +L+ (Pustejovsky 1995) provides us with a model of the lexicon which couples sufficiently expressive +L+ lexical semantic representations with mechanisms which capture the relationship between those +L+ representations and their syntactic expression. In our approach, the qualia structures of the +L+ nouns in a compound provide relational structure enabling compositional interpretation of the +L+ modification of the head noun by the modifying noun. This brings compound interpretation +L+ under the same rubric as other forms of composition in natural language, including argument +L+ selection, adjectival modification, and type coercion (Pustejovsky (1991,1995), Bouillon 1995). +L+ We examine data from both English and Italian and develop analyses for both languages which use +L+ phrase structure schemata to account for the connections between lexical semantic representation +L+ and syntactic expression. In addition to applications in natural language understanding, machine +L+ translation, and generation, the model of compound interpretation developed here can be applied +L+ to multi-lingual information extraction tasks. +L+ </abstract> <page> +PAGE+ </page> 
<title> The Undecidability of +L+ Mitchell's Subtyping Relationship +L+ </title> <author> J. B. Wells +L+ </author> <email> jbw@cs.bu.edu +L+ </email> <affiliation> Dept. of Computer Science +L+ Boston University +L+ </affiliation> <address> Boston, MA 02215, U.S.A. +L+ </address> <date> December 10, 1995 +L+ </date> <abstract> Abstract +L+ Mitchell defined and axiomatized a subtyping relationship (also known +L+ as containment, coercibility, or subsumption) over the types of System F +L+ (with "!" and "8"). This subtyping relationship is quite simple and does +L+ not involve bounded quantification. Tiuryn and Urzyczyn quite recently +L+ proved this subtyping relationship to be undecidable. This paper supplies a new undecidability proof for this subtyping relationship. First, a +L+ new syntax-directed axiomatization of the subtyping relationship is defined. Then, this axiomatization is used to prove a reduction from the +L+ undecidable problem of semi-unification to subtyping. The undecidability of subtyping implies the undecidability of type checking for System F +L+ extended with Mitchell's subtyping, also known as "F plus eta". +L+ </abstract> <intro> 1 Introduction </intro> 
<title> Experience with Rover Navigation for Lunar-Like Terrains +L+ </title> <author> Reid Simmons , Eric Krotkov , Lalitesh Katragadda , and Martial Hebert +L+ </author> <affiliation> Robotics Institute, Carnegie Mellon University +L+ </affiliation> <address> 5000 Forbes Avenue, Pittsburgh, PA 15213 +L+ </address> <email> reids@cs.cmu.edu +L+ </email> <intro> Introduction </intro> 
<title> Fast Soft Shadows +L+ </title> <author> Michael Herf and Paul S. Heckbert +L+ </author> <abstract> Abstract +L+ Presented is a new algorithm to generate soft shadows. It +L+ employs graphics hardware, including texture mapping and +L+ accumulation buffering, to produce shadows resulting from +L+ area light sources quickly. +L+ </abstract> <affiliation> Computer Science Dept., Carnegie Mellon University, </affiliation> <address> Pittsburgh PA 15213-3891, USA. </address> <web> http://www.cs.cmu.edu/ph, </web> <email> herf+@cmu.edu, +L+ ph@cs.cmu.edu. +L+ </email> <page> +PAGE+ </page> 
<note> To appear in the Proceedings of the 16th ACM Symposium on Operating System Principles +L+ </note> <title> Agile Application-Aware Adaptation for Mobility +L+ </title> <author> Brian D. Noble , M. Satyanarayanan , Dushyanth Narayanan , James Eric Tilton , Jason Flinn , Kevin R. Walker +L+ </author> <affiliation> School of Computer Science +L+ Carnegie Mellon University +L+ </affiliation> <abstract> Abstract +L+ In this paper we show that application-aware adaptation, a +L+ collaborative partnership between the operating system and +L+ applications, offers the most general and effective approach +L+ to mobile information access. We describe the design of +L+ Odyssey, a prototype implementing this approach, and show +L+ how it supports concurrent execution of diverse mobile applications. We identify agility as a key attribute of adaptive systems, and describe how to quantify and measure it. +L+ We present the results of our evaluation of Odyssey, indicating performance improvements up to a factor of 5 on a +L+ benchmark of three applications concurrently using remote +L+ services over a network with highly variable bandwidth. +L+ </abstract> <intro> 1 Introduction </intro> 
<note> Submitted to the Future Generation Computer Systems special issue on Data Mining. +L+ </note> <title> Using Neural Networks for Data Mining +L+ </title> <author> Mark W. Craven +L+ </author> <affiliation> School of Computer Science +L+ Carnegie Mellon University +L+ </affiliation> <address> Pittsburgh, PA 15213-3891 +L+ </address> <email> mark.craven@cs.cmu.edu +L+ </email> <author> Jude W. Shavlik +L+ </author> <affiliation> Computer Sciences Department +L+ University of Wisconsin-Madison +L+ </affiliation> <address> Madison, WI 53706-1685 +L+ </address> <email> shavlik@cs.wisc.edu +L+ </email> <abstract> Abstract +L+ Neural networks have been successfully applied in a wide range of supervised and unsupervised learning applications. Neural-network methods are not commonly used for data-mining +L+ tasks, however, because they often produce incomprehensible models and require long training +L+ times. In this article, we describe neural-network learning algorithms that are able to produce +L+ comprehensible models, and that do not require excessive training times. Specifically, we discuss +L+ two classes of approaches for data mining with neural networks. The first type of approach, +L+ often called rule extraction, involves extracting symbolic models from trained neural networks. +L+ The second approach is to directly learn simple, easy-to-understand networks. We argue that, +L+ given the current state of the art, neural-network methods deserve a place in the tool boxes of +L+ data-mining specialists. +L+ </abstract> <keyword> Keywords: machine learning, neural networks, rule extraction, comprehensible +L+ models, decision trees, perceptrons +L+ </keyword> <intro> 1 Introduction </intro> 
<title> Metamorphosis Networks: +L+ An Alternative to Constructive Methods +L+ </title> <author> Brian V. Bonnlander Michael C. Mozer +L+ </author> <affiliation> Department of Computer Science & +L+ Institute of Cognitive Science +L+ University of Colorado +L+ </affiliation> <address> Boulder, CO 80309-0430 +L+ </address> <abstract> Abstract +L+ Given a set of training examples, determining the appropriate number of free parameters is a challenging problem. Constructive +L+ learning algorithms attempt to solve this problem automatically by +L+ adding hidden units, and therefore free parameters, during learning. We explore an alternative class of algorithms|called metamorphosis algorithms|in which the number of units is fixed, but +L+ the number of free parameters gradually increases during learning. +L+ The architecture we investigate is composed of RBF units on a lattice, which imposes flexible constraints on the parameters of the +L+ network. Virtues of this approach include variable subset selection, robust parameter selection, multiresolution processing, and +L+ interpolation of sparse training data. +L+ </abstract> <intro> 1 INTRODUCTION </intro> 
<title> Scalability of Hierarchical Meta-Learning +L+ on Partitioned Data +L+ </title> <author> Philip K. Chan +L+ </author> <affiliation> Computer Science +L+ Florida Institute of Technology +L+ </affiliation> <address> Melbourne, FL 32901 +L+ </address> <email> pkc@cs.fit.edu +L+ </email> <phone> FAX: (407) 984-8461 +L+ </phone> <author> Salvatore J. Stolfo +L+ </author> <affiliation> Department of Computer Science +L+ Columbia University +L+ </affiliation> <address> New York, NY 10027 +L+ </address> <email> sal@cs.columbia.edu +L+ </email> <phone> (212) 939-7080 +L+ </phone> <date> May 8, 1997 +L+ </date> <abstract> Abstract +L+ In this paper we study the issue of how to scale machine learning algorithms, that +L+ typically are designed to deal with main-memory based datasets, to efficiently learn +L+ models from large distributed databases. We have explored an approach called meta-learning that is related to the traditional approaches of data reduction commonly +L+ employed in distributed database query processing systems. We explore the scalability +L+ of learning arbiter and combiner trees from partitioned data. Arbiter and combiner +L+ trees integrate classifiers trained in parallel from small disjoint subsets. Previous work +L+ demonstrated the efficacy of these meta-learning architectures in terms of accuracy +L+ of the computed meta-classifiers. Here we discuss the computational performance +L+ of constructing arbiter and combiner trees in terms of speedup and scalability as a +L+ function of database size and number of partitions. The performance of serial learning +L+ algorithms is evaluated. We then analyze the performance of the algorithms used to +L+ construct combiner and arbiter trees in parallel. Our empirical results validate these +L+ analyses and indicate that the techniques can effectively scale up to large datasets with +L+ millions of records using cheap commodity hardware. +L+ </abstract> <keyword> Keywords: speedup, scalability, arbiter and combiner trees, meta-learning, parallel/distributed +L+ processing, inductive learning +L+ </keyword> <note> This work was partially funded by grants from NSF (IRI-96-32225 & CDA-96-25374), ARPA (F30602 +L+ 96-1-0311), and NYSSTF (423115-445). +L+ </note> <page> +PAGE+ </page> 
<note> DIMACS Series in Discrete Mathematics +L+ and Theoretical Computer Science +L+ Volume 00, 19xx +L+ </note> <title> Some applications of generalized FFTs +L+ </title> <author> Daniel N. Rockmore +L+ </author> <abstract> Abstract. Generalized FFTs are efficient algorithms for computing a Fourier +L+ transform of a function defined on finite group, or a bandlimited function defined on a compact group. The development of such algorithms has been accompanied and motivated by a growing number of both potential and realized +L+ applications. This paper will attempt to survey some of these applications. +L+ Appendices include some more detailed examples. +L+ </abstract> <intro> 1. A brief history </intro> 
<title> A Protocol for Efficient Transfer of Data over Fiber/Cable Systems +L+ </title> <author> Dolors Sala John O. Limb +L+ </author> <affiliation> School of Electrical College of Computing +L+ and Computer Engineering +L+ Georgia Institute of Technology +L+ </affiliation> <address> Atlanta, GA 30332-0280 +L+ </address> <email> E-mail: (dolors,limb)@cc.gatech.edu +L+ </email> <abstract> Abstract +L+ A revolution is occurring in the scope and range +L+ of information, communication and education services +L+ that will be made available to schools, libraries, town-halls, clinics and, most importantly, residences. These +L+ services will be provided initially, primarily over hybrid fiber-cable systems, either by telephone companies +L+ or cable companies. The old cable plant is being upgraded and used in totally new ways. +L+ The topology and physical characteristics of the upstream channel present new challenges for efficient +L+ channel access. We present a media access protocol +L+ that efficiently transfers data on this channel. A primary goal in the design was to keep the portion of the +L+ protocol resident in the station as simple as possible. +L+ Thus we use centralized control located in the cable +L+ head-end and minimize intelligence in the station. We +L+ refer to this protocol as Centralized Priority Reservation or CPR. A station wishing to transmit sends a request to the head-end using a contention channel. The +L+ head-end acknowledges the request and then schedules +L+ the request, informing the station by means of a grant +L+ message when to transmit. +L+ The protocol performs well under heavy load. Performance is affected little by the number of stations, +L+ the speed of the system and the physical length of the +L+ system. +L+ </abstract> <intro> 1 Introduction </intro> 
<title> Using Queue Time Predictions for Processor Allocation +L+ </title> <author> Allen B. Downey +L+ </author> <affiliation> University of California at Berkeley +L+ San Diego Supercomputer Center +L+ </affiliation> <abstract> Abstract +L+ When a moldable job is submitted to a space-sharing +L+ parallel computer, it must choose whether to begin execution on a small, available cluster or wait in queue for +L+ more processors to become available. To make this decision, it must predict how long it will have to wait for +L+ the larger cluster. We propose statistical techniques for +L+ predicting these queue times, and develop an allocation +L+ strategy that uses these predictions. We present a workload model based on observed workloads at the San Diego +L+ Supercomputer Center and the Cornell Theory Center, +L+ and use this model to drive simulations of various allocation strategies. We find that prediction-based allocation +L+ not only improves the turnaround time of individual jobs; +L+ it also improves the utilization of the system as a whole. +L+ </abstract> <intro> 1 Introduction </intro> 
<title> A Ray Tracing Method for Illumination Calculation in +L+ Diffuse-Specular Scenes +L+ </title> <author> Peter Shirley +L+ </author> <affiliation> Department of Computer Science +L+ University of Illinois +L+ </affiliation> <address> 1304 West Springfield Avenue +L+ Urbana, Illinois 61801 +L+ USA +L+ </address> <abstract> Abstract +L+ Several ways of improving the realism of the results +L+ of traditional ray tracing are presented. The essential physical quantities of spectral radiant power and +L+ spectral radiance and their use in lighting calculations +L+ are discussed. Global illumination terms are derived +L+ by employing illumination ray tracing for calculation of +L+ quickly changing indirect lighting components, and ra-diosity ray tracing for slowly changing indirect lighting +L+ components. Direct lighting is calculated during the +L+ viewing phase allowing the use of bump maps. Finally, +L+ a method is introduced that reduces the total number +L+ of shadow rays to no more than the total number of +L+ viewing rays for a given picture. +L+ </abstract> <keyword> Keywords: Bump Mapping, Illumination, Radiosity, +L+ Radiance, Ray Tracing, Realism, Stratified Sampling, +L+ Texture Mapping. +L+ </keyword> <intro> 1 Introduction </intro> 
<title> Aditi-Prolog language manual +L </title>+ <author> James Harland +L+ David B. Kemp +L+ Tim S. Leask +L+ Kotagiri Ramamohanarao +L+ John A. Shepherd +L+ Zoltan Somogyi +L+ Peter J. Stuckey +L+ Jayen Vaghani +L+ </author> <abstract> Abstract +L+ Aditi is a deductive database system under development at the Collaborative Information +L+ Technology Research Institute by researchers from the University of Melbourne. The main +L+ language in which users interact with Aditi is Aditi-Prolog. This document is a reference +L+ manual for Aditi-Prolog. +L+ </abstract> <intro> 1 Introduction </intro> 
<title> Contingency Selection in Plan Generation +L+ </title> <author> Nilufer Onder +L+ </author> <affiliation> Department of Computer Science +L+ University of Pittsburgh +L+ </affiliation> <address> Pittsburgh, PA 15260 +L+ </address> <note> nilufer@cs.pitt.edu +L+ </note> <author> Martha E. Pollack +L+ </author> <affiliation> Department of Computer Science +L+ and Intelligent Systems Program +L+ University of Pittsburgh +L+ </affiliation> <address> Pittsburgh, PA 15260 +L+ </address> <note> pollack@cs.pitt.edu +L+ </note> <abstract> Abstract +L+ A key question in conditional planning is: how many, +L+ and which of the possible execution failures should be +L+ planned for? One cannot, in general, plan for all the +L+ possible failures because the search space is too large. +L+ One cannot ignore all the possible failures, or one will +L+ fail to produce sufficiently flexible plans. In this paper, +L+ we describe an approach to conditional planning that +L+ attempts to identify the contingencies that contribute +L+ the most to a plan's overall utility. Plan generation +L+ proceeds by handling the most important contingencies first, extending the plan to include actions that +L+ will be taken in case the contingency fails. We discuss +L+ the representational issues that must be addressed in +L+ order to implement such an algorithm, and present an +L+ example which illustrates our approach. +L+ </abstract> <intro> Introduction </intro> 
<title> Navigation in Three Dimensional Spaces +L+ </title> <pubnum> CS-590Z +L+ </pubnum> <author> Carlos Gonzalez Ochoa Aleman +L+ </author> <date> May 23, 1994 +L+ </date> <abstract> Abstract +L+ Current graphic hardware have helped to develop scientific visualization tools, +L+ but this progress has not level with the magnitude of data genereted in some areas needing to be visualized. Techniques to navigate data have been developed, +L+ including new hardware and algorithms to improve the rendering speed and quality. +L+ This paper will describe the issues of navigation, current display and interaction +L+ technology, and algorithms. At the end a set of problems yet to be solved will be +L+ discussed +L+ </abstract> <intro> 1 Introduction </intro> 
<title> Carlsberg: A Distributed Execution Environment +L+ Providing Coherent Shared Memory and +L+ Integrated Message Passing +L+ </title> <note> A Position/Work-in-Progress Paper presented at +L+ Nordic Workshop on Programming Environment Research, NWPER'94, +L+ Lund, Sweden, June, 1994 +L+ </note> <author> Povl T. Koch Robert J. Fowler +L+ </author> <affiliation> Department of Computer Science, University of Copenhagen (DIKU) +L+ </affiliation> <address> Universitetsparken 1, 2100 Copenhagen, Denmark +L+ </address> <phone> Tel: +45 35 32 14 18 Fax: +45 35 32 14 01 </phone> <email> E-mail: koch,fowler@diku.dk +L+ </email> <abstract> Abstract +L+ The Carlsberg prototype is a distributed operating system designed to provide efficient support for distributed-parallel applications on a cluster of high-performance workstations. A unique feature of Carlsberg is the integration of +L+ coherent shared memory, multithreading, and message passing in one system. +L+ In this paper we discuss the motivation for the Carlsberg system and we present +L+ aspects of its design. +L+ </abstract> <intro> 1 Introduction </intro> 
<title> Intelligent Model Selection for Hillclimbing Search in +L+ Computer-Aided Design +L+ </title> <author> Thomas Ellman John Keane Mark Schwabacher +L+ </author> <affiliation> Department of Computer Science, Hill Center for Mathematical Sciences +L+ Rutgers University, </affiliation> <address> New Brunswick, NJ 08903 +L+ </address> <email> fellman,keane,schwabacg@cs.rutgers.edu +L+ </email> <abstract> Abstract +L+ Models of physical systems can differ according to +L+ computational cost, accuracy and precision, among +L+ other things. Depending on the problem solving +L+ task at hand, different models will be appropriate. Several investigators have recently developed +L+ methods of automatically selecting among multiple models of physical systems. Our research is +L+ novel in that we are developing model selection +L+ techniques specifically suited to computer-aided de +L+ sign. Our approach is based on the idea that artifact performance models for computer-aided design +L+ should be chosen in light of the design decisions +L+ they are required to support. We have developed +L+ a technique called "Gradient Magnitude Model Selection" (GMMS), which embodies this principle. +L+ GMMS operates in the context of a hillclimbing +L+ search process. It selects the simplest model that +L+ meets the needs of the hillclimbing algorithm in +L+ which it operates. We are using the domain of sailing yacht design as a testbed for this research. We +L+ have implemented GMMS and used it in hillclimb-ing search to decide between a computationally expensive potential-flow program and an algebraic +L+ approximation to analyze the performance of sailing yachts. Experimental tests show that GMMS +L+ makes the design process faster than it would be if +L+ the most expensive model were used for all design +L+ evaluations. GMMS achieves this performance improvement with little or no sacrifice in the quality +L+ of the resulting design. +L+ </abstract> <intro> 1. Introduction </intro> 
<title> Learning to Select Useful Landmarks +L+ </title> <author> Russell Greiner +L+ </author> <affiliation> Siemens Corporate Research +L+ </affiliation> <address> Princeton, NJ 08540 +L+ </address> <email> greiner@learning.siemens.com +L+ </email> <author> Ramana Isukapalli +L+ </author> <affiliation> Department of Computer Science +L+ Rutgers University +L+ </affiliation> <email> ramana@cs.rutgers.edu +L+ </email> <note> Appears in the +L+ Proceedings of the Twelfth National Conference on Artificial Intelligence (AAAI-94), +L+ Seattle, Washington, July 1994. +L+ </note> <abstract> Abstract +L+ To navigate effectively, an autonomous agent must be +L+ able to quickly and accurately determine its current +L+ location. Given an initial estimate of its position (perhaps based on dead-reckoning) and an image taken of +L+ a known environment, our agent first attempts to locate a set of landmarks (real-world objects at known +L+ locations), then uses their angular separation to obtain an improved estimate of its current position. Unfortunately, some landmarks may not be visible, or +L+ worse, may be confused with other landmarks, resulting in both time wasted in searching for invisible landmarks, and in further errors in the agent's estimate of +L+ its position. To address these problems, we propose a +L+ method that uses previous experiences to learn a selection function that, given the set of landmarks that +L+ might be visible, returns the subset which can reliably +L+ be found correctly, and so provide an accurate registration of the agent's position. We use statistical techniques to prove that the learned selection function is, +L+ with high probability, effectively at a local optimal in +L+ the space of such functions. This report also presents +L+ empirical evidence, using real-world data, that demonstrate the effectiveness of our approach. +L+ </abstract> <intro> 1. Introduction </intro> 
<title> Jade: A High-Level, Machine-Independent Language for Parallel +L+ Programming +L+ </title> <author> Martin C. Rinard, Daniel J. Scales and Monica S. Lam +L+ </author> <affiliation> Computer Systems Laboratory +L+ Stanford University, </affiliation> <address> CA 94305 +L+ </address> <intro> 1 Introduction </intro> 
<title> Almost All Regular Graphs are +L+ Hamiltonian +L+ </title> <author> R. W. Robinson +L+ </author> <affiliation> Computer Science Department +L+ University of Georgia +L+ </affiliation> <address> Athens, GA 30602, U.S.A. +L+ </address> <author> N. C. Wormald +L+ </author> <affiliation> Department of Mathematics +L+ University of Melbourne +L+ </affiliation> <address> Parkville, VIC 3052, Australia +L+ </address> <abstract> Abstract +L+ In a previous paper the authors showed that almost all labelled +L+ cubic graphs are hamiltonian. In the present paper, this result is +L+ used to show that almost all r-regular graphs are hamiltonian for any +L+ fixed r 3, by an analysis of the distribution of 1-factors in random +L+ regular graphs. Moreover, almost all such graphs are r-edge-colourable +L+ if they have an even number of vertices. Similarly, almost all r-regular +L+ bipartite graphs are hamiltonian and r-edge-colourable for fixed r 3. +L+ </abstract> <note> Research supported by the Australian Research Council +L+ </note> <page> +PAGE+ </page> 
<title> Quantum Computing | A treatise +L+ </title> <author> Prabhat Kumar +L+ </author> <date> October 24, 1996 +L+ </date> <abstract> Abstract +L+ Quantum computing has witnessed a surge of activity recently owing +L+ to some very exciting discoveries on both the theoretical and practical +L+ fronts. In this overview, we sketch an account of the developments in +L+ this scientifically intriguing field, starting in the early 80's when the first +L+ questions about the computability of quantum processes were raised, +L+ and which led to the formal definitions of a Quantum Computer and a +L+ Quantum Complexity Theory. Peter Shor's recent remarkable discovery of quantum algorithms to solve the problems of integer factoring +L+ and discrete log computing, which are believed to be extremely hard to +L+ solve efficiently on classical computers, is a compelling demonstration +L+ of the suspected superiority of quantum computing over the classical +L+ model that is in use today. We discuss one of his algorithms and the +L+ implications it has for classical cryptography. We discuss some of the +L+ latest work in this field which has brought us yet closer to achieving a +L+ physical realization of a quantum computer. Whenever it happens, if it +L+ happens, it would be yet another revolution in the field of computing, +L+ and maybe the biggest one to date. +L+ </abstract> <intro> 1 Birth of Quantum Computing </intro> 
<note> To appear in Proceedings of the Twenty Third ACM SIGPLAN-SIGACT +L+ Symposium on Principles of Programming Languages, St. Petersburg +L+ Beach, Florida, January 21-24, 1996. c fl1996 ACM (see notice below). +L+ </note> <title> Is it a Tree, a DAG, or a Cyclic Graph? +L+ A Shape Analysis for Heap-Directed Pointers in C +L+ </title> <author> Rakesh Ghiya and Laurie J. Hendren +L+ </author> <affiliation> School of Computer Science, McGill University +L+ </affiliation> <address> Montreal, Quebec, CANADA H3A 2A7 +L+ </address> <email> fghiya,hendreng@cs.mcgill.ca +L+ </email> <abstract> Abstract +L+ This paper reports on the design and implementation of a practical shape analysis for C. The purpose of the analysis is to aid in the disambiguation of +L+ heap-allocated data structures by estimating the shape +L+ (Tree, DAG, or Cyclic Graph) of the data structure accessible from each heap-directed pointer. This shape +L+ information can be used to improve dependence testing and in parallelization, and to guide the choice of +L+ more complex heap analyses. +L+ The method has been implemented as a context-sensitive interprocedural analysis in the McCAT compiler. Experimental results and observations are given +L+ for 16 benchmark programs. These results show that +L+ the analysis gives accurate and useful results for an +L+ important group of applications. +L+ </abstract> <intro> 1 Introduction and Related </intro> 
<note> To be presented at the 17th IEEE Real-Time Systems Symposium, December 1996. +L+ </note> <title> A Framework for Implementing Objects and Scheduling Tasks in Lock-Free +L+ Real-Time Systems +L+ </title> <author> James H. Anderson and Srikanth Ramamurthy +L+ </author> <affiliation> Department of Computer Science, University of North Carolina at Chapel Hill +L+ </affiliation> <abstract> Abstract +L+ We present an integrated framework for developing real-time systems in which lock-free algorithms are employed to +L+ implement shared objects. There are two key objectives of +L+ our work. The first is to enable functionality for object sharing in lock-free real-time systems that is comparable to that +L+ in lock-based systems. Our main contribution toward this +L+ objective is an efficient approach for implementing multi-object lock-free operations and transactions. A second key +L+ objective of our work is to improve upon previously proposed +L+ scheduling conditions for tasks that share lock-free objects. +L+ When developing such conditions, the key issue is to bound +L+ the cost of operation interferences. We present a general +L+ approach for doing this, based on linear programming. +L+ </abstract> <intro> 1. Introduction </intro> 
<title> Stability and Chaos in an Inertial Two +L+ Neuron System +L+ </title> <author> Diek W. Wheeler 1 and W. C. Schieve +L+ </author> <affiliation> Ilya Prigogine Center for Studies in Statistical Mechanics and +L+ Complex Systems +L+ and +L+ Physics Department, The University of Texas, +L+ </affiliation> <address> Austin, TX 78712 +L+ </address> <abstract> Abstract. +L+ Inertia is added to a continuous-time, Hopfield [1] effective-neuron system. +L+ We explore the effects on the stability of the fixed points of the system. A two +L+ neuron system with one or two inertial terms added is shown to exhibit chaos. +L+ The chaos is confirmed by Lyapunov exponents, power spectra, and phase space +L+ plots. +L+ </abstract> <intro> INTRODUCTION </intro> 
<title> Automated Proof Support for +L+ Reasoning about Distributed Mobile +L+ Programs +L+ </title> <degree> A thesis +L+ submitted in partial fulfilment +L+ of the requirements for +L+ the degree +L+ of +L+ Bachelor of Technology +L+ in +L+ Computer Science and Engineering +L+ </degree> <author> by +L+ B Karthikeyan +L+ T R Vishwanath +L+ </author> <degree> under the guidance of +L+ Dr Sanjiva Prasad +L+ </degree> <affiliation> Department of Computer Science & Engineering +L+ Indian Institute of Technology, Delhi +L+ </affiliation> <date> May 1997 +L+ </date> <page> +PAGE+ </page> 
<title> Scheduling and Page Migration for Multiprocessor Compute Servers +L+ </title> <author> Rohit Chandra , Scott Devine , Ben Verghese, +L+ Anoop Gupta , and Mendel Rosenblum +L+ </author> <affiliation> Computer Systems Laboratory +L+ Stanford University, </affiliation> <address> Stanford CA 94305 +L+ </address> <abstract> Abstract +L+ Several cache-coherent shared-memory multiprocessors have been +L+ developed that are scalable and offer a very tight coupling between +L+ the processing resources. They are therefore quite attractive for +L+ use as compute servers for multiprogramming and parallel application workloads. Process scheduling and memory management, +L+ however, remain challenging due to the distributed main memory found on such machines. This paper examines the effects of +L+ OS scheduling and page migration policies on the performance +L+ of such compute servers. Our experiments are done on the Stan-ford DASH, a distributed-memory cache-coherent multiprocessor. +L+ We show that for our multiprogramming workloads consisting of +L+ sequential jobs, the traditional Unix scheduling policy does very +L+ poorly. In contrast, a policy incorporating cluster and cache affinity along with a simple page-migration algorithm offers up to twofold performance improvement. For our workloads consisting of +L+ multiple parallel applications, we compare space-sharing policies +L+ that divide the processors among the applications to time-slicing +L+ policies such as standard Unix or gang scheduling. We show +L+ that space-sharing policies can achieve better processor utilization +L+ due to the operating point effect, but time-slicing policies benefit +L+ strongly from user-level data distribution. Our initial experience +L+ with automatic page migration suggests that policies based only +L+ on TLB miss information can be quite effective, and useful for +L+ addressing the data distribution problems of space-sharing sched-ulers. +L+ </abstract> <intro> 1 Introduction </intro> 
<title> Demand Interprocedural Dataflow Analysis +L+ </title> <author> Susan Horwitz , Thomas Reps , and Mooly Sagiv +L+ </author> <affiliation> University of Wisconsin +L+ </affiliation> <abstract> Abstract +L+ An exhaustive dataflow-analysis algorithm associates with each point in a program a set of dataflow facts +L+ that are guaranteed to hold whenever that point is reached during program execution. By contrast, a +L+ demand dataflow-analysis algorithm determines whether a single given dataflow fact holds at a single given +L+ point. +L+ This paper presents a new demand algorithm for interprocedural dataflow analysis. The algorithm has +L+ four important properties: +L+ g It provides precise (meet-over-all-interprocedurally-valid-paths) solutions to a large class of problems. +L+ g It has a polynomial worst-case cost for both a single demand and a sequence of all possible demands. +L+ g The worst-case total cost of the sequence of all possible demands is no worse than the worst-case cost +L+ of a single run of the current best exhaustive algorithm. +L+ g Experimental results show that in many situations (e.g., when only a small number of demands are +L+ made, or when most demands are answered yes) the demand algorithm is superior to the current best +L+ exhaustive algorithm. +L+ </abstract> <keyword> CR Categories and Subject Descriptors: D.2.2 [Software Engineering]: Tools and Techniques; D.3.4 +L+ [Programming Languages]: Processors compilers, optimization; E.1 [Data Structures] graphs; F.2.2 +L+ [Analysis of Algorithms and Problem Complexity]: Nonnumerical Algorithms and Problems computations on discrete structures; G.2.2 [Discrete Mathematics]: Graph Theory graph algorithms +L+ General Terms: Algorithms, Experimentation, Theory +L+ Additional Key Words and Phrases: demand dataflow analysis, distributive dataflow framework, graph +L+ reachability, interprocedural dataflow analysis, interprocedurally realizable path, interprocedurally valid +L+ path, meet-over-all-valid-paths solution +L+ </keyword> <note> On leave from IBM Scientific Center, Haifa, Israel. +L+ This work was supported in part by a David and Lucile Packard Fellowship for Science and Engineering, by the National Science +L+ Foundation under grants CCR-8958530 and CCR-9100424, by the Defense Advanced Research Projects Agency under ARPA Order +L+ No. 8856 (monitored by the Office of Naval Research under contract N00014-92-J-1937), by the Air Force Office of Scientific +L+ Research under grant AFOSR-91-0308, and by a grant from Xerox Corporate Research. +L+ Part of this work was done while the authors were visiting the University of Copenhagen. +L+ A preliminary version of this paper appeared in SIGSOFT 95: Proceedings of the Third ACM SIGSOFT Symposium on Foundations +L+ of Software Engineering (Washington DC, October 10-13, 1995) [15] +L+ Authors' address: </note> <affiliation> Computer Sciences Department; Univ. of Wisconsin; </affiliation> <address> 1210 West Dayton Street; Madison, WI 53706; USA. +L+ </address> <email> Electronic mail: -horwitz, reps, sagiv-@cs.wisc.edu. +L+ </email> <page> +PAGE+ </page> 
<title> High-Order Accurate Schemes for Incompressible Viscous Flow +L+ </title> <author> John C. Strikwerday +L+ </author> <affiliation> Computer Sciences Department +L+ University of Wisconsin-Madison +L+ </affiliation> <abstract> Abstract +L+ We present new finite difference schemes for the incompressible Navier-Stokes equations. The schemes are based on two spatial differencing methods, one is fourth-order +L+ accurate and the other is sixth-order accurate. The temporal differencing is based on +L+ backward differencing formulas. The schemes use non-staggered grids and satisfy regularity estimates, guaranteeing smoothness of the solutions. The schemes are computationally +L+ efficient. Computational results demonstrating the accuracy are presented. +L+ </abstract> <keyword> Keywords: incompressible Navier-Stokes, finite difference schemes, GMRES. +L+ </keyword> <note> AMS(MOS) classifications: 65M05, 65N05, 76D05 +L+ </note> <intro> 1. Introduction. </intro> 
<title> Moufang Quasigroups +L+ </title> <author> Kenneth Kunen 1 +L+ </author> <affiliation> University of Wisconsin, </affiliation> <address> Madison, WI 53706, U.S.A. +L+ </address> <email> kunen@cs.wisc.edu +L+ </email> <date> September 5, 1995 +L+ </date> <abstract> ABSTRACT +L+ Each of the Moufang identities in a quasigroup implies that the +L+ quasigroup is a loop. +L+ </abstract> <intro> x1. Introduction. </intro> 
<title> Measuring the Performance of Communication +L+ Middleware on High-Speed Networks +L+ </title> <author> Aniruddha Gokhale and Douglas C. Schmidt +L+ </author> <email> gokhale@cs.wustl.edu and schmidt@cs.wustl.edu +L+ </email> <affiliation> Department of Computer Science, Washington University +L+ </affiliation> <address> St. Louis, MO 63130, USA +L+ </address> <note> An earlier version of this paper appeared in the Proceedings +L+ of the SIGCOMM Conference, 1996, Stanford University, +L+ August, 1996. +L+ </note> <abstract> Abstract +L+ Conventional implementations of communication middle-ware (such as CORBA and traditional RPC toolkits) incur +L+ considerable overhead when used for performance-sensitive +L+ applications over high-speed networks. As gigabit networks +L+ become pervasive, inefficient middleware will force programmers to use lower-level mechanisms to achieve the necessary +L+ transfer rates. This is a serious problem for mission/life-critical applications (such as satellite surveillance and medical imaging). +L+ This paper compares the performance of several widely +L+ used communication middleware mechanisms on a high-speed ATM network. The middleware ranged from lower-level mechanisms (such as socket-based C interfaces and +L+ C++ wrappers for sockets) to higher-level mechanisms (such +L+ as RPC, hand-optimized RPC and two implementations of +L+ CORBA - Orbix 2.0.1 and ORBeline 2.0). These measurements reveal that the lower-level C and C++ implementations outperform the CORBA implementations significantly +L+ (the best CORBA throughput for remote transfer was roughly +L+ 75 to 80 percent of the best C/C++ throughput for sending scalar data types and only around 33 percent for sending structs containing binary fields), and the hand-optimized +L+ RPC code performs slightly better than the CORBA implementations. Our goal in precisely pinpointing the sources of +L+ overhead for communication middleware is to develop scalable and flexible CORBA implementations that can deliver +L+ gigabit data rates to applications. +L+ </abstract> <keyword> Keywords: Communication middleware, distributed object computing, CORBA, high-speed networks. +L+ </keyword> <intro> 1 Introduction and Motivation </intro> 
<title> Defining and Measuring Conflicts +L+ in Optimistic Replication +L+ </title> <author> John Heidemann Ashvin Goel Gerald Popek +L+ </author> <affiliation> University of California, Los Angeles +L+ </affiliation> <pubnum> Technical report UCLA-CSD-950033 +L+ </pubnum> <abstract> Abstract +L+ Optimistic replication is often viewed as essential for +L+ large scale systems and for supporting mobile computing. In optimistic replication, updates can be made concurrently to different file replicas, resulting in multiple +L+ versions of the file. To recover from these conflicting +L+ updates, after-the fact conflict resolution actions are +L+ required to recombine multiple versions into one. This +L+ paper defines these concepts and discusses approaches +L+ to measure them in optimistically replicated systems. +L+ Measurement of the number of conflicting updates +L+ and conflict resolution is important to judge the practicality of optimistic replication. An environment +L+ where conflicting updates are frequent will not be attractive since users cannot assume they have up-to-date +L+ data. Although many conflicts can be automatically +L+ resolved, some conflicts require user intervention; such +L+ conflicts cannot be too common. This paper shows an +L+ approach to measure the number of conflicting updates. +L+ From this measurement we derive the actual amount of +L+ work done by the user or system to resolve conflicts +L+ and the minimum amount of work required to resolve +L+ conflicts. +L+ </abstract> <intro> 1 Introduction </intro> 
<title> Using Linguistic Phenomena to Motivate a Set of Rhetorical +L+ Relations +L+ </title> <author> Alistair Knott +L+ </author> <affiliation> Department of Artificial Intelligence, University of Edinburgh +L+ </affiliation> <address> 80 South Bridge, Edinburgh EH1 1HN, Scotland +L+ </address> <email> Email: A.Knott@ed.ac.uk +L+ </email> <author> Robert Dale +L+ </author> <affiliation> Human Communication Research Centre, University of Edinburgh +L+ </affiliation> <address> 2 Buccleuch Place, Edinburgh EH8 9LW, Scotland +L+ </address> <email> Email: R.Dale@ed.ac.uk +L+ </email> <date> May 5, 1993 +L+ </date> <note> Running head: Motivating Rhetorical Relations +L+ </note> <page> +PAGE+ </page> 
<title> What's Decidable about Hybrid Automata? +L+ </title> <author> Thomas A. Henzinger 2 Peter W. Kopke 2 Anuj Puri 3 Pravin Varaiya 3 +L+ </author> <abstract> Abstract. Hybrid automata model systems with both +L+ digital and analog components, such as embedded control programs. Many verification tasks for such programs +L+ can be expressed as reachability problems for hybrid automata. By improving on previous decidability and undecidability results, we identify the precise boundary between decidability and undecidability of the reachability +L+ problem for hybrid automata. +L+ On the positive side, we give an (optimal) PSPACE +L+ reachability algorithm for the case of initialized rectangular automata, where all analog variables follow trajectories within piecewise-linear envelopes and are reinitialized +L+ whenever the envelope changes. Our algorithm is based +L+ on a translation of an initialized rectangular automaton +L+ into a timed automaton that defines the same timed language. The translation has practical significance for verification, because it guarantees the termination of symbolic +L+ procedures for the reachability analysis of initialized rectangular automata. +L+ On the negative side, we show that several slight generalizations of initialized rectangular automata lead to an +L+ undecidable reachability problem. In particular, we prove +L+ that the reachability problem is undecidable for timed automata with a single stopwatch. +L+ </abstract> <intro> 1 Introduction </intro> 
<title> Spheres of Control: +L+ An Approach to Advanced Recovery +L+ </title> <author> C. Wallace N. Soparkar +L+ </author> <affiliation> Electrical Engineering & Computer Science +L+ The University of Michigan +L+ </affiliation> <address> Ann Arbor, MI 48109-2122 +L+ USA +L+ </address> <email> fwallace,soparkarg@eecs.umich.edu +L+ </email> <abstract> Abstract +L+ Recovery from failures and erroneous executions is a crucial but complicated issue for concurrently accessed data systems. Increasingly sophisticated techniques are being developed to improve performance +L+ and functionality of recovery protocols. To better understand and analyze recovery schemes, we reexamine the concept of spheres of control [Dav78], using it as a unifying framework for specifying diverse +L+ recovery models simply and precisely. We constrain sphere-of-control formulations appropriately to capture transaction-oriented recovery in both centralized and distributed environments and with different +L+ types of schedules, as well as semantics-based recovery and compensation. In addition, we discuss how +L+ the operational semantics methodology of evolving algebras [Gur95] can model spheres of control formally +L+ and refine them to lower levels of abstraction. +L+ </abstract> <intro> 1 Introduction </intro> 
<title> Video Server on an ATM Connected Cluster of Workstations +L+ </title> <author> Olav Sandsta , Stein Langrgen , and Roger Midtstraum +L+ </author> <affiliation> Department of Computer and Information Science +L+ Norwegian University of Science and Technology +L+ </affiliation> <address> N-7034 Trondheim, Norway +L+ </address> <email> folavsa, steinl, rogerg@idi.ntnu.no +L+ </email> <abstract> Abstract +L+ Video servers are important for applications which make +L+ use of digital video. The video servers should provide better +L+ functionality than most of today's video servers offer, - e.g., +L+ support of flexible and instant user interactions, delivery of +L+ multiple video formats and support of virtual video documents. In this paper we discuss the requirements that video +L+ servers should fulfill and we describe the design and implementation of the Elvira video server. The Elvira video server +L+ is built on a cluster of standard UNIX workstations interconnected by an ATM switch. The capacity of the Elvira server +L+ is evaluated and we show the effects of different strategies +L+ for allocation of video data across nodes and disks. +L+ </abstract> <intro> 1. Introduction </intro> 
<note> To appear in Expert Systems with Applications: An International Journal, Vol.10(1996) +L+ </note> <title> Efficient Rule Induction from Noise Data +L+ </title> <author> Huan Liu +L+ </author> <affiliation> Department of Information Systems and Computer Science +L+ National University of Singapore +L+ </affiliation> <address> Kent Ridge, Singapore 0511 +L+ </address> <email> liuh@iscs.nus.sg +L+ </email> <phone> Tel: (+65)-772-6563; Fax: (+65) 779-4580 +L+ </phone> <note> Acknowledgments +L+ Many thanks to Rudy Setiono and Tiow Seng Tan for providing valuable com +L+ ments and help. +L+ </note> <page> +PAGE+ </page> 
<note> To appear in the Proceedings of the Fifteenth National Conference on Artificial Intelligence (AAAI-98) +L+ </note> <title> Learning to Predict User Operations for Adaptive Scheduling +L+ </title> <author> Melinda T. Gervasio and Wayne Iba and Pat Langley +L+ </author> <affiliation> Institute for the Study of Learning and Expertise +L+ </affiliation> <address> 2164 Staunton Court, Palo Alto, California 94306 +L+ </address> <email> fgervasio,iba,langleyg@isle.org +L+ </email> <abstract> Abstract +L+ Mixed-initiative systems present the challenge of finding an effective level of interaction between humans +L+ and computers. Machine learning presents a promising approach to this problem in the form of systems +L+ that automatically adapt their behavior to accommodate different users. In this paper, we present an empirical study of learning user models in an adaptive +L+ assistant for crisis scheduling. We describe the problem domain and the scheduling assistant, then present +L+ an initial formulation of the adaptive assistant's learning task and the results of a baseline study. After this, +L+ we report the results of three subsequent experiments +L+ that investigate the effects of problem reformulation +L+ and representation augmentation. The results suggest +L+ that problem reformulation leads to significantly better accuracy without sacrificing the usefulness of the +L+ learned behavior. The studies also raise several interesting issues in adaptive assistance for scheduling. +L+ </abstract> <intro> Introduction </intro> 
<title> ON COMPUTABLE BELIEFS OF RATIONAL MACHINES +L+ </title> <author> Nimrod Megiddo +L+ </author> <abstract> Abstract. Traditional decision theory has assumed that agents have complete, consistent and readily available beliefs and preferences. Obviously, even if +L+ an expert system has complete and consistent beliefs, it cannot have them readily +L+ available. Moreover, some beliefs about beliefs are not even approximately computable. It is shown that if all players have complete and consistent beliefs, they +L+ can compute approximate beliefs about beliefs of any order by considering events +L+ arbitrarily close in some well-defined sense to the ones in question. +L+ </abstract> <intro> 1. Introduction </intro> 
<title> Rule Combination +L+ in +L+ Inductive Learning +L+ </title> <author> Luis Torgo +L+ </author> <affiliation> LIACC +L+ </affiliation> <address> R.Campo Alegre, 823 - 2. +L+ 4100 PORTO +L+ PORTUGAL +L+ </address> <phone> Telf. : (+351) 2 600 16 72 - Ext. 115 +L+ Fax : (+351) 2 600 3654 +L+ </phone> <email> email : ltorgo@ciup1.ncc.up.pt +L+ </email> <abstract> Abstract. This paper describes the work on methods for combining rules +L+ obtained by machine learning systems. Three methods for obtaining the +L+ classification of examples with those rules are compared. The advantages and +L+ disadvantages of each method are discussed and the results obtained on three +L+ real world domains are commented. The methods compared are: selection of +L+ the best rule; PROSPECTOR-like probabilistic approximation for rule +L+ combination; and MYCIN-like approximation. Results show significant +L+ differences between methods indicating that the problemsolving strategy is +L+ important for accuracy of learning systems. +L+ </abstract> <intro> 1 Introduction </intro> 
<title> Designing Distributed Applications +L+ with Mobile Code Paradigms +L+ </title> <author> Antonio Carzaniga +L+ </author> <affiliation> Politecnico di Milano +L+ </affiliation> <address> Piazza Leonardo da Vinci, 32 +L+ 20133 Milano, Italy +L+ </address> <phone> +39-2-2399-3638 +L+ </phone> <email> carzaniga@elet.polimi.it +L+ </email> <author> Gian Pietro Picco +L+ </author> <affiliation> Politecnico di Torino +L+ </affiliation> <address> Corso Duca degli Abruzzi, 24 +L+ 10129 Torino, Italy +L+ </address> <phone> +39-11-564-7008 +L+ </phone> <email> picco@athena.polito.it +L+ </email> <author> Giovanni Vigna +L+ </author> <affiliation> Politecnico di Milano +L+ </affiliation> <address> Piazza Leonardo da Vinci, 32 +L+ 20133 Milano, Italy +L+ </address> <phone> +39-2-2399-3666 +L+ </phone> <email> vigna@elet.polimi.it +L+ </email> <abstract> ABSTRACT +L+ Large scale distributed systems are becoming of +L+ paramount importance, due to the evolution of technology and to the interest of market. Their development, +L+ however, is not yet supported by a sound technological and methodological background, as the results developed for small size distributed systems often do not +L+ scale up. Recently, mobile code languages (MCLs) have +L+ been proposed as a technological answer to the problem. +L+ In this work, we abstract away from the details of these +L+ languages by deriving design paradigms exploiting code +L+ mobility that are independent of any particular technology. We present such design paradigms, together +L+ with a discussion of their features, their application domain, and some hints about the selection of the correct +L+ paradigm for a given distributed application. +L+ </abstract> <keyword> Keywords +L+ Mobile code, design paradigms, distributed applications. +L+ </keyword> <intro> INTRODUCTION </intro> 
<title> Sensor-based Registration and Stacking +L+ of Electronic Substrate Layers +L+ </title> <author> Andrew E. Brennemann, 1 Robert Hammer, 2 +L+ William V. Jecusco II, 3 +L+ and Ralph L. Hollis 4 +L+ </author> <affiliation> IBM Research Division +L+ Thomas J. Watson Research Center +L+ </affiliation> <address> Yorktown Heights, New York, USA +L+ </address> <abstract> Abstract +L+ Substrates for most of today's electronic products contain many wiring layers +L+ which are individually fabricated, mechanically registered with one another, +L+ and laminated together. Alignment tolerances of 0.05 mm to 0.1 mm are +L+ sufficient to register the vertical connection pads or vias on each layer. More +L+ aggressive designs of the future will, however, require manufacturing accuracies of at least an order of magnitude better to accommodate much finer +L+ wire widths and pin spacings. Conventional equipment relying on mechanical +L+ "pin-in-slot" methods will likely be inadequate, and a new approach will be +L+ needed. +L+ We describe here a sensor-based approach for registration and stacking +L+ of electronic substrate sublaminates that replaces pin-in-slot methods, yet +L+ does not require accurate automation equipment. A pilot work cell for this +L+ approach is presented, which has an IBM 7576 coarse-positioning robot, a +L+ specially-developed fine-positioning robot, optical sensors, and several routine +L+ low accuracy fixtures. A novel robot bracing method was used to minimize +L+ environmental vibration during sublaminate stacking. +L+ Pairs of test sublaminates, each containing an identical pattern of 100 +L+ m holes, were aligned, stacked and bonded. The accuracy of registration +L+ </abstract> <note> 1 Retired, </note> <address> 4 Morningside Court, Ossining, NY, 10562. </address> 
<title> Improving Programming-by-Demonstration With Better Semantic Expression +L+ </title> <degree> Thesis Proposal +L+ </degree> <author> Richard McDaniel +L+ </author> <date> November 14, 1995 +L+ </date> <abstract> Abstract +L+ The domain of applications that can be created with programming-by-demonstration +L+ (PBD) can be extended by improving the developers ability to communicate with the system. The +L+ techniques provided in this thesis will allow nonprogrammers to create a new variety of complete, +L+ interactive applications including many board games and educational software using PBD. +L+ A PBD software tool uses inferencing to induce programs by watching the developer demonstrate examples that show how the application should behave. Current systems reduce their scope +L+ or resort to having the developer program because they do not provide sufficient ways to express +L+ behaviors and the factors that affect them. Therefore, the goal of this thesis is to develop understandable forms of annotated expression and manipulation that help a system infer a broader range +L+ of behavior. To test these ideas, this proposal introduces a new system called Gamut that will +L+ present the techniques in a unified software tool. +L+ The first technique replaces the macro recorder method for demonstrating behavior used +L+ in other PBD systems with a technique called nudges. The developer demonstrates by correcting +L+ the system at important points during program execution and also using two nudge commands to +L+ communicate important situations. First, the Do Something! nudge causes the system to reconsider +L+ past learned behavior and try to generalize its knowledge to fit the current situation. Using the +L+ Stop That! nudge will point out improper behavior and generate negative examples. +L+ Second, Gamut will use a new deck-of-playing-cards metaphor to express concepts such +L+ as randomness, sequencing, and data storage. By constructing an appropriate deck, shufing, sorting, and playing cards at key moments, developers can incorporate many effects not available without programming in other systems. +L+ Third, Gamut will improve communication about behaviors by making them more manipulable than in previous systems. Behaviors will be represented as small icons near the objects they +L+ affect. Using the familiar cut, copy, and paste commands, the developer can transfer behavior +L+ between objects. Determining how to make a behavior operate in the new context will be inferred +L+ automatically. An objects state from the recent past will be represented as temporal ghosts in +L+ which objects become dimmed, translucent images. Many sorts of behavior refer to prior states +L+ such as a previous position or an old property value. The ghost objects will allow the developer to +L+ make explicit connections. +L+ Finally, to reduce the number of options the system must explore, the developer will be +L+ able to give hints by highlighting important objects and properties. A new inferencing algorithm +L+ will be created that will take advantage of the hints. +L+ By combining these techniques, Gamut will provide a rich medium for expressing developer intentions, fostering greater communication between the PBD system and the developer and +L+ enabling the developer to create highly interactive software with minimal programming expertise. +L+ </abstract> <page> +PAGE+ </page> 
<title> Problem Solving for Redesign +L+ </title> <author> Anita Pos 1 and Hans Akkermans 1 and Remco Straatman 2 +L+ </author> <affiliation> 1 University of Twente (UT) +L+ Department of Computer Science +L+ </affiliation> <address> P.O. Box 217 +L+ NL-7500 AE Enschede +L+ The Netherlands +L+ </address> <email> E-mail: fpos,akkermang@cs.utwente.nl +L+ </email> <affiliation> 2 University of Amsterdam (UvA) +L+ Department of Social Science Informatics (SWI) +L+ </affiliation> <address> Roetersstraat 15 +L+ 1081 WB Amsterdam +L+ The Netherlands +L+ </address> <email> E-mail: remco@swi.psy.uva.nl +L+ </email> <abstract> Abstract. A knowledge-level analysis of complex tasks like diagnosis and design can give us a better understanding of these tasks in terms of the goals they +L+ aim to achieve and the different ways to achieve these goals. In this paper we +L+ present a knowledge-level analysis of redesign. Redesign is viewed as a family of +L+ methods based on some common principles, and a number of dimensions along +L+ which redesign problem solving methods can vary are distinguished. By examining the problem-solving behavior of a number of existing redesign systems and approaches, we came up with a collection of problem-solving methods for redesign +L+ and developed a task-method structure for redesign. +L+ In constructing a system for redesign a large number of knowledge-related choices +L+ and decisions are made. In order to describe all relevant choices in redesign problem solving, we have to extend the current notion of possible relations between +L+ tasks and methods in a PSM architecture. The realization of a task by a problem-solving method, and the decomposition of a problem-solving method into subtasks are the most common relations in a PSM architecture. However, we suggest +L+ to extend these relations with the notions of task refinement and method refinement. These notions represent intermediate decisions in a task-method structure, +L+ in which the competence of a task or method is refined without immediately paying attention to its operationalization in terms of subtasks. Explicit representation +L+ of this kind of intermediate decisions helps to make and represent decisions in a +L+ more piecemeal fashion. +L+ </abstract> <intro> 1 Introduction </intro> 
<title> Perfect Simulation of some Point Processes +L+ for the Impatient User +L+ </title> <author> Elke Thonnes +L+ </author> <affiliation> Department of Statistics, University of Warwick +L+ </affiliation> <date> February 9, 1998 +L+ </date> <abstract> Abstract +L+ Recently Propp and Wilson [14] have proposed an algorithm, called +L+ Coupling from the Past (CFTP), which allows not only an approximate but perfect (i.e. exact) simulation of the stationary distribution +L+ of certain finite state space Markov chains. Perfect Sampling using +L+ CFTP has been successfully extended to the context of point processes, amongst other authors, by Haggstrom et al. [5]. In [5] Gibbs +L+ sampling is applied to a bivariate point process, the penetrable spheres +L+ mixture model [19]. However, in general the running time of CFTP +L+ in terms of number of transitions is not independent of the state sampled. Thus an impatient user who aborts long runs may introduce a +L+ subtle bias, the user impatience bias. Fill [3] introduced an exact sampling algorithm for finite state space Markov chains which, in contrast +L+ to CFTP, is unbiased for user impatience. Fill's algorithm is a form +L+ of rejection sampling and similar to CFTP requires sufficient mono-tonicity properties of the transition kernel used. We show how Fill's +L+ version of rejection sampling can be extended to an infinite state space +L+ context to produce an exact sample of the penetrable spheres mixture +L+ process and related models. Following [5] we use Gibbs sampling and +L+ make use of the partial order of the mixture model state space. Thus +L+ </abstract> <note> Research supported by EPSRC earmarked studentship and University of Warwick +L+ graduate award. Postal address: </note> <affiliation> Dept. of Statistics, University of Warwick, </affiliation> <address> Coventry, +L+ CV4 7AL, UK +L+ </address> <page> +PAGE+ </page> 
