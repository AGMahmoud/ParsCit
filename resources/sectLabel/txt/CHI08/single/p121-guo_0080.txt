CHI 2008 Proceedings · Human-Robot Interaction	April 5-10, 2008 · Florence, Italy
and focused on the computer screen that displayed the 
posture images. However, when the participants used the 
keypad interface, they often looked at the computer screen 
first, and then focus on the keypad to find the right button 
to press. This attention shifting problem slowed down the 
participants’ task completion time and can again be 
associated with the separation between action and 
perception space created by the keypad.
Most participants felt they were simply mimicking the 
postures on the computer screen when using the 
Wiimote/Nunchuk interface, but they felt the keypad 
interface required them to “act”. Following, we believe that 
the intuitiveness of gesture input had definitely reduced the 
cognitive load of associating user inputs with zoomorphic 
robotic actions.
In addition, gesture input tends to support simultaneous 
input compared to button input. As one of the participants 
commented, “I could do both hands (both arm movements) 
at the same time without a lot of logical thinking (with the 
Wiimote/Nunchuk interface), where with the keyboard I 
had to press one (button) and the other (button) if I was 
doing two hand movements at the same time. Although they 
would be in succession, they would not be at the same 
time.”
It is worth to point out that even though posture 1 and 2 
only required single arm movements, there was a 
significant difference between the task completion times of 
both techniques. In our opinion, we think this is perhaps 
due to the participants not being fully trained at the 
beginning of the study. Thus, they tend to make more 
mistakes with the first few postures. This may also imply 
that the Wiimote/Nunchuk interface was easier to learn 
compared to the keypad interface and can be utilized faster.
Subjective Ratings
We also asked the participants to rate the intuitiveness of 
both input techniques and indicate their preferred 
techniques for both tasks. Figure 12 and 13 shows the 
results of participants’ ratings.
After the study, we asked the participants who preferred to 
use the keypad for the navigation task about their subjective 
reasoning. All of them responded that they are more 
familiar with the keypad interface because of related 
computer game experiences. However, their performance 
indicates they completed the navigation task when using the 
keypad slower than when using the Wiimote interface. One 
of the participants commented, “I have to think harder when 
I use the keyboard, and this kind of mental overhead 
coupled with the lag time just makes it feel harder.”
For the participants who preferred to use the keypad for the 
posture task, their reasoning was that they can easily 
memorize the key-action mapping since there were only 
four postures for each arm and the buttons associated with 
both arms are symmetrical on the keypad layout. As one of 
the participants stated, “With so few postures available, the 
keyboard was just as easy as the Wiimote.” We agree with 
this participant’s comment. We believe that if we provided 
extensive training to all of the participants using the keypad
interface, they would eventually outperform the 
Wiimote/Nunchuk interface in terms of task completion 
time. However, we think that the gestural TUI control 
method would prevail if we increase the number of degrees-
of-freedom and postures to an amount that participants 
cannot easily memorize, or if we deal with an interaction 
task that cannot afford intensive training.
During the experiment, many participants asked whether 
the Wiimote interface supports gradual motion sensing. The 
consensus indicates that people expect gesture interface to 
be capable of sensing and reacting to gradual changes of
Figure 12. Mean ratings on post-study questionnaire. 
The rating scale ranges from 1 (strongly disagree) to 7 
(strongly agree).
Figure 13. Users’ preference for each interaction 
technique
129
