CHI 2008 Proceedings · On the Move	April 5-10, 2008 · Florence, Italy
ontextContext ensingSensing
iActivity	iiPredictions
liPopulation	iBehavior Patterns
lPersonal Patterns
Figure 4. The Activity prediction process.
Activity Prob Slots
Eating	.40	8
Shopping	.20	4
Seeing	.15	3
Doing	.10	2
Reading	.15	3
iRecommendation	lModels	Item Utility Ratings
Content 
Content
Repository
Collaborative
Filtering
iDistance
Preferences
ontextContext SensingSensing
Future 
Plans
Apple Store
Straits Cafe
Fuki Sushi
Dance Clubs
...
0.77
0.64
0.62
0.39
...
types, product, type, gallery genre, expensiveness, etc.). 
Because of error rates in GPS and other data, the behavior 
model tracks the uncertainty of visits and constructs a 
probabilistic model, rather than a precise definite record, of 
visited venues.
Past context-aware mobile information-retrieval systems 
such as Jiminy [32], stick-e documents [8], and Lamming 
and Newman’s activity-based information-retrieval system 
[20], among others, were based on calculating the distance 
between the user’s current context (location, time, people, 
etc.) and corresponding features in the metadata of 
documents. Rhodes found that recommending documents 
based on context similarity had only marginal value in the 
domain of memory assistance [32], but he did not study 
leisure activity. These systems did not try to classify users’ 
likely current or future activity modes, as Magitti does.
Prior research has shown that the activity predictions will 
not be completely accurate, but complete accuracy is not 
necessary for our system. Magitti presents a list containing 
a mix of content related to the activity probabilities, 
allowing the user to decide which items are of interest.
Recommender System
For a given user and context, the Recommender computes 
the utility of each content item by combining results from a 
variety of recommendation models. When all items have 
been scored, the top results are returned to fill the slots 
allocated by the activity model.
Recommender systems use a variety of techniques. Two of 
the most common are collaborative filtering [11, 31], based 
on identifying clusters of people with similar interest, and 
content similarity [2], which calculates the similarity of 
various attributes of content (genre, date, etc.). There are 
tradeoffs in the techniques and some systems use a 
combination [23]. Magitti takes this hybrid approach.
In Magitti, the final score for an item is computed based on 
the results of a large number of models (see Figure 5). A 
Set Generator maintains a list of all models available, and 
combines them in an ad hoc fashion depending on the input 
it receives from other system components. The way models 
are combined can be specified in a set of rules, or inferred 
from the user’s context. The Set Generator can also learn 
which models are most appropriate for a user in a given
Figure 5. For each activity type, the Recommendation 
system uses different combinations and weightings of 
utility models to score recommendable content items.
context. In the current incarnation of Magitti we combine 
eight models:
•	Collaborative filtering: This model uses ratings to 
compute similarities between users and scores each item 
based on how other similar users rated it.
•	Stated Preferences: This model scores items according
to how closely they match the user’s stated preferences 
(cuisines, noise level, price range, product types, etc.).
•	Learned Preferences: This model works similarly to the
Stated Preferences, but is learned from observed behavior 
rather than explicitly stated preferences.
•	Content preference: This model measures the similarity
of an item’s content to a profile of the user’s previously 
viewed content in web pages and documents.
•	Distance: This system gives maximum weight to items
within a distance range (either entered or inferred from 
location traces) and uses an exponential decay function to 
rate the others.
•	Reading: The system uses a model of when users are
most likely to read according to data from the fieldwork.
•	Boredom Buster: This model reduces the scores of items
that have previously been seen, providing diversity to the 
set of recommended items.
•	Future Plans: This model temporarily raises scores
based on evidence of future plans derived from the 
Content Analysis, described below.
Content Repository
The Content Repository contains the items to be rated and 
returned by the Recommender for presentation to the user. 
Each activity type can have one or more content types 
associated with it. Spatial data structures and caching 
mechanisms are used to hold the content in memory, 
avoiding repeated trips to the database and providing for 
fast location-specific queries.
The recommendable content is indexed according to 
contextual metadata that indicates the physical situations in 
which a piece of content might be useful, such as a venue’s
1162
