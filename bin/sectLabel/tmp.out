title ||| Heterogeneous Transfer Learning for Image Clustering via the Social Web
author ||| Qiang Yang
affiliation ||| Hong Kong University of Science and Technology, Clearway Bay, Kowloon, Hong Kong
email ||| qyang@cs.ust.hk
author ||| Yuqiang Chen	Gui-Rong Xue	Wenyuan Dai	Yong Yu
affiliation ||| Shanghai Jiao Tong University, 800 Dongchuan Road, Shanghai 200240, China
email ||| {yuqiangchen,grxue,dwyak,yyu}@apex.sjtu.edu.cn
sectionHeader ||| Abstract
bodyText ||| In this paper, we present a new learning
bodyText ||| scenario, heterogeneous transfer learn-
bodyText ||| ing, which improves learning performance
bodyText ||| when the data can be in different feature
bodyText ||| spaces and where no correspondence be-
bodyText ||| tween data instances in these spaces is pro-
bodyText ||| vided. In the past, we have classified Chi-
bodyText ||| nese text documents using English train-
bodyText ||| ing data under the heterogeneous trans-
bodyText ||| fer learning framework. In this paper,
bodyText ||| we present image clustering as an exam-
bodyText ||| ple to illustrate how unsupervised learning
bodyText ||| can be improved by transferring knowl-
bodyText ||| edge from auxiliary heterogeneous data
bodyText ||| obtained from the social Web. Image
bodyText ||| clustering is useful for image sense dis-
bodyText ||| ambiguation in query-based image search,
bodyText ||| but its quality is often low due to image-
bodyText ||| data sparsity problem. We extend PLSA
bodyText ||| to help transfer the knowledge from social
bodyText ||| Web data, which have mixed feature repre-
bodyText ||| sentations. Experiments on image-object
bodyText ||| clustering and scene clustering tasks show
bodyText ||| that our approach in heterogeneous trans-
bodyText ||| fer learning based on the auxiliary data is
bodyText ||| indeed effective and promising.
sectionHeader ||| 1 Introduction
bodyText ||| Traditional machine learning relies on the avail-
bodyText ||| ability of a large amount of data to train a model,
bodyText ||| which is then applied to test data in the same
bodyText ||| feature space. However, labeled data are often
bodyText ||| scarce and expensive to obtain. Various machine
bodyText ||| learning strategies have been proposed to address
bodyText ||| this problem, including semi-supervised learning
bodyText ||| (Zhu, 2007), domain adaptation (Wu and Diet-
bodyText ||| terich, 2004; Blitzer et al., 2006; Blitzer et al.,
bodyText ||| 2007; Arnold et al., 2007; Chan and Ng, 2007;
bodyText ||| Daume, 2007; Jiang and Zhai, 2007; Reichart
bodyText ||| and Rappoport, 2007; Andreevskaia and Bergler,
bodyText ||| 2008), multi-task learning (Caruana, 1997; Re-
bodyText ||| ichart et al., 2008; Arnold et al., 2008), self-taught
bodyText ||| learning (Raina et al., 2007), etc. A commonality
bodyText ||| among these methods is that they all require the
bodyText ||| training data and test data to be in the same fea-
bodyText ||| ture space. In addition, most of them are designed
bodyText ||| for supervised learning. However, in practice, we
bodyText ||| often face the problem where the labeled data are
bodyText ||| scarce in their own feature space, whereas there
bodyText ||| may be a large amount of labeled heterogeneous
bodyText ||| data in another feature space. In such situations, it
bodyText ||| would be desirable to transfer the knowledge from
bodyText ||| heterogeneous data to domains where we have rel-
bodyText ||| atively little training data available.
bodyText ||| To learn from heterogeneous data, researchers
bodyText ||| have previously proposed multi-view learning
bodyText ||| (Blum and Mitchell, 1998; Nigam and Ghani,
bodyText ||| 2000) in which each instance has multiple views in
bodyText ||| different feature spaces. Different from previous
bodyText ||| works, we focus on the problem of heterogeneous
bodyText ||| transfer learning, which is designed for situation
bodyText ||| when the training data are in one feature space
bodyText ||| (such as text), and the test data are in another (such
bodyText ||| as images), and there may be no correspondence
bodyText ||| between instances in these spaces. The type of
bodyText ||| heterogeneous data can be very different, as in the
bodyText ||| case of text and image. To consider how hetero-
bodyText ||| geneous transfer learning relates to other types of
bodyText ||| learning, Figure 1 presents an intuitive illustration
bodyText ||| of four learning strategies, including traditional
bodyText ||| machine learning, transfer learning across differ-
bodyText ||| ent distributions, multi-view learning and hetero-
bodyText ||| geneous transfer learning. As we can see, an
bodyText ||| important distinguishing feature of heterogeneous
bodyText ||| transfer learning, as compared to other types of
bodyText ||| learning, is that more constraints on the problem
bodyText ||| are relaxed, such that data instances do not need to
bodyText ||| correspond anymore. This allows, for example, a
bodyText ||| collection of Chinese text documents to be classi-
bodyText ||| fied using another collection of English text as the
page ||| 1
note ||| Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 1–9,
note ||| Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP
bodyText ||| training data (c.f. (Ling et al., 2008) and Section
bodyText ||| 2.1).
bodyText ||| In this paper, we will give an illustrative exam-
bodyText ||| ple of heterogeneous transfer learning to demon-
bodyText ||| strate how the task of image clustering can ben-
bodyText ||| efit from learning from the heterogeneous social
bodyText ||| Web data. A major motivation of our work is
bodyText ||| Web-based image search, where users submit tex-
bodyText ||| tual queries and browse through the returned result
bodyText ||| pages. One problem is that the user queries are of-
bodyText ||| ten ambiguous. An ambiguous keyword such as
bodyText ||| “Apple” might retrieve images of Apple comput-
bodyText ||| ers and mobile phones, or images of fruits. Im-
bodyText ||| age clustering is an effective method for improv-
bodyText ||| ing the accessibility of image search result. Loeff
bodyText ||| et al. (2006) addressed the image clustering prob-
bodyText ||| lem with a focus on image sense discrimination.
bodyText ||| In their approach, images associated with textual
bodyText ||| features are used for clustering, so that the text
bodyText ||| and images are clustered at the same time. Specif-
bodyText ||| ically, spectral clustering is applied to the distance
bodyText ||| matrix built from a multimodal feature set associ-
bodyText ||| ated with the images to get a better feature repre-
bodyText ||| sentation. This new representation contains both
bodyText ||| image and text information, with which the per-
bodyText ||| formance of image clustering is shown to be im-
bodyText ||| proved. A problem with this approach is that when
bodyText ||| images contained in the Web search results are
bodyText ||| very scarce and when the textual data associated
bodyText ||| with the images are very few, clustering on the im-
bodyText ||| ages and their associated text may not be very ef-
bodyText ||| fective.
bodyText ||| Different from these previous works, in this pa-
bodyText ||| per, we address the image clustering problem as
bodyText ||| a heterogeneous transfer learning problem. We
bodyText ||| aim to leverage heterogeneous auxiliary data, so-
bodyText ||| cial annotations, etc. to enhance image cluster-
bodyText ||| ing performance. We observe that the World Wide
bodyText ||| Web has many annotated images in Web sites such
bodyText ||| as Flickr (http : / /www. flickr . com), which
bodyText ||| can be used as auxiliary information source for
bodyText ||| our clustering task. In this work, our objective
bodyText ||| is to cluster a small collection of images that we
bodyText ||| are interested in, where these images are not suf-
bodyText ||| ficient for traditional clustering algorithms to per-
bodyText ||| form well due to data sparsity and the low level of
bodyText ||| image features. We investigate how to utilize the
bodyText ||| readily available socially annotated image data on
bodyText ||| the Web to improve image clustering. Although
bodyText ||| these auxiliary data may be irrelevant to the im-
bodyText ||| ages to be clustered and cannot be directly used
bodyText ||| to solve the data sparsity problem, we show that
bodyText ||| they can still be used to estimate a good latentfea-
bodyText ||| ture representation, which can be used to improve
bodyText ||| image clustering.
sectionHeader ||| 2 Related Works
subsectionHeader ||| 2.1 Heterogeneous Transfer Learning
subsectionHeader ||| Between Languages
bodyText ||| In this section, we summarize our previous work
bodyText ||| on cross-language classification as an example of
bodyText ||| heterogeneous transfer learning. This example
bodyText ||| is related to our image clustering problem be-
bodyText ||| cause they both rely on data from different feature
bodyText ||| spaces.
bodyText ||| As the World Wide Web in China grows rapidly,
bodyText ||| it has become an increasingly important prob-
bodyText ||| lem to be able to accurately classify Chinese Web
bodyText ||| pages. However, because the labeled Chinese Web
bodyText ||| pages are still not sufficient, we often find it diffi-
bodyText ||| cult to achieve high accuracy by applying tradi-
bodyText ||| tional machine learning algorithms to the Chinese
bodyText ||| Web pages directly. Would it be possible to make
bodyText ||| the best use of the relatively abundant labeled En-
bodyText ||| glish Web pages for classifying the Chinese Web
bodyText ||| pages?
bodyText ||| To answer this question, in (Ling et al., 2008),
bodyText ||| we developed a novel approach for classifying the
bodyText ||| Web pages in Chinese using the training docu-
bodyText ||| ments in English. In this subsection, we give a
bodyText ||| brief summary of this work. The problem to be
bodyText ||| solved is: we are given a collection of labeled
bodyText ||| English documents and a large number of unla-
bodyText ||| beled Chinese documents. The English and Chi-
bodyText ||| nese texts are not aligned. Our objective is to clas-
bodyText ||| sify the Chinese documents into the same label
bodyText ||| space as the English data.
bodyText ||| Our key observation is that even though the data
bodyText ||| use different text features, they may still share
bodyText ||| many of the same semantic information. What we
bodyText ||| need to do is to uncover this latent semantic in-
bodyText ||| formation by finding out what is common among
bodyText ||| them. We did this in (Ling et al., 2008) by us-
bodyText ||| ing the information bottleneck theory (Tishby et
bodyText ||| al., 1999). In our work, we first translated the
bodyText ||| Chinese document into English automatically us-
bodyText ||| ing some available translation software, such as
bodyText ||| Google translate. Then, we encoded the training
bodyText ||| text as well as the translated target text together,
bodyText ||| in terms of the information theory. We allowed all
bodyText ||| the information to be put through a ‘bottleneck’
bodyText ||| and be represented by a limited number of code-
page ||| 2
figureCaption ||| Figure 1: An intuitive illustration of different kinds learning strategies using classification/clustering of
bodyText ||| image apple and banana as the example.
bodyText ||| words (i.e. labels in the classification problem).
bodyText ||| Finally, information bottleneck was used to main-
bodyText ||| tain most of the common information between the
bodyText ||| two data sources, and discard the remaining irrel-
bodyText ||| evant information. In this way, we can approxi-
bodyText ||| mate the ideal situation where similar training and
bodyText ||| translated test pages shared in the common part are
bodyText ||| encoded into the same codewords, and are thus as-
bodyText ||| signed the correct labels. In (Ling et al., 2008), we
bodyText ||| experimentally showed that heterogeneous trans-
bodyText ||| fer learning can indeed improve the performance
bodyText ||| of cross-language text classification as compared
bodyText ||| to directly training learning models (e.g., Naive
bodyText ||| Bayes or SVM) and testing on the translated texts.
subsectionHeader ||| 2.2 Other Works in Transfer Learning
bodyText ||| In the past, several other works made use of trans-
bodyText ||| fer learning for cross-feature-space learning. Wu
bodyText ||| and Oard (2008) proposed to handle the cross-
bodyText ||| language learning problem by translating the data
bodyText ||| into a same language and applying kNN on the
bodyText ||| latent topic space for classification. Most learning
bodyText ||| algorithms for dealing with cross-language hetero-
bodyText ||| geneous data require a translator to convert the
bodyText ||| data to the same feature space. For those data that
bodyText ||| are in different feature spaces where no transla-
bodyText ||| tor is available, Davis and Domingos (2008) pro-
bodyText ||| posed a Markov-logic-based transfer learning al-
bodyText ||| gorithm, which is called deep transfer, for trans-
bodyText ||| ferring knowledge between biological domains
bodyText ||| and Web domains. Dai et al. (2008a) proposed
bodyText ||| a novel learning paradigm, known as translated
bodyText ||| learning, to deal with the problem of learning het-
bodyText ||| erogeneous data that belong to quite different fea-
bodyText ||| ture spaces by using a risk minimization frame-
bodyText ||| work.
subsectionHeader ||| 2.3 Relation to PLSA
bodyText ||| Our work makes use of PLSA. Probabilistic la-
bodyText ||| tent semantic analysis (PLSA) is a widely used
bodyText ||| probabilistic model (Hofmann, 1999), and could
bodyText ||| be considered as a probabilistic implementation of
bodyText ||| latent semantic analysis (LSA) (Deerwester et al.,
bodyText ||| 1990). An extension to PLSA was proposed in
bodyText ||| (Cohn and Hofmann, 2000), which incorporated
bodyText ||| the hyperlink connectivity in the PLSA model by
bodyText ||| using a joint probabilistic model for connectivity
bodyText ||| and content. Moreover, PLSA has shown a lot
bodyText ||| of applications ranging from text clustering (Hof-
bodyText ||| mann, 2001) to image analysis (Sivic et al., 2005).
subsectionHeader ||| 2.4 Relation to Clustering
bodyText ||| Compared to many previous works on image clus-
bodyText ||| tering, we note that traditional image cluster-
bodyText ||| ing is generally based on techniques such as K-
bodyText ||| means (MacQueen, 1967) and hierarchical clus-
bodyText ||| tering (Kaufman and Rousseeuw, 1990). How-
bodyText ||| ever, when the data are sparse, traditional clus-
bodyText ||| tering algorithms may have difficulties in obtain-
bodyText ||| ing high-quality image clusters. Recently, several
bodyText ||| researchers have investigated how to leverage the
bodyText ||| auxiliary information to improve target clustering
page ||| 3
equation ||| P(zIv)	P(fIz)
bodyText ||| performance, such as supervised clustering (Fin-
bodyText ||| ley and Joachims, 2005), semi-supervised cluster-
bodyText ||| ing (Basu et al., 2004), self-taught clustering (Dai
bodyText ||| et al., 2008b), etc.
sectionHeader ||| 3 Image Clustering with Annotated
sectionHeader ||| Auxiliary Data
bodyText ||| In this section, we present our annotation-based
bodyText ||| probabilistic latent semantic analysis algorithm
bodyText ||| (aPLSA), which extends the traditional PLSA
bodyText ||| model by incorporating annotated auxiliary im-
bodyText ||| age data. Intuitively, our algorithm aPLSA per-
bodyText ||| forms PLSA analysis on the target images, which
bodyText ||| are converted to an image instance-to-feature co-
bodyText ||| occurrence matrix. At the same time, PLSA is
bodyText ||| also applied to the annotated image data from so-
bodyText ||| cial Web, which is converted into a text-to-image-
bodyText ||| feature co-occurrence matrix. In order to unify
bodyText ||| those two separate PLSA models, these two steps
bodyText ||| are done simultaneously with common latent vari-
bodyText ||| ables used as a bridge linking them. Through
bodyText ||| these common latent variables, which are now
bodyText ||| constrained by both target image data and auxil-
bodyText ||| iary annotation data, a better clustering result is
bodyText ||| expected for the target data.
subsectionHeader ||| 3.1 Probabilistic Latent Semantic Analysis
bodyText ||| Let F = { fi}!Fi be an image feature space, and
bodyText ||| V = {vi}iv11 be the image data set. Each image
bodyText ||| vi E V is represented by a bag-of-features {f I f E
bodyText ||| vi A f E F}.
bodyText ||| Based on the image data set V, we can esti-
bodyText ||| mate an image instance-to-feature co-occurrence
bodyText ||| matrix AIVI x I FI E RIVIx IFI, where each element
bodyText ||| AiT (1 G i G IV I and 1 G j G IF I) in the matrix
bodyText ||| A is the frequency of the feature fT appearing in
bodyText ||| the instance vi.
bodyText ||| Let W = {wi } I WI i��be a text feature space. The
bodyText ||| annotated image data allow us to obtain the co-
bodyText ||| occurrence information between images v and text
bodyText ||| features w E W. An example of annotated im-
bodyText ||| age data is the Flickr (http : / /www. f l ickr .
bodyText ||| com), which is a social Web site containing a large
bodyText ||| number of annotated images.
bodyText ||| By extracting image features from the annotated
bodyText ||| images v, we can estimate a text-to-image fea-
bodyText ||| ture co-occurrence matrix B I WIxIFI E RIW IxIFI,
bodyText ||| where each element BiT (1 G i G I W I and
bodyText ||| 1 G j G IFI) in the matrix B is the frequency
bodyText ||| of the text feature wi and the image feature fT oc-
bodyText ||| curring together in the annotated image data set.
bodyText ||| Figure 2: Graphical model representation of PLSA
bodyText ||| model.
bodyText ||| Let Z = {ziffl be the latent variable set in our
bodyText ||| aPLSA model. In clustering, each latent variable
bodyText ||| zi E Z corresponds to a certain cluster.
bodyText ||| Our objective is to estimate a clustering func-
bodyText ||| tion g : V H Z with the help of the two co-
bodyText ||| occurrence matrices A and B as defined above.
bodyText ||| To formally introduce the aPLSA model, we
bodyText ||| start from the probabilistic latent semantic anal-
bodyText ||| ysis (PLSA) (Hofmann, 1999) model. PLSA is
bodyText ||| a probabilistic implementation of latent seman-
bodyText ||| tic analysis (LSA) (Deerwester et al., 1990). In
bodyText ||| our image clustering task, PLSA decomposes the
bodyText ||| instance-feature co-occurrence matrix A under the
bodyText ||| assumption of conditional independence of image
bodyText ||| instances V and image features F, given the latent
bodyText ||| variables Z.
equation ||| P(f Iv) = 1: P(f I z)P(zI v).	(1)
equation ||| ZEZ
bodyText ||| The graphical model representation of PLSA is
bodyText ||| shown in Figure 2.
bodyText ||| Based on the PLSA model, the log-likelihood can
bodyText ||| be defined as:
equation ||| 1: L =
equation ||| i 1:AiT
equation ||| T ET, AiT, log P(fT I vi)	(2)
bodyText ||| where AIVI x IFI E RIVI xIFI is the image instance-
bodyText ||| feature co-occurrence matrix. The term : A�j
bodyText ||| j, Azj/
bodyText ||| in Equation (2) is a normalization term ensuring
bodyText ||| each image is giving the same weight in the log-
bodyText ||| likelihood.
bodyText ||| Using EM algorithm (Dempster et al., 1977),
bodyText ||| which locally maximizes the log-likelihood of
bodyText ||| the PLSA model (Equation (2)), the probabilities
bodyText ||| P(f I z) and P(zI v) can be estimated. Then, the
bodyText ||| clustering function is derived as
equation ||| g(v) = argmax P(zIv).	(3)
equation ||| ZEZ
bodyText ||| Due to space limitation, we omit the details for the
bodyText ||| PLSA model, which can be found in (Hofmann,
bodyText ||| 1999).
subsectionHeader ||| 3.2 aPLSA: Annotation-based PLSA
bodyText ||| In this section, we consider how to incorporate
bodyText ||| a large number of socially annotated images in a
equation ||| V	Z	F
page ||| 4
figureCaption ||| Figure 3: Graphical model representation of
figureCaption ||| aPLSA model.
bodyText ||| unified PLSA model for the purpose of utilizing
bodyText ||| the correlation between text features and image
bodyText ||| features. In the auxiliary data, each image has cer-
bodyText ||| tain textual tags that are attached by users. The
bodyText ||| correlation between text features and image fea-
bodyText ||| tures can be formulated as follows.
equation ||| P(f Iw) = X P(f I z)P(zI w). (4)
equation ||| ZEZ
bodyText ||| It is clear that Equations (1) and (4) share a same
bodyText ||| term P(f I z). So we design a new PLSA model by
bodyText ||| joining the probabilistic model in Equation (1) and
bodyText ||| the probabilistic model in Equation (4) into a uni-
bodyText ||| fied model, as shown in Figure 3. In Figure 3, the
bodyText ||| latent variables Z depend not only on the corre-
bodyText ||| lation between image instances V and image fea-
bodyText ||| tures F, but also the correlation between text fea-
bodyText ||| tures W and image features F. Therefore, the aux-
bodyText ||| iliary socially-annotated image data can be used
bodyText ||| to help the target image clustering performance by
bodyText ||| estimating good set of latent variables Z.
bodyText ||| Based on the graphical model representation in
bodyText ||| Figure 3, we derive the log-likelihood objective
bodyText ||| function, in a similar way as in (Cohn and Hof-
bodyText ||| mann, 2000), as follows
bodyText ||| text-to-image occurrence matrix B. In this case,
bodyText ||| the aPLSA model degenerates to the traditional
bodyText ||| PLSA model. Therefore, aPLSA is an extension
bodyText ||| to the PLSA model.
bodyText ||| Now, the objective is to maximize the log-
bodyText ||| likelihood L of the aPLSA model in Equation (5).
bodyText ||| Then we apply the EM algorithm (Dempster et
bodyText ||| al., 1977) to estimate the conditional probabilities
bodyText ||| P(f I z), P(zI w) and P(zI v) with respect to each
bodyText ||| dependence in Figure 3 as follows.
listItem ||| •	E-Step: calculate the posterior probability of
listItem ||| each latent variable z given the observation
listItem ||| of image features f, image instances v and
listItem ||| text features w based on the old estimate of
equation ||| P(f I z), P(zI w) and P(zI v):
equation ||| PIvi,fj) =	P(fjIzk)P(zkIvi)
equation ||| (zk
equation ||| P(zkI wl, fj) =	P(fjIzk)P(zkIwl)
equation ||| Pk, P(fjIzk,)P(zk,Iwl)
equation ||| (7)
listItem ||| •	M-Step: re-estimates conditional probabili-
listItem ||| ties P(zkIvi) and P(zkI wl):
equation ||| PAAP(zkIvi,fj) (8)
equation ||| PBlBlj, P(zk I wl , fj) (9)
bodyText ||| and conditional probability P(fj I zk ), which
bodyText ||| is a mixture portion of posterior probability
bodyText ||| of latent variables
equation ||| W
equation ||| V
equation ||| Z	F
equation ||| P(fIz)
equation ||| P
equation ||| k, P(fj Izk,)P(zk, I vi)
equation ||| (6)
equation ||| XP(zkIvi) =
equation ||| j
equation ||| XP(zkIwl) =
equation ||| j
equation ||| P(fjIzk) a AX
equation ||| i
equation ||| L=X
equation ||| j
equation ||| P
equation ||| j, Blj,
equation ||| X
equation ||| +(1 — A)
equation ||| l
equation ||| +(1—A)X
equation ||| l
equation ||| Aij  P( zkI vi, fj)
equation ||| Pj,Aij,
equation ||| Blj P(zkIwl,fj)
equation ||| (10)
equation ||| �
equation ||| XAij
equation ||| A i Pj, Aij, log P(fj I vi)
equation ||| �
equation ||| Blj	log P(fj I wl )
equation ||| Pj, Blj,
equation ||| (5)
bodyText ||| where AIVIxIFI E RIVIxIFI is the image instance-
bodyText ||| feature co-occurrence matrix, and BIW I xIFI E
bodyText ||| RIWIxIFI is the text-to-image feature-level co-
bodyText ||| occurrence matrix. Similar to Equation (2),
bodyText ||| PAij and PB`j in Equation (5) are the nor-
bodyText ||| ij,
bodyText ||| malization terms to prevent imbalanced cases.
bodyText ||| Furthermore, A acts as a trade-off parameter be-
bodyText ||| tween the co-occurrence matrices A and B. In
bodyText ||| the extreme case when A = 1, the log-likelihood
bodyText ||| objective function ignores all the biases from the
bodyText ||| Finally, the clustering function for a certain im-
bodyText ||| age v is
equation ||| g(v) = argmax P(zIv).	(11)
equation ||| ZEZ
bodyText ||| From the above equations, we can derive
bodyText ||| our annotation-based probabilistic latent semantic
bodyText ||| analysis (aPLSA) algorithm. As shown in Algo-
bodyText ||| rithm 1, aPLSA iteratively performs the E-Step
bodyText ||| and the M-Step in order to seek local optimal
bodyText ||| points based on the objective function L in Equa-
bodyText ||| tion (5).
page ||| 5
construct ||| Algorithm 1 Annotation-based PLSA Algorithm
construct ||| (aPLSA)
construct ||| Input: The V-F co-occurrence matrix A and W-
construct ||| F co-occurrence matrix B.
construct ||| Output: A clustering (partition) function g : V H
construct ||| i, which maps an image instance v E V to a latent
construct ||| variable z E i.
listItem ||| 1: Initial i so that IiI equals the number clus-
listItem ||| ters desired.
listItem ||| 2: Initialize P(zIv), P(zIw), P(f Iz) randomly.
listItem ||| 3: while the change of L in Eq. (5) between two
listItem ||| sequential iterations is greater than a prede-
listItem ||| fined threshold do
listItem ||| 4: E-Step: Update P(zIv, f) and P(zIw, f)
listItem ||| based on Eq. (6) and (7) respectively.
listItem ||| 5: M-Step: Update P(zIv), P(zIw) and
listItem ||| P(f Iz) based on Eq. (8), (9) and (10) re-
listItem ||| spectively.
listItem ||| 6: end while
listItem ||| 7: for all v in V do
listItem ||| 8:	g(v) +— argmaxP(zIv).
listItem ||| 9: end for
listItem ||| 10: Return g.
sectionHeader ||| 4 Experiments
bodyText ||| In this section, we empirically evaluate the aPLSA
bodyText ||| algorithm together with some state-of-art base-
bodyText ||| line methods on two widely used image corpora,
bodyText ||| to demonstrate the effectiveness of our algorithm
bodyText ||| aPLSA.
subsectionHeader ||| 4.1 Data Sets
bodyText ||| In order to evaluate the effectiveness of our algo-
bodyText ||| rithm aPLSA, we conducted experiments on sev-
bodyText ||| eral data sets generated from two image corpora,
bodyText ||| Caltech-256 (Griffin et al., 2007) and the fifteen-
bodyText ||| scene (Lazebnik et al., 2006). The Caltech-256
bodyText ||| data set has 256 image objective categories, rang-
bodyText ||| ing from animals to buildings, from plants to au-
bodyText ||| tomobiles, etc. The fifteen-scene data set con-
bodyText ||| tains 15 scenes such as store and forest.
bodyText ||| From these two corpora, we randomly generated
bodyText ||| eleven image clustering tasks, including seven 2-
bodyText ||| way clustering tasks, two 4-way clustering task,
bodyText ||| one 5-way clustering task and one 8-way cluster-
bodyText ||| ing task. The detailed descriptions for these clus-
bodyText ||| tering tasks are given in Table 1. In these tasks,
bodyText ||| b i 7 and o c t 1 were generated from fifteen-scene
bodyText ||| data set, and the rest were from Caltech-256 data
bodyText ||| set.
table ||| DATA SET INVOLVED CLASSES	DATA SIZE
table ||| bi1	skateboard, airplanes	102,800
table ||| bi2	billiards, mars	278, 155
table ||| bi3	cd, greyhound	102,	94
table ||| bi4	electric-guitar, snake	122,112
table ||| bi5	calculator, dolphin	100,106
table ||| bi6	mushroom, teddy-bear	202,	99
table ||| bi7	MIThighway, livingroom	260,289
table ||| quad1	calculator,	diamond-ring,	dolphin,	100, 118, 106,116
table ||| 	microscope
table ||| quad2	bonsai, comet, frog, saddle	122, 120, 115, 110
table ||| quint1	frog, kayak, bear, jesus-christ,watch115,102,101,87,	201
table ||| oct1	MIThighway,	MITmountain,	260, 374, 210, 360,
table ||| 	kitchen, MITcoast, PARoffice, MIT- tallbuilding, livingroom, bedroom	215, 356, 289, 216
table ||| tune1	coin, horse	123,270
table ||| tune2	socks, spider	111,106
table ||| tune3	galaxy, snowmobile	80,112
table ||| tune4	dice, fern	98,110
table ||| tune5	backpack, lightning, mandolin, swan	151, 136,	93,114
tableCaption ||| Table 1: The descriptions of all the image clus-
tableCaption ||| tering tasks used in our experiment. Among
tableCaption ||| these data sets, b i 7 and o c t 1 were generated
tableCaption ||| from fifteen-scene data set, and the rest were from
tableCaption ||| Caltech-256 data set.
bodyText ||| To empirically investigate the parameter A and
bodyText ||| the convergence of our algorithm aPLSA, we gen-
bodyText ||| erated five more date sets as the development sets.
bodyText ||| The detailed description of these five development
bodyText ||| sets, namely tune1 to tune5 is listed in Table 1
bodyText ||| as well.
bodyText ||| The auxiliary data were crawled from the Flickr
bodyText ||| (http://www.flickr.com/) web site dur-
bodyText ||| ing August 2007. Flickr is an internet community
bodyText ||| where people share photos online and express their
bodyText ||| opinions as social tags (annotations) attached to
bodyText ||| each image. From Flicker, we collected 19,959
bodyText ||| images and 91,719 related annotations, among
bodyText ||| which 2,600 words are distinct. Based on the
bodyText ||| method described in Section 3, we estimated the
bodyText ||| co-occurrence matrix B between text features and
bodyText ||| image features. This co-occurrence matrix B was
bodyText ||| used by all the clustering tasks in our experiments.
bodyText ||| For data preprocessing, we adopted the bag-of-
bodyText ||| features representation of images (Li and Perona,
bodyText ||| 2005) in our experiments. Interesting points were
bodyText ||| found in the images and described via the SIFT
bodyText ||| descriptors (Lowe, 2004). Then, the interesting
bodyText ||| points were clustered to generate a codebook to
bodyText ||| form an image feature space. The size of code-
bodyText ||| book was set to 2, 000 in our experiments. Based
bodyText ||| on the codebook, which serves as the image fea-
bodyText ||| ture space, each image can be represented as a cor-
bodyText ||| responding feature vector to be used in the next
bodyText ||| step.
bodyText ||| To set our evaluation criterion, we used the
page ||| 6
table ||| Data Set	KMeancombined		PLSA		STC	aPLSA
table ||| 	separate		separate	combined
table ||| bi1	0.645±0.064	0.548±0.031	0.544±0.074	0.537±0.033	0.586±0.139	0.482±0.062
table ||| bi2	0.687±0.003	0.662±0.014	0.464±0.074	0.692±0.001	0.577±0.016	0.455±0.096
table ||| bi3	1.294±0.060	1.300±0.015	1.085±0.073	1.126±0.036	1.103±0.108	1.029±0.074
table ||| bi4	1.227±0.080	1.164±0.053	0.976±0.051	1.038±0.068	1.024±0.089	0.919±0.065
table ||| bi5	1.450±0.058	1.417±0.045	1.426±0.025	1.405±0.040	1.411±0.043	1.377±0.040
table ||| bi6	1.969±0.078	1.852±0.051	1.514±0.039	1.709±0.028	1.589±0.121	1.503±0.030
table ||| bi7	0.686±0.006	0.683±0.004	0.643±0.058	0.632±0.037	0.651±0.012	0.624±0.066
table ||| quad1	0.591±0.094	0.675±0.017	0.488±0.071	0.662±0.013	0.580±0.115	0.432±0.085
table ||| quad2	0.648±0.036	0.646±0.045	0.614±0.062	0.626±0.026	0.591±0.087	0.515±0.098
table ||| quint1	0.557±0.021	0.508±0.104	0.547±0.060	0.539±0.051	0.538±0.100	0.502±0.067
table ||| oct1	0.659±0.031	0.680±0.012	0.340±0.147	0.691±0.002	0.411±0.089	0.306±0.101
table ||| average	0.947±0.029	0.922±0.017	0.786±0.009	0.878±0.006	0.824±0.036	0.741±0.018
tableCaption ||| Table 2: Experimental result in term of entropy for all data sets and evaluation methods.
bodyText ||| entropy to measure the quality of our clustering
bodyText ||| results. In information theory, entropy (Shan-
bodyText ||| non, 1948) is a measure of the uncertainty as-
bodyText ||| sociated with a random variable. In our prob-
bodyText ||| lem, entropy serves as a measure of randomness
bodyText ||| of clustering result. The entropy of g on a sin-
bodyText ||| gle latent variable z is defined to be H(g, z)
bodyText ||| - PcEC P(c�z)lo�2 P(cIz), where C is the class
bodyText ||| label set of V and P(clz) = ��v�s(v)=zAt(v)=c}�
bodyText ||| 11v1s(v)=z}1 ,
bodyText ||| in which t(v) is the true class label of image v.
bodyText ||| Lower entropy H(g, i) indicates less randomness
bodyText ||| and thus better clustering result.
subsectionHeader ||| 4.2 Empirical Analysis
bodyText ||| We now empirically analyze the effectiveness of
bodyText ||| our aPLSA algorithm. Because, to our best of
bodyText ||| knowledge, few existing methods addressed the
bodyText ||| problem of image clustering with the help of so-
bodyText ||| cial annotation image data, we can only compare
bodyText ||| our aPLSA with several state-of-the-art cluster-
bodyText ||| ing algorithms that are not directly designed for
bodyText ||| our problem. The first baseline is the well-known
bodyText ||| KMeans algorithm (MacQueen, 1967). Since our
bodyText ||| algorithm is designed based on PLSA (Hofmann,
bodyText ||| 1999), we also included PLSA for clustering as a
bodyText ||| baseline method in our experiments.
bodyText ||| For each of the above two baselines, we have
bodyText ||| two strategies: (1) separated: the baseline
bodyText ||| method was applied on the target image data only;
bodyText ||| (2) combined: the baseline method was applied
bodyText ||| to cluster the combined data consisting of both
bodyText ||| target image data and the annotated image data.
bodyText ||| Clustering results on target image data were used
bodyText ||| for evaluation. Note that, in the combined data, all
bodyText ||| the annotations were thrown away since baseline
bodyText ||| methods evaluated in this paper do not leverage
bodyText ||| annotation information.
bodyText ||| In addition, we compared our algorithm aPLSA
bodyText ||| to a state-of-the-art transfer clustering strategy,
bodyText ||| known as self-taught clustering (STC) (Dai et al.,
bodyText ||| 2008b). STC makes use of auxiliary data to esti-
bodyText ||| mate a better feature representation to benefit the
bodyText ||| target clustering. In these experiments, the anno-
bodyText ||| tated image data were used as auxiliary data in
bodyText ||| STC, which does not use the annotation text.
bodyText ||| In our experiments, the performance is in the
bodyText ||| form of the average entropy and variance of five
bodyText ||| repeats by randomly selecting 50 images from
bodyText ||| each of the categories. We selected only 50 im-
bodyText ||| ages per category, since this paper is focused on
bodyText ||| clustering sparse data. Table 2 shows the perfor-
bodyText ||| mance with respect to all comparison methods on
bodyText ||| each of the image clustering tasks measured by
bodyText ||| the entropy criterion. From the tables, we can see
bodyText ||| that our algorithm aPLSA outperforms the base-
bodyText ||| line methods in all the data sets. We believe that is
bodyText ||| because aPLSA can effectively utilize the knowl-
bodyText ||| edge from the socially annotated image data. On
bodyText ||| average, aPLSA gives rise to 21.8% of entropy re-
bodyText ||| duction and as compared to KMeans, 5.7% of en-
bodyText ||| tropy reduction as compared to PLSA, and 10.1%
bodyText ||| of entropy reduction as compared to S TC.
subsectionHeader ||| 4.2.1 Varying Data Size
bodyText ||| We now show how the data size affects aPLSA,
bodyText ||| with two baseline methods KMeans and PLSA as
bodyText ||| reference. The experiments were conducted on
bodyText ||| different amounts of target image data, varying
bodyText ||| from 10 to 80. The corresponding experimental
bodyText ||| results in average entropy over all the 11 clustering
bodyText ||| tasks are shown in Figure 4(a). From this figure,
bodyText ||| we observe that aPLSA always yields a significant
bodyText ||| reduction in entropy as compared with two base-
bodyText ||| line methods KMeans and PLSA, regardless of the
bodyText ||| size of target image data that we used.
page ||| 7
figure ||| 1
figure ||| 0.95
figure ||| 0.9
figure ||| 0.85
figure ||| 0.8
figure ||| 0.75
figure ||| 0.7
figure ||| 10	20	30	40	50	60	70	80
figure ||| KMeans
figure ||| PLSA
figure ||| aPLSA
figure ||| 0.75
figure ||| 0.65
figure ||| 0.6
figure ||| 0.55
figure ||| 0.45
figure ||| 0.7
figure ||| 0.5
figure ||| 0.4
figure ||| 0	0.2	0.4	0.6	0.8	1
figure ||| average over 5 development sets
figure ||| 0.75
figure ||| 0.65
figure ||| 0.55
figure ||| 0.7
figure ||| 0.6
figure ||| 0.5
figure ||| 0	50	100	150	200	250 300
figure ||| average over 5 development sets
figure ||| Data size per category		Number of Iteration
figure ||| (a)	(b)	(c)
figureCaption ||| Figure 4: (a) The entropy curve as a function of different amounts of data per category. (b) The entropy
figureCaption ||| curve as a function of different number of iterations. (c) The entropy curve as a function of different
figureCaption ||| trade-off parameter A.
subsubsectionHeader ||| 4.2.2 Parameter Sensitivity
bodyText ||| In aPLSA, there is a trade-off parameter A that af-
bodyText ||| fects how the algorithm relies on auxiliary data.
bodyText ||| When A = 0, the aPLSA relies only on annotated
bodyText ||| image data B. When A = 1, aPLSA relies only
bodyText ||| on target image data A, in which case aPLSA de-
bodyText ||| generates to PLSA. Smaller A indicates heavier re-
bodyText ||| liance on the annotated image data. We have done
bodyText ||| some experiments on the development sets to in-
bodyText ||| vestigate how different A affect the performance
bodyText ||| of aPLSA. We set the number of images per cate-
bodyText ||| gory to 50, and tested the performance of aPLSA.
bodyText ||| The result in average entropy over all development
bodyText ||| sets is shown in Figure 4(b). In the experiments
bodyText ||| described in this paper, we set A to 0.2, which is
bodyText ||| the best point in Figure 4(b).
subsectionHeader ||| 4.2.3 Convergence
bodyText ||| In our experiments, we tested the convergence
bodyText ||| property of our algorithm aPLSA as well. Fig-
bodyText ||| ure 4(c) shows the average entropy curve given
bodyText ||| by aPLSA over all development sets. From this
bodyText ||| figure, we see that the entropy decreases very fast
bodyText ||| during the first 100 iterations and becomes stable
bodyText ||| after 150 iterations. We believe that 200 iterations
bodyText ||| is sufficient for aPLSA to converge.
sectionHeader ||| 5 Conclusions
bodyText ||| In this paper, we proposed a new learning scenario
bodyText ||| called heterogeneous transfer learning and illus-
bodyText ||| trated its application to image clustering. Image
bodyText ||| clustering, a vital component in organizing search
bodyText ||| results for query-based image search, was shown
bodyText ||| to be improved by transferring knowledge from
bodyText ||| unrelated images with annotations in a social Web.
bodyText ||| This is done by first learning the high-quality la-
bodyText ||| tent variables in the auxiliary data, and then trans-
bodyText ||| ferring this knowledge to help improve the cluster-
bodyText ||| ing of the target image data. We conducted experi-
bodyText ||| ments on two image data sets, using the Flickr data
bodyText ||| as the annotated auxiliary image data, and showed
bodyText ||| that our aPLSA algorithm can greatly outperform
bodyText ||| several state-of-the-art clustering algorithms.
bodyText ||| In natural language processing, there are many
bodyText ||| future opportunities to apply heterogeneous trans-
bodyText ||| fer learning. In (Ling et al., 2008) we have shown
bodyText ||| how to classify the Chinese text using English text
bodyText ||| as the training data. We may also consider cluster-
bodyText ||| ing, topic modeling, question answering, etc., to
bodyText ||| be done using data in different feature spaces. We
bodyText ||| can consider data in different modalities, such as
bodyText ||| video, image and audio, as the training data. Fi-
bodyText ||| nally, we will explore the theoretical foundations
bodyText ||| and limitations of heterogeneous transfer learning
bodyText ||| as well.
sectionHeader ||| Acknowledgement Qiang Yang thanks Hong
bodyText ||| Kong CERG grant 621307 for supporting the re-
bodyText ||| search.
sectionHeader ||| References
reference ||| Alina Andreevskaia and Sabine Bergler. 2008. When spe-
reference ||| cialists and generalists work together: Overcoming do-
reference ||| main dependence in sentiment tagging. In ACL-08: HLT,
reference ||| pages 290–298, Columbus, Ohio, June.
reference ||| Andrew Arnold, Ramesh Nallapati, and William W. Cohen.
reference ||| 2007. A comparative study of methods for transductive
reference ||| transfer learning. In ICDM 2007 Workshop on Mining
reference ||| and Management of Biological Data, pages 77-82.
reference ||| Andrew Arnold, Ramesh Nallapati, and William W. Cohen.
reference ||| 2008. Exploiting feature hierarchy for transfer learning in
reference ||| named entity recognition. In ACL-08: HLT.
reference ||| Sugato Basu, Mikhail Bilenko, and Raymond J. Mooney.
reference ||| 2004. A probabilistic framework for semi-supervised
reference ||| clustering. In ACM SIGKDD 2004, pages 59–68.
reference ||| John Blitzer, Ryan Mcdonald, and Fernando Pereira. 2006.
reference ||| Domain adaptation with structural correspondence learn-
reference ||| ing. In EMNLP 2006, pages 120–128, Sydney, Australia.
page ||| 8
reference ||| John Blitzer, Mark Dredze, and Fernando Pereira. 2007.
reference ||| Biographies, bollywood, boom-boxes and blenders: Do-
reference ||| main adaptation for sentiment classification. In ACL 2007,
reference ||| pages 440–447, Prague, Czech Republic.
reference ||| Avrim Blum and Tom Mitchell. 1998. Combining labeled
reference ||| and unlabeled data with co-training. In COLT 1998, pages
reference ||| 92–100, New York, NY, USA. ACM.
reference ||| Rich Caruana. 1997. Multitask learning. Machine Learning,
reference ||| 28(1):41–75.
reference ||| Yee Seng Chan and Hwee Tou Ng. 2007. Domain adaptation
reference ||| with active learning for word sense disambiguation. In
reference ||| ACL 2007, Prague, Czech Republic.
reference ||| David A. Cohn and Thomas Hofmann. 2000. The missing
reference ||| link - a probabilistic model of document content and hy-
reference ||| pertext connectivity. In NIPS 2000, pages 430–436.
reference ||| Wenyuan Dai, Yuqiang Chen, Gui-Rong Xue, Qiang Yang,
reference ||| and Yong Yu. 2008a. Translated learning: Transfer learn-
reference ||| ing across different feature spaces. In NIPS 2008, pages
reference ||| 353–360.
reference ||| Wenyuan Dai, Qiang Yang, Gui-Rong Xue, and Yong Yu.
reference ||| 2008b. Self-taught clustering. In ICML 2008, pages 200–
reference ||| 207. Omnipress.
reference ||| Hal Daume,III. 2007. Frustratingly easy domain adaptation.
reference ||| In ACL 2007, pages 256–263, Prague, Czech Republic.
reference ||| Jesse Davis and Pedro Domingos. 2008. Deep transfer via
reference ||| second-order markov logic. In AAAI 2008 Workshop on
reference ||| Transfer Learning, Chicago, USA.
reference ||| Scott Deerwester, Susan T. Dumais, George W. Furnas,
reference ||| Thomas K. L, and Richard Harshman. 1990. Indexing by
reference ||| latent semantic analysis. Journal of the American Society
reference ||| for Information Science, pages 391–407.
reference ||| A. P. Dempster, N. M. Laird, and D. B. Rubin. 1977. Max-
reference ||| imum likelihood from incomplete data via the em algo-
reference ||| rithm. J. of the Royal Statistical Society, 39:1–38.
reference ||| Thomas Finley and Thorsten Joachims. 2005. Supervised
reference ||| clustering with support vector machines. In ICML 2005,
reference ||| pages 217–224, New York, NY, USA. ACM.
reference ||| G. Griffin, A. Holub, and P. Perona. 2007. Caltech-256 ob-
reference ||| ject category dataset. Technical Report 7694, California
reference ||| Institute of Technology.
reference ||| Thomas Hofmann. 1999 Probabilistic latent semantic anal-
reference ||| ysis. In Proc. of Uncertainty in Artificial Intelligence,
reference ||| UAI99. Pages 289–296
reference ||| Thomas Hofmann. 2001. Unsupervised learning by proba-
reference ||| bilistic latent semantic analysis. Machine Learning. vol-
reference ||| ume 42, number 1-2, pages 177–196. Kluwer Academic
reference ||| Publishers.
reference ||| Jing Jiang and Chengxiang Zhai. 2007. Instance weighting
reference ||| for domain adaptation in NLP. In ACL 2007, pages 264–
reference ||| 271, Prague, Czech Republic, June.
reference ||| Leonard Kaufman and Peter J. Rousseeuw. 1990. Finding
reference ||| groups in data: an introduction to cluster analysis. John
reference ||| Wiley and Sons, New York.
reference ||| Svetlana Lazebnik, Cordelia Schmid, and Jean Ponce. 2006.
reference ||| Beyond bags of features: Spatial pyramid matching for
reference ||| recognizing natural scene categories. In CVPR 2006,
reference ||| pages 2169–2178, Washington, DC, USA.
reference ||| Fei-Fei Li and Pietro Perona. 2005. A bayesian hierarchi-
reference ||| cal model for learning natural scene categories. In CVPR
reference ||| 2005, pages 524–531, Washington, DC, USA.
reference ||| Xiao Ling, Gui-Rong Xue, Wenyuan Dai, Yun Jiang, Qiang
reference ||| Yang, and Yong Yu. 2008. Can chinese web pages be
reference ||| classified with english data source? In WWW 2008, pages
reference ||| 969–978, New York, NY, USA. ACM.
reference ||| Nicolas Loeff, Cecilia Ovesdotter Alm, and David A.
reference ||| Forsyth. 2006. Discriminating image senses by clustering
reference ||| with multimodal features. In COLING/ACL 2006 Main
reference ||| conference poster sessions, pages 547–554.
reference ||| David G. Lowe. 2004. Distinctive image features from scale-
reference ||| invariant keypoints. International Journal of Computer
reference ||| Vision (IJCV) 2004, volume 60, number 2, pages 91–110.
reference ||| J. B. MacQueen. 1967. Some methods for classification and
reference ||| analysis of multivariate observations. In Proceedings of
reference ||| Fifth Berkeley Symposium on Mathematical Statistics and
reference ||| Probability, pages 1:281–297, Berkeley, CA, USA.
reference ||| Kamal Nigam and Rayid Ghani. 2000. Analyzing the effec-
reference ||| tiveness and applicability of co-training. In Proceedings
reference ||| of the Ninth International Conference on Information and
reference ||| Knowledge Management, pages 86–93, New York, USA.
reference ||| Rajat Raina, Alexis Battle, Honglak Lee, Benjamin Packer,
reference ||| and Andrew Y. Ng. 2007. Self-taught learning: transfer
reference ||| learning from unlabeled data. In ICML 2007, pages 759–
reference ||| 766, New York, NY, USA. ACM.
reference ||| Roi Reichart and Ari Rappoport. 2007. Self-training for
reference ||| enhancement and domain adaptation of statistical parsers
reference ||| trained on small datasets. In ACL 2007.
reference ||| Roi Reichart, Katrin Tomanek, Udo Hahn, and Ari Rap-
reference ||| poport. 2008. Multi-task active learning for linguistic
reference ||| annotations. In ACL-08: HLT, pages 861–869.
reference ||| C. E. Shannon. 1948. A mathematical theory of communi-
reference ||| cation. Bell system technicaljournal, 27.
reference ||| J. Sivic, B. C. Russell, A. A. Efros, A. Zisserman, and W. T.
reference ||| Freeman. 2005. Discovering object categories in image
reference ||| collections. In ICCV 2005.
reference ||| Naftali Tishby, Fernando C. Pereira, and William Bialek. The
reference ||| information bottleneck method. 1999. In Proc. of the 37-
reference ||| th Annual Allerton Conference on Communication, Con-
reference ||| trol and Computing, pages 368–377.
reference ||| Pengcheng Wu and Thomas G. Dietterich. 2004. Improving
reference ||| svm accuracy by training on auxiliary data sources. In
reference ||| ICML 2004, pages 110–117, New York, NY, USA.
reference ||| Yejun Wu and Douglas W. Oard. 2008. Bilingual topic as-
reference ||| pect classification with a few training examples. In ACM
reference ||| SIGIR 2008, pages 203–210, New York, NY, USA.
reference ||| Xiaojin Zhu. 2007. Semi-supervised learning literature sur-
reference ||| vey. Technical Report 1530, Computer Sciences, Univer-
reference ||| sity of Wisconsin-Madison.
page ||| 9

title ||| Investigations on Word Senses and Word Usages
author ||| Katrin Erk	Diana McCarthy	Nicholas Gaylord
affiliation ||| University of Texas at Austin	University of Sussex	University of Texas at Austin
email ||| katrin.erk@mail.utexas.edu	dianam@sussex.ac.uk	nlgaylord@mail.utexas.edu
sectionHeader ||| Abstract
bodyText ||| The vast majority of work on word senses
bodyText ||| has relied on predefined sense invento-
bodyText ||| ries and an annotation schema where each
bodyText ||| word instance is tagged with the best fit-
bodyText ||| ting sense. This paper examines the case
bodyText ||| for a graded notion of word meaning in
bodyText ||| two experiments, one which uses WordNet
bodyText ||| senses in a graded fashion, contrasted with
bodyText ||| the “winner takes all” annotation, and one
bodyText ||| which asks annotators to judge the similar-
bodyText ||| ity of two usages. We find that the graded
bodyText ||| responses correlate with annotations from
bodyText ||| previous datasets, but sense assignments
bodyText ||| are used in a way that weakens the case for
bodyText ||| clear cut sense boundaries. The responses
bodyText ||| from both experiments correlate with the
bodyText ||| overlap of paraphrases from the English
bodyText ||| lexical substitution task which bodes well
bodyText ||| for the use of substitutes as a proxy for
bodyText ||| word sense. This paper also provides two
bodyText ||| novel datasets which can be used for eval-
bodyText ||| uating computational systems.
sectionHeader ||| 1 Introduction
bodyText ||| The vast majority of work on word sense tag-
bodyText ||| ging has assumed that predefined word senses
bodyText ||| from a dictionary are an adequate proxy for the
bodyText ||| task, although of course there are issues with
bodyText ||| this enterprise both in terms of cognitive valid-
bodyText ||| ity (Hanks, 2000; Kilgarriff, 1997; Kilgarriff,
bodyText ||| 2006) and adequacy for computational linguis-
bodyText ||| tics applications (Kilgarriff, 2006). Furthermore,
bodyText ||| given a predefined list of senses, annotation efforts
bodyText ||| and computational approaches to word sense dis-
bodyText ||| ambiguation (WSD) have usually assumed that one
bodyText ||| best fitting sense should be selected for each us-
bodyText ||| age. While there is usually some allowance made
bodyText ||| for multiple senses, this is typically not adopted by
bodyText ||| annotators or computational systems.
bodyText ||| Research on the psychology of concepts (Mur-
bodyText ||| phy, 2002; Hampton, 2007) shows that categories
bodyText ||| in the human mind are not simply sets with clear-
bodyText ||| cut boundaries: Some items are perceived as
bodyText ||| more typical than others (Rosch, 1975; Rosch and
bodyText ||| Mervis, 1975), and there are borderline cases on
bodyText ||| which people disagree more often, and on whose
bodyText ||| categorization they are more likely to change their
bodyText ||| minds (Hampton, 1979; McCloskey and Glucks-
bodyText ||| berg, 1978). Word meanings are certainly related
bodyText ||| to mental concepts (Murphy, 2002). This raises
bodyText ||| the question of whether there is any such thing as
bodyText ||| the one appropriate sense for a given occurrence.
bodyText ||| In this paper we will explore using graded re-
bodyText ||| sponses for sense tagging within a novel annota-
bodyText ||| tion paradigm. Modeling the annotation frame-
bodyText ||| work after psycholinguistic experiments, we do
bodyText ||| not train annotators to conform to sense distinc-
bodyText ||| tions; rather we assess individual differences by
bodyText ||| asking annotators to produce graded ratings in-
bodyText ||| stead of making a binary choice. We perform two
bodyText ||| annotation studies. In the first one, referred to
bodyText ||| as WSsim (Word Sense Similarity), annotators
bodyText ||| give graded ratings on the applicability of Word-
bodyText ||| Net senses. In the second one, Usim (Usage Sim-
bodyText ||| ilarity), annotators rate the similarity of pairs of
bodyText ||| occurrences (usages) of a common target word.
bodyText ||| Both studies explore whether users make use of
bodyText ||| a graded scale or persist in making binary deci-
bodyText ||| sions even when there is the option for a graded
bodyText ||| response. The first study additionally tests to what
bodyText ||| extent the judgments on WordNet senses fall into
bodyText ||| clear-cut clusters, while the second study allows
bodyText ||| us to explore meaning similarity independently of
bodyText ||| any lexicon resource.
page ||| 10
note ||| Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 10–18,
note ||| Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP
sectionHeader ||| 2 Related Work
bodyText ||| Manual word sense assignment is difficult for
bodyText ||| human annotators (Krishnamurthy and Nicholls,
bodyText ||| 2000). Reported inter-annotator agreement (ITA)
bodyText ||| for fine-grained word sense assignment tasks has
bodyText ||| ranged between 69% (Kilgarriff and Rosenzweig,
bodyText ||| 2000) for a lexical sample using the HECTOR dic-
bodyText ||| tionary and 78.6.% using WordNet (Landes et al.,
bodyText ||| 1998) in all-words annotation. The use of more
bodyText ||| coarse-grained senses alleviates the problem: In
bodyText ||| OntoNotes (Hovy et al., 2006), an ITA of 90% is
bodyText ||| used as the criterion for the construction of coarse-
bodyText ||| grained sense distinctions. However, intriguingly,
bodyText ||| for some high-frequency lemmas such as leave
bodyText ||| this ITA threshold is not reached even after mul-
bodyText ||| tiple re-partitionings of the semantic space (Chen
bodyText ||| and Palmer, 2009). Similarly, the performance
bodyText ||| of WSD systems clearly indicates that WSD is not
bodyText ||| easy unless one adopts a coarse-grained approach,
bodyText ||| and then systems tagging all words at best perform
bodyText ||| a few percentage points above the most frequent
bodyText ||| sense heuristic (Navigli et al., 2007). Good perfor-
bodyText ||| mance on coarse-grained sense distinctions may
bodyText ||| be more useful in applications than poor perfor-
bodyText ||| mance on fine-grained distinctions (Ide and Wilks,
bodyText ||| 2006) but we do not know this yet and there is
bodyText ||| some evidence to the contrary (Stokoe, 2005).
bodyText ||| Rather than focus on the granularity of clus-
bodyText ||| ters, the approach we will take in this paper
bodyText ||| is to examine the phenomenon of word mean-
bodyText ||| ing both with and without recourse to predefined
bodyText ||| senses by focusing on the similarity of uses of a
bodyText ||| word. Human subjects show excellent agreement
bodyText ||| on judging word similarity out of context (Ruben-
bodyText ||| stein and Goodenough, 1965; Miller and Charles,
bodyText ||| 1991), and human judgments have previously been
bodyText ||| used successfully to study synonymy and near-
bodyText ||| synonymy (Miller and Charles, 1991; Bybee and
bodyText ||| Eddington, 2006). We focus on polysemy rather
bodyText ||| than synonymy. Our aim will be to use WSsim
bodyText ||| to determine to what extent annotations form co-
bodyText ||| hesive clusters. In principle, it should be possi-
bodyText ||| ble to use existing sense-annotated data to explore
bodyText ||| this question: almost all sense annotation efforts
bodyText ||| have allowed annotators to assign multiple senses
bodyText ||| to a single occurrence, and the distribution of these
bodyText ||| sense labels should indicate whether annotators
bodyText ||| viewed the senses as disjoint or not. However,
bodyText ||| the percentage of markables that received multi-
bodyText ||| ple sense labels in existing corpora is small, and it
bodyText ||| varies massively between corpora: In the SemCor
bodyText ||| corpus (Landes et al., 1998), only 0.3% of all
bodyText ||| markables received multiple sense labels. In the
bodyText ||| SENSEVAL-3 English lexical task corpus (Mihal-
bodyText ||| cea et al., 2004) (hereafter referred to as SE-3), the
bodyText ||| ratio is much higher at 8% of all markables1. This
bodyText ||| could mean annotators feel that there is usually a
bodyText ||| single applicable sense, or it could point to a bias
bodyText ||| towards single-sense assignment in the annotation
bodyText ||| guidelines and/or the annotation tool. The WSsim
bodyText ||| experiment that we report in this paper is designed
bodyText ||| to eliminate such bias as far as possible and we
bodyText ||| conduct it on data taken from SemCor and SE-3 so
bodyText ||| that we can compare the annotations. Although we
bodyText ||| use WordNet for the annotation, our study is not a
bodyText ||| study of WordNet per se. We choose WordNet be-
bodyText ||| cause it is sufficiently fine-grained to examine sub-
bodyText ||| tle differences in usage, and because traditionally
bodyText ||| annotated datasets exist to which we can compare
bodyText ||| our results.
bodyText ||| Predefined dictionaries and lexical resources are
bodyText ||| not the only possibilities for annotating lexical
bodyText ||| items with meaning. In cross-lingual settings, the
bodyText ||| actual translations of a word can be taken as the
bodyText ||| sense labels (Resnik and Yarowsky, 2000). Re-
bodyText ||| cently, McCarthy and Navigli (2007) proposed
bodyText ||| the English Lexical Substitution task (hereafter
bodyText ||| referred to as LEXSUB) under the auspices of
bodyText ||| SemEval-2007. It uses paraphrases for words in
bodyText ||| context as a way of annotating meaning. The task
bodyText ||| was proposed following a background of discus-
bodyText ||| sions in the WSD community as to the adequacy
bodyText ||| of predefined word senses. The LEXSUB dataset
bodyText ||| comprises open class words (nouns, verbs, adjec-
bodyText ||| tives and adverbs) with token instances of each
bodyText ||| word appearing in the context of one sentence
bodyText ||| taken from the English Internet Corpus (Sharoff,
bodyText ||| 2006). The methodology can only work where
bodyText ||| there are paraphrases, so the dataset only contains
bodyText ||| words with more than one meaning where at least
bodyText ||| two different meanings have near synonyms. For
bodyText ||| meanings without obvious substitutes the annota-
bodyText ||| tors were allowed to use multiword paraphrases or
bodyText ||| words with slightly more general meanings. This
bodyText ||| dataset has been used to evaluate automatic sys-
bodyText ||| tems which can find substitutes appropriate for the
bodyText ||| context. To the best of our knowledge there has
bodyText ||| been no study of how the data collected relates to
bodyText ||| word sense annotations or judgments of semantic
bodyText ||| similarity. In this paper we examine these relation-
footnote ||| 1 This is even though both annotation efforts use balanced
footnote ||| corpora, the Brown corpus in the case of SemCor, the British
footnote ||| National Corpus for SE-3.
page ||| 11
bodyText ||| ships by re-using data from LEXSUB in both new
bodyText ||| annotation experiments and testing the results for
bodyText ||| correlation.
sectionHeader ||| 3 Annotation
bodyText ||| We conducted two experiments through an on-
bodyText ||| line annotation interface. Three annotators partic-
bodyText ||| ipated in each experiment; all were native British
bodyText ||| English speakers. The first experiment, WSsim,
bodyText ||| collected annotator judgments about the applica-
bodyText ||| bility of dictionary senses using a 5-point rating
bodyText ||| scale. The second, Usim, also utilized a 5-point
bodyText ||| scale but collected judgments on the similarity in
bodyText ||| meaning between two uses of a word. 2 The scale
bodyText ||| was 1 – completely different, 2 – mostly different,
bodyText ||| 3 – similar, 4 – very similar and 5 – identical. In
bodyText ||| Usim, this scale rated the similarity of the two uses
bodyText ||| of the common target word; in WSsim it rated the
bodyText ||| similarity between the use of the target word and
bodyText ||| the sense description. In both experiments, the an-
bodyText ||| notation interface allowed annotators to revisit and
bodyText ||| change previously supplied judgments, and a com-
bodyText ||| ment box was provided alongside each item.
bodyText ||| WSsim. This experiment contained a total of
bodyText ||| 430 sentences spanning 11 lemmas (nouns, verbs
bodyText ||| and adjectives). For 8 of these lemmas, 50 sen-
bodyText ||| tences were included, 25 of them randomly sam-
bodyText ||| pled from SemCor 3 and 25 randomly sampled
bodyText ||| from SE-3 .4 The remaining 3 lemmas in the ex-
bodyText ||| periment each had 10 sentences taken from the
bodyText ||| LEXSUB data.
bodyText ||| WSsim is a word sense annotation task using
bodyText ||| WordNet senses.5 Unlike previous word sense an-
bodyText ||| notation projects, we asked annotators to provide
bodyText ||| judgments on the applicability of every WordNet
bodyText ||| sense of the target lemma with the instruction: 6
footnote ||| 2Throughout this paper, a target word is assumed to be a
footnote ||| word in a given PoS.
footnote ||| 3The SemCor dataset was produced alongside WordNet,
footnote ||| so it can be expected to support the WordNet sense distinc-
footnote ||| tions. The same cannot be said for SE-3.
footnote ||| 4Sentence fragments and sentences with 5 or fewer words
footnote ||| were excluded from the sampling. Annotators were given
footnote ||| the sentences, but not the original annotation from these re-
footnote ||| sources.
footnote ||| 5WordNet 1.7.1 was used in the annotation of both SE-3
footnote ||| and SemCor; we used the more current WordNet 3.0 after
footnote ||| verifying that the lemmas included in this experiment had the
footnote ||| same senses listed in both versions. Care was taken addition-
footnote ||| ally to ensure that senses were not presented in an order that
footnote ||| reflected their frequency of occurrence.
footnote ||| 6The guidelines for both experiments are avail-
footnote ||| able	at	http://comp.ling.utexas.edu/
footnote ||| people/katrin erk/graded sense and usage
footnote ||| annotation
construct ||| Your task is to rate, for each of these descriptions,
construct ||| how well they reflect the meaning of the boldfaced
construct ||| word in the sentence.
bodyText ||| Applicability judgments were not binary, but were
bodyText ||| instead collected using the five-point scale given
bodyText ||| above which allowed annotators to indicate not
bodyText ||| only whether a given sense applied, but to what
bodyText ||| degree. Each annotator annotated each of the 430
bodyText ||| items. By having multiple annotators per item and
bodyText ||| a graded, non-binary annotation scheme we al-
bodyText ||| low for and measure differences between annota-
bodyText ||| tors, rather than training annotators to conform to
bodyText ||| a common sense distinction guideline. By asking
bodyText ||| annotators to provide ratings for each individual
bodyText ||| sense, we strive to eliminate all bias towards either
bodyText ||| single-sense or multiple-sense assignment. In tra-
bodyText ||| ditional word sense annotation, such bias could be
bodyText ||| introduced directly through annotation guidelines
bodyText ||| or indirectly, through tools that make it easier to
bodyText ||| assign fewer senses. We focus not on finding the
bodyText ||| best fitting sense but collect judgments on the ap-
bodyText ||| plicability of all senses.
bodyText ||| Usim. This experiment used data from LEXSUB.
bodyText ||| For more information on LEXSUB, see McCarthy
bodyText ||| and Navigli (2007). 34 lemmas (nouns, verbs, ad-
bodyText ||| jectives and adverbs) were manually selected, in-
bodyText ||| cluding the 3 lemmas also used in WSsim. We se-
bodyText ||| lected lemmas which exhibited a range of mean-
bodyText ||| ings and substitutes in the LEXSUB data, with
bodyText ||| as few multiword substitutes as possible. Each
bodyText ||| lemma is the target in 10 LEXSUB sentences. For
bodyText ||| our experiment, we took every possible pairwise
bodyText ||| comparison of these 10 sentences for a lemma. We
bodyText ||| refer to each such pair of sentences as an SPAIR.
bodyText ||| The resulting dataset comprised 45 SPAIRs per
bodyText ||| lemma, adding up to 1530 comparisons per anno-
bodyText ||| tator overall.
bodyText ||| In this annotation experiment, annotators saw
bodyText ||| SPAIRs with a common target word and rated the
bodyText ||| similarity in meaning between the two uses of the
bodyText ||| target word with the instruction:
construct ||| Your task is to rate, for each pair of sentences, how
construct ||| similar in meaning the two boldfaced words are on
construct ||| a five -point scale.
bodyText ||| In addition annotators had the ability to respond
bodyText ||| with “Cannot Decide”, indicating that they were
bodyText ||| unable to make an effective comparison between
bodyText ||| the two contexts, for example because the mean-
bodyText ||| ing of one usage was unclear. This occurred in
bodyText ||| 9 paired occurrences during the course of anno-
bodyText ||| tation, and these items (paired occurrences) were
page ||| 12
bodyText ||| excluded from further analysis.
bodyText ||| The purpose of Usim was to collect judgments
bodyText ||| about degrees of similarity between a word’s
bodyText ||| meaning in different contexts. Unlike WSsim,
bodyText ||| Usim does not rely upon any dictionary resource
bodyText ||| as a basis for the judgments.
sectionHeader ||| 4 Analyses
bodyText ||| This section reports on analyses on the annotated
bodyText ||| data. In all the analyses we use Spearman’s rank
bodyText ||| correlation coefficient (p), a nonparametric test,
bodyText ||| because the data does not seem to be normally
bodyText ||| distributed. We used two-tailed tests in all cases,
bodyText ||| rather than assume the direction of the relation-
bodyText ||| ship. As noted above, we have three annotators
bodyText ||| per task, and each annotator gave judgments for
bodyText ||| every sentence (WSsim) or sentence pair (Usim).
bodyText ||| Since the annotators may vary as to how they use
bodyText ||| the ordinal scale, we do not use the mean of judg-
bodyText ||| ments7 but report all individual correlations. All
bodyText ||| analyses were done using the R package.8
subsectionHeader ||| 4.1 WSsim analysis
bodyText ||| In the WSsim experiment, annotators rated the ap-
bodyText ||| plicability of each WordNet 3.0 sense for a given
bodyText ||| target word occurrence. Table 1 shows a sample
bodyText ||| annotation for the target argument.n. 9
bodyText ||| Pattern of annotation and annotator agree-
bodyText ||| ment. Figure 1 shows how often each of the five
bodyText ||| judgments on the scale was used, individually and
bodyText ||| summed over all annotators. (The y-axis shows
bodyText ||| raw counts of each judgment.) We can see from
bodyText ||| this figure that the extreme ratings 1 and 5 are used
bodyText ||| more often than the intermediate ones, but annota-
bodyText ||| tors make use of the full ordinal scale when judg-
bodyText ||| ing the applicability of a sense. Also, the figure
bodyText ||| shows that annotator 1 used the extreme negative
bodyText ||| rating 1 much less than the other two annotators.
bodyText ||| Figure 2 shows the percentage of times each judg-
bodyText ||| ment was used on senses of three lemmas, differ-
bodyText ||| ent.a, interest.n, and win.v. In WordNet, they have
bodyText ||| 5, 7, and 4 senses, respectively. The pattern for
bodyText ||| win.v resembles the overall distribution of judg-
bodyText ||| ments, with peaks at the extreme ratings 1 and 5.
bodyText ||| The lemma interest.n has a single peak at rating
bodyText ||| 1, partly due to the fact that senses 5 (financial
footnote ||| 7We have also performed several of our calculations us-
footnote ||| ing the mean judgment, and they also gave highly significant
footnote ||| results in all the cases we tested.
footnote ||| 8http://www.r-project.org/
footnote ||| 9We use word.PoS to denote a target word (lemma).
footnote ||| Annotator 1 Annotator 2 Annotator 3 overall
figureCaption ||| Figure 1: WSsim experiment: number of times
figureCaption ||| each judgment was used, by annotator and
figureCaption ||| summed over all annotators. The y-axis shows raw
figureCaption ||| counts of each judgment.
figureCaption ||| different.a	interest.n	win.v
figureCaption ||| Figure 2: WSsim experiment: percentage of times
figureCaption ||| each judgment was used for the lemmas differ-
figureCaption ||| ent.a, interest.n and win.v. Judgment counts were
figureCaption ||| summed over all three annotators.
bodyText ||| involvement) and 6 (interest group) were rarely
bodyText ||| judged to apply. For the lemma different.a, all
bodyText ||| judgments have been used with approximately the
bodyText ||| same frequency.
bodyText ||| We measured the level of agreement between
bodyText ||| annotators using Spearman’s p between the judg-
bodyText ||| ments of every pair of annotators. The pairwise
bodyText ||| correlations were p = 0.506, p = 0.466 and p =
bodyText ||| 0.540, all highly significant with p < 2.2e-16.
bodyText ||| Agreement with previous annotation in
bodyText ||| SemCor and SE-3. 200 of the items in WSsim
bodyText ||| had been previously annotated in SemCor, and
bodyText ||| 200 in SE-3. This lets us compare the annotation
bodyText ||| results across annotation efforts. Table 2 shows
bodyText ||| the percentage of items where more than one
bodyText ||| sense was assigned in the subset of WSsim from
bodyText ||| SemCor (first row), from SE-3 (second row), and
figure ||| 1
figure ||| 2
figure ||| 3
figure ||| 5
page ||| 13
table ||| Sentence	1	2	Senses	5	6	7	Annotator
table ||| 			3	4
table ||| This question provoked arguments in America about the	1	4	4	2	1	1	3	Ann. 1
table ||| Norton Anthology of Literature by Women, some of the	4	5	4	2	1	1	4	Ann. 2
table ||| contents of which were said to have had little value as literature.	1	4	5	1	1	1	1	Ann. 3
tableCaption ||| Table 1: A sample annotation in the WSsim experiment. The senses are: 1:statement, 2:controversy,
tableCaption ||| 3:debate, 4:literary argument, 5:parameter, 6:variable, 7:line of reasoning
table ||| WSsim judgment
table ||| >3 >4 5
table ||| 80.2 57.5 28.3
table ||| 78.0 58.3 27.1
table ||| 78.8 57.4 27.7
table ||| Data	Orig.
table ||| W Ssim/SemCor	0.0
table ||| WSsim/SE-3	24.0
table ||| All WSsim
table ||| 	p<0.05 pos	neg		p<0.01 pos	neg
table ||| Ann. 1	30.8	11.4	23.2	5.9
table ||| Ann. 2	22.2	24.1	19.6	19.6
table ||| Ann. 3	12.7	12.0	10.0	6.0
tableCaption ||| Table 2: Percentage of items with multiple senses
tableCaption ||| assigned. Orig: in the original SemCor/SE-3 data.
tableCaption ||| WSsim judgment: items with judgments at or
tableCaption ||| above the specified threshold. The percentages for
tableCaption ||| WSsim are averaged over the three annotators.
bodyText ||| all of WSsim (third row). The Orig. column
bodyText ||| indicates how many items had multiple labels in
bodyText ||| the original annotation (SemCor or SE-3)10. Note
bodyText ||| that no item had more than one sense label in
bodyText ||| SemCor. The columns under WSsim judgment
bodyText ||| show the percentage of items (averaged over
bodyText ||| the three annotators) that had judgments at or
bodyText ||| above the specified threshold, starting from rating
bodyText ||| 3 – similar. Within WSsim, the percentage of
bodyText ||| multiple assignments in the three rows is fairly
bodyText ||| constant. WSsim avoids the bias to one sense
bodyText ||| by deliberately asking for judgments on the
bodyText ||| applicability of each sense rather than asking
bodyText ||| annotators to find the best one.
bodyText ||| To compute the Spearman’s correlation between
bodyText ||| the original sense labels and those given in the
bodyText ||| WSsim annotation, we converted SemCor and
bodyText ||| SE-3 labels to the format used within WSsim: As-
bodyText ||| signed senses were converted to a judgment of 5,
bodyText ||| and unassigned senses to a judgment of 1. For the
bodyText ||| WSsim/SemCor dataset, the correlation between
bodyText ||| original and WSsim annotation was p = 0.234,
bodyText ||| p = 0.448, and p = 0.390 for the three anno-
bodyText ||| tators, each highly significant with p < 2.2e-16.
bodyText ||| For the WSsim/SE-3 dataset, the correlations were
bodyText ||| p = 0.346, p = 0.449 and p = 0.338, each of them
bodyText ||| again highly significant at p < 2.2e-16.
bodyText ||| Degree of sense grouping. Next we test to what
bodyText ||| extent the sense applicability judgments in the
footnote ||| 10Overall, 0.3% of tokens in SemCor have multiple labels,
footnote ||| and 8% of tokens in SE-3, so the multiple label assignment in
footnote ||| our sample is not an underestimate.
tableCaption ||| Table 3: Percentage of sense pairs that were sig-
tableCaption ||| nificantly positively (pos) or negatively (neg) cor-
tableCaption ||| related at p < 0.05 and p < 0.01, shown by anno-
tableCaption ||| tator.
table ||| 	j>3	j>4	j=5
table ||| Ann. 1	71.9	49.1	8.1
table ||| Ann. 2	55.3	24.7	8.1
table ||| Ann. 3	42.8	24.0	4.9
tableCaption ||| Table 4: Percentage of sentences in which at least
tableCaption ||| two uncorrelated (p > 0.05) or negatively corre-
tableCaption ||| lated senses have been annotated with judgments
tableCaption ||| at the specified threshold.
bodyText ||| WSsim task could be explained by more coarse-
bodyText ||| grained, categorial sense assignments. We first
bodyText ||| test how many pairs of senses for a given lemma
bodyText ||| show similar patterns in the ratings that they re-
bodyText ||| ceive. Table 3 shows the percentage of sense pairs
bodyText ||| that were significantly correlated for each anno-
bodyText ||| tator.11 Significantly positively correlated senses
bodyText ||| can possibly be reduced to more coarse-grained
bodyText ||| senses. Would annotators have been able to des-
bodyText ||| ignate a single appropriate sense given these more
bodyText ||| coarse-grained senses? Call two senses groupable
bodyText ||| if they are significantly positively correlated; in or-
bodyText ||| der not to overlook correlations that are relatively
bodyText ||| weak but existent, we use a cutoff of p = 0.05 for
bodyText ||| significant correlation. We tested how often anno-
bodyText ||| tators gave ratings of at least similar, i.e. ratings
bodyText ||| > 3, to senses that were not groupable. Table 4
bodyText ||| shows the percentages of items where at least two
bodyText ||| non-groupable senses received ratings at or above
bodyText ||| the specified threshold. The table shows that re-
bodyText ||| gardless of which annotator we look at, over 40%
bodyText ||| of all items had two or more non-groupable senses
bodyText ||| receive judgments of at least 3 (similar). There
footnote ||| 11 We exclude senses that received a uniform rating of 1 on
footnote ||| all items. This concerned 4 senses for annotator 2 and 6 for
footnote ||| annotator 3.
page ||| 14
figure ||| 1) We study the methods and concepts that each writer uses to
figure ||| defend the cogency of legal, deliberative, or more generally
figure ||| political prudence against explicit or implicit charges that
figure ||| practical thinking is merely a knack or form of cleverness.
figure ||| 2) Eleven CIRA members have been convicted of criminal
figure ||| charges and others are awaiting trial.
figureCaption ||| Figure 3: An SPAIR for charge.n. Annotator judg-
figureCaption ||| ments: 2,3,4
bodyText ||| were even several items where two or more non-
bodyText ||| groupable senses each got a judgment of 5. The
bodyText ||| sentence in table 1 is a case where several non-
bodyText ||| groupable senses got ratings > 3. This is most
bodyText ||| pronounced for Annotator 2, who along with sense
bodyText ||| 2 (controversy) assigned senses 1 (statement), 7
bodyText ||| (line of reasoning), and 3 (debate), none of which
bodyText ||| are groupable with sense 2.
subsectionHeader ||| 4.2 Usim analysis
bodyText ||| In this experiment, ratings between 1 and 5 were
bodyText ||| given for every pairwise combination of sentences
bodyText ||| for each target lemma. An example of an SPAIR
bodyText ||| for charge.n is shown in figure 3. In this case the
bodyText ||| verdicts from the annotators were 2, 3 and 4.
bodyText ||| Pattern of Annotations and Annotator Agree-
bodyText ||| ment Figure 4 gives a bar chart of the judgments
bodyText ||| for each annotator and summed over annotators.
bodyText ||| We can see from this figure that the annotators
bodyText ||| use the full ordinal scale when judging the simi-
bodyText ||| larity of a word’s usages, rather than sticking to
bodyText ||| the extremes. There is variation across words, de-
bodyText ||| pending on the relatedness of each word’s usages.
bodyText ||| Figure 5 shows the judgments for the words bar.n,
bodyText ||| work.v and raw.a. We see that bar.n has predom-
bodyText ||| inantly different usages with a peak for category
bodyText ||| 1, work.v has more similar judgments (category 5)
bodyText ||| compared to any other category and raw.a has a
bodyText ||| peak in the middle category (3). 12 There are other
bodyText ||| words, like for example fresh.a, where the spread
bodyText ||| is more uniform.
bodyText ||| To gauge the level of agreement between anno-
bodyText ||| tators, we calculated Spearman’s p between the
bodyText ||| judgments of every pair of annotators as in sec-
bodyText ||| tion 4.1. The pairwise correlations are all highly
bodyText ||| significant (p < 2.2e-16) with Spearman’s p =
bodyText ||| 0.502, 0.641 and 0.501 giving an average corre-
bodyText ||| lation of 0.548. We also perform leave-one-out re-
bodyText ||| sampling following Lapata (2006) which gave us
bodyText ||| a Spearman’s correlation of 0.630.
footnote ||| 12For figure 5 we sum the judgments over annotators.
figureCaption ||| Figure 4: Usim experiment: number of times each
figureCaption ||| judgment was used, by annotator and summed
figureCaption ||| over all annotators
figure ||| bar.n	raw.a	work.v
figureCaption ||| Figure 5: Usim experiment: number of times each
figureCaption ||| judgment was used for bar.n, work.v and raw. a
bodyText ||| Comparison with LEXSUB substitutions Next
bodyText ||| we look at whether the Usim judgments on sen-
bodyText ||| tence pairs (SPAIRs) correlate with LEXSUB sub-
bodyText ||| stitutes. To do this we use the overlap of substi-
bodyText ||| tutes provided by the five LEXSUB annotators be-
bodyText ||| tween two sentences in an SPAIR. In LEXSUB the
bodyText ||| annotators had to replace each item (a target word
bodyText ||| within the context of a sentence) with a substitute
bodyText ||| that fitted the context. Each annotator was permit-
bodyText ||| ted to supply up to three substitutes provided that
bodyText ||| they all fitted the context equally. There were 10
bodyText ||| sentences per lemma. For our analyses we take
bodyText ||| every SPAIR for a given lemma and calculate the
bodyText ||| overlap (inter) of the substitutes provided by the
bodyText ||| annotators for the two usages under scrutiny. Let
bodyText ||| s1 and s2 be a pair of sentences in an SPAIR and
bodyText ||| Annotator 4 Annotator 5 Annotator 6	overall
figure ||| 1
figure ||| 2
figure ||| 3
figure ||| 4
figure ||| 5
figure ||| 1
figure ||| 2
figure ||| 3
figure ||| 4
figure ||| 5
page ||| 15
bodyText ||| x1 and x2 be the multisets of substitutes for the
bodyText ||| respective sentences. Let freq(w,x) be the fre-
bodyText ||| quency of a substitute w in a multiset x of sub-
bodyText ||| stitutes for a given sentence. 13 INTER(s1,s2) =
equation ||| �wEx1f1x2 min (freq(w,x1), freq(w,x2))
equation ||| max(1x1 1, 1x2 1)
bodyText ||| Using this calculation for each SPAIR we can
bodyText ||| now compute the correlation between the Usim
bodyText ||| judgments for each annotator and the INTER val-
bodyText ||| ues, again using Spearman’s. The figures are
bodyText ||| shown in the leftmost block of table 5. The av-
bodyText ||| erage correlation for the 3 annotators was 0.488
bodyText ||| and the p-values were all < 2.2e-16. This shows
bodyText ||| a highly significant correlation of the Usim judg-
bodyText ||| ments and the overlap of substitutes.
bodyText ||| We also compare the WSsim judgments against
bodyText ||| the LEXSUB substitutes, again using the INTER
bodyText ||| measure of substitute overlap. For this analysis,
bodyText ||| we only use those WSsim sentences that are origi-
bodyText ||| nally from LEXSUB. In WSsim, the judgments for
bodyText ||| a sentence comprise judgments for each WordNet
bodyText ||| sense of that sentence. In order to compare against
bodyText ||| INTER, we need to transform these sentence-wise
bodyText ||| ratings in WSsim to a WSsim-based judgment of
bodyText ||| sentence similarity. To this end, we compute the
bodyText ||| Euclidean Distance14 (ED) between two vectors J1
bodyText ||| and J2 of judgments for two sentences s1, s2 for the
bodyText ||| same lemma E. Each of the n indexes of the vector
bodyText ||| represent one of the n different WordNet senses
bodyText ||| for E. The value at entry i of the vector J1 is the
bodyText ||| judgment that the annotator in question (we do not
bodyText ||| average over annotators here) provided for sense i
bodyText ||| of E for sentence s1.
equation ||| (J1[i]—J2[i])2) (1)
bodyText ||| We correlate the Euclidean distances with
bodyText ||| INTER. We can only test correlation for the subset
bodyText ||| of WSsim that overlaps with the LEXSUB data: the
bodyText ||| 30 sentences for investigator.n, function.n and or-
bodyText ||| der.v, which together give 135 unique SPAIRs. We
bodyText ||| refer to this subset as Wf1U. The results are given
bodyText ||| in the third block of table 5. Note that since we are
bodyText ||| measuring distance between SPAIRs for WSsim
footnote ||| 13The frequency of a substitute in a multiset depends on
footnote ||| the number of LEXSUB annotators that picked the substitute
footnote ||| for this item.
footnote ||| 14We use Euclidean Distance rather than a normalizing
footnote ||| measure like Cosine because a sentence where all ratings are
footnote ||| 5 should be very different from a sentence where all senses
footnote ||| received a rating of 1.
table ||| Usim All		Usim Wf1U	WSsim Wf1U
table ||| ann.	p	p	ann.	p
table ||| 4	0.383	0.330	1	-0.520
table ||| 5	0.498	0.635	2	-0.503
table ||| 6	0.584	0.631	3	-0.463
tableCaption ||| Table 5: Annotator correlation with LEXSUB sub-
tableCaption ||| stitute overlap (inter)
bodyText ||| whereas INTER is a measure of similarity, the cor-
bodyText ||| relation is negative. The results are highly signif-
bodyText ||| icant with individual p-values from < 1.067e-10
bodyText ||| to < 1.551e-08 and a mean correlation of -0.495.
bodyText ||| The results in the first and third block of table 5 are
bodyText ||| not directly comparable, as the results in the first
bodyText ||| block are for all Usim data and not the subset of
bodyText ||| LEXSUB with WSsim annotations. We therefore
bodyText ||| repeated the analysis for Usim on the subset of
bodyText ||| data in WSsim and provide the correlation in the
bodyText ||| middle section of table 5. The mean correlation
bodyText ||| for Usim on this subset of the data is 0.532, which
bodyText ||| is a stronger relationship compared to WSsim, al-
bodyText ||| though there is more discrepancy between individ-
bodyText ||| ual annotators, with the result for annotator 4 giv-
bodyText ||| ing a p-value = 9.139e-05 while the other two an-
bodyText ||| notators had p-values < 2.2e-16.
bodyText ||| The LEXSUB substitute overlaps between dif-
bodyText ||| ferent usages correlate well with both Usim and
bodyText ||| WSsim judgments, with a slightly stronger rela-
bodyText ||| tionship to Usim, perhaps due to the more compli-
bodyText ||| cated representation of word meaning in WSsim
bodyText ||| which uses the full set of WordNet senses.
subsectionHeader ||| 4.3 Correlation between WSsim and Usim
bodyText ||| As we showed in section 4.1, WSsim correlates
bodyText ||| with previous word sense annotations in SemCor
bodyText ||| and SE-3 while allowing the user a more graded
bodyText ||| response to sense tagging. As we saw in sec-
bodyText ||| tion 4.2, Usim and WSsim judgments both have a
bodyText ||| highly significant correlation with similarity of us-
bodyText ||| ages as measured using the overlap of substitutes
bodyText ||| from LEXSUB. Here, we look at the correlation
bodyText ||| of WSsim and Usim, considering again the sub-
bodyText ||| set of data that is common to both experiments.
bodyText ||| We again transform WSsim sense judgments for
bodyText ||| individual sentences to distances between SPAIRs
bodyText ||| using Euclidean Distance (ED). The Spearman’s
bodyText ||| p range between —0.307 and —0.671, and all re-
bodyText ||| sults are highly significant with p-values between
bodyText ||| 0.0003 and < 2.2e-16. As above, the correla-
bodyText ||| tion is negative because ED is a distance measure
bodyText ||| between sentences in an SPAIR, whereas the judg-
equation ||| ED(J1,J2) = V1(
equation ||| n
equation ||| �
equation ||| i=1
page ||| 16
bodyText ||| ments for Usim are similarity judgments. We see
bodyText ||| that there is highly significant correlation for every
bodyText ||| pairing of annotators from the two experiments.
sectionHeader ||| 5 Discussion
bodyText ||| Validity of annotation scheme. Annotator rat-
bodyText ||| ings show highly significant correlation on both
bodyText ||| tasks. This shows that the tasks are well-defined.
bodyText ||| In addition, there is a strong correlation between
bodyText ||| WSsim and Usim, which indicates that the poten-
bodyText ||| tial bias introduced by the use of dictionary senses
bodyText ||| in WSsim is not too prominent. However, we note
bodyText ||| that WSsim only contained a small portion of 3
bodyText ||| lemmas (30 sentences and 135 SPAIRs) in com-
bodyText ||| mon with Usim, so more annotation is needed to
bodyText ||| be certain of this relationship. Given the differ-
bodyText ||| ences between annotator 1 and the other annota-
bodyText ||| tors in Fig. 1, it would be interesting to collect
bodyText ||| judgments for additional annotators.
bodyText ||| Graded judgments of use similarity and sense
bodyText ||| applicability. The annotators made use of the
bodyText ||| full spectrum of ratings, as shown in Figures 1 and
bodyText ||| 4. This may be because of a graded perception of
bodyText ||| the similarity of uses as well as senses, or because
bodyText ||| some uses and senses are very similar. Table 4
bodyText ||| shows that for a large number of WSsim items,
bodyText ||| multiple senses that were not significantly posi-
bodyText ||| tively correlated got high ratings. This seems to
bodyText ||| indicate that the ratings we obtained cannot sim-
bodyText ||| ply be explained by more coarse-grained senses. It
bodyText ||| may hence be reasonable to pursue computational
bodyText ||| models of word meaning that are graded, maybe
bodyText ||| even models that do not rely on dictionary senses
bodyText ||| at all (Erk and Pado, 2008).
bodyText ||| Comparison to previous word sense annotation.
bodyText ||| Our graded WSsim annotations do correlate with
bodyText ||| traditional “best fitting sense” annotations from
bodyText ||| SemCor and SE-3; however, if annotators perceive
bodyText ||| similarity between uses and senses as graded, tra-
bodyText ||| ditional word sense annotation runs the risk of in-
bodyText ||| troducing bias into the annotation.
bodyText ||| Comparison to lexical substitutions. There is a
bodyText ||| strong correlation between both Usim and WSsim
bodyText ||| and the overlap in paraphrases that annotators gen-
bodyText ||| erated for LEXSUB. This is very encouraging, and
bodyText ||| especially interesting because LEXSUB annotators
bodyText ||| freely generated paraphrases rather than selecting
bodyText ||| them from a list.
sectionHeader ||| 6 Conclusions
bodyText ||| We have introduced a novel annotation paradigm
bodyText ||| for word sense annotation that allows for graded
bodyText ||| judgments and for some variation between anno-
bodyText ||| tators. We have used this annotation paradigm
bodyText ||| in two experiments, WSsim and Usim, that shed
bodyText ||| some light on the question of whether differences
bodyText ||| between word usages are perceived as categorial
bodyText ||| or graded. Both datasets will be made publicly
bodyText ||| available. There was a high correlation between
bodyText ||| annotator judgments within and across tasks, as
bodyText ||| well as with previous word sense annotation and
bodyText ||| with paraphrases proposed in the English Lex-
bodyText ||| ical Substitution task. Annotators made ample
bodyText ||| use of graded judgments in a way that cannot
bodyText ||| be explained through more coarse-grained senses.
bodyText ||| These results suggest that it may make sense to
bodyText ||| evaluate WSD systems on a task of graded rather
bodyText ||| than categorial meaning characterization, either
bodyText ||| through dictionary senses or similarity between
bodyText ||| uses. In that case, it would be useful to have more
bodyText ||| extensive datasets with graded annotation, even
bodyText ||| though this annotation paradigm is more time con-
bodyText ||| suming and thus more expensive than traditional
bodyText ||| word sense annotation.
bodyText ||| As a next step, we will automatically cluster the
bodyText ||| judgments we obtained in the WSsim and Usim
bodyText ||| experiments to further explore the degree to which
bodyText ||| the annotation gives rise to sense grouping. We
bodyText ||| will also use the ratings in both experiments to
bodyText ||| evaluate automatically induced models of word
bodyText ||| meaning. The SemEval-2007 word sense induc-
bodyText ||| tion task (Agirre and Soroa, 2007) already allows
bodyText ||| for evaluation of automatic sense induction sys-
bodyText ||| tems, but compares output to gold-standard senses
bodyText ||| from OntoNotes. We hope that the Usim dataset
bodyText ||| will be particularly useful for evaluating methods
bodyText ||| which relate usages without necessarily producing
bodyText ||| hard clusters. Also, we will extend the current
bodyText ||| dataset using more annotators and exploring ad-
bodyText ||| ditional lexicon resources.
sectionHeader ||| Acknowledgments. We acknowledge support
sectionHeader ||| from the UK Royal Society for a Dorothy Hodkin
sectionHeader ||| Fellowship to the second author. We thank Sebas-
sectionHeader ||| tian Pado for many helpful discussions, and An-
sectionHeader ||| drew Young for help with the interface.
sectionHeader ||| References
reference ||| E. Agirre and A. Soroa. 2007. SemEval-2007
reference ||| task 2: Evaluating word sense induction and dis-
page ||| 17
reference ||| crimination systems. In Proceedings of the 4th
reference ||| International Workshop on Semantic Evaluations
reference ||| (SemEval-2007), pages 7–12, Prague, Czech Repub-
reference ||| lic.
reference ||| J. Bybee and D. Eddington. 2006. A usage-based ap-
reference ||| proach to Spanish verbs of ’becoming’. Language,
reference ||| 82(2):323–355.
reference ||| J. Chen and M. Palmer. 2009. Improving English
reference ||| verb sense disambiguation performance with lin-
reference ||| guistically motivated features and clear sense dis-
reference ||| tinction boundaries. Journal of Language Resources
reference ||| and Evaluation, Special Issue on SemEval-2007. in
reference ||| press.
reference ||| K. Erk and S. Pado. 2008. A structured vector space
reference ||| model for word meaning in context. In Proceedings
reference ||| of EMNLP-08, Waikiki, Hawaii.
reference ||| J. A. Hampton. 1979. Polymorphous concepts in se-
reference ||| mantic memory. Journal of Verbal Learning and
reference ||| Verbal Behavior, 18:441–461.
reference ||| J. A. Hampton. 2007. Typicality, graded membership,
reference ||| and vagueness. Cognitive Science, 31:355–384.
reference ||| P. Hanks. 2000. Do word meanings exist? Computers
reference ||| and the Humanities, 34(1-2):205–215(11).
reference ||| E. H. Hovy, M. Marcus, M. Palmer, S. Pradhan,
reference ||| L. Ramshaw, and R. Weischedel. 2006. OntoNotes:
reference ||| The 90% solution. In Proceedings of the Hu-
reference ||| man Language Technology Conference of the North
reference ||| American Chapter of the ACL (NAACL-2006), pages
reference ||| 57–60, New York.
reference ||| N. Ide and Y. Wilks. 2006. Making sense about
reference ||| sense. In E. Agirre and P. Edmonds, editors,
reference ||| Word Sense Disambiguation, Algorithms and Appli-
reference ||| cations, pages 47–73. Springer.
reference ||| A. Kilgarriff and J. Rosenzweig. 2000. Framework
reference ||| and results for English Senseval. Computers and the
reference ||| Humanities, 34(1-2):15–48.
reference ||| A. Kilgarriff. 1997. I don’t believe in word senses.
reference ||| Computers and the Humanities, 31(2):91–113.
reference ||| A. Kilgarriff. 2006. Word senses. In E. Agirre
reference ||| and P. Edmonds, editors, Word Sense Disambigua-
reference ||| tion, Algorithms and Applications, pages 29–46.
reference ||| Springer.
reference ||| R. Krishnamurthy and D. Nicholls. 2000. Peeling
reference ||| an onion: the lexicographers’ experience of man-
reference ||| ual sense-tagging. Computers and the Humanities,
reference ||| 34(1-2).
reference ||| S. Landes, C. Leacock, and R. Tengi. 1998. Build-
reference ||| ing semantic concordances. In C. Fellbaum, editor,
reference ||| WordNet: An Electronic Lexical Database. The MIT
reference ||| Press, Cambridge, MA.
reference ||| M. Lapata. 2006. Automatic evaluation of information
reference ||| ordering. Computational Linguistics, 32(4):471–
reference ||| 484.
reference ||| D. McCarthy and R. Navigli. 2007. SemEval-2007
reference ||| task 10: English lexical substitution task. In Pro-
reference ||| ceedings of the 4th International Workshop on Se-
reference ||| mantic Evaluations (SemEval-2007), pages 48–53,
reference ||| Prague, Czech Republic.
reference ||| M. McCloskey and S. Glucksberg. 1978. Natural cat-
reference ||| egories: Well defined or fuzzy sets? Memory &
reference ||| Cognition, 6:462–472.
reference ||| R. Mihalcea, T. Chklovski, and A. Kilgarriff. 2004.
reference ||| The Senseval-3 English lexical sample task. In
reference ||| 3rd International Workshop on Semantic Evalua-
reference ||| tions (SensEval-3) atACL-2004, Barcelona, Spain.
reference ||| G. Miller and W. Charles. 1991. Contextual correlates
reference ||| of semantic similarity. Language and cognitive pro-
reference ||| cesses, 6(1):1–28.
reference ||| G. L. Murphy. 2002. The Big Book of Concepts. MIT
reference ||| Press.
reference ||| R. Navigli, K. C. Litkowski, and O. Hargraves.
reference ||| 2007. SemEval-2007 task 7: Coarse-grained En-
reference ||| glish all-words task. In Proceedings of the 4th
reference ||| International Workshop on Semantic Evaluations
reference ||| (SemEval-2007), pages 30–35, Prague, Czech Re-
reference ||| public.
reference ||| P. Resnik and D. Yarowsky. 2000. Distinguishing
reference ||| systems and distinguishing senses: New evaluation
reference ||| methods for word sense disambiguation. Natural
reference ||| Language Engineering, 5(3):113–133.
reference ||| E. Rosch and C. B. Mervis. 1975. Family resem-
reference ||| blance: Studies in the internal structure of cate-
reference ||| gories. Cognitive Psychology, 7:573–605.
reference ||| E. Rosch. 1975. Cognitive representations of seman-
reference ||| tic categories. Journal of Experimental Psychology:
reference ||| General, 104:192–233.
reference ||| H. Rubenstein and J. Goodenough. 1965. Contextual
reference ||| correlates of synonymy. Computational Linguistics,
reference ||| 8:627–633.
reference ||| S. Sharoff. 2006. Open-source corpora: Using the net
reference ||| to fish for linguistic data. International Journal of
reference ||| Corpus Linguistics, 11(4):435–462.
reference ||| C. Stokoe. 2005. Differentiating homonymy and pol-
reference ||| ysemy in information retrieval. In Proceedings of
reference ||| HLT/EMNLP-05, pages 403–410, Vancouver, B.C.,
reference ||| Canada.
page ||| 18

title ||| A Comparative Study on Generalization of Semantic Roles in FrameNet
author ||| Yuichiroh Matsubayashit	Naoaki Okazakit	Jun’ichi Tsujiit$*
affiliation ||| tDepartment of Computer Science, University of Tokyo, Japan
affiliation ||| $School of Computer Science, University of Manchester, UK
affiliation ||| *National Centre for Text Mining, UK
email ||| {y-matsu,okazaki,tsujii}@is.s.u-tokyo.ac.jp
sectionHeader ||| Abstract
bodyText ||| A number of studies have presented
bodyText ||| machine-learning approaches to semantic
bodyText ||| role labeling with availability of corpora
bodyText ||| such as FrameNet and PropBank. These
bodyText ||| corpora define the semantic roles of predi-
bodyText ||| cates for each frame independently. Thus,
bodyText ||| it is crucial for the machine-learning ap-
bodyText ||| proach to generalize semantic roles across
bodyText ||| different frames, and to increase the size
bodyText ||| of training instances. This paper ex-
bodyText ||| plores several criteria for generalizing se-
bodyText ||| mantic roles in FrameNet: role hierar-
bodyText ||| chy, human-understandable descriptors of
bodyText ||| roles, semantic types of filler phrases, and
bodyText ||| mappings from FrameNet roles to the-
bodyText ||| matic roles of VerbNet. We also pro-
bodyText ||| pose feature functions that naturally com-
bodyText ||| bine and weight these criteria, based on
bodyText ||| the training data. The experimental result
bodyText ||| of the role classification shows 19.16%
bodyText ||| and 7.42% improvements in error reduc-
bodyText ||| tion rate and macro-averaged F 1 score, re-
bodyText ||| spectively. We also provide in-depth anal-
bodyText ||| yses of the proposed criteria.
sectionHeader ||| 1 Introduction
bodyText ||| Semantic Role Labeling (SRL) is a task of analyz-
bodyText ||| ing predicate-argument structures in texts. More
bodyText ||| specifically, SRL identifies predicates and their
bodyText ||| arguments with appropriate semantic roles. Re-
bodyText ||| solving surface divergence of texts (e.g., voice
bodyText ||| of verbs and nominalizations) into unified seman-
bodyText ||| tic representations, SRL has attracted much at-
bodyText ||| tention from researchers into various NLP appli-
bodyText ||| cations including question answering (Narayanan
bodyText ||| and Harabagiu, 2004; Shen and Lapata, 2007;
figure ||| buy.v	PropBank	FrameNet
figure ||| Frame	buy.01	Commerce buy
figure ||| Roles	ARG0: buyer	Buyer Goods Seller Money Recipient
figure ||| 	ARG1: thing bought	...
figure ||| 	ARG2: seller
figure ||| 	ARG3: paid
figure ||| 	ARG4: benefactive
figure ||| 	...
figureCaption ||| Figure 1: A comparison of frames for buy.v de-
figureCaption ||| fined in PropBank and FrameNet
bodyText ||| Moschitti et al., 2007), and information extrac-
bodyText ||| tion (Surdeanu et al., 2003).
bodyText ||| In recent years, with the wide availability of cor-
bodyText ||| pora such as PropBank (Palmer et al., 2005) and
bodyText ||| FrameNet (Baker et al., 1998), a number of stud-
bodyText ||| ies have presented statistical approaches to SRL
bodyText ||| (M`arquez et al., 2008). Figure 1 shows an exam-
bodyText ||| ple of the frame definitions for a verb buy in Prop-
bodyText ||| Bank and FrameNet. These corpora define a large
bodyText ||| number of frames and define the semantic roles for
bodyText ||| each frame independently. This fact is problem-
bodyText ||| atic in terms of the performance of the machine-
bodyText ||| learning approach, because these definitions pro-
bodyText ||| duce many roles that have few training instances.
bodyText ||| PropBank defines a frame for each sense of
bodyText ||| predicates (e.g., buy.01), and semantic roles are
bodyText ||| defined in a frame-specific manner (e.g., buyer and
bodyText ||| seller for buy.01). In addition, these roles are asso-
bodyText ||| ciated with tags such as ARG0-5 and AM-*, which
bodyText ||| are commonly used in different frames. Most
bodyText ||| SRL studies on PropBank have used these tags
bodyText ||| in order to gather a sufficient amount of training
bodyText ||| data, and to generalize semantic-role classifiers
bodyText ||| across different frames. However, Yi et al. (2007)
bodyText ||| reported that tags ARG2 –ARG5 were inconsis-
bodyText ||| tent and not that suitable as training instances.
bodyText ||| Some recent studies have addressed alternative ap-
bodyText ||| proaches to generalizing semantic roles across dif-
bodyText ||| ferent frames (Gordon and Swanson, 2007; Zapi-
page ||| 19
note ||| Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 19–27,
note ||| Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP
figure ||| Commerce_sell::Buyer Commerce_buy::Buyer
figure ||| Givi ng:: Reci pi ent
figure ||| Recipient
figure ||| Transfer::Recipient
figure ||| Buyer
figure ||| Agent
figure ||| Commerce_sell::Seller Commerce_buy::Seller
figure ||| Giving::Donor
figure ||| Transfer::Donor
figure ||| Donor
figure ||| Seller
figure ||| role-to-role relation
figure ||| hierarchical class
figure ||| thematic role
figure ||| role descriptor
figureCaption ||| Figure 2: An example of role groupings using different criteria.
figureCaption ||| rain et al., 2008).
bodyText ||| FrameNet designs semantic roles as frame spe-
bodyText ||| cific, but also defines hierarchical relations of se-
bodyText ||| mantic roles among frames. Figure 2 illustrates
bodyText ||| an excerpt of the role hierarchy in FrameNet; this
bodyText ||| figure indicates that the Buyer role for the Com-
bodyText ||| merce buy frame (Commerce buy::Buyer here-
bodyText ||| after) and the Commerce sell::Buyer role are in-
bodyText ||| herited from the Transfer:: Recipient role. Al-
bodyText ||| though the role hierarchy was expected to gener-
bodyText ||| alize semantic roles, no positive results for role
bodyText ||| classification have been reported (Baldewein et al.,
bodyText ||| 2004). Therefore, the generalization of semantic
bodyText ||| roles across different frames has been brought up
bodyText ||| as a critical issue for FrameNet (Gildea and Juraf-
bodyText ||| sky, 2002; Shi and Mihalcea, 2005; Giuglea and
bodyText ||| Moschitti, 2006)
bodyText ||| In this paper, we explore several criteria for gen-
bodyText ||| eralizing semantic roles in FrameNet. In addi-
bodyText ||| tion to the FrameNet hierarchy, we use various
bodyText ||| pieces of information: human-understandable de-
bodyText ||| scriptors of roles, semantic types of filler phrases,
bodyText ||| and mappings from FrameNet roles to the thematic
bodyText ||| roles of VerbNet. We also propose feature func-
bodyText ||| tions that naturally combines these criteria in a
bodyText ||| machine-learning framework. Using the proposed
bodyText ||| method, the experimental result of the role classi-
bodyText ||| fication shows 19.16% and 7.42% improvements
bodyText ||| in error reduction rate and macro-averaged F1, re-
bodyText ||| spectively. We provide in-depth analyses with re-
bodyText ||| spect to these criteria, and state our conclusions.
sectionHeader ||| 2 Related Work
bodyText ||| Moschitti et al. (2005) first classified roles by us-
bodyText ||| ing four coarse-grained classes (Core Roles, Ad-
bodyText ||| juncts, Continuation Arguments and Co-referring
bodyText ||| Arguments), and built a classifier for each coarse-
bodyText ||| grained class to tag PropBank ARG tags. Even
bodyText ||| though the initial classifiers could perform rough
bodyText ||| estimations of semantic roles, this step was not
bodyText ||| able to solve the ambiguity problem in PropBank
bodyText ||| ARG2-5. When training a classifier for a seman-
bodyText ||| tic role, Baldewein et al. (2004) re-used the train-
bodyText ||| ing instances of other roles that were similar to the
bodyText ||| target role. As similarity measures, they used the
bodyText ||| FrameNet hierarchy, peripheral roles of FrameNet,
bodyText ||| and clusters constructed by a EM-based method.
bodyText ||| Gordon and Swanson (2007) proposed a general-
bodyText ||| ization method for the PropBank roles based on
bodyText ||| syntactic similarity in frames.
bodyText ||| Many previous studies assumed that thematic
bodyText ||| roles bridged semantic roles in different frames.
bodyText ||| Gildea and Jurafsky (2002) showed that classifica-
bodyText ||| tion accuracy was improved by manually replac-
bodyText ||| ing FrameNet roles into 18 thematic roles. Shi
bodyText ||| and Mihalcea (2005) and Giuglea and Moschitti
bodyText ||| (2006) employed VerbNet thematic roles as the
bodyText ||| target of mappings from the roles defined by the
bodyText ||| different semantic corpora. Using the thematic
bodyText ||| roles as alternatives of ARG tags, Loper et al.
bodyText ||| (2007) and Yi et al. (2007) demonstrated that the
bodyText ||| classification accuracy of PropBank roles was im-
bodyText ||| proved for ARG2 roles, but that it was diminished
bodyText ||| for ARG1. Yi et al. (2007) also described that
bodyText ||| ARG2–5 were mapped to a variety of thematic
bodyText ||| roles. Zapirain et al. (2008) evaluated PropBank
bodyText ||| ARG tags and VerbNet thematic roles in a state-of-
bodyText ||| the-art SRL system, and concluded that PropBank
bodyText ||| ARG tags achieved a more robust generalization of
bodyText ||| the roles than did VerbNet thematic roles.
sectionHeader ||| 3 Role Classification
bodyText ||| SRL is a complex task wherein several problems
bodyText ||| are intertwined: frame-evoking word identifica-
bodyText ||| tion, frame disambiguation (selecting a correct
bodyText ||| frame from candidates for the evoking word), role-
bodyText ||| phrase identification (identifying phrases that fill
bodyText ||| semantic roles), and role classification (assigning
bodyText ||| correct roles to the phrases). In this paper, we fo-
bodyText ||| cus on role classification, in which the role gen-
bodyText ||| eralization is particularly critical to the machine
bodyText ||| learning approach.
bodyText ||| In the role classification task, we are given a
bodyText ||| sentence, a frame evoking word, a frame, and
page ||| 20
figure ||| Hierarchical-relation groups
figure ||| Role-descriptor groups
figure ||| Thematic-role groups
figure ||| Semantic-type groups
figureCaption ||| Figure 4: Examples for each type of role group.
figure ||| INPUT:
figure ||| frame = Commerce_sell
figure ||| candidate roles = { Seller, Buyer, Goods, Reason, Time, ... , Place}
figure ||| sentence = Can't [you] [sell Commerce_sell] [the factory] [to some other
figure ||| company]?
figure ||| OUTPUT:
figure ||| sentence = Can't [you Seller] [sell Commerce_sell] [the factory Goods]
figure ||| [to some other company Buyer] ?
figureCaption ||| Figure 3: An example of input and output of role
figureCaption ||| classification.
bodyText ||| phrases that take semantic roles. We are inter-
bodyText ||| ested in choosing the correct role from the can-
bodyText ||| didate roles for each phrase in the frame. Figure 3
bodyText ||| shows a concrete example of input and output; the
bodyText ||| semantic roles for the phrases are chosen from the
bodyText ||| candidate roles: Seller, Buyer, Goods, Reason,
bodyText ||| ... , and Place.
bodyText ||| role at a node in the hierarchy inherits the char-
bodyText ||| acteristics of the roles of its ancestor nodes. For
bodyText ||| example, Commerce sell::Seller in Figure 2 in-
bodyText ||| herits the property of Giving:: Donor.
bodyText ||| For Inheritance, Using, Perspective on, and
bodyText ||| Subframe relations, we assume that descendant
bodyText ||| roles in these relations have the same or special-
bodyText ||| ized properties of their ancestors. Hence, for each
bodyText ||| role yi, we define the following two role groups,
equation ||| Hchild	= {y y = yi V y is a child of yi},
equation ||| yi	= {yly = yi V y is a descendant of yij.
equation ||| Hdesc
equation ||| yi
bodyText ||| The hierarchical-relation groups in Figure 4 are
bodyText ||| the illustrations of Hdesc
equation ||| yi	.
bodyText ||| For the relation types Inchoative of and
bodyText ||| Causative of, we define role groups in the oppo-
bodyText ||| site direction of the hierarchy,
sectionHeader ||| 4 Design of Role Groups	Hparent	= {yjy = yi V y is a parent of yi},
equation ||| 	yi	= {yjy = yi V y is anancestor of yij.
equation ||| 	Hance
equation ||| 	yi
bodyText ||| We formalize the generalization of semantic roles
bodyText ||| as the act of grouping several roles into a
bodyText ||| class. We define a role group as a set of
bodyText ||| role labels grouped by a criterion. Figure 4
bodyText ||| shows examples of role groups; a group Giv-
bodyText ||| ing::Donor (in the hierarchical-relation groups)
bodyText ||| contains the roles Giving::Donor and Com-
bodyText ||| merce pay::Buyer. The remainder of this section
bodyText ||| describes the grouping criteria in detail.
subsectionHeader ||| 4.1 Hierarchical relations among roles
bodyText ||| FrameNet defines hierarchical relations among
bodyText ||| frames (frame-to-frame relations). Each relation
bodyText ||| is assigned one of the seven types of directional
bodyText ||| relationships (Inheritance, Using, Perspective on,
bodyText ||| Causative of, Inchoative of, Subframe, and Pre-
bodyText ||| cedes). Some roles in two related frames are also
bodyText ||| connected with role-to-role relations. We assume
bodyText ||| that this hierarchy is a promising resource for gen-
bodyText ||| eralizing the semantic roles; the idea is that the
bodyText ||| This is because lower roles of Inchoative of
bodyText ||| and Causative of relations represent more neu-
bodyText ||| tral stances or consequential states; for example,
bodyText ||| Killing::Victim is a parent of Death:: Protagonist
bodyText ||| in the Causative of relation.
bodyText ||| Finally, the Precedes relation describes the se-
bodyText ||| quence of states and events, but does not spec-
bodyText ||| ify the direction of semantic inclusion relations.
bodyText ||| Therefore, we simply try Hchild Hdesc Hparent
bodyText ||| yi , yi,yi ,
bodyText ||| and Hynce for this relation type.
subsectionHeader ||| 4.2 Human-understandable role descriptor
bodyText ||| FrameNet defines each role as frame-specific; in
bodyText ||| other words, the same identifier does not appear
bodyText ||| in different frames. However, in FrameNet,
bodyText ||| human experts assign a human-understandable
bodyText ||| name to each role in a rather systematic man-
bodyText ||| ner. Some names are shared by the roles in
bodyText ||| different frames, whose identifiers are dif-
bodyText ||| ferent. Therefore, we examine the semantic
page ||| 21
bodyText ||| commonality of these names; we construct an
bodyText ||| equivalence class of the roles sharing the same
bodyText ||| name. We call these human-understandable
bodyText ||| names role descriptors. In Figure 4, the role-
bodyText ||| descriptor group Buyer collects the roles Com-
bodyText ||| merce pay::Buyer, Commerce buy::Buyer,
bodyText ||| and Commerce sell::Buyer.
bodyText ||| This criterion may be effective in collecting
bodyText ||| similar roles since the descriptors have been anno-
bodyText ||| tated by intuition of human experts. As illustrated
bodyText ||| in Figure 2, the role descriptors group the seman-
bodyText ||| tic roles which are similar to the roles that the
bodyText ||| FrameNet hierarchy connects as sister or parent-
bodyText ||| child relations. However, role-descriptor groups
bodyText ||| cannot express the relations between the roles
bodyText ||| as inclusions since they are equivalence classes.
bodyText ||| For example, the roles Commerce sell::Buyer
bodyText ||| and Commerce buy::Buyer are included in the
bodyText ||| role descriptor group Buyer in Figure 2; how-
bodyText ||| ever, it is difficult to merge Giving:: Recipient
bodyText ||| and Commerce sell::Buyer because the Com-
bodyText ||| merce sell:: Buyer has the extra property that one
bodyText ||| gives something of value in exchange and a hu-
bodyText ||| man assigns different descriptors to them. We ex-
bodyText ||| pect that the most effective weighting of these two
bodyText ||| criteria will be determined from the training data.
subsectionHeader ||| 4.3 Semantic type of phrases
bodyText ||| We consider that the selectional restriction is help-
bodyText ||| ful in detecting the semantic roles. FrameNet pro-
bodyText ||| vides information concerning the semantic types
bodyText ||| of role phrases (fillers); phrases that play spe-
bodyText ||| cific roles in a sentence should fulfill the se-
bodyText ||| mantic constraint from this information. For
bodyText ||| instance, FrameNet specifies the constraint that
bodyText ||| Self motion::Area should be filled by phrases
bodyText ||| whose semantic type is Location. Since these
bodyText ||| types suggest a coarse-grained categorization of
bodyText ||| semantic roles, we construct role groups that con-
bodyText ||| tain roles whose semantic types are identical.
subsectionHeader ||| 4.4 Thematic roles of VerbNet
bodyText ||| VerbNet thematic roles are 23 frame-independent
bodyText ||| semantic categories for arguments of verbs,
bodyText ||| such as Agent, Patient, Theme and Source.
bodyText ||| These categories have been used as consis-
bodyText ||| tent labels across verbs. We use a partial
bodyText ||| mapping between FrameNet roles and Verb-
bodyText ||| Net thematic roles provided by SemLink. 1
bodyText ||| Each group is constructed as a set Tti =
footnote ||| 1http://verbs.colorado.edu/semlink/
bodyText ||| {yISemLink maps y into the thematic role ti}.
bodyText ||| SemLink currently maps 1,726 FrameNet roles
bodyText ||| into VerbNet thematic roles, which are 37.61% of
bodyText ||| roles appearing at least once in the FrameNet cor-
bodyText ||| pus. This may diminish the effect of thematic-role
bodyText ||| groups than its potential.
sectionHeader ||| 5 Role classification method
subsectionHeader ||| 5.1 Traditional approach
bodyText ||| We are given a frame-evoking word e, a frame f
bodyText ||| and a role phrase x detected by a human or some
bodyText ||| automatic process in a sentence s. Let Yf be the
bodyText ||| set of semantic roles that FrameNet defines as be-
bodyText ||| ing possible role assignments for the frame f, and
bodyText ||| let x = {x1, ... , x,,,} be observed features for x
bodyText ||| from s, e and f . The task of semantic role classifi-
bodyText ||| cation can be formalized as the problem of choos-
bodyText ||| ing the most suitable role y� from Yf. Suppose we
bodyText ||| have a model P(yIf, x) which yields the condi-
bodyText ||| tional probability of the semantic role y for given
bodyText ||| f and x. Then we can choose y� as follows:
equation ||| y� = argmax P(y� f, x).	(1)
equation ||| yEYf
bodyText ||| A traditional way to incorporate role groups
bodyText ||| into this formalization is to overwrite each role
bodyText ||| y in the training and test data with its role
bodyText ||| group m(y) according to the memberships of
bodyText ||| the group. For example, semantic roles Com-
bodyText ||| merce sell::Seller and Giving::Donor can be re-
bodyText ||| placed by their thematic-role group Theme::Agent
bodyText ||| in this approach. We determine the most suitable
bodyText ||| role group c� as follows:
equation ||| c� = argmax P-(c�f, x).	(2)
equation ||| cE �-(y)�yEYf}
bodyText ||| Here, P-(c�f, x) presents the probability of the
bodyText ||| role group c for f and x. The role y� is determined
bodyText ||| uniquely iff a single role y E Yf is associated
bodyText ||| with �c. Some previous studies have employed this
bodyText ||| idea to remedy the data sparseness problem in the
bodyText ||| training data (Gildea and Jurafsky, 2002). How-
bodyText ||| ever, we cannot apply this approach when multi-
bodyText ||| ple roles in Yf are contained in the same class. For
bodyText ||| example, we can construct a semantic-type group
bodyText ||| St::State of affairs in which Giving::Reason and
bodyText ||| Giving:: Means are included, as illustrated in Fig-
bodyText ||| ure 4. If c� = St:: State of affairs, we cannot dis-
bodyText ||| ambiguate which original role is correct. In ad-
bodyText ||| dition, it may be more effective to use various
page ||| 22
bodyText ||| groupings of roles together in the model. For in-
bodyText ||| stance, the model could predict the correct role
bodyText ||| Commerce sell::Seller for the phrase “you” in
bodyText ||| Figure 3 more confidently, if it could infer its
bodyText ||| thematic-role group as Theme::Agent and its par-
bodyText ||| ent group Giving::Donor correctly. Although the
bodyText ||| ensemble of various groupings seems promising,
bodyText ||| we need an additional procedure to prioritize the
bodyText ||| groupings for the case where the models for mul-
bodyText ||| tiple role groupings disagree; for example, it is un-
bodyText ||| satisfactory if two models assign the groups Giv-
bodyText ||| ing:: Theme and Theme::Agent to the same phrase.
subsectionHeader ||| 5.2 Role groups as feature functions
bodyText ||| We thus propose another approach that incorpo-
bodyText ||| rates group information as feature functions. We
bodyText ||| model the conditional probability P(y� f, x) by us-
bodyText ||| ing the maximum entropy framework,
equation ||| exp(Ei Aigi(x, y))
equation ||| �( y� f, x) = Ey,Y, exp(Ei Aigi(x, y)). (3)
bodyText ||| Here, G = Jgi� denotes a set of n feature func-
bodyText ||| tions, and A = JAi� denotes a weight vector for
bodyText ||| the feature functions.
bodyText ||| In general, feature functions for the maximum
bodyText ||| entropy model are designed as indicator functions
bodyText ||| for possible pairs of xj and y. For example, the
bodyText ||| event where the head word of x is “you” (xi = 1)
bodyText ||| and x plays the role Commerce sell::Seller in a
bodyText ||| sentence is expressed by the indicator function,
equation ||| 1 (xi =1A
equation ||| y = Commerce sell::Seller)
equation ||| 0 (otherwise)
equation ||| (4)
bodyText ||| We call this kind of feature function an x-role.
bodyText ||| In order to incorporate role groups into the
bodyText ||| model, we also include all feature functions for
bodyText ||| possible pairs of xj and role groups. Equation 5
bodyText ||| is an example of a feature function for instances
bodyText ||| where the head word of x is “you” and y is in the
bodyText ||| role group Theme::Agent,
equation ||| 1 (xi=1A
equation ||| y E Theme::Agent) . (5)
equation ||| 0 (otherwise)
bodyText ||| Thus, this feature function fires for the roles wher-
bodyText ||| ever the head word “you” plays Agent (e.g., Com-
bodyText ||| merce sell::Seller, Commerce buy::Buyer and
bodyText ||| Giving:: Donor). We call this kind of feature func-
bodyText ||| tion an x-group function.
bodyText ||| In this way, we obtain x-group functions for
bodyText ||| all grouping methods, e.g., gtheme
bodyText ||| k, ghierarchy
bodyText ||| k .
bodyText ||| The role-group features will receive more training
bodyText ||| instances by collecting instances for fine-grained
bodyText ||| roles. Thus, semantic roles with few training in-
bodyText ||| stances are expected to receive additional clues
bodyText ||| from other training instances via role-group fea-
bodyText ||| tures. Another advantage of this approach is that
bodyText ||| the usefulness of the different role groups is de-
bodyText ||| termined by the training processes in terms of
bodyText ||| weights of feature functions. Thus, we do not need
bodyText ||| to assume that we have found the best criterion for
bodyText ||| grouping roles; we can allow a training process to
bodyText ||| choose the criterion. We will discuss the contribu-
bodyText ||| tions of different groupings in the experiments.
subsectionHeader ||| 5.3 Comparison with related work
bodyText ||| Baldewein et al. (2004) suggested an approach
bodyText ||| that uses role descriptors and hierarchical rela-
bodyText ||| tions as criteria for generalizing semantic roles
bodyText ||| in FrameNet. They created a classifier for each
bodyText ||| frame, additionally using training instances for the
bodyText ||| role A to train the classifier for the role B, if the
bodyText ||| roles A and B were judged as similar by a crite-
bodyText ||| rion. This approach performs similarly to the over-
bodyText ||| writing approach, and it may obscure the differ-
bodyText ||| ences among roles. Therefore, they only re-used
bodyText ||| the descriptors as a similarity measure for the roles
bodyText ||| whose coreness was peripheral. 2
bodyText ||| In contrast, we use all kinds of role descriptors
bodyText ||| to construct groups. Since we use the feature func-
bodyText ||| tions for both the original roles and their groups,
bodyText ||| appropriate units for classification are determined
bodyText ||| automatically in the training process.
sectionHeader ||| 6 Experiment and Discussion
bodyText ||| We used the training set of the Semeval-2007
bodyText ||| Shared task (Baker et al., 2007) in order to ascer-
bodyText ||| tain the contributions of role groups. This dataset
bodyText ||| consists of the corpus of FrameNet release 1.3
bodyText ||| (containing roughly 150,000 annotations), and an
bodyText ||| additional full-text annotation dataset. We ran-
bodyText ||| domly extracted 10% of the dataset for testing, and
bodyText ||| used the remainder (90%) for training.
bodyText ||| Performance was measured by micro- and
bodyText ||| macro-averaged F 1(Chang and Zheng, 2008) with
bodyText ||| respect to a variety of roles. The micro average bi-
bodyText ||| ases each F1 score by the frequencies of the roles,
footnote ||| 2In FrameNet, each role is assigned one of four different
footnote ||| types of coreness (core, core-unexpressed, peripheral, extra-
footnote ||| thematic) It represents the conceptual necessity of the roles
footnote ||| in the frame to which it belongs.
equation ||| giole(x, y) = {
equation ||| .
equation ||| gtheme
equation ||| 2(x, y) =
equation ||| {
page ||| 23
bodyText ||| and the average is equal to the classification accu-
bodyText ||| racy when we calculate it with all of the roles in
bodyText ||| the test set. In contrast, the macro average does
bodyText ||| not bias the scores, thus the roles having a small
bodyText ||| number of instances affect the average more than
bodyText ||| the micro average.
subsectionHeader ||| 6.1 Experimental settings
bodyText ||| We constructed a baseline classifier that uses
bodyText ||| only the x-role features. The feature de-
bodyText ||| sign is similar to that of the previous stud-
bodyText ||| ies (M`arquez et al., 2008). The characteristics
bodyText ||| of x are: frame, frame evoking word, head
bodyText ||| word, content word (Surdeanu et al., 2003),
bodyText ||| first/last word, head word of left/right sister,
bodyText ||| phrase type, position, voice, syntactic path (di-
bodyText ||| rected/undirected/partial), governing category
bodyText ||| (Gildea and Jurafsky, 2002), WordNet super-
bodyText ||| sense in the phrase, combination features of
bodyText ||| frame evoking word & headword, combination
bodyText ||| features of frame evoking word & phrase type,
bodyText ||| and combination features of voice & phrase type.
bodyText ||| We also used PoS tags and stem forms as extra
bodyText ||| features of any word-features.
bodyText ||| We employed Charniak and Johnson’s rerank-
bodyText ||| ing parser (Charniak and Johnson, 2005) to an-
bodyText ||| alyze syntactic trees. As an alternative for the
bodyText ||| traditional named-entity features, we used Word-
bodyText ||| Net supersenses: 41 coarse-grained semantic cate-
bodyText ||| gories of words such as person, plant, state, event,
bodyText ||| time, location. We used Ciaramita and Altun’s Su-
bodyText ||| per Sense Tagger (Ciaramita and Altun, 2006) to
bodyText ||| tag the supersenses. The baseline system achieved
bodyText ||| 89.00% with respect to the micro-averaged F1.
bodyText ||| The x-group features were instantiated similarly
bodyText ||| to the x-role features; the x-group features com-
bodyText ||| bined the characteristics of x with the role groups
bodyText ||| presented in this paper. The total number of fea-
bodyText ||| tures generated for all x-roles and x-groups was
bodyText ||| 74,873,602. The optimal weights A of the fea-
bodyText ||| tures were obtained by the maximum a poste-
bodyText ||| rior (MAP) estimation. We maximized an L2-
bodyText ||| regularized log-likelihood of the training set us-
bodyText ||| ing the Limited-memory BFGS (L-BFGS) method
bodyText ||| (Nocedal, 1980).
subsectionHeader ||| 6.2 Effect of role groups
bodyText ||| Table 1 shows the micro and macro averages of F 1
bodyText ||| scores. Each role group type improved the micro
bodyText ||| average by 0.5 to 1.7 points. The best result was
bodyText ||| obtained by using all types of groups together. The
bodyText ||| result indicates that different kinds of group com-
table ||| Feature	Micro	Macro	-Err.
table ||| Baseline	89.00	68.50	0.00
table ||| role descriptor	90.78	76.58	16.17
table ||| role descriptor (replace)	90.23	76.19	11.23
table ||| hierarchical relation	90.25	72.41	11.40
table ||| semantic type	90.36	74.51	12.38
table ||| VN thematic role	89.50	69.21	4.52
table ||| All	91.10	75.92	19.16
tableCaption ||| Table 1: The accuracy and error reduction rate of
tableCaption ||| role classification for each type of role group.
table ||| Feature	#instances	Pre.	Rec.	Micro
table ||| baseline	< 10	63.89	38.00	47.66
table ||| 	< 20	69.01	51.26	58.83
table ||| 	<50	75.84	65.85	70.50
table ||| + all groups	< 10	72.57	55.85	63.12
table ||| 	<20	76.30	65.41	70.43
table ||| 	< 50	80.86	74.59	77.60
tableCaption ||| Table 2: The effect of role groups on the roles with
tableCaption ||| few instances.
bodyText ||| plement each other with respect to semantic role
bodyText ||| generalization. Baldewein et al. (2004) reported
bodyText ||| that hierarchical relations did not perform well for
bodyText ||| their method and experimental setting; however,
bodyText ||| we found that significant improvements could also
bodyText ||| be achieved with hierarchical relations. We also
bodyText ||| tried a traditional label-replacing approach with
bodyText ||| role descriptors (in the third row of Table 1). The
bodyText ||| comparison between the second and third rows in-
bodyText ||| dicates that mixing the original fine-grained roles
bodyText ||| and the role groups does result in a more accurate
bodyText ||| classification.
bodyText ||| By using all types of groups together, the
bodyText ||| model reduced 19.16 % of the classification errors
bodyText ||| from the baseline. Moreover, the macro-averaged
bodyText ||| F1 scores clearly showed improvements resulting
bodyText ||| from using role groups. In order to determine
bodyText ||| the reason for the improvements, we measured
bodyText ||| the precision, recall, and F1-scores with respect
bodyText ||| to roles for which the number of training instances
bodyText ||| was at most 10, 20, and 50. In Table 2, we show
bodyText ||| that the micro-averaged F1 score for roles hav-
bodyText ||| ing 10 instances or less was improved (by 15.46
bodyText ||| points) when all role groups were used. This result
bodyText ||| suggests the reason for the effect of role groups; by
bodyText ||| bridging similar semantic roles, they supply roles
bodyText ||| having a small number of instances with the infor-
bodyText ||| mation from other roles.
subsectionHeader ||| 6.3 Analyses of role descriptors
bodyText ||| In Table 1, the largest improvement was obtained
bodyText ||| by the use of role descriptors. We analyze the ef-
bodyText ||| fect of role descriptors in detail in Tables 3 and 4.
bodyText ||| Table 3 shows the micro-averaged F 1 scores of all
page ||| 24
table ||| Coreness	#roles	#instances/#role	#groups	#instances/#group	#roles/#group
table ||| Core	1902	122.06	655	354.4	2.9
table ||| Peripheral	1924	25.24	250	194.3	7.7
table ||| Extra-thematic	763	13.90	171	62.02	4.5
tableCaption ||| Table 4: The analysis of the numbers of roles, instances, and role-descriptor groups, for each type of
tableCaption ||| coreness.
table ||| Coreness	Micro
table ||| Baseline	89.00
table ||| Core	89.51
table ||| Peripheral	90.12
table ||| Extra-thematic	89.09
table ||| All	90.77
tableCaption ||| Table 3: The effect of employing role-descriptor
bodyText ||| groups of each type of coreness.
bodyText ||| semantic roles when we use role-descriptor groups
bodyText ||| constructed from each type of coreness (core3, pe-
bodyText ||| ripheral, and extra-thematic) individually. The pe-
bodyText ||| ripheral type generated the largest improvements.
bodyText ||| Table 4 shows the number of roles associated
bodyText ||| with each type of coreness (#roles), the number of
bodyText ||| instances for the original roles (#instances/#role),
bodyText ||| the number of groups for each type of coreness
bodyText ||| (#groups), the number of instances for each group
bodyText ||| (#instances/#group), and the number of roles per
bodyText ||| each group (#roles/#group). In the peripheral
bodyText ||| type, the role descriptors subdivided 1,924 distinct
bodyText ||| roles into 250 groups, each of which contained 7.7
bodyText ||| roles on average. The peripheral type included
bodyText ||| semantic roles such as place, time, reason, dura-
bodyText ||| tion. These semantic roles appear in many frames,
bodyText ||| because they have general meanings that can be
bodyText ||| shared by different frames. Moreover, the seman-
bodyText ||| tic roles of peripheral type originally occurred in
bodyText ||| only a small number (25.24) of training instances
bodyText ||| on average. Thus, we infer that the peripheral
bodyText ||| type generated the largest improvement because
bodyText ||| semantic roles in this type acquired the greatest
bodyText ||| benefit from the generalization.
subsectionHeader ||| 6.4 Hierarchical relations and relation types
bodyText ||| We analyzed the contributions of the FrameNet hi-
bodyText ||| erarchy for each type of role-to-role relations and
bodyText ||| for different depths of grouping. Table 5 shows
bodyText ||| the micro-averaged F1 scores obtained from var-
bodyText ||| ious relation types and depths. The Inheritance
bodyText ||| and Using relations resulted in a slightly better ac-
bodyText ||| curacy than the other types. We did not observe
bodyText ||| any real differences among the remaining five re-
bodyText ||| lation types, possibly because there were few se-
footnote ||| 3 We include Core-unexpressed in core, because it has a
footnote ||| property of core inside one frame.
table ||| No.	Relation Type	Micro
table ||| -	baseline	89.00
table ||| 1	+ Inheritance (children)	89.52
table ||| 2	+ Inheritance (descendants)	89.70
table ||| 3	+Using (children)	89.35
table ||| 4	+Using (descendants)	89.37
table ||| 5	+ Perspective on (children)	89.01
table ||| 6	+ Perspective on (descendants)	89.01
table ||| 7	+ Subframe (children)	89.04
table ||| 8	+ Subframe (descendants)	89.05
table ||| 9	+ Causative of (parents)	89.03
table ||| 10	+ Causative of (ancestors)	89.03
table ||| 11	+ Inchoative of (parents)	89.02
table ||| 12	+ Inchoative of (ancestors)	89.02
table ||| 13	+Precedes (children)	89.01
table ||| 14	+Precedes (descendants)	89.03
table ||| 15	+Precedes (parents)	89.00
table ||| 16	+Precedes (ancestors)	89.00
table ||| 18	+all relations (2,4,6,8,10,12,14)	90.25
tableCaption ||| Table 5: Comparison of the accuracy with differ-
tableCaption ||| ent types of hierarchical relations.
bodyText ||| mantic roles associated with these types. We ob-
bodyText ||| tained better results by using not only groups for
bodyText ||| parent roles, but also groups for all ancestors. The
bodyText ||| best result was obtained by using all relations in
bodyText ||| the hierarchy.
subsectionHeader ||| 6.5 Analyses of different grouping criteria
bodyText ||| Table 6 reports the precision, recall, and micro-
bodyText ||| averaged F1 scores of semantic roles with respect
bodyText ||| to each coreness type .4 In general, semantic roles
bodyText ||| of the core coreness were easily identified by all
bodyText ||| of the grouping criteria; even the baseline system
bodyText ||| obtained an F 1 score of 91.93. For identifying se-
bodyText ||| mantic roles of the peripheral and extra-thematic
bodyText ||| types of coreness, the simplest solution, the de-
bodyText ||| scriptor criterion, outperformed other criteria.
bodyText ||| In Table 7, we categorize feature functions
bodyText ||| whose weights are in the top 1000 in terms of
bodyText ||| greatest absolute value. The behaviors of the role
bodyText ||| groups can be distinguished by the following two
bodyText ||| characteristics. Groups of role descriptors and se-
bodyText ||| mantic types have large weight values for the first
bodyText ||| word and supersense features, which capture the
bodyText ||| characteristics of adjunctive phrases. The original
bodyText ||| roles and hierarchical-relation groups have strong
footnote ||| 4The figures of role descriptors in Tables 4 and 6 differ.
footnote ||| In Table 4, we measured the performance when we used one
footnote ||| or all types of coreness for training. In contrast, in Table 6,
footnote ||| we used all types of coreness for training, but computed the
footnote ||| performance of semantic roles for each coreness separately.
page ||| 25
table ||| Feature	Type	Pre.	Rec.	Micro
table ||| baseline	c	91.07	92.83	91.93
table ||| 	p	81.05	76.03	78.46
table ||| 	e	78.17	66.51	71.87
table ||| + descriptor group	c	92.50	93.41	92.95
table ||| 	p	84.32	82.72	83.51
table ||| 	e	80.91	69.59	74.82
table ||| +hierarchical	c	92.10	93.28	92.68
table ||| relation	p	82.23	79.84	81.01
table ||| class	e	77.94	65.58	71.23
table ||| + semantic	c	92.23	93.31	92.77
table ||| type group	p	83.66	81.76	82.70
table ||| 	e	80.29	67.26	73.20
table ||| + VN thematic	c	91.57	93.06	92.31
table ||| role group	p	80.66	76.95	78.76
table ||| 	e	78.12	66.60	71.90
table ||| + all group	c	92.66	93.61	93.13
table ||| 	p	84.13	82.51	83.31
table ||| 	e	80.77	68.56	74.17
tableCaption ||| Table 6: The precision and recall of each type of
tableCaption ||| coreness with role groups. Type represents the
tableCaption ||| type of coreness; c denotes core, p denotes periph-
tableCaption ||| eral, and e denotes extra-thematic.
bodyText ||| associations with lexical and structural character-
bodyText ||| istics such as the syntactic path, content word, and
bodyText ||| head word. Table 7 suggests that role-descriptor
bodyText ||| groups and semantic-type groups are effective for
bodyText ||| peripheral or adjunctive roles, and hierarchical re-
bodyText ||| lation groups are effective for core roles.
sectionHeader ||| 7 Conclusion
bodyText ||| We have described different criteria for general-
bodyText ||| izing semantic roles in FrameNet. They were:
bodyText ||| role hierarchy, human-understandable descriptors
bodyText ||| of roles, semantic types of filler phrases, and
bodyText ||| mappings from FrameNet roles to thematic roles
bodyText ||| of VerbNet. We also proposed a feature design
bodyText ||| that combines and weights these criteria using the
bodyText ||| training data. The experimental result of the role
bodyText ||| classification task showed a 19.16% of the error
bodyText ||| reduction and a 7.42% improvement in the macro-
bodyText ||| averaged F1 score. In particular, the method we
bodyText ||| have presented was able to classify roles having
bodyText ||| few instances. We confirmed that modeling the
bodyText ||| role generalization at feature level was better than
bodyText ||| the conventional approach that replaces semantic
bodyText ||| role labels.
bodyText ||| Each criterion presented in this paper improved
bodyText ||| the accuracy of classification. The most success-
bodyText ||| ful criterion was the use of human-understandable
bodyText ||| role descriptors. Unfortunately, the FrameNet hi-
bodyText ||| erarchy did not outperform the role descriptors,
bodyText ||| contrary to our expectations. A future direction
bodyText ||| of this study would be to analyze the weakness of
bodyText ||| the FrameNet hierarchy in order to discuss possi-
bodyText ||| ble improvement of the usage and annotations of
table ||| features of x	class type
table ||| 	or	hr	rl	st	vn
table ||| frame	0	4	0	1	0
table ||| evoking word	3	4	7	3	0
table ||| ew & hw stem	9	34	20	8	0
table ||| ew & phrase type	11	7	11	3	1
table ||| head word	13	19	8	3	1
table ||| hw stem	11	17	8	8	1
table ||| content word	7	19	12	3	0
table ||| cw stem	11	26	13	5	0
table ||| cw PoS	4	5	14	15	2
table ||| directed path	19	27	24	6	7
table ||| undirected path	21	35	17	2	6
table ||| partial path	15	18	16	13	5
table ||| last word	15	18	12	3	2
table ||| first word	11	23	53	26	10
table ||| supersense	7	7	35	25	4
table ||| position	4	6	30	9	5
table ||| others	27	29	33	19	6
table ||| total	188	298	313	152	50
tableCaption ||| Table 7: The analysis of the top 1000 feature func-
tableCaption ||| tions. Each number denotes the number of feature
tableCaption ||| functions categorized in the corresponding cell.
tableCaption ||| Notations for the columns are as follows. ‘or’:
tableCaption ||| original role, ‘hr’: hierarchical relation, ‘rd’: role
tableCaption ||| descriptor, ‘st’: semantic type, and ‘vn’: VerbNet
tableCaption ||| thematic role.
bodyText ||| the hierarchy.
bodyText ||| Since we used the latest release of FrameNet
bodyText ||| in order to use a greater number of hierarchical
bodyText ||| role-to-role relations, we could not make a direct
bodyText ||| comparison of performance with that of existing
bodyText ||| systems; however we may say that the 89.00% F 1
bodyText ||| micro-average of our baseline system is roughly
bodyText ||| comparable to the 88.93% value of Bejan and
bodyText ||| Hathaway (2007) for SemEval-2007 (Baker et al.,
bodyText ||| 2007). 5 In addition, the methodology presented in
bodyText ||| this paper applies generally to any SRL resources;
bodyText ||| we are planning to determine several grouping cri-
bodyText ||| teria from existing linguistic resources and to ap-
bodyText ||| ply the methodology to the PropBank corpus.
sectionHeader ||| Acknowledgments
bodyText ||| The authors thank Sebastian Riedel for his useful
bodyText ||| comments on our work. This work was partially
bodyText ||| supported by Grant-in-Aid for Specially Promoted
bodyText ||| Research (MEXT, Japan).
sectionHeader ||| References
reference ||| Collin F. Baker, Charles J. Fillmore, and John B. Lowe.
reference ||| 1998. The berkeley framenet project. In Proceed-
reference ||| ings of Coling -ACL 1998, pages 86–90.
reference ||| Collin Baker, Michael Ellsworth, and Katrin Erk.
reference ||| 2007. Semeval-2007 task 19: Frame semantic struc-
footnote ||| 5There were two participants that performed whole SRL
footnote ||| in SemEval-2007. Bejan and Hathaway (2007) evaluated role
footnote ||| classification accuracy separately for the training data.
page ||| 26
reference ||| ture extraction. In Proceedings of SemEval-2007,
reference ||| pages 99–104.
reference ||| Ulrike Baldewein, Katrin Erk, Sebastian Pad´o, and
reference ||| Detlef Prescher. 2004. Semantic role labeling
reference ||| with similarity based generalization using EM-based
reference ||| clustering. In Proceedings of Senseval-3, pages 64–
reference ||| 68.
reference ||| Cosmin Adrian Bejan and Chris Hathaway. 2007.
reference ||| UTD-SRL: A Pipeline Architecture for Extract-
reference ||| ing Frame Semantic Structures. In Proceedings
reference ||| of SemEval-2007, pages 460–463. Association for
reference ||| Computational Linguistics.
reference ||| X. Chang and Q. Zheng. 2008. Knowledge Ele-
reference ||| ment Extraction for Knowledge-Based Learning Re-
reference ||| sources Organization. Lecture Notes in Computer
reference ||| Science, 4823:102–113.
reference ||| Eugene Charniak and Mark Johnson. 2005. Coarse-
reference ||| to-fine n-best parsing and MaxEnt discriminative
reference ||| reranking. In Proceedings of the 43rd Annual Meet-
reference ||| ing on Association for Computational Linguistics,
reference ||| pages 173–180.
reference ||| Massimiliano Ciaramita and Yasemin Altun. 2006.
reference ||| Broad-coverage sense disambiguation and informa-
reference ||| tion extraction with a supersense sequence tagger. In
reference ||| Proceedings ofEMNLP-2006, pages 594–602.
reference ||| Daniel Gildea and Daniel Jurafsky. 2002. Automatic
reference ||| labeling of semantic roles. Computational Linguis-
reference ||| tics, 28(3):245–288.
reference ||| Ana-Maria Giuglea and Alessandro Moschitti. 2006.
reference ||| Semantic role labeling via FrameNet, VerbNet and
reference ||| PropBank. In Proceedings of the 21st International
reference ||| Conference on Computational Linguistics and the
reference ||| 44th Annual Meeting of the ACL, pages 929–936.
reference ||| Andrew Gordon and Reid Swanson. 2007. General-
reference ||| izing semantic role annotations across syntactically
reference ||| similar verbs. In Proceedings of ACL-2007, pages
reference ||| 192–199.
reference ||| Edward Loper, Szu-ting Yi, and Martha Palmer. 2007.
reference ||| Combining lexical resources: Mapping between
reference ||| propbank and verbnet. In Proceedings of the 7th In-
reference ||| ternational Workshop on Computational Semantics,
reference ||| pages 118–128.
reference ||| Lluis M`arquez, Xavier Carreras, Kenneth C.
reference ||| Litkowski, and Suzanne Stevenson. 2008. Se-
reference ||| mantic role labeling: an introduction to the special
reference ||| issue. Computational linguistics, 34(2):145–159.
reference ||| Alessandro Moschitti, Ana-Maria Giuglea, Bonaven-
reference ||| tura Coppola, and Roberto Basili. 2005. Hierar-
reference ||| chical semantic role labeling. In Proceedings of
reference ||| CoNLL-2005, pages 201–204.
reference ||| Alessandro Moschitti, Silvia Quarteroni, Roberto
reference ||| Basili, and Suresh Manandhar. 2007. Exploiting
reference ||| syntactic and shallow semantic kernels for question
reference ||| answer classification. In Proceedings of ACL-07,
reference ||| pages 776–783.
reference ||| Srini Narayanan and Sanda Harabagiu. 2004. Ques-
reference ||| tion answering based on semantic structures. In Pro-
reference ||| ceedings of Coling-2004, pages 693–701.
reference ||| Jorge Nocedal. 1980. Updating quasi-newton matrices
reference ||| with limited storage. Mathematics of Computation,
reference ||| 35(151):773–782.
reference ||| Martha Palmer, Daniel Gildea, and Paul Kingsbury.
reference ||| 2005. The proposition bank: An annotated cor-
reference ||| pus of semantic roles. Computational Linguistics,
reference ||| 31(1):71–106.
reference ||| Dan Shen and Mirella Lapata. 2007. Using semantic
reference ||| roles to improve question answering. In Proceed-
reference ||| ings ofEMNLP-CoNLL 2007, pages 12–21.
reference ||| Lei Shi and Rada Mihalcea. 2005. Putting Pieces To-
reference ||| gether: Combining FrameNet, VerbNet and Word-
reference ||| Net for Robust Semantic Parsing. In Proceedings of
reference ||| CICLing-2005, pages 100–111.
reference ||| Mihai Surdeanu, Sanda Harabagiu, John Williams, and
reference ||| Paul Aarseth. 2003. Using predicate-argument
reference ||| structures for information extraction. In Proceed-
reference ||| ings ofACL-2003, pages 8–15.
reference ||| Szu-ting Yi, Edward Loper, and Martha Palmer. 2007.
reference ||| Can semantic roles generalize across genres? In
reference ||| Proceedings ofHLT-NAACL 2007, pages 548–555.
reference ||| Be˜nat Zapirain, Eneko Agirre, and Lluis M`arquez.
reference ||| 2008. Robustness and generalization of role sets:
reference ||| PropBank vs. VerbNet. In Proceedings of ACL-08:
reference ||| HLT, pages 550–558.
page ||| 27

title ||| Unsupervised Argument Identification for Semantic Role Labeling
author ||| Omri Abend' Roi Reichart2 Ari Rappoport'
affiliation ||| 'Institute of Computer Science, 2ICNC
affiliation ||| Hebrew University of Jerusalem
email ||| {omria01|roiri|arir}@cs.huji.ac.il
sectionHeader ||| Abstract
bodyText ||| The task of Semantic Role Labeling
bodyText ||| (SRL) is often divided into two sub-tasks:
bodyText ||| verb argument identification, and argu-
bodyText ||| ment classification. Current SRL algo-
bodyText ||| rithms show lower results on the identifi-
bodyText ||| cation sub-task. Moreover, most SRL al-
bodyText ||| gorithms are supervised, relying on large
bodyText ||| amounts of manually created data. In
bodyText ||| this paper we present an unsupervised al-
bodyText ||| gorithm for identifying verb arguments,
bodyText ||| where the only type of annotation required
bodyText ||| is POS tagging. The algorithm makes use
bodyText ||| of a fully unsupervised syntactic parser,
bodyText ||| using its output in order to detect clauses
bodyText ||| and gather candidate argument colloca-
bodyText ||| tion statistics. We evaluate our algorithm
bodyText ||| on PropBank10, achieving a precision of
bodyText ||| 56%, as opposed to 47% of a strong base-
bodyText ||| line. We also obtain an 8% increase in
bodyText ||| precision for a Spanish corpus. This is
bodyText ||| the first paper that tackles unsupervised
bodyText ||| verb argument identification without using
bodyText ||| manually encoded rules or extensive lexi-
bodyText ||| cal or syntactic resources.
sectionHeader ||| 1 Introduction
bodyText ||| Semantic Role Labeling (SRL) is a major NLP
bodyText ||| task, providing a shallow sentence-level semantic
bodyText ||| analysis. SRL aims at identifying the relations be-
bodyText ||| tween the predicates (usually, verbs) in the sen-
bodyText ||| tence and their associated arguments.
bodyText ||| The SRL task is often viewed as consisting of
bodyText ||| two parts: argument identification (ARGID) and ar-
bodyText ||| gument classification. The former aims at identi-
bodyText ||| fying the arguments of a given predicate present
bodyText ||| in the sentence, while the latter determines the
bodyText ||| type of relation that holds between the identi-
bodyText ||| fied arguments and their corresponding predicates.
bodyText ||| The division into two sub-tasks is justified by
bodyText ||| the fact that they are best addressed using differ-
bodyText ||| ent feature sets (Pradhan et al., 2005). Perfor-
bodyText ||| mance in the ARGID stage is a serious bottleneck
bodyText ||| for general SRL performance, since only about
bodyText ||| 81% of the arguments are identified, while about
bodyText ||| 95% of the identified arguments are labeled cor-
bodyText ||| rectly (M`arquez et al., 2008).
bodyText ||| SRL is a complex task, which is reflected by the
bodyText ||| algorithms used to address it. A standard SRL al-
bodyText ||| gorithm requires thousands to dozens of thousands
bodyText ||| sentences annotated with POS tags, syntactic an-
bodyText ||| notation and SRL annotation. Current algorithms
bodyText ||| show impressive results but only for languages and
bodyText ||| domains where plenty of annotated data is avail-
bodyText ||| able, e.g., English newspaper texts (see Section 2).
bodyText ||| Results are markedly lower when testing is on a
bodyText ||| domain wider than the training one, even in En-
bodyText ||| glish (see the WSJ-Brown results in (Pradhan et
bodyText ||| al., 2008)).
bodyText ||| Only a small number of works that do not re-
bodyText ||| quire manually labeled SRL training data have
bodyText ||| been done (Swier and Stevenson, 2004; Swier and
bodyText ||| Stevenson, 2005; Grenager and Manning, 2006).
bodyText ||| These papers have replaced this data with the
bodyText ||| VerbNet (Kipper et al., 2000) lexical resource or
bodyText ||| a set of manually written rules and supervised
bodyText ||| parsers.
bodyText ||| A potential answer to the SRL training data bot-
bodyText ||| tleneck are unsupervised SRL models that require
bodyText ||| little to no manual effort for their training. Their
bodyText ||| output can be used either by itself, or as training
bodyText ||| material for modern supervised SRL algorithms.
bodyText ||| In this paper we present an algorithm for unsu-
bodyText ||| pervised argument identification. The only type of
bodyText ||| annotation required by our algorithm is POS tag-
page ||| 28
note ||| Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 28–36,
note ||| Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP
bodyText ||| ging, which needs relatively little manual effort.
bodyText ||| The algorithm consists of two stages. As pre-
bodyText ||| processing, we use a fully unsupervised parser to
bodyText ||| parse each sentence. Initially, the set of possi-
bodyText ||| ble arguments for a given verb consists of all the
bodyText ||| constituents in the parse tree that do not contain
bodyText ||| that predicate. The first stage of the algorithm
bodyText ||| attempts to detect the minimal clause in the sen-
bodyText ||| tence that contains the predicate in question. Us-
bodyText ||| ing this information, it further reduces the possible
bodyText ||| arguments only to those contained in the minimal
bodyText ||| clause, and further prunes them according to their
bodyText ||| position in the parse tree. In the second stage we
bodyText ||| use pointwise mutual information to estimate the
bodyText ||| collocation strength between the arguments and
bodyText ||| the predicate, and use it to filter out instances of
bodyText ||| weakly collocating predicate argument pairs.
bodyText ||| We use two measures to evaluate the perfor-
bodyText ||| mance of our algorithm, precision and F-score.
bodyText ||| Precision reflects the algorithm’s applicability for
bodyText ||| creating training data to be used by supervised
bodyText ||| SRL models, while the standard SRL F-score mea-
bodyText ||| sures the model’s performance when used by it-
bodyText ||| self. The first stage of our algorithm is shown to
bodyText ||| outperform a strong baseline both in terms of F-
bodyText ||| score and of precision. The second stage is shown
bodyText ||| to increase precision while maintaining a reason-
bodyText ||| able recall.
bodyText ||| We evaluated our model on sections 2-21 of
bodyText ||| Propbank. As is customary in unsupervised pars-
bodyText ||| ing work (e.g. (Seginer, 2007)), we bounded sen-
bodyText ||| tence length by 10 (excluding punctuation). Our
bodyText ||| first stage obtained a precision of 52.8%, which is
bodyText ||| more than 6% improvement over the baseline. Our
bodyText ||| second stage improved precision to nearly 56%, a
bodyText ||| 9.3% improvement over the baseline. In addition,
bodyText ||| we carried out experiments on Spanish (on sen-
bodyText ||| tences of length bounded by 15, excluding punctu-
bodyText ||| ation), achieving an increase of over 7.5% in pre-
bodyText ||| cision over the baseline. Our algorithm increases
bodyText ||| F–score as well, showing an 1.8% improvement
bodyText ||| over the baseline in English and a 2.2% improve-
bodyText ||| ment in Spanish.
bodyText ||| Section 2 reviews related work. In Section 3 we
bodyText ||| detail our algorithm. Sections 4 and 5 describe the
bodyText ||| experimental setup and results.
sectionHeader ||| 2 Related Work
bodyText ||| The advance of machine learning based ap-
bodyText ||| proaches in this field owes to the usage of large
bodyText ||| scale annotated corpora. English is the most stud-
bodyText ||| ied language, using the FrameNet (FN) (Baker et
bodyText ||| al., 1998) and PropBank (PB) (Palmer et al., 2005)
bodyText ||| resources. PB is a corpus well suited for evalu-
bodyText ||| ation, since it annotates every non-auxiliary verb
bodyText ||| in a real corpus (the WSJ sections of the Penn
bodyText ||| Treebank). PB is a standard corpus for SRL eval-
bodyText ||| uation and was used in the CoNLL SRL shared
bodyText ||| tasks of 2004 (Carreras and M`arquez, 2004) and
bodyText ||| 2005 (Carreras and M`arquez, 2005).
bodyText ||| Most work on SRL has been supervised, requir-
bodyText ||| ing dozens of thousands of SRL annotated train-
bodyText ||| ing sentences. In addition, most models assume
bodyText ||| that a syntactic representation of the sentence is
bodyText ||| given, commonly in the form of a parse tree, a de-
bodyText ||| pendency structure or a shallow parse. Obtaining
bodyText ||| these is quite costly in terms of required human
bodyText ||| annotation.
bodyText ||| The first work to tackle SRL as an indepen-
bodyText ||| dent task is (Gildea and Jurafsky, 2002), which
bodyText ||| presented a supervised model trained and evalu-
bodyText ||| ated on FrameNet. The CoNLL shared tasks of
bodyText ||| 2004 and 2005 were devoted to SRL, and stud-
bodyText ||| ied the influence of different syntactic annotations
bodyText ||| and domain changes on SRL results. Computa-
bodyText ||| tional Linguistics has recently published a special
bodyText ||| issue on the task (M`arquez et al., 2008), which
bodyText ||| presents state-of-the-art results and surveys the lat-
bodyText ||| est achievements and challenges in the field.
bodyText ||| Most approaches to the task use a multi-level
bodyText ||| approach, separating the task to an ARGID and an
bodyText ||| argument classification sub-tasks. They then use
bodyText ||| the unlabeled argument structure (without the se-
bodyText ||| mantic roles) as training data for the ARGID stage
bodyText ||| and the entire data (perhaps with other features)
bodyText ||| for the classification stage. Better performance
bodyText ||| is achieved on the classification, where state-
bodyText ||| of-the-art supervised approaches achieve about
bodyText ||| 81% F-score on the in-domain identification task,
bodyText ||| of which about 95% are later labeled correctly
bodyText ||| (M`arquez et al., 2008).
bodyText ||| There have been several exceptions to the stan-
bodyText ||| dard architecture described in the last paragraph.
bodyText ||| One suggestion poses the problem of SRL as a se-
bodyText ||| quential tagging of words, training an SVM clas-
bodyText ||| sifier to determine for each word whether it is in-
bodyText ||| side, outside or in the beginning of an argument
bodyText ||| (Hacioglu and Ward, 2003). Other works have in-
bodyText ||| tegrated argument classification and identification
bodyText ||| into one step (Collobert and Weston, 2007), while
bodyText ||| others went further and combined the former two
bodyText ||| along with parsing into a single model (Musillo
page ||| 29
bodyText ||| and Merlo, 2006).
bodyText ||| Work on less supervised methods has been
bodyText ||| scarce. Swier and Stevenson (2004) and Swier
bodyText ||| and Stevenson (2005) presented the first model
bodyText ||| that does not use an SRL annotated corpus. How-
bodyText ||| ever, they utilize the extensive verb lexicon Verb-
bodyText ||| Net, which lists the possible argument structures
bodyText ||| allowable for each verb, and supervised syntac-
bodyText ||| tic tools. Using VerbNet along with the output of
bodyText ||| a rule-based chunker (in 2004) and a supervised
bodyText ||| syntactic parser (in 2005), they spot instances in
bodyText ||| the corpus that are very similar to the syntactic
bodyText ||| patterns listed in VerbNet. They then use these as
bodyText ||| seed for a bootstrapping algorithm, which conse-
bodyText ||| quently identifies the verb arguments in the corpus
bodyText ||| and assigns their semantic roles.
bodyText ||| Another less supervised work is that
bodyText ||| of (Grenager and Manning, 2006), which presents
bodyText ||| a Bayesian network model for the argument
bodyText ||| structure of a sentence. They use EM to learn
bodyText ||| the model’s parameters from unannotated data,
bodyText ||| and use this model to tag a test corpus. However,
bodyText ||| ARGID was not the task of that work, which dealt
bodyText ||| solely with argument classification. ARGID was
bodyText ||| performed by manually-created rules, requiring a
bodyText ||| supervised or manual syntactic annotation of the
bodyText ||| corpus to be annotated.
bodyText ||| The three works above are relevant but incom-
bodyText ||| parable to our work, due to the extensive amount
bodyText ||| of supervision (namely, VerbNet and a rule-based
bodyText ||| or supervised syntactic system) they used, both in
bodyText ||| detecting the syntactic structure and in detecting
bodyText ||| the arguments.
bodyText ||| Work has been carried out in a few other lan-
bodyText ||| guages besides English. Chinese has been studied
bodyText ||| in (Xue, 2008). Experiments on Catalan and Span-
bodyText ||| ish were done in SemEval 2007 (M`arquez et al.,
bodyText ||| 2007) with two participating systems. Attempts
bodyText ||| to compile corpora for German (Burdchardt et al.,
bodyText ||| 2006) and Arabic (Diab et al., 2008) are also un-
bodyText ||| derway. The small number of languages for which
bodyText ||| extensive SRL annotated data exists reflects the
bodyText ||| considerable human effort required for such en-
bodyText ||| deavors.
bodyText ||| Some SRL works have tried to use unannotated
bodyText ||| data to improve the performance of a base su-
bodyText ||| pervised model. Methods used include bootstrap-
bodyText ||| ping approaches (Gildea and Jurafsky, 2002; Kate
bodyText ||| and Mooney, 2007), where large unannotated cor-
bodyText ||| pora were tagged with SRL annotation, later to
bodyText ||| be used to retrain the SRL model. Another ap-
bodyText |||  proach used similarity measures either between
bodyText ||| verbs (Gordon and Swanson, 2007) or between
bodyText ||| nouns (Gildea and Jurafsky, 2002) to overcome
bodyText ||| lexical sparsity. These measures were estimated
bodyText ||| using statistics gathered from corpora augmenting
bodyText ||| the model’s training data, and were then utilized
bodyText ||| to generalize across similar verbs or similar argu-
bodyText ||| ments.
bodyText ||| Attempts to substitute full constituency pars-
bodyText ||| ing by other sources of syntactic information have
bodyText ||| been carried out in the SRL community. Sugges-
bodyText ||| tions include posing SRL as a sequence labeling
bodyText ||| problem (M`arquez et al., 2005) or as an edge tag-
bodyText ||| ging problem in a dependency representation (Ha-
bodyText ||| cioglu, 2004). Punyakanok et al. (2008) provide
bodyText ||| a detailed comparison between the impact of us-
bodyText ||| ing shallow vs. full constituency syntactic infor-
bodyText ||| mation in an English SRL system. Their results
bodyText ||| clearly demonstrate the advantage of using full an-
bodyText ||| notation.
bodyText ||| The identification of arguments has also been
bodyText ||| carried out in the context of automatic subcatego-
bodyText ||| rization frame acquisition. Notable examples in-
bodyText ||| clude (Manning, 1993; Briscoe and Carroll, 1997;
bodyText ||| Korhonen, 2002) who all used statistical hypothe-
bodyText ||| sis testing to filter a parser’s output for arguments,
bodyText ||| with the goal of compiling verb subcategorization
bodyText ||| lexicons. However, these works differ from ours
bodyText ||| as they attempt to characterize the behavior of a
bodyText ||| verb type, by collecting statistics from various in-
bodyText ||| stances of that verb, and not to determine which
bodyText ||| are the arguments of specific verb instances.
bodyText ||| The algorithm presented in this paper performs
bodyText ||| unsupervised clause detection as an intermedi-
bodyText ||| ate step towards argument identification. Super-
bodyText ||| vised clause detection was also tackled as a sepa-
bodyText ||| rate task, notably in the CoNLL 2001 shared task
bodyText ||| (Tjong Kim Sang and D`ejean, 2001). Clause in-
bodyText ||| formation has been applied to accelerating a syn-
bodyText ||| tactic parser (Glaysher and Moldovan, 2006).
sectionHeader ||| 3 Algorithm
bodyText ||| In this section we describe our algorithm. It con-
bodyText ||| sists of two stages, each of which reduces the set
bodyText ||| of argument candidates, which a-priori contains all
bodyText ||| consecutive sequences of words that do not con-
bodyText ||| tain the predicate in question.
subsectionHeader ||| 3.1 Algorithm overview
bodyText ||| As pre-processing, we use an unsupervised parser
bodyText ||| that generates an unlabeled parse tree for each sen-
page ||| 30
bodyText ||| tence (Seginer, 2007). This parser is unique in that
bodyText ||| it is able to induce a bracketing (unlabeled pars-
bodyText ||| ing) from raw text (without even using POS tags)
bodyText ||| achieving state-of-the-art results. Since our algo-
bodyText ||| rithm uses millions to tens of millions sentences,
bodyText ||| we must use very fast tools. The parser’s high
bodyText ||| speed (thousands of words per second) enables us
bodyText ||| to process these large amounts of data.
bodyText ||| The only type of supervised annotation we
bodyText ||| use is POS tagging. We use the taggers MX-
bodyText ||| POST (Ratnaparkhi, 1996) for English and Tree-
bodyText ||| Tagger (Schmid, 1994) for Spanish, to obtain POS
bodyText ||| tags for our model.
bodyText ||| The first stage of our algorithm uses linguisti-
bodyText ||| cally motivated considerations to reduce the set of
bodyText ||| possible arguments. It does so by confining the set
bodyText ||| of argument candidates only to those constituents
bodyText ||| which obey the following two restrictions. First,
bodyText ||| they should be contained in the minimal clause
bodyText ||| containing the predicate. Second, they should be
bodyText ||| k-th degree cousins of the predicate in the parse
bodyText ||| tree. We propose a novel algorithm for clause de-
bodyText ||| tection and use its output to determine which of
bodyText ||| the constituents obey these two restrictions.
bodyText ||| The second stage of the algorithm uses point-
bodyText ||| wise mutual information to rule out constituents
bodyText ||| that appear to be weakly collocating with the pred-
bodyText ||| icate in question. Since a predicate greatly re-
bodyText ||| stricts the type of arguments with which it may
bodyText ||| appear (this is often referred to as “selectional re-
bodyText ||| strictions”), we expect it to have certain character-
bodyText ||| istic arguments with which it is likely to collocate.
subsectionHeader ||| 3.2 Clause detection stage
bodyText ||| The main idea behind this stage is the observation
bodyText ||| that most of the arguments of a predicate are con-
bodyText ||| tained within the minimal clause that contains the
bodyText ||| predicate. We tested this on our development data
bodyText ||| – section 24 of the WSJ PTB, where we saw that
bodyText ||| 86% of the arguments that are also constituents
bodyText ||| (in the gold standard parse) were indeed contained
bodyText ||| in that minimal clause (as defined by the tree la-
bodyText ||| bel types in the gold standard parse that denote
bodyText ||| a clause, e.g., S, SBAR). Since we are not pro-
bodyText ||| vided with clause annotation (or any label), we at-
bodyText ||| tempted to detect them in an unsupervised manner.
bodyText ||| Our algorithm attempts to find sub-trees within the
bodyText ||| parse tree, whose structure resembles the structure
bodyText ||| of a full sentence. This approximates the notion of
bodyText ||| a clause.
figure ||| VBP L
figure ||| L
figure ||| VBP L
figureCaption ||| Figure 1: An example of an unlabeled POS tagged
figureCaption ||| parse tree. The middle tree is the ST of ‘reach’
figureCaption ||| with the root as the encoded ancestor. The bot-
figureCaption ||| tom one is the ST with its parent as the encoded
figureCaption ||| ancestor.
bodyText ||| Statistics gathering. In order to detect which
bodyText ||| of the verb’s ancestors is the minimal clause, we
bodyText ||| score each of the ancestors and select the one that
bodyText ||| maximizes the score. We represent each ancestor
bodyText ||| using its Spinal Tree (ST). The ST of a given
bodyText ||| verb’s ancestor is obtained by replacing all the
bodyText ||| constituents that do not contain the verb by a leaf
bodyText ||| having a label. This effectively encodes all the k-
bodyText ||| th degree cousins of the verb (for every k). The
bodyText ||| leaf labels are either the word’s POS in case the
bodyText ||| constituent is a leaf, or the generic label “L” de-
bodyText ||| noting a non-leaf. See Figure 1 for an example.
bodyText ||| In this stage we collect statistics of the occur-
bodyText ||| rences of STs in a large corpus. For every ST in
bodyText ||| the corpus, we count the number of times it oc-
bodyText ||| curs in a form we consider to be a clause (positive
bodyText ||| examples), and the number of times it appears in
bodyText ||| other forms (negative examples).
bodyText ||| Positive examples are divided into two main
bodyText ||| types. First, when the ST encodes the root an-
bodyText ||| cestor (as in the middle tree of Figure 1); second,
bodyText ||| when the ancestor complies to a clause lexico-
bodyText ||| syntactic pattern. In many languages there is a
bodyText ||| small set of lexico-syntactic patterns that mark a
bodyText ||| clause, e.g. the English ‘that’, the German ‘dass’
bodyText ||| and the Spanish ‘que’. The patterns which were
bodyText ||| used in our experiments are shown in Figure 2.
bodyText ||| For each verb instance, we traverse over its an-
figure ||| L
figure ||| L
figure ||| L
figure ||| L
figure ||| IN
figure ||| DT
figure ||| NNS
figure ||| The
figure ||| materials
figure ||| L
figure ||| L
figure ||| VBP
figure ||| L
figure ||| in	DT NN
figure ||| NNS
figure ||| IN
figure ||| students
figure ||| CD
figure ||| about	90
figure ||| each	set
figure ||| reach
figure ||| L
figure ||| L
figure ||| L	L
figure ||| L	L
page ||| 31
figure ||| English
figure ||| TO + VB. The constituent starts with “to” followed by a verb in infinitive form.
figure ||| WP. The constituent is preceded by a Wh-pronoun.
figure ||| That. The constituent is preceded by a “that” marked by an “IN” POS tag indicating that it is a subordinating conjunction.
figure ||| Spanish
figure ||| CQUE. The constituent is preceded by a word with the POS “CQUE” which denotes the word “que” as a con-junction.
figure ||| INT. The constituent is preceded by a word with the POS “INT” which denotes an interrogative pronoun.
figure ||| CSUB. The constituent is preceded by a word with one of the POSs “CSUBF”, “CSUBI” or “CSUBX”, which denote a subordinating conjunction.
figureCaption ||| Figure 2: The set of lexico-syntactic patterns that
figureCaption ||| mark clauses which were used by our model.
bodyText ||| cestors from top to bottom. For each of them we
bodyText ||| update the following counters: sentence(5T) for
bodyText ||| the root ancestor’s 5T, patternz (5T) for the ones
bodyText ||| complying to the i-th lexico-syntactic pattern and
bodyText ||| negative(5T) for the other ancestors1.
bodyText ||| Clause detection. At test time, when detecting
bodyText ||| the minimal clause of a verb instance, we use
bodyText ||| the statistics collected in the previous stage. De-
bodyText ||| note the ancestors of the verb with A1 ... Am.
bodyText ||| For each of them, we calculate clause(5TA, )
bodyText ||| and total (5TA, ). clause(5TA,) is the sum
bodyText ||| of sentence(5TA,) and patternz (5TA,) if this
bodyText ||| ancestor complies to the i-th pattern (if there
bodyText ||| is no such pattern, clause(5TA,) is equal to
bodyText ||| sentence (5TA, )). total (5TA,) is the sum of
bodyText ||| clause(5TA,) and negative(5TA, ).
bodyText ||| The selected ancestor is given by:
bodyText ||| clause(STA, )
equation ||| (1) Amax = argmaxA,  total(STA,)
bodyText ||| An 5T whose total(5T) is less than a small
bodyText ||| threshold2 is not considered a candidate to be the
bodyText ||| minimal clause, since its statistics may be un-
bodyText ||| reliable. In case of a tie, we choose the low-
bodyText ||| est constituent that obtained the maximal score.
footnote ||| 1If while traversing the tree, we encounter an ancestor
footnote ||| whose first word is preceded by a coordinating conjunction
footnote ||| (marked by the POS tag “CC”), we refrain from performing
footnote ||| any additional counter updates. Structures containing coor-
footnote ||| dinating conjunctions tend not to obey our lexico-syntactic
footnote ||| rules.
footnote ||| 2We used 4 per million sentences, derived from develop-
footnote ||| ment data.
bodyText ||| If there is only one verb in the sentence3 or if
bodyText ||| clause(5TA,) = 0 for every 1 G j G m, we
bodyText ||| choose the top level constituent by default to be
bodyText ||| the minimal clause containing the verb. Other-
bodyText ||| wise, the minimal clause is defined to be the yield
bodyText ||| of the selected ancestor.
bodyText ||| Argument identification. For each predicate in
bodyText ||| the corpus, its argument candidates are now de-
bodyText ||| fined to be the constituents contained in the min-
bodyText ||| imal clause containing the predicate. However,
bodyText ||| these constituents may be (and are) nested within
bodyText ||| each other, violating a major restriction on SRL
bodyText ||| arguments. Hence we now prune our set, by keep-
bodyText ||| ing only the siblings of all of the verb’s ancestors,
bodyText ||| as is common in supervised SRL (Xue and Palmer,
bodyText ||| 2004).
subsectionHeader ||| 3.3 Using collocations
bodyText ||| We use the following observation to filter out some
bodyText ||| superfluous argument candidates: since the argu-
bodyText ||| ments of a predicate many times bear a semantic
bodyText ||| connection with that predicate, they consequently
bodyText ||| tend to collocate with it.
bodyText ||| We collect collocation statistics from a large
bodyText ||| corpus, which we annotate with parse trees and
bodyText ||| POS tags. We mark arguments using the argu-
bodyText ||| ment detection algorithm described in the previous
bodyText ||| two sections, and extract all (predicate, argument)
bodyText ||| pairs appearing in the corpus. Recall that for each
bodyText ||| sentence, the arguments are a subset of the con-
bodyText ||| stituents in the parse tree.
bodyText ||| We use two representations of an argument: one
bodyText ||| is the POS tag sequence of the terminals contained
bodyText ||| in the argument, the other is its head word4. The
bodyText ||| predicate is represented as the conjunction of its
bodyText ||| lemma with its POS tag.
bodyText ||| Denote the number of times a predicate x
bodyText ||| appeared with an argument y by nxy. Denote
bodyText ||| the total number of (predicate, argument) pairs
bodyText ||| by N. Using these notations, we define the
bodyText ||| following quantities: nx = Eynxy, ny = Exnxy,
bodyText ||| p(x) = n�N , p(y) = n�N and p(x, y) = nx N . The
bodyText ||| pointwise mutual information of x and y is then
bodyText ||| given by:
footnote ||| 3In this case, every argument in the sentence must be re-
footnote ||| lated to that verb.
footnote ||| 4Since we do not have syntactic labels, we use an approx-
footnote ||| imate notion. For English we use the Bikel parser default
footnote ||| head word rules (Bikel, 2004). For Spanish, we use the left-
footnote ||| most word.
page ||| 32
equation ||| (2) PMI(x, y) = log  p( x) P(y) =log n�y
equation ||| (n� �ny)/N
bodyText ||| PMI effectively measures the ratio between
bodyText ||| the number of times x and y appeared together and
bodyText ||| the number of times they were expected to appear,
bodyText ||| had they been independent.
bodyText ||| At test time, when an (x, y) pair is observed, we
bodyText ||| check if PMI (x, y), computed on the large cor-
bodyText ||| pus, is lower than a threshold a for either of x’s
bodyText ||| representations. If this holds, for at least one rep-
bodyText ||| resentation, we prune all instances of that (x, y)
bodyText ||| pair. The parameter a may be selected differently
bodyText ||| for each of the argument representations.
bodyText ||| In order to avoid using unreliable statistics,
bodyText ||| we apply this for a given pair only if n .ny N>
bodyText ||| r, for some parameter r. That is, we consider
bodyText ||| PMI (x, y) to be reliable, only if the denomina-
bodyText ||| tor in equation (2) is sufficiently large.
sectionHeader ||| 4 Experimental Setup
bodyText ||| Corpora. We used the PropBank corpus for de-
bodyText ||| velopment and for evaluation on English. Section
bodyText ||| 24 was used for the development of our model,
bodyText ||| and sections 2 to 21 were used as our test data.
bodyText ||| The free parameters of the collocation extraction
bodyText ||| phase were tuned on the development data. Fol-
bodyText ||| lowing the unsupervised parsing literature, multi-
bodyText ||| ple brackets and brackets covering a single word
bodyText ||| are omitted. We exclude punctuation according
bodyText ||| to the scheme of (Klein, 2005). As is customary
bodyText ||| in unsupervised parsing (e.g. (Seginer, 2007)), we
bodyText ||| bounded the lengths of the sentences in the cor-
bodyText ||| pus to be at most 10 (excluding punctuation). This
bodyText ||| results in 207 sentences in the development data,
bodyText ||| containing a total of 132 different verbs and 173
bodyText ||| verb instances (of the non-auxiliary verbs in the
bodyText ||| SRL task, see ‘evaluation’ below) having 403 ar-
bodyText ||| guments. The test data has 6007 sentences con-
bodyText ||| taining 1008 different verbs and 5130 verb in-
bodyText ||| stances (as above) having 12436 arguments.
bodyText ||| Our algorithm requires large amounts of data
bodyText ||| to gather argument structure and collocation pat-
bodyText ||| terns. For the statistics gathering phase of the
bodyText ||| clause detection algorithm, we used 4.5M sen-
bodyText ||| tences of the NANC (Graff, 1995) corpus, bound-
bodyText ||| ing their length in the same manner. In order
bodyText ||| to extract collocations, we used 2M sentences
bodyText ||| from the British National Corpus (Burnard, 2000)
bodyText ||| and about 29M sentences from the Dmoz cor-
bodyText ||| pus (Gabrilovich and Markovitch, 2005). Dmoz
bodyText ||| is a web corpus obtained by crawling and clean-
bodyText ||| ing the URLs in the Open Directory Project
bodyText ||| (dmoz.org). All of the above corpora were parsed
bodyText ||| using Seginer’s parser and POS-tagged by MX-
bodyText ||| POST (Ratnaparkhi, 1996).
bodyText ||| For our experiments on Spanish, we used 3.3M
bodyText ||| sentences of length at most 15 (excluding punctua-
bodyText ||| tion) extracted from the Spanish Wikipedia. Here
bodyText ||| we chose to bound the length by 15 due to the
bodyText ||| smaller size of the available test corpus. The
bodyText ||| same data was used both for the first and the sec-
bodyText ||| ond stages. Our development and test data were
bodyText ||| taken from the training data released for the Se-
bodyText ||| mEval 2007 task on semantic annotation of Span-
bodyText ||| ish (M`arquez et al., 2007). This data consisted
bodyText ||| of 1048 sentences of length up to 15, from which
bodyText ||| 200 were randomly selected as our development
bodyText ||| data and 848 as our test data. The development
bodyText ||| data included 313 verb instances while the test
bodyText ||| data included 1279. All corpora were parsed us-
bodyText ||| ing the Seginer parser and tagged by the “Tree-
bodyText ||| Tagger” (Schmid, 1994).
bodyText ||| Baselines. Since this is the first paper, to our
bodyText ||| knowledge, which addresses the problem of unsu-
bodyText ||| pervised argument identification, we do not have
bodyText ||| any previous results to compare to. We instead
bodyText ||| compare to a baseline which marks all k-th degree
bodyText ||| cousins of the predicate (for every k) as arguments
bodyText ||| (this is the second pruning we use in the clause
bodyText ||| detection stage). We name this baseline the ALL
bodyText ||| COUSINS baseline. We note that a random base-
bodyText ||| line would score very poorly since any sequence of
bodyText ||| terminals which does not contain the predicate is
bodyText ||| a possible candidate. Therefore, beating this ran-
bodyText ||| dom baseline is trivial.
bodyText ||| Evaluation. Evaluation is carried out using
bodyText ||| standard SRL evaluation software5. The algorithm
bodyText ||| is provided with a list of predicates, whose argu-
bodyText ||| ments it needs to annotate. For the task addressed
bodyText ||| in this paper, non-consecutive parts of arguments
bodyText ||| are treated as full arguments. A match is consid-
bodyText ||| ered each time an argument in the gold standard
bodyText ||| data matches a marked argument in our model’s
bodyText ||| output. An unmatched argument is an argument
bodyText ||| which appears in the gold standard data, and fails
bodyText ||| to appear in our model’s output, and an exces-
bodyText ||| sive argument is an argument which appears in
bodyText ||| our model’s output but does not appear in the gold
bodyText ||| standard. Precision and recall are defined accord-
bodyText ||| ingly. We report an F-score as well (the harmonic
bodyText ||| mean of precision and recall). We do not attempt
footnote ||| 5http://www.lsi.upc.edu/—srlconll/soft.html#software.
page ||| 33
bodyText ||| to identify multi-word verbs, and therefore do not
bodyText ||| report the model’s performance in identifying verb
bodyText ||| boundaries.
bodyText ||| Since our model detects clauses as an interme-
bodyText ||| diate product, we provide a separate evaluation
bodyText ||| of this task for the English corpus. We show re-
bodyText ||| sults on our development data. We use the stan-
bodyText ||| dard parsing F-score evaluation measure. As a
bodyText ||| gold standard in this evaluation, we mark for each
bodyText ||| of the verbs in our development data the minimal
bodyText ||| clause containing it. A minimal clause is the low-
bodyText ||| est ancestor of the verb in the parse tree that has
bodyText ||| a syntactic label of a clause according to the gold
bodyText ||| standard parse of the PTB. A verb is any terminal
bodyText ||| marked by one of the POS tags of type verb ac-
bodyText ||| cording to the gold standard POS tags of the PTB.
sectionHeader ||| 5 Results
bodyText ||| Our results are shown in Table 1. The left section
bodyText ||| presents results on English and the right section
bodyText ||| presents results on Spanish. The top line lists re-
bodyText ||| sults of the clause detection stage alone. The next
bodyText ||| two lines list results of the full algorithm (clause
bodyText ||| detection + collocations) in two different settings
bodyText ||| of the collocation stage. The bottom line presents
bodyText ||| the performance of the ALL COUSINS baseline.
bodyText ||| In the “Collocation Maximum Precision” set-
bodyText ||| ting the parameters of the collocation stage (a and
bodyText ||| r) were generally tuned such that maximal preci-
bodyText ||| sion is achieved while preserving a minimal recall
bodyText ||| level (40% for English, 20% for Spanish on the de-
bodyText ||| velopment data). In the “Collocation Maximum F-
bodyText ||| score” the collocation parameters were generally
bodyText ||| tuned such that the maximum possible F-score for
bodyText ||| the collocation algorithm is achieved.
bodyText ||| The best or close to best F-score is achieved
bodyText ||| when using the clause detection algorithm alone
bodyText ||| (59.14% for English, 23.34% for Spanish). Note
bodyText ||| that for both English and Spanish F-score im-
bodyText ||| provements are achieved via a precision improve-
bodyText ||| ment that is more significant than the recall degra-
bodyText ||| dation. F-score maximization would be the aim of
bodyText ||| a system that uses the output of our unsupervised
bodyText ||| ARGID by itself.
bodyText ||| The “Collocation Maximum Precision”
bodyText ||| achieves the best precision level (55.97% for
bodyText ||| English, 21.8% for Spanish) but at the expense
bodyText ||| of the largest recall loss. Still, it maintains a
bodyText ||| reasonable level of recall. The “Collocation
bodyText ||| Maximum F-score” is an example of a model that
bodyText ||| provides a precision improvement (over both the
bodyText ||| baseline and the clause detection stage) with a
bodyText ||| relatively small recall degradation. In the Spanish
bodyText ||| experiments its F-score (23.87%) is even a bit
bodyText ||| higher than that of the clause detection stage
bodyText ||| (23.34%).
bodyText ||| The full two–stage algorithm (clause detection
bodyText ||| + collocations) should thus be used when we in-
bodyText ||| tend to use the model’s output as training data for
bodyText ||| supervised SRL engines or supervised ARGID al-
bodyText ||| gorithms.
bodyText ||| In our algorithm, the initial set of potential ar-
bodyText ||| guments consists of constituents in the Seginer
bodyText ||| parser’s parse tree. Consequently the fraction
bodyText ||| of arguments that are also constituents (81.87%
bodyText ||| for English and 51.83% for Spanish) poses an
bodyText ||| upper bound on our algorithm’s recall. Note
bodyText ||| that the recall of the ALL COUSINS baseline is
bodyText ||| 74.27% (45.75%) for English (Spanish). This
bodyText ||| score emphasizes the baseline’s strength, and jus-
bodyText ||| tifies the restriction that the arguments should be
bodyText ||| k-th cousins of the predicate. The difference be-
bodyText ||| tween these bounds for the two languages provides
bodyText ||| a partial explanation for the corresponding gap in
bodyText ||| the algorithm’s performance.
bodyText ||| Figure 3 shows the precision of the collocation
bodyText ||| model (on development data) as a function of the
bodyText ||| amount of data it was given. We can see that
bodyText ||| the algorithm reaches saturation at about 5M sen-
bodyText ||| tences. It achieves this precision while maintain-
bodyText ||| ing a reasonable recall (an average recall of 43.1%
bodyText ||| after saturation). The parameters of the colloca-
bodyText ||| tion model were separately tuned for each corpus
bodyText ||| size, and the graph displays the maximum which
bodyText ||| was obtained for each of the corpus sizes.
bodyText ||| To better understand our model’s performance,
bodyText ||| we performed experiments on the English cor-
bodyText ||| pus to test how well its first stage detects clauses.
bodyText ||| Clause detection is used by our algorithm as a step
bodyText ||| towards argument identification, but it can be of
bodyText ||| potential benefit for other purposes as well (see
bodyText ||| Section 2). The results are 23.88% recall and 40%
bodyText ||| precision. As in the ARGID task, a random se-
bodyText ||| lection of arguments would have yielded an ex-
bodyText ||| tremely poor result.
sectionHeader ||| 6 Conclusion
bodyText ||| In this work we presented the first algorithm for ar-
bodyText ||| gument identification that uses neither supervised
bodyText ||| syntactic annotation nor SRL tagged data. We
bodyText ||| have experimented on two languages: English and
bodyText ||| Spanish. The straightforward adaptability of un-
page ||| 34
table ||| 	English (Test Data)			Spanish (Test Data)
table ||| 	Precision	Recall	F1	Precision	Recall	F1
table ||| Clause Detection	52.84	67.14	59.14	18.00	33.19	23.34
table ||| Collocation Maximum F–score	54.11	63.53	58.44	20.22	29.13	23.87
table ||| Collocation Maximum Precision	55.97	40.02	46.67	21.80	18.47	20.00
table ||| ALL COUSINS baseline	46.71	74.27	57.35	14.16	45.75	21.62
tableCaption ||| Table 1: Precision, Recall and F 1 score for the different stages of our algorithm. Results are given for English (PTB, sentences
tableCaption ||| length bounded by 10, left part of the table) and Spanish (SemEval 2007 Spanish SRL task, right part of the table). The results
tableCaption ||| of the collocation (second) stage are given in two configurations, Collocation Maximum F-score and Collocation Maximum
tableCaption ||| Precision (see text). The upper bounds on Recall, obtained by taking all arguments output by our unsupervised parser, are
tableCaption ||| 81.87% for English and 51.83% for Spanish.
figure ||| Number of Sentences (Millions)
figureCaption ||| Figure 3: The performance of the second stage on English
figureCaption ||| (squares) vs. corpus size. The precision of the baseline (trian-
figureCaption ||| gles) and of the first stage (circles) is displayed for reference.
figureCaption ||| The graph indicates the maximum precision obtained for each
figureCaption ||| corpus size. The graph reaches saturation at about 5M sen-
figureCaption ||| tences. The average recall of the sampled points from there
figureCaption ||| on is 43.1%. Experiments were performed on the English
figureCaption ||| development data.
bodyText ||| supervised models to different languages is one
bodyText ||| of their most appealing characteristics. The re-
bodyText ||| cent availability of unsupervised syntactic parsers
bodyText ||| has offered an opportunity to conduct research on
bodyText ||| SRL, without reliance on supervised syntactic an-
bodyText ||| notation. This work is the first to address the ap-
bodyText ||| plication of unsupervised parses to an SRL related
bodyText ||| task.
bodyText ||| Our model displayed an increase in precision of
bodyText ||| 9% in English and 8% in Spanish over a strong
bodyText ||| baseline. Precision is of particular interest in this
bodyText ||| context, as instances tagged by high quality an-
bodyText ||| notation could be later used as training data for
bodyText ||| supervised SRL algorithms. In terms of F–score,
bodyText ||| our model showed an increase of 1.8% in English
bodyText ||| and of 2.2% in Spanish over the baseline.
bodyText ||| Although the quality of unsupervised parses is
bodyText ||| currently low (compared to that of supervised ap-
bodyText ||| proaches), using great amounts of data in identi-
bodyText ||| fying recurring structures may reduce noise and
bodyText ||| in addition address sparsity. The techniques pre-
bodyText ||| sented in this paper are based on this observation,
bodyText ||| using around 35M sentences in total for English
bodyText ||| and 3.3M sentences for Spanish.
bodyText ||| As this is the first work which addressed un-
bodyText ||| supervised ARGID, many questions remain to be
bodyText ||| explored. Interesting issues to address include as-
bodyText ||| sessing the utility of the proposed methods when
bodyText ||| supervised parses are given, comparing our model
bodyText ||| to systems with no access to unsupervised parses
bodyText ||| and conducting evaluation using more relaxed
bodyText ||| measures.
bodyText ||| Unsupervised methods for syntactic tasks have
bodyText ||| matured substantially in the last few years. No-
bodyText ||| table examples are (Clark, 2003) for unsupervised
bodyText ||| POS tagging and (Smith and Eisner, 2006) for un-
bodyText ||| supervised dependency parsing. Adapting our al-
bodyText ||| gorithm to use the output of these models, either to
bodyText ||| reduce the little supervision our algorithm requires
bodyText ||| (POS tagging) or to provide complementary syn-
bodyText ||| tactic information, is an interesting challenge for
bodyText ||| future work.
sectionHeader ||| References
reference ||| Collin F. Baker, Charles J. Fillmore and John B. Lowe,
reference ||| 1998. The Berkeley FrameNet Project. ACL-
reference ||| COLING ’98.
reference ||| Daniel M. Bikel, 2004. Intricacies of Collins’ Parsing
reference ||| Model. Computational Linguistics, 30(4):479–511.
reference ||| Ted Briscoe, John Carroll, 1997. Automatic Extraction
reference ||| of Subcategorization from Corpora. Applied NLP
reference ||| 1997.
reference ||| Aljoscha Burchardt, Katrin Erk, Anette Frank, Andrea
reference ||| Kowalski, Sebastian Pad and Manfred Pinkal, 2006
reference ||| The SALSA Corpus: a German Corpus Resource for
reference ||| Lexical Semantics. LREC ’06.
reference ||| Lou Burnard, 2000. User Reference Guide for the
reference ||| British National Corpus. Technical report, Oxford
reference ||| University.
reference ||| Xavier Carreras and Lluis M`arquez, 2004. Intro-
reference ||| duction to the CoNLL–2004 Shared Task: Semantic
reference ||| Role Labeling. CoNLL ’04.
figure ||| 0	2	4	6	8	10
figure ||| 48
figure ||| 46
figure ||| 44
figure ||| 42
figure ||| 52
figure ||| 50
figure ||| Second Stage
figure ||| First Stage
figure ||| Baseline
page ||| 35
reference ||| Xavier Carreras and Lluis M`arquez, 2005. Intro-
reference ||| duction to the CoNLL –2005 Shared Task: Semantic
reference ||| Role Labeling. CoNLL ’05.
reference ||| Alexander Clark, 2003. Combining Distributional and
reference ||| Morphological Information for Part of Speech In-
reference ||| duction. EACL ’03.
reference ||| Ronan Collobert and Jason Weston, 2007. Fast Se-
reference ||| mantic Extraction Using a Novel Neural Network
reference ||| Architecture. ACL ’07.
reference ||| Mona Diab, Aous Mansouri, Martha Palmer, Olga
reference ||| Babko-Malaya, Wajdi Zaghouani, Ann Bies and
reference ||| Mohammed Maamouri, 2008. A pilot Arabic Prop-
reference ||| Bank. LREC ’08.
reference ||| Evgeniy Gabrilovich and Shaul Markovitch, 2005.
reference ||| Feature Generation for Text Categorization using
reference ||| World Knowledge. IJCAI ’05.
reference ||| Daniel Gildea and Daniel Jurafsky, 2002. Automatic
reference ||| Labeling of Semantic Roles. Computational Lin-
reference ||| guistics, 28(3):245–288.
reference ||| Elliot Glaysher and Dan Moldovan, 2006. Speed-
reference ||| ing Up Full Syntactic Parsing by Leveraging Partial
reference ||| Parsing Decisions. COLING/ACL ’06 poster ses-
reference ||| sion.
reference ||| Andrew Gordon and Reid Swanson, 2007. Generaliz-
reference ||| ing Semantic Role Annotations across Syntactically
reference ||| Similar Verbs. ACL ’07.
reference ||| David Graff, 1995. North American News Text Cor-
reference ||| pus. Linguistic Data Consortium. LDC95T21.
reference ||| Trond Grenager and Christopher D. Manning, 2006.
reference ||| Unsupervised Discovery of a Statistical Verb Lexi-
reference ||| con. EMNLP ’06.
reference ||| Kadri Hacioglu, 2004. Semantic Role Labeling using
reference ||| Dependency Trees. COLING’04.
reference ||| Kadri Hacioglu and Wayne Ward, 2003. Target Word
reference ||| Detection and Semantic Role Chunking using Sup-
reference ||| port Vector Machines. HLT-NAACL ’03.
reference ||| Rohit J. Kate and Raymond J. Mooney, 2007. Semi-
reference ||| Supervised Learning for Semantic Parsing using
reference ||| Support Vector Machines. HLT–NAACL ’07.
reference ||| Karin Kipper, Hoa Trang Dang and Martha Palmer,
reference ||| 2000. Class-Based Construction of a Verb Lexicon.
reference ||| AAAI ’00.
reference ||| Dan Klein, 2005. The Unsupervised Learning ofNatu-
reference ||| ral Language Structure. Ph.D. thesis, Stanford Uni-
reference ||| versity.
reference ||| Anna Korhonen, 2002. Subcategorization Acquisition.
reference ||| Ph.D. thesis, University of Cambridge.
reference ||| Christopher D. Manning, 1993. Automatic Acquisition
reference ||| of a Large Subcategorization Dictionary. ACL ’93.
reference ||| Lluis M`arquez, Xavier Carreras, Kenneth C. Lit-
reference ||| tkowski and Suzanne Stevenson, 2008. Semantic
reference ||| Role Labeling: An introdution to the Special Issue.
reference ||| Computational Linguistics, 34(2):145–159
reference ||| Lluis M`arquez, Jesus Gim`enez Pere Comas and Neus
reference ||| Catal`a, 2005. Semantic Role Labeling as Sequential
reference ||| Tagging. CoNLL’05.
reference ||| Lluis M`arquez, Lluis Villarejo, M. A. Marti and Mar-
reference ||| iona Taul`e, 2007. SemEval–2007 Task 09: Multi-
reference ||| level Semantic Annotation of Catalan and Spanish.
reference ||| The 4th international workshop on Semantic Evalu-
reference ||| ations (SemEval ’07).
reference ||| Gabriele Musillo and Paula Merlo, 2006. Accurate
reference ||| Parsing of the proposition bank. HLT-NAACL ’06.
reference ||| Martha Palmer, Daniel Gildea and Paul Kingsbury,
reference ||| 2005. The Proposition Bank: A Corpus Annotated
reference ||| with Semantic Roles. Computational Linguistics,
reference ||| 31(1):71–106.
reference ||| Sameer Pradhan, Kadri Hacioglu, Valerie Krugler,
reference ||| Wayne Ward, James H. Martin and Daniel Jurafsky,
reference ||| 2005. Support Vector Learning for Semantic Argu-
reference ||| ment Classification. Machine Learning, 60(1):11–
reference ||| 39.
reference ||| Sameer Pradhan, Wayne Ward, James H. Martin, 2008.
reference ||| Towards Robust Semantic Role Labeling. Computa-
reference ||| tional Linguistics, 34(2):289–310.
reference ||| Adwait Ratnaparkhi, 1996. Maximum Entropy Part-
reference ||| Of-Speech Tagger. EMNLP ’96.
reference ||| Helmut Schmid, 1994. Probabilistic Part-of-Speech
reference ||| Tagging Using Decision Trees International Confer-
reference ||| ence on New Methods in Language Processing.
reference ||| Yoav Seginer, 2007. Fast Unsupervised Incremental
reference ||| Parsing. ACL ’07.
reference ||| Noah A. Smith and Jason Eisner, 2006. Annealing
reference ||| Structural Bias in Multilingual Weighted Grammar
reference ||| Induction. ACL ’06.
reference ||| Robert S. Swier and Suzanne Stevenson, 2004. Unsu-
reference ||| pervised Semantic Role Labeling. EMNLP ’04.
reference ||| Robert S. Swier and Suzanne Stevenson, 2005. Ex-
reference ||| ploiting a Verb Lexicon in Automatic Semantic Role
reference ||| Labelling. EMNLP ’05.
reference ||| Erik F. Tjong Kim Sang and Herv´e D´ejean, 2001. In-
reference ||| troduction to the CoNLL-2001 Shared Task: Clause
reference ||| Identification. CoNLL ’01.
reference ||| Nianwen Xue and Martha Palmer, 2004. Calibrating
reference ||| Features for Semantic Role Labeling. EMNLP ’04.
reference ||| Nianwen Xue, 2008. Labeling Chinese Predicates
reference ||| with Semantic Roles. Computational Linguistics,
reference ||| 34(2):225–255.
page ||| 36

title ||| Brutus: A Semantic Role Labeling System Incorporating CCG, CFG, and
title ||| Dependency Features
author ||| Stephen A. Boxwell, Dennis Mehay, and Chris Brew
affiliation ||| Department of Linguistics
affiliation ||| The Ohio State University
email ||| {boxwe11,mehay,cbrew}@1ing.ohio-state.edu
sectionHeader ||| Abstract
bodyText ||| We describe a semantic role labeling system
bodyText ||| that makes primary use of CCG-based fea-
bodyText ||| tures. Most previously developed systems
bodyText ||| are CFG-based and make extensive use of a
bodyText ||| treepath feature, which suffers from data spar-
bodyText ||| sity due to its use of explicit tree configura-
bodyText ||| tions. CCG affords ways to augment treepath-
bodyText ||| based features to overcome these data sparsity
bodyText ||| issues. By adding features over CCG word-
bodyText ||| word dependencies and lexicalized verbal sub-
bodyText ||| categorization frames (“supertags”), we can
bodyText ||| obtain an F-score that is substantially better
bodyText ||| than a previous CCG-based SRL system and
bodyText ||| competitive with the current state of the art. A
bodyText ||| manual error analysis reveals that parser errors
bodyText ||| account for many of the errors of our system.
bodyText ||| This analysis also suggests that simultaneous
bodyText ||| incremental parsing and semantic role labeling
bodyText ||| may lead to performance gains in both tasks.
sectionHeader ||| 1 Introduction
bodyText ||| Semantic Role Labeling (SRL) is the process of assign-
bodyText ||| ing semantic roles to strings of words in a sentence ac-
bodyText ||| cording to their relationship to the semantic predicates
bodyText ||| expressed in the sentence. The task is difficult because
bodyText ||| the relationship between syntactic relations like “sub-
bodyText ||| ject” and “object” do not always correspond to seman-
bodyText ||| tic relations like “agent” and “patient”. An effective
bodyText ||| semantic role labeling system must recognize the dif-
bodyText ||| ferences between different configurations:
listItem ||| (a) [The man]Arg0 opened [the door]A�g1 [for
listItem ||| him]Arg3 [today]ArgM-TMP.
listItem ||| (b) [The door]A�g1 opened.
listItem ||| (c) [The door]A�g1 was opened by [a man]A�g0.
bodyText ||| We use Propbank (Palmer et al., 2005), a corpus of
bodyText ||| newswire text annotated with verb predicate semantic
bodyText ||| role information that is widely used in the SRL litera-
bodyText ||| ture (M`arquez et al., 2008). Rather than describe se-
bodyText ||| mantic roles in terms of “agent” or “patient”, Propbank
bodyText ||| defines semantic roles on a verb-by-verb basis. For ex-
bodyText ||| ample, the verb open encodes the OPENER as Arg0, the
bodyText ||| OPENEE as Arg1, and the beneficiary of the OPENING
bodyText ||| action as Arg3. Propbank also defines a set of adjunct
bodyText ||| roles, denoted by the letter M instead of a number. For
bodyText ||| example, ArgM-TMP denotes a temporal role, like “to-
bodyText ||| day”. By using verb-specific roles, Propbank avoids
bodyText ||| specific claims about parallels between the roles of dif-
bodyText ||| ferent verbs.
bodyText ||| We follow the approach in (Punyakanok et al., 2008)
bodyText ||| in framing the SRL problem as a two-stage pipeline:
bodyText ||| identification followed by labeling. During identifica-
bodyText ||| tion, every word in the sentence is labeled either as
bodyText ||| bearing some (as yet undetermined) semantic role or
bodyText ||| not . This is done for each verb. Next, during label-
bodyText ||| ing, the precise verb-specific roles for each word are
bodyText ||| determined. In contrast to the approach in (Punyakanok
bodyText ||| et al., 2008), which tags constituents directly, we tag
bodyText ||| headwords and then associate them with a constituent,
bodyText ||| as in a previous CCG-based approach (Gildea and
bodyText ||| Hockenmaier, 2003). Another difference is our choice
bodyText ||| of parsers. Brutus uses the CCG parser of (Clark and
bodyText ||| Curran, 2007, henceforth the C&C parser), Charniak’s
bodyText ||| parser (Charniak, 2001) for additional CFG-based fea-
bodyText ||| tures, and MALT parser (Nivre et al., 2007) for de-
bodyText ||| pendency features, while (Punyakanok et al., 2008)
bodyText ||| use results from an ensemble of parses from Char-
bodyText ||| niak’s Parser and a Collins parser (Collins, 2003; Bikel,
bodyText ||| 2004). Finally, the system described in (Punyakanok et
bodyText ||| al., 2008) uses a joint inference model to resolve dis-
bodyText ||| crepancies between multiple automatic parses. We do
bodyText ||| not employ a similar strategy due to the differing no-
bodyText ||| tions of constituency represented in our parsers (CCG
bodyText ||| having a much more fluid notion of constituency and
bodyText ||| the MALT parser using a different approach entirely).
bodyText ||| For the identification and labeling steps, we train
bodyText ||| a maximum entropy classifier (Berger et al., 1996)
bodyText ||| over sections 02-21 of a version of the CCGbank cor-
bodyText ||| pus (Hockenmaier and Steedman, 2007) that has been
bodyText ||| augmented by projecting the Propbank semantic anno-
bodyText ||| tations (Boxwell and White, 2008). We evaluate our
bodyText ||| SRL system’s argument predictions at the word string
bodyText ||| level, making our results directly comparable for each
bodyText ||| argument labeling.1
bodyText ||| In the following, we briefly introduce the CCG
bodyText ||| grammatical formalism and motivate its use in SRL
bodyText ||| (Sections 2–3). Our main contribution is to demon-
bodyText ||| strate that CCG — arguably a more expressive and lin-
footnote ||| 1This is guaranteed by our string-to-string mapping from
footnote ||| the original Propbank to the CCGbank.
page ||| 37
note ||| Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 37–45,
note ||| Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP
bodyText ||| guistically appealing syntactic framework than vanilla
bodyText ||| CFGs — is a viable basis for the SRL task. This is sup-
bodyText ||| ported by our experimental results, the setup and details
bodyText ||| of which we give in Sections 4–10. In particular, using
bodyText ||| CCG enables us to map semantic roles directly onto
bodyText ||| verbal categories, an innovation of our approach that
bodyText ||| leads to performance gains (Section 7). We conclude
bodyText ||| with an error analysis (Section 11), which motivates
bodyText ||| our discussion of future research for computational se-
bodyText ||| mantics with CCG (Section 12).
sectionHeader ||| 2 Combinatory Categorial Grammar
bodyText ||| Combinatory Categorial Grammar (Steedman, 2000)
bodyText ||| is a grammatical framework that describes syntactic
bodyText ||| structure in terms of the combinatory potential of the
bodyText ||| lexical (word-level) items. Rather than using standard
bodyText ||| part-of-speech tags and grammatical rules, CCG en-
bodyText ||| codes much of the combinatory potential of each word
bodyText ||| by assigning a syntactically informative category. For
bodyText ||| example, the verb loves has the category (s\np)/np,
bodyText ||| which could be read “the kind of word that would be
bodyText ||| a sentence if it could combine with a noun phrase on
bodyText ||| the right and a noun phrase on the left”. Further, CCG
bodyText ||| has the advantage of a transparent interface between the
bodyText ||| way the words combine and their dependencies with
bodyText ||| other words. Word-word dependencies in the CCG-
bodyText ||| bank are encoded using predicate-argument (PARG)
bodyText ||| relations. PARG relations are defined by the functor
bodyText ||| word, the argument word, the category of the functor
bodyText ||| word and which argument slot of the functor category
bodyText ||| is being filled. For example, in the sentence John loves
bodyText ||| Mary (figure 1), there are two slots on the verbal cat-
bodyText ||| egory to be filled by NP arguments. The first argu-
bodyText ||| ment (the subject) fills slot 1. This can be encoded
bodyText ||| as <loves,john,(s\np)/np,1>, indicating the head of
bodyText ||| the functor, the head of the argument, the functor cat-
bodyText ||| egory and the argument slot. The second argument
bodyText ||| (the direct object) fills slot 2. This can be encoded as
bodyText ||| <loves,mary,(s\np)/np,2>. One of the potential ad-
bodyText ||| vantages to using CCGbank-style PARG relations is
bodyText ||| that they uniformly encode both local and long-range
bodyText ||| dependencies — e.g., the noun phrase the Mary that
bodyText ||| John loves expresses the same set of two dependencies.
bodyText ||| We will show this to be a valuable tool for semantic
bodyText ||| role prediction.
sectionHeader ||| 3 Potential Advantages to using CCG
bodyText ||| There are many potential advantages to using the CCG
bodyText ||| formalism in SRL. One is the uniformity with which
bodyText ||| CCG can express equivalence classes of local and long-
bodyText ||| range (including unbounded) dependencies. CFG-
bodyText ||| based approaches often rely on examining potentially
bodyText ||| long sequences of categories (or treepaths) between the
bodyText ||| verb and the target word. Because there are a number of
bodyText ||| different treepaths that correspond to a single relation
bodyText ||| (figure 2), this approach can suffer from data sparsity.
bodyText ||| CCG, however, can encode all treepath-distinct expres-
bodyText ||| sions of a single grammatical relation into a single
bodyText ||| predicate-argument relationship (figure 3). This fea-
bodyText ||| ture has been shown (Gildea and Hockenmaier, 2003)
bodyText ||| to be an effective substitute for treepath-based features.
bodyText ||| But while predicate-argument-based features are very
bodyText ||| effective, they are still vulnerable both to parser er-
bodyText ||| rors and to cases where the semantics of a sentence
bodyText ||| do not correspond directly to syntactic dependencies.
bodyText ||| To counteract this, we use both kinds of features with
bodyText ||| the expectation that the treepath feature will provide
bodyText ||| low-level detail to compensate for missed, incorrect or
bodyText ||| syntactically impossible dependencies.
bodyText ||| Another advantage of a CCG-based approach (and
bodyText ||| lexicalist approaches in general) is the ability to en-
bodyText ||| code verb-specific argument mappings. An argument
bodyText ||| mapping is a link between the CCG category and the
bodyText ||| semantic roles that are likely to go with each of its ar-
bodyText ||| guments. The projection of argument mappings onto
bodyText ||| CCG verbal categories is explored in (Boxwell and
bodyText ||| White, 2008). We describe this feature in more detail
bodyText ||| in section 7.
sectionHeader ||| 4 Identification and Labeling Models
bodyText ||| As in previous approaches to SRL, Brutus uses a two-
bodyText ||| stage pipeline of maximum entropy classifiers. In ad-
bodyText ||| dition, we train an argument mapping classifier (de-
bodyText ||| scribed in more detail below) whose predictions are
bodyText ||| used as features for the labeling model. The same
bodyText ||| features are extracted for both treebank and automatic
bodyText ||| parses. Automatic parses were generated using the
bodyText ||| C&C CCG parser (Clark and Curran, 2007) with its
bodyText ||| derivation output format converted to resemble that of
bodyText ||| the CCGbank. This involved following the derivational
bodyText ||| bracketings of the C&C parser’s output and recon-
bodyText ||| structing the backpointers to the lexical heads using an
bodyText ||| in-house implementation of the basic CCG combina-
bodyText ||| tory operations. All classifiers were trained to 500 iter-
bodyText ||| ations of L-BFGS training — a quasi-Newton method
bodyText ||| from the numerical optimization literature (Liu and No-
bodyText ||| cedal, 1989) — using Zhang Le’s maxent toolkit. 2 To
bodyText ||| prevent overfitting we used Gaussian priors with global
bodyText ||| variances of 1 and 5 for the identifier and labeler, re-
bodyText ||| spectively.3 The Gaussian priors were determined em-
bodyText ||| pirically by testing on the development set.
bodyText ||| Both the identifier and the labeler use the following
bodyText ||| features:
listItem ||| (1) Words. Words drawn from a 3 word window
listItem ||| around the target word ,4 with each word asso-
listItem ||| ciated with a binary indicator feature.
listItem ||| (2) Part of Speech. Part of Speech tags drawn
listItem ||| from a 3 word window around the target word,
footnote ||| 2Available for download at http://homepages.
footnote ||| inf.ed.ac.uk/s0450736/maxent_toolkit.
footnote ||| html.
footnote ||| 3Gaussian priors achieve a smoothing effect (to prevent
footnote ||| overfitting) by penalizing very large feature weights.
footnote ||| 4The size of the window was determined experimentally
footnote ||| on the development set – we use the same window sizes
footnote ||| throughout.
page ||| 38
figure ||| Robin	fixed	the car
figure ||| np	(s\np)/np np/n	n
figure ||| np
figure ||| s\np
figure ||| s
figure ||| John	loves	Mary
figure ||| >
figure ||| >
figure ||| �
figure ||| np	(s[dcl]\np)/np	np
figure ||| 		>
figure ||| 		�
figure ||| 	s[dcl]\np
figure ||| 	s[dcl]
figureCaption ||| Figure 1:	This sentence has two depen-
figureCaption ||| dencies:	<loves,mary,(s\np)/np,2>	and
figureCaption ||| <loves,john,(s\np)/np, 1 >
figure ||| fixed
figureCaption ||| Figure 2: The semantic relation (Arg1) between ‘car’
figureCaption ||| and ‘fixed’ in both phrases is the same, but the
figureCaption ||| treepaths — traced with arrows above — are differ-
figureCaption ||| ent: (V>VP<NP<N and V>VP>S>RC>N<N, re-
figureCaption ||| spectively).
figure ||| the car	that	Robin	fixed
figure ||| np/n	n	(np\np)/(s/np)	np	(s\np)/np
figure ||| >T
figure ||| s/(s\np)
figure ||| 	> 	>s
figure ||| np
figure ||| s/np
figure ||| >
figure ||| �
figureCaption ||| Figure 3: CCG word-word dependencies are passed
figureCaption ||| up through subordinate clauses, encoding the rela-
figureCaption ||| tion between car and fixed the same in both cases:
figureCaption ||| (s\np)/np.2.—> (Gildea and Hockenmaier, 2003)
bodyText ||| with each associated with a binary indicator
bodyText ||| feature.
listItem ||| (3) CCG Categories. CCG categories drawn from
bodyText ||| a 3 word window around the target word, with
bodyText ||| each associated with a binary indicator feature.
listItem ||| (4) Predicate. The lemma of the predicate we are
listItem ||| tagging. E.g. fix is the lemma offixed.
listItem ||| (5) Result Category Detail. The grammatical fea-
bodyText ||| ture on the category of the predicate (indicat-
bodyText ||| ing declarative, passive, progressive, etc). This
bodyText ||| can be read off the verb category: declarative
bodyText ||| for eats: (s[dcl]\np)/np or progressive for run-
bodyText ||| ning:s[ng]\np.
listItem ||| (6) Before/After. A binary indicator variable indi-
listItem ||| cating whether the target word is before or after
listItem ||| the verb.
listItem ||| (7) Treepath. The sequence of CCG categories
bodyText ||| representing the path through the derivation
bodyText ||| from the predicate to the target word. For
bodyText ||| the relationship between fixed and car in the
bodyText ||| first sentence of figure 3, the treepath is
bodyText ||| (s[dcl]\np)/np>s[dcl]\np<np<n, with > and
bodyText ||| < indicating movement up and down the tree,
bodyText ||| respectively.
listItem ||| (8) Short Treepath. Similar to the above treepath
bodyText ||| feature, except the path stops at the highest
bodyText ||| node under the least common subsumer that
bodyText ||| is headed by the target word (this is the con-
bodyText ||| stituent that the role would be marked on if we
bodyText ||| identified this terminal as a role-bearing word).
bodyText ||| Again, for the relationship between fixed and
bodyText ||| car in the first sentence of figure 3, the short
bodyText ||| treepath is (s[dcl]\np)/np>s[dcl]\np<np.
listItem ||| (9) NP Modified. A binary indicator feature indi-
listItem ||| cating whether the target word is modified by
listItem ||| an NP modifier.5
footnote ||| 5This is easily read off of the CCG PARG relationships.
figure ||| S
figure ||| �� � ���
figure ||| VP
figure ||| � ��
figure ||| �
figure ||| V	NP
figure ||| � �
figure ||| fixed Det N
figure ||| NP
figure ||| Robin
figure ||| the
figure ||| car
figure ||| N
figure ||| the
figure ||| RC
figure ||| car
figure ||| Rel
figure ||| ^S
figure ||| that
figure ||| NP
figure ||| VP
figure ||| Robin
figure ||| V
figure ||| NP
figure ||| �� � ���
figure ||| Det
figure ||| N
figure ||| �� � ���
figure ||| np\np
figure ||| np
page ||| 39
listItem ||| (10) Subcategorization. A sequence of the cate-
bodyText ||| gories that the verb combines with in the CCG
bodyText ||| derivation tree. For the first sentence in fig-
bodyText ||| ure 3, the correct subcategorization would be
bodyText ||| np,np. Notice that this is not necessarily a re-
bodyText ||| statement of the verbal category – in the second
bodyText ||| sentence of figure 3, the correct subcategoriza-
bodyText ||| tion is s/(s\np),(np\np)/(s[dcl]/np),np.
listItem ||| (11) PARG feature. We follow a previous CCG-
bodyText ||| based approach (Gildea and Hockenmaier,
bodyText ||| 2003) in using a feature to describe the PARG
bodyText ||| relationship between the two words, if one ex-
bodyText ||| ists. If there is a dependency in the PARG
bodyText ||| structure between the two words, then this fea-
bodyText ||| ture is defined as the conjunction of (1) the cat-
bodyText ||| egory of the functor, (2) the argument slot that
bodyText ||| is being filled in the functor category, and (3)
bodyText ||| an indication as to whether the functor (—>) or
bodyText ||| the argument (+—) is the lexical head. For ex-
bodyText ||| ample, to indicate the relationship between car
bodyText ||| and fixed in both sentences of figure 3, the fea-
bodyText ||| ture is (s\np)/np.2.—>.
bodyText ||| The labeler uses all of the previous features, plus the
bodyText ||| following:
listItem ||| (12) Headship. A binary indicator feature as to
bodyText ||| whether the functor or the argument is the lex-
bodyText ||| ical head of the dependency between the two
bodyText ||| words, if one exists.
listItem ||| (13) Predicate and Before/After. The conjunction
bodyText ||| of two earlier features: the predicate lemma
bodyText ||| and the Before/After feature.
listItem ||| (14) Rel Clause. Whether the path from predicate
bodyText ||| to target word passes through a relative clause
bodyText ||| (e.g., marked by the word ‘that’ or any other
bodyText ||| word with a relativizer category).
listItem ||| (15) PP features. When the target word is a prepo-
bodyText ||| sition, we define binary indicator features for
bodyText ||| the word, POS, and CCG category of the head
bodyText ||| of the topmost NP in the prepositional phrase
bodyText ||| headed by a preposition (a.k.a. the ‘lexical
bodyText ||| head’ of the PP). So, if on heads the phrase ‘on
bodyText ||| the third Friday’, then we extract features re-
bodyText ||| lating to Friday for the preposition on. This is
bodyText ||| null when the target word is not a preposition.
listItem ||| (16) Argument Mappings. If there is a PARG rela-
bodyText ||| tion between the predicate and the target word,
bodyText ||| the argument mapping is the most likely pre-
bodyText ||| dicted role to go with that argument. These
bodyText ||| mappings are predicted using a separate classi-
bodyText ||| fier that is trained primarily on lexical informa-
bodyText ||| tion of the verb, its immediate string-level con-
bodyText ||| text, and its observed arguments in the train-
bodyText ||| ing data. This feature is null when there is
bodyText ||| no PARG relation between the predicate and
bodyText ||| the target word. The Argument Mapping fea-
bodyText ||| ture can be viewed as a simple prediction about
bodyText ||| some of the non-modifier semantic roles that a
bodyText ||| verb is likely to express. We use this informa-
bodyText ||| tion as a feature and not a hard constraint to
bodyText ||| allow other features to overrule the recommen-
bodyText ||| dation made by the argument mapping classi-
bodyText ||| fier. The features used in the argument map-
bodyText ||| ping classifier are described in detail in section
bodyText ||| 7.
sectionHeader ||| 5 CFG based Features
bodyText ||| In addition to CCG-based features, features can be
bodyText ||| drawn from a traditional CFG-style approach when
bodyText ||| they are available. Our motivation for this is twofold.
bodyText ||| First, others (Punyakanok et al., 2008, e.g.), have found
bodyText ||| that different parsers have different error patterns, and
bodyText ||| so using multiple parsers can yield complementary
bodyText ||| sources of correct information. Second, we noticed
bodyText ||| that, although the CCG-based system performed well
bodyText ||| on head word labeling, performance dropped when
bodyText ||| projecting these labels to the constituent level (see sec-
bodyText ||| tions 8 and 9 for more). This may have to do with the
bodyText ||| fact that CCG is not centered around a constituency-
bodyText ||| based analysis, as well as with inconsistencies between
bodyText ||| CCG and Penn Treebank-style bracketings (the latter
bodyText ||| being what was annotated in the original Propbank).
bodyText ||| Penn Treebank-derived features are used in the iden-
bodyText ||| tifier, labeler, and argument mapping classifiers. For
bodyText ||| automatic parses, we use Charniak’s parser (Charniak,
bodyText ||| 2001). For gold-standard parses, we remove func-
bodyText ||| tional tag and trace information from the Penn Tree-
bodyText ||| bank parses before we extract features over them, so as
bodyText ||| to simulate the conditions of an automatic parse. The
bodyText ||| Penn Treebank features are as follows:
listItem ||| (17) CFG Treepath. A sequence of traditional
listItem ||| CFG-style categories representing the path
listItem ||| from the verb to the target word.
listItem ||| (18) CFG Short Treepath. Analogous to the CCG-
listItem ||| based short treepath feature.
listItem ||| (19) CFG Subcategorization. Analogous to the
listItem ||| CCG-based subcategorization feature.
listItem ||| (20) CFG Least Common Subsumer. The cate-
listItem ||| gory of the root of the smallest tree that domi-
listItem ||| nates both the verb and the target word.
sectionHeader ||| 6 Dependency Parser Features
bodyText ||| Finally, several features can be extracted from a de-
bodyText ||| pendency representation of the same sentence. Au-
bodyText ||| tomatic dependency relations were produced by the
bodyText ||| MALT parser. We incorporate MALT into our col-
bodyText ||| lection of parses because it provides detailed informa-
bodyText ||| tion on the exact syntactic relations between word pairs
bodyText ||| (subject, object, adverb, etc) that is not found in other
bodyText ||| automatic parsers. The features used from the depen-
bodyText ||| dency parses are listed below:
page ||| 40
listItem ||| (21) DEP-Exists A binary indicator feature show-
listItem ||| ing whether or not there is a dependency be-
listItem ||| tween the target word and the predicate.
listItem ||| (22) DEP-Type If there is a dependency between
listItem ||| the target word and the predicate, what type of
listItem ||| dependency it is (SUBJ, OBJ, etc).
sectionHeader ||| 7 Argument Mapping Model
bodyText ||| An innovation in our approach is to use a separate clas-
bodyText ||| sifier to predict an argument mapping feature. An ar-
bodyText ||| gument mapping is a mapping from the syntactic argu-
bodyText ||| ments of a verbal category to the semantic arguments
bodyText ||| that should correspond to them (Boxwell and White,
bodyText ||| 2008). In order to generate examples of the argument
bodyText ||| mapping for training purposes, it is necessary to em-
bodyText ||| ploy the PARG relations for a given sentence to identify
bodyText ||| the headwords of each of the verbal arguments. That is,
bodyText ||| we use the PARG relations to identify the headwords of
bodyText ||| each of the constituents that are arguments of the verb.
bodyText ||| Next, the appropriate semantic role that corresponds to
bodyText ||| that headword (given by Propbank) is identified. This
bodyText ||| is done by climbing the CCG derivation tree towards
bodyText ||| the root until we find a semantic role corresponding to
bodyText ||| the verb in question — i.e., by finding the point where
bodyText ||| the constituent headed by the verbal category combines
bodyText ||| with the constituent headed by the argument in ques-
bodyText ||| tion. These semantic roles are then marked on the cor-
bodyText ||| responding syntactic argument of the verb.
bodyText ||| As an example, consider the sentence The boy loves
bodyText ||| a girl. (figure 4). By examining the arguments that the
bodyText ||| verbal category combines with in the treebank, we can
bodyText ||| identify the corresponding semantic role for each argu-
bodyText ||| ment that is marked on the verbal category. We then use
bodyText ||| these tags to train the Argument Mapping model, which
bodyText ||| will predict likely argument mappings for verbal cate-
bodyText ||| gories based on their local surroundings and the head-
bodyText ||| words of their arguments, similar to the supertagging
bodyText ||| approaches used to label the informative syntactic cat-
bodyText ||| egories of the verbs (Bangalore and Joshi, 1999; Clark,
bodyText ||| 2002), except tagging “one level above” the syntax.
bodyText ||| The Argument Mapping Predictor uses the following
bodyText ||| features:
listItem ||| (23) Predicate. The lemma of the predicate, as be-
listItem ||| fore.
listItem ||| (24) Words. Words drawn from a 5 word window
listItem ||| around the target word, with each word associ-
listItem ||| ated with a binary indicator feature, as before.
listItem ||| (25) Parts of Speech. Part of Speech tags drawn
listItem ||| from a 5 word window around the target word,
listItem ||| with each tag associated with a binary indicator
listItem ||| feature, as before.
listItem ||| (26) CCG Categories. CCG categories drawn from
bodyText ||| a 5 word window around the target word, with
bodyText ||| each category associated with a binary indica-
bodyText ||| tor feature, as before.
figure ||| the boy	loves	a	girl
figure ||| np/n	n	(s[dcl]\npArg0)/npArg1 np/n	n
figure ||| np — Arga	np — Argl
figure ||| �
figure ||| s[dcl]
figureCaption ||| Figure 4: By looking at the constituents that the verb
figureCaption ||| combines with, we can identify the semantic roles cor-
figureCaption ||| responding to the arguments marked on the verbal cat-
figureCaption ||| egory.
listItem ||| (27) Argument Data. The word, POS, and CCG
listItem ||| category, and treepath of the headwords of each
listItem ||| of the verbal arguments (i.e., PARG depen-
listItem ||| dents), each encoded as a separate binary in-
listItem ||| dicator feature.
listItem ||| (28) Number of arguments. The number of argu-
listItem ||| ments marked on the verb.
listItem ||| (29) Words of Arguments. The head words of each
listItem ||| of the verb’s arguments.
listItem ||| (30) Subcategorization. The CCG categories that
listItem ||| combine with this verb. This includes syntactic
listItem ||| adjuncts as well as arguments.
listItem ||| (31) CFG-Sisters. The POS categories of the sis-
listItem ||| ters of this predicate in the CFG representation.
listItem ||| (32) DEP-dependencies. The individual depen-
bodyText ||| dency types of each of the dependencies re-
bodyText ||| lating to the verb (SBJ, OBJ, ADV, etc) taken
bodyText ||| from the dependency parse. We also incorpo-
bodyText ||| rate a single feature representing the entire set
bodyText ||| of dependency types associated with this verb
bodyText ||| into a single feature, representing the set of de-
bodyText ||| pendencies as a whole.
bodyText ||| Given these features with gold standard parses, our
bodyText ||| argument mapping model can predict entire argument
bodyText ||| mappings with an accuracy rate of 87.96% on the test
bodyText ||| set, and 87.70% on the development set. We found the
bodyText ||| features generated by this model to be very useful for
bodyText ||| semantic role prediction, as they enable us to make de-
bodyText ||| cisions about entire sets of semantic roles associated
bodyText ||| with individual lemmas, rather than choosing them in-
bodyText ||| dependently of each other.
sectionHeader ||| 8 Enabling Cross-System Comparison
bodyText ||| The Brutus system is designed to label headwords of
bodyText ||| semantic roles, rather than entire constituents. How-
bodyText ||| ever, because most SRL systems are designed to label
bodyText ||| constituents rather than headwords, it is necessary to
bodyText ||| project the roles up the derivation to the correct con-
bodyText ||| stituent in order to make a meaningful comparison of
bodyText ||| the system’s performance. This introduces the poten-
bodyText ||| tial for further error, so we report results on the ac-
bodyText ||| curacy of headwords as well as the correct string of
bodyText ||| words. We deterministically move the role to the high-
bodyText ||| est constituent in the derivation that is headed by the
bodyText ||| s[dcl]\np
page ||| 41
table ||| 	P	R	F
table ||| P. et al (treebank)	86.22%	87.40%	86.81%
table ||| Brutus (treebank)	88.29%	86.39%	87.33%
table ||| P. et al (automatic)	77.09%	75.51%	76.29%
table ||| Brutus (automatic)	76.73%	70.45%	73.45%
figure ||| a man	with	glasses spoke
figure ||| np/n	n	(np\np)/np	np	s\np
figure ||| �np
figure ||| np\np
figure ||| np - speak.Arg0
figure ||| s
figureCaption ||| Figure 5: The role is moved towards the root until the
figureCaption ||| original node is no longer the head of the marked con-
figureCaption ||| stituent.
table ||| 	P	R	F
table ||| G&H (treebank)	67.5%	60.0%	63.5%
table ||| Brutus (treebank)	88.18%	85.00%	86.56%
table ||| G&H (automatic)	55.7%	49.5%	52.4%
table ||| Brutus (automatic)	76.06%	70.15%	72.99%
tableCaption ||| Table 1: Accuracy of semantic role prediction using
tableCaption ||| only CCG based features.
bodyText ||| originally tagged terminal. In most cases, this corre-
bodyText ||| sponds to the node immediately dominated by the low-
bodyText ||| est common subsuming node of the the target word and
bodyText ||| the verb (figure 5). In some cases, the highest con-
bodyText ||| stituent that is headed by the target word is not imme-
bodyText ||| diately dominated by the lowest common subsuming
bodyText ||| node (figure 6).
sectionHeader ||| 9 Results
bodyText ||| Using a version of Brutus incorporating only the CCG-
bodyText ||| based features described above, we achieve better re-
bodyText ||| sults than a previous CCG based system (Gildea and
bodyText ||| Hockenmaier, 2003, henceforth G&H). This could be
bodyText ||| due to a number of factors, including the fact that our
bodyText ||| system employs a different CCG parser, uses a more
bodyText ||| complete mapping of the Propbank onto the CCGbank,
bodyText ||| uses a different machine learning approach,6 and has a
bodyText ||| richer feature set. The results for constituent tagging
bodyText ||| accuracy are shown in table 1.
bodyText ||| As expected, by incorporating Penn Treebank-based
bodyText ||| features and dependency features, we obtain better re-
bodyText ||| sults than with the CCG-only system. The results for
bodyText ||| gold standard parses are comparable to the winning
bodyText ||| system of the CoNLL 2005 shared task on semantic
bodyText ||| role labeling (Punyakanok et al., 2008). Other systems
bodyText ||| (Toutanova et al., 2008; Surdeanu et al., 2007; Johans-
bodyText ||| son and Nugues, 2008) have also achieved comparable
bodyText ||| results – we compare our system to (Punyakanok et
bodyText ||| al., 2008) due to the similarities in our approaches. The
bodyText ||| performance of the full system is shown in table 2.
bodyText ||| Table 3 shows the ability of the system to predict
bodyText ||| the correct headwords of semantic roles. This is a nec-
bodyText ||| essary condition for correctness of the full constituent,
bodyText ||| but not a sufficient one. In parser evaluation, Carroll,
bodyText ||| Minnen, and Briscoe (Carroll et al., 2003) have argued
bodyText ||| 6G&H use a generative model with a back-off lattice,
bodyText ||| whereas we use a maximum entropy classifier.
tableCaption ||| Table 2: Accuracy of semantic role prediction using
tableCaption ||| CCG, CFG, and MALT based features.
table ||| 	P	R	F
table ||| Headword (treebank)	88.94%	86.98%	87.95%
table ||| Boundary (treebank)	88.29%	86.39%	87.33%
table ||| Headword (automatic)	82.36%	75.97%	79.04%
table ||| Boundary (automatic)	76.33%	70.59%	73.35%
tableCaption ||| Table 3: Accuracy of the system for labeling semantic
tableCaption ||| roles on both constituent boundaries and headwords.
tableCaption ||| Headwords are easier to predict than boundaries, re-
tableCaption ||| flecting CCG’s focus on word-word relations rather
tableCaption ||| than constituency.
bodyText ||| for dependencies as a more appropriate means of eval-
bodyText ||| uation, reflecting the focus on headwords from con-
bodyText ||| stituent boundaries. We argue that, especially in the
bodyText ||| heavily lexicalized CCG framework, headword evalu-
bodyText ||| ation is more appropriate, reflecting the emphasis on
bodyText ||| headword combinatorics in the CCG formalism.
sectionHeader ||| 10 The Contribution of the New Features
bodyText ||| Two features which are less frequently used in SRL
bodyText ||| research play a major role in the Brutus system: The
bodyText ||| PARG feature (Gildea and Hockenmaier, 2003) and
bodyText ||| the argument mapping feature. Removing them has
bodyText ||| a strong effect on accuracy when labeling treebank
bodyText ||| parses, as shown in our feature ablation results in ta-
bodyText ||| ble 4. We do not report results including the Argu-
bodyText ||| ment Mapping feature but not the PARG feature, be-
bodyText ||| cause some predicate-argument relation information is
bodyText ||| assumed in generating the Argument Mapping feature.
table ||| 	P	R	F
table ||| +PARG +AM	88.77%	86.15%	87.44%
table ||| +PARG -AM	88.42%	85.78%	87.08%
table ||| -PARG -AM	87.92%	84.65%	86.26%
tableCaption ||| Table 4: The effects of removing key features from the
tableCaption ||| system on gold standard parses.
bodyText ||| The same is true for automatic parses, as shown in ta-
bodyText ||| ble 5.
sectionHeader ||| 11 Error Analysis
bodyText ||| Many of the errors made by the Brutus system can be
bodyText ||| traced directly to erroneous parses, either in the auto-
bodyText ||| matic or treebank parse. In some cases, PP attachment
page ||| 42
figure ||| with	even brief exposures	causing	symptoms
figure ||| (((vp\vp)/vp[ng])/np	n/n	n/n	n	(s[ng]\np)/np	np
figure ||| 	� 	�
figure ||| n
figure ||| s[ng]\np
figure ||| n
figure ||| np — cause.Arg0
figure ||| 		�
figure ||| (vp\vp)/vp[ng]			�
figure ||| 	vp\vp
figureCaption ||| Figure 6: In this case, with is the head of with even brief exposures, so the role is correctly marked on even brief
figureCaption ||| exposures (based on wsj 0003.2).
table ||| �
table ||| 	P	R	F
table ||| +PARG +AM	74.14%	62.09%	67.58%
table ||| +PARG -AM	70.02%	64.68%	67.25%
table ||| -PARG -AM	73.90%	61.15%	66.93%
table ||| a form	of	asbestos used to make filters
table ||| np	(np\np)/np	np	np\np
table ||| 		�
table ||| 		�
table ||| 	np\np
table ||| 	np — Arg1
table ||| 	�
table ||| np
tableCaption ||| Table 5: The effects of removing key features from the
tableCaption ||| system on automatic parses.
bodyText ||| ambiguities cause a role to be marked too high in the
bodyText ||| derivation. In the sentence the company stopped using
bodyText ||| asbestos in 1956 (figure 7), the correct Arg 1 of stopped
bodyText ||| is using asbestos. However, because in 1956 is erro-
bodyText ||| neously modifying the verb using rather than the verb
bodyText ||| stopped in the treebank parse, the system trusts the syn-
bodyText ||| tactic analysis and places Arg1 of stopped on using as-
bodyText ||| bestos in 1956. This particular problem is caused by an
bodyText ||| annotation error in the original Penn Treebank that was
bodyText ||| carried through in the conversion to CCGbank.
bodyText ||| Another common error deals with genitive construc-
bodyText ||| tions. Consider the phrase a form of asbestos used
bodyText ||| to make filters. By CCG combinatorics, the relative
bodyText ||| clause could either attach to asbestos or to a form of
bodyText ||| asbestos. The gold standard CCG parse attaches the
bodyText ||| relative clause to a form of asbestos (figure 8). Prop-
bodyText ||| bank agrees with this analysis, assigning Arg1 of use
bodyText ||| to the constituent a form of asbestos. The automatic
bodyText ||| parser, however, attaches the relative clause low – to
bodyText ||| asbestos (figure 9). When the system is given the au-
bodyText ||| tomatically generated parse, it incorrectly assigns the
bodyText ||| semantic role to asbestos. In cases where the parser at-
bodyText ||| taches the relative clause correctly, the system is much
bodyText ||| more likely to assign the role correctly.
bodyText ||| Problems with relative clause attachment to genitives
bodyText ||| are not limited to automatic parses – errors in gold-
bodyText ||| standard treebank parses cause similar problems when
bodyText ||| Treebank parses disagree with Propbank annotator in-
bodyText ||| tuitions. In the phrase a group of workers exposed to
bodyText ||| asbestos (figure 10), the gold standard CCG parse at-
bodyText ||| taches the relative clause to workers. Propbank, how-
bodyText ||| ever, annotates a group of workers as Arg 1 of exposed,
bodyText ||| rather than following the parse and assigning the role
bodyText ||| only to workers. The system again follows the parse
bodyText ||| and incorrectly assigns the role to workers instead of a
bodyText ||| group of workers. Interestingly, the C&C parser opts
bodyText ||| for high attachment in this instance, resulting in the
figureCaption ||| Figure 8: CCGbank gold-standard parse of a relative
figureCaption ||| clause attachment. The system correctly identifies a
figureCaption ||| form of asbestos as Arg1 of used. (wsj 0003.1)
figure ||| a form	of	asbestos used to make filters
figure ||| np	(np\np)/np np — Arg1	np\np
figure ||| �
figure ||| 	�
figure ||| np\np
figure ||| �
figureCaption ||| Figure 9: Automatic parse of the noun phrase in fig-
figureCaption ||| ure 8. Incorrect relative clause attachment causes the
figureCaption ||| misidentification of asbestos as a semantic role bearing
figureCaption ||| unit. (wsj 0003.1)
bodyText ||| correct prediction of a group of workers as Arg1 of ex-
bodyText ||| posed in the automatic parse.
sectionHeader ||| 12 Future Work
bodyText ||| As described in the error analysis section, a large num-
bodyText ||| ber of errors in the system are attributable to errors in
bodyText ||| the CCG derivation, either in the gold standard or in
bodyText ||| automatically generated parses. Potential future work
bodyText ||| may focus on developing an improved CCG parser us-
bodyText ||| ing the revised (syntactic) adjunct-argument distinc-
bodyText ||| tions (guided by the Propbank annotation) described in
bodyText ||| (Boxwell and White, 2008). This resource, together
bodyText ||| with the reasonable accuracy (,: 90%) with which ar-
bodyText ||| gument mappings can be predicted, suggests the possi-
bodyText ||| bility of an integrated, simultaneous syntactic-semantic
bodyText ||| parsing process, similar to that of (Musillo and Merlo,
bodyText ||| 2006; Merlo and Musillo, 2008). We expect this would
bodyText ||| improve the reliability and accuracy of both the syntac-
bodyText ||| tic and semantic analysis components.
sectionHeader ||| 13 Acknowledgments
bodyText ||| This research was funded by NSF grant IIS-0347799.
bodyText ||| We are deeply indebted to Julia Hockenmaier for the
figure ||| np
figure ||| np
page ||| 43
figure ||| the company	stopped	using	asbestos	in 1956
figure ||| np	((s[dcl]\np)/(s[ng]\np)) (s[ng]\np)/np	np	(s\np)\(s\np)
figure ||| 	�
figure ||| s[ng]\np
figure ||| s[ng]\np - stop.Arg1
figure ||| s[dcl]\np
figure ||| s[dcl]
figure ||| �
figure ||| �
figure ||| �
figureCaption ||| Figure 7: An example of how incorrect PP attachment can cause an incorrect labeling. Stop.Arg1 should cover us-
figureCaption ||| ing asbestos rather than using asbestos in 1956. This sentence is based on wsj 0003.3, with the structure simplified
figureCaption ||| for clarity.
figure ||| a group	of	workers	exposed to asbestos
figure ||| np	(np\np)/np np - exposed.Arg1	np\np
figure ||| 					�
figure ||| 					�
figure ||| 					�
figure ||| 				np
figure ||| 			np\np
figure ||| 		np
figureCaption ||| Figure 10: Propbank annotates a group of workers as Arg1 of exposed, while CCGbank attaches the relative clause
figureCaption ||| low. The system incorrectly labels workers as a role bearing unit. (Gold standard – wsj 0003.1)
bodyText ||| use of her PARG generation tool.
sectionHeader ||| References
reference ||| Srinivas Bangalore and Aravind Joshi. 1999. Su-
reference ||| pertagging: An approach to almost parsing. Com-
reference ||| putational Linguistics, 25(2):237–265.
reference ||| Adam L. Berger, S. Della Pietra, and V. Della Pietra.
reference ||| 1996. A maximum entropy approach to natural
reference ||| language processing. Computational Linguistics,
reference ||| 22(1):39–71.
reference ||| D.M. Bikel. 2004. Intricacies of Collins’ parsing
reference ||| model. Computational Linguistics, 30(4):479–511.
reference ||| Stephen A. Boxwell and Michael White. 2008.
reference ||| Projecting propbank roles onto the ccgbank. In
reference ||| Proceedings of the Sixth International Language
reference ||| Resources and Evaluation Conference (LREC-08),
reference ||| Marrakech, Morocco.
reference ||| J. Carroll, G. Minnen, and T. Briscoe. 2003. Parser
reference ||| evaluation. Treebanks: Building and Using Parsed
reference ||| Corpora, pages 299–316.
reference ||| E. Charniak. 2001. Immediate-head parsing for lan-
reference ||| guage models. In Proc. ACL-01, volume 39, pages
reference ||| 116–123.
reference ||| Stephen Clark and James R. Curran. 2007. Wide-
reference ||| coverage Efficient Statistical Parsing with CCG and
reference ||| Log-linear Models. Computational Linguistics,
reference ||| 33(4):493–552.
reference ||| Stephen Clark. 2002. Supertagging for combinatory
reference ||| categorial grammar. In Proceedings of the 6th In-
reference ||| ternational Workshop on Tree Adjoining Grammars
reference ||| and Related Frameworks (TAG+6), pages 19–24,
reference ||| Venice, Italy.
reference ||| M. Collins. 2003. Head-driven statistical models for
reference ||| natural language parsing. Computational Linguis-
reference ||| tics, 29(4):589–637.
reference ||| Daniel Gildea and Julia Hockenmaier. 2003. Identi-
reference ||| fying semantic roles using Combinatory Categorial
reference ||| Grammar. In Proc. EMNLP-03.
reference ||| Julia Hockenmaier and Mark Steedman. 2007. CCG-
reference ||| bank: A Corpus of CCG Derivations and Depen-
reference ||| dency Structures Extracted from the Penn Treebank.
reference ||| Computational Linguistics, 33(3):355–396.
reference ||| R. Johansson and P. Nugues. 2008. Dependency-
reference ||| based syntactic–semantic analysis with PropBank
reference ||| and NomBank. Proceedings of CoNLL –2008.
reference ||| D C Liu and Jorge Nocedal. 1989. On the limited
reference ||| memory method for large scale optimization. Math-
reference ||| ematical Programming B, 45(3).
reference ||| Lluis M`arquez, Xavier Carreras, Kenneth C. Litowski,
reference ||| and Suzanne Stevenson. 2008. Semantic Role La-
reference ||| beling: An Introduction to the Special Issue. Com-
reference ||| putational Linguistics, 34(2):145–159.
reference ||| Paola Merlo and Gabrile Musillo. 2008. Semantic
reference ||| parsing for high-precision semantic role labelling. In
reference ||| Proceedings of CONLL-08, Manchester, UK.
reference ||| Gabriele Musillo and Paola Merlo. 2006. Robust pars-
reference ||| ing of the proposition bank. In Proceedings of the
reference ||| EACL 2006 Workshop ROMAND, Trento.
reference ||| J. Nivre, J. Hall, J. Nilsson, A. Chanev, G. Eryigit,
reference ||| S. K¨ubler, S. Marinov, and E. Marsi. 2007. Malt-
reference ||| Parser: A language-independent system for data-
reference ||| driven dependency parsing. Natural Language En-
reference ||| gineering, 13(02):95–135.
reference ||| Martha Palmer, Daniel Gildea, and Paul Kingsbury.
reference ||| 2005. The Proposition Bank: An Annotated Cor-
reference ||| pus of Semantic Roles. Computational Linguistics,
reference ||| 31(1):71–106.
page ||| 44
reference ||| Vasin Punyakanok, Dan Roth, and Wen tau Yih. 2008.
reference ||| The Importance of Syntactic Parsing and Inference
reference ||| in Semantic Role Labeling. Computational Linguis-
reference ||| tics, 34(2):257–287.
reference ||| Mark Steedman. 2000. The Syntactic Process. MIT
reference ||| Press.
reference ||| M. Surdeanu, L. M`arquez, X. Carreras, and P. Comas.
reference ||| 2007. Combination strategies for semantic role la-
reference ||| beling. Journal of Artificial Intelligence Research,
reference ||| 29:105–151.
reference ||| K. Toutanova, A. Haghighi, and C.D. Manning. 2008.
reference ||| A global joint model for semantic role labeling.
reference ||| Computational Linguistics, 34(2):161–191.
page ||| 45

title ||| Exploiting Heterogeneous Treebanks for Parsing
author ||| Zheng-Yu Niu, Haifeng Wang, Hua Wu
affiliation ||| Toshiba (China) Research and Development Center
address ||| 5/F., Tower W2, Oriental Plaza, Beijing, 100738, China
email ||| {niuzhengyu,wanghaifeng,wuhua}@rdc.toshiba.com.cn
sectionHeader ||| Abstract
bodyText ||| We address the issue of using heteroge-
bodyText ||| neous treebanks for parsing by breaking
bodyText ||| it down into two sub-problems, convert-
bodyText ||| ing grammar formalisms of the treebanks
bodyText ||| to the same one, and parsing on these
bodyText ||| homogeneous treebanks. First we pro-
bodyText ||| pose to employ an iteratively trained tar-
bodyText ||| get grammar parser to perform grammar
bodyText ||| formalism conversion, eliminating prede-
bodyText ||| fined heuristic rules as required in previ-
bodyText ||| ous methods. Then we provide two strate-
bodyText ||| gies to refine conversion results, and adopt
bodyText ||| a corpus weighting technique for parsing
bodyText ||| on homogeneous treebanks. Results on the
bodyText ||| Penn Treebank show that our conversion
bodyText ||| method achieves 42% error reduction over
bodyText ||| the previous best result. Evaluation on
bodyText ||| the Penn Chinese Treebank indicates that a
bodyText ||| converted dependency treebank helps con-
bodyText ||| stituency parsing and the use of unlabeled
bodyText ||| data by self-training further increases pars-
bodyText ||| ing f-score to 85.2%, resulting in 6% error
bodyText ||| reduction over the previous best result.
sectionHeader ||| 1 Introduction
bodyText ||| The last few decades have seen the emergence of
bodyText ||| multiple treebanks annotated with different gram-
bodyText ||| mar formalisms, motivated by the diversity of lan-
bodyText ||| guages and linguistic theories, which is crucial to
bodyText ||| the success of statistical parsing (Abeille et al.,
bodyText ||| 2000; Brants et al., 1999; Bohmova et al., 2003;
bodyText ||| Han et al., 2002; Kurohashi and Nagao, 1998;
bodyText ||| Marcus et al., 1993; Moreno et al., 2003; Xue et
bodyText ||| al., 2005). Availability of multiple treebanks cre-
bodyText ||| ates a scenario where we have a treebank anno-
bodyText ||| tated with one grammar formalism, and another
bodyText ||| treebank annotated with another grammar formal-
bodyText ||| ism that we are interested in. We call the first
bodyText ||| a source treebank, and the second a target tree-
bodyText ||| bank. We thus encounter a problem of how to
bodyText ||| use these heterogeneous treebanks for target gram-
bodyText ||| mar parsing. Here heterogeneous treebanks refer
bodyText ||| to two or more treebanks with different grammar
bodyText ||| formalisms, e.g., one treebank annotated with de-
bodyText ||| pendency structure (DS) and the other annotated
bodyText ||| with phrase structure (PS).
bodyText ||| It is important to acquire additional labeled data
bodyText ||| for the target grammar parsing through exploita-
bodyText ||| tion of existing source treebanks since there is of-
bodyText ||| ten a shortage of labeled data. However, to our
bodyText ||| knowledge, there is no previous study on this is-
bodyText ||| sue.
bodyText ||| Recently there have been some works on us-
bodyText ||| ing multiple treebanks for domain adaptation of
bodyText ||| parsers, where these treebanks have the same
bodyText ||| grammar formalism (McClosky et al., 2006b;
bodyText ||| Roark and Bacchiani, 2003). Other related works
bodyText ||| focus on converting one grammar formalism of a
bodyText ||| treebank to another and then conducting studies on
bodyText ||| the converted treebank (Collins et al., 1999; Forst,
bodyText ||| 2003; Wang et al., 1994; Watkinson and Manand-
bodyText ||| har, 2001). These works were done either on mul-
bodyText ||| tiple treebanks with the same grammar formalism
bodyText ||| or on only one converted treebank. We see that
bodyText ||| their scenarios are different from ours as we work
bodyText ||| with multiple heterogeneous treebanks.
bodyText ||| For the use of heterogeneous treebanks1, we
bodyText ||| propose a two-step solution: (1) converting the
bodyText ||| grammar formalism of the source treebank to the
bodyText ||| target one, (2) refining converted trees and using
bodyText ||| them as additional training data to build a target
bodyText ||| grammar parser.
bodyText ||| For grammar formalism conversion, we choose
bodyText ||| the DS to PS direction for the convenience of the
bodyText ||| comparison with existing works (Xia and Palmer,
bodyText ||| 2001; Xia et al., 2008). Specifically, we assume
bodyText ||| that the source grammar formalism is dependency
footnote ||| 1Here we assume the existence of two treebanks.
page ||| 46
note ||| Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 46–54,
note ||| Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP
bodyText ||| grammar, and the target grammar formalism is
bodyText ||| phrase structure grammar.
bodyText ||| Previous methods for DS to PS conversion
bodyText ||| (Collins et al., 1999; Covington, 1994; Xia and
bodyText ||| Palmer, 2001; Xia et al., 2008) often rely on pre-
bodyText ||| defined heuristic rules to eliminate converison am-
bodyText ||| biguity, e.g., minimal projection for dependents,
bodyText ||| lowest attachment position for dependents, and the
bodyText ||| selection of conversion rules that add fewer num-
bodyText ||| ber of nodes to the converted tree. In addition, the
bodyText ||| validity of these heuristic rules often depends on
bodyText ||| their target grammars. To eliminate the heuristic
bodyText ||| rules as required in previous methods, we propose
bodyText ||| to use an existing target grammar parser (trained
bodyText ||| on the target treebank) to generate N-best parses
bodyText ||| for each sentence in the source treebank as conver-
bodyText ||| sion candidates, and then select the parse consis-
bodyText ||| tent with the structure of the source tree as the con-
bodyText ||| verted tree. Furthermore, we attempt to use con-
bodyText ||| verted trees as additional training data to retrain
bodyText ||| the parser for better conversion candidates. The
bodyText ||| procedure of tree conversion and parser retraining
bodyText ||| will be run iteratively until a stopping condition is
bodyText ||| satisfied.
bodyText ||| Since some converted trees might be imper-
bodyText ||| fect from the perspective of the target grammar,
bodyText ||| we provide two strategies to refine conversion re-
bodyText ||| sults: (1) pruning low-quality trees from the con-
bodyText ||| verted treebank, (2) interpolating the scores from
bodyText ||| the source grammar and the target grammar to se-
bodyText ||| lect better converted trees. Finally we adopt a cor-
bodyText ||| pus weighting technique to get an optimal combi-
bodyText ||| nation of the converted treebank and the existing
bodyText ||| target treebank for parser training.
bodyText ||| We have evaluated our conversion algorithm on
bodyText ||| a dependency structure treebank (produced from
bodyText ||| the Penn Treebank) for comparison with previous
bodyText ||| work (Xia et al., 2008). We also have investi-
bodyText ||| gated our two-step solution on two existing tree-
bodyText ||| banks, the Penn Chinese Treebank (CTB) (Xue et
bodyText ||| al., 2005) and the Chinese Dependency Treebank
bodyText ||| (CDT)2 (Liu et al., 2006). Evaluation on WSJ data
bodyText ||| demonstrates that it is feasible to use a parser for
bodyText ||| grammar formalism conversion and the conversion
bodyText ||| benefits from converted trees used for parser re-
bodyText ||| training. Our conversion method achieves 93.8%
bodyText ||| f-score on dependency trees produced from WSJ
bodyText ||| section 22, resulting in 42% error reduction over
bodyText ||| the previous best result for DS to PS conversion.
bodyText ||| Results on CTB show that score interpolation is
footnote ||| 2Available at http://ir.hit.edu.cn/.
bodyText ||| more effective than instance pruning for the use
bodyText ||| of converted treebanks for parsing and converted
bodyText ||| CDT helps parsing on CTB. When coupled with
bodyText ||| self-training technique, a reranking parser with
bodyText ||| CTB and converted CDT as labeled data achieves
bodyText ||| 85.2% f-score on CTB test set, an absolute 1.0%
bodyText ||| improvement (6% error reduction) over the previ-
bodyText ||| ous best result for Chinese parsing.
bodyText ||| The rest of this paper is organized as follows. In
bodyText ||| Section 2, we first describe a parser based method
bodyText ||| for DS to PS conversion, and then we discuss pos-
bodyText ||| sible strategies to refine conversion results, and
bodyText ||| finally we adopt the corpus weighting technique
bodyText ||| for parsing on homogeneous treebanks. Section
bodyText ||| 3 provides experimental results of grammar for-
bodyText ||| malism conversion on a dependency treebank pro-
bodyText ||| duced from the Penn Treebank. In Section 4, we
bodyText ||| evaluate our two-step solution on two existing het-
bodyText ||| erogeneous Chinese treebanks. Section 5 reviews
bodyText ||| related work and Section 6 concludes this work.
sectionHeader ||| 2 Our Two-Step Solution
subsectionHeader ||| 2.1 Grammar Formalism Conversion
bodyText ||| Previous DS to PS conversion methods built a
bodyText ||| converted tree by iteratively attaching nodes and
bodyText ||| edges to the tree with the help of conversion
bodyText ||| rules and heuristic rules, based on current head-
bodyText ||| dependent pair from a source dependency tree and
bodyText ||| the structure of the built tree (Collins et al., 1999;
bodyText ||| Covington, 1994; Xia and Palmer, 2001; Xia et
bodyText ||| al., 2008). Some observations can be made on
bodyText ||| these methods: (1) for each head-dependent pair,
bodyText ||| only one locally optimal conversion was kept dur-
bodyText ||| ing tree-building process, at the risk of pruning
bodyText ||| globally optimal conversions, (2) heuristic rules
bodyText ||| are required to deal with the problem that one
bodyText ||| head-dependent pair might have multiple conver-
bodyText ||| sion candidates, and these heuristic rules are usu-
bodyText ||| ally hand-crafted to reflect the structural prefer-
bodyText ||| ence in their target grammars. To overcome these
bodyText ||| limitations, we propose to employ a parser to gen-
bodyText ||| erate N-best parses as conversion candidates and
bodyText ||| then use the structural information of source trees
bodyText ||| to select the best parse as a converted tree.
bodyText ||| We formulate our conversion method as fol-
bodyText ||| lows.
bodyText ||| Let CDS be a source treebank annotated with
bodyText ||| DS and CPS be a target treebank annotated with
bodyText ||| PS. Our goal is to convert the grammar formalism
bodyText ||| of CDS to that of CPS.
bodyText ||| We first train a constituency parser on CPS
page ||| 47
bodyText ||| Input: CPS, CDS, Q, and a constituency parser	Output: Converted trees Cps
listItem ||| 1. Initialize:
listItem ||| — Set Cps,0 as null, DevScore=0, q=0;
listItem ||| — Split CPS into training set CPS,train and development set CPS,dev;
listItem ||| — Train the parser on CPS,train and denote it by Pq–l;
listItem ||| 2. Repeat:
listItem ||| — Use Pq_i to generate N-best PS parses for each sentence in CDS, and convert PS to DS for each parse;
listItem ||| — For each sentence in CDS Do
listItem ||| o �t=argmaxt Score (xi,t), and select the �t-th parse as a converted tree for this sentence;
listItem ||| — Let CD S,q S represent these converted trees, and let Ctrain=CPS,train U CDSS,q ;
listItem ||| — Train the parser on Ctrain, and denote the updated parser by Pq;
listItem ||| — Let DevScoreq be the f-score of Pq on CPS,dev;
listItem ||| — If DevScoreq > DevScore Then DevScore=DevScoreq, and Cps=Cps,q;
listItem ||| — Else break;
listItem ||| — q++;
listItem ||| Until q > Q
tableCaption ||| Table 1: Our algorithm for DS to PS conversion.
bodyText ||| (90% trees in CPS as training set CPS,train, and
bodyText ||| other trees as development set CPS,dev) and then
bodyText ||| let the parser generate N-best parses for each sen-
bodyText ||| tence in CDS.
bodyText ||| Let n be the number of sentences (or trees) in
bodyText ||| CDS and ni be the number of N-best parses gen-
bodyText ||| erated by the parser for the i-th (1 < i < n) sen-
bodyText ||| tence in CDS. Let xi,t be the t-th (1 < t < ni)
bodyText ||| parse for the i-th sentence. Let yi be the tree of the
bodyText ||| i-th (1 < i < n) sentence in CDS.
bodyText ||| To evaluate the quality of xi,t as a conversion
bodyText ||| candidate for yi, we convert xi,t to a dependency
bodyText ||| tree (denoted as xDS) and then use unlabeled de-
bodyText ||| pendency f-score to measure the similarity be-
bodyText ||| tween xDS and yi. Let Score(xi,t) denote the
bodyText ||| unlabeled dependency f-score of xDS against yi.
bodyText ||| Then we determine the converted tree for yi by
bodyText ||| maximizing Score(xi,t) over the N-best parses.
bodyText ||| The conversion from PS to DS works as fol-
bodyText ||| lows:
bodyText ||| Step 1. Use a head percolation table to find the
bodyText ||| head of each constituent in xi,t.
bodyText ||| Step 2. Make the head of each non-head child
bodyText ||| depend on the head of the head child for each con-
bodyText ||| stituent.
bodyText ||| Unlabeled dependency f-score is a harmonic
bodyText ||| mean of unlabeled dependency precision and unla-
bodyText ||| beled dependency recall. Precision measures how
bodyText ||| many head-dependent word pairs found in xDS
bodyText ||| i,t
bodyText ||| are correct and recall is the percentage of head-
bodyText ||| dependent word pairs defined in the gold-standard
bodyText ||| tree that are found in xDS. Here we do not take
bodyText ||| dependency tags into consideration for evaluation
bodyText ||| since they cannot be obtained without more so-
bodyText ||| phisticated rules.
bodyText ||| To improve the quality of N-best parses, we at-
bodyText ||| tempt to use the converted trees as additional train-
bodyText ||| ing data to retrain the parser. The procedure of
bodyText ||| tree conversion and parser retraining can be run it-
bodyText ||| eratively until a termination condition is satisfied.
bodyText ||| Here we use the parser’s f-score on CPS,dev as a
bodyText ||| termination criterion. If the update of training data
bodyText ||| hurts the performance on CPS,dev, then we stop
bodyText ||| the iteration.
bodyText ||| Table 1 shows this DS to PS conversion algo-
bodyText ||| rithm. Q is an upper limit of the number of loops,
bodyText ||| and Q>0.
subsectionHeader ||| 2.2 Target Grammar Parsing
bodyText ||| Through grammar formalism conversion, we have
bodyText ||| successfully turned the problem of using hetero-
bodyText ||| geneous treebanks for parsing into the problem of
bodyText ||| parsing on homogeneous treebanks. Before using
bodyText ||| converted source treebank for parsing, we present
bodyText ||| two strategies to refine conversion results.
bodyText ||| Instance Pruning For some sentences in
bodyText ||| CDS, the parser might fail to generate high qual-
bodyText ||| ity N-best parses, resulting in inferior converted
bodyText ||| trees. To clean the converted treebank, we can re-
bodyText ||| move the converted trees with low unlabeled de-
bodyText ||| pendency f-scores (defined in Section 2.1) before
bodyText ||| using the converted treebank for parser training
page ||| 48
figureCaption ||| Figure 1: A parse tree in CTB for a sentence of
figureCaption ||| " t1t A<world> -X <every> � <country> A
figureCaption ||| V�<people> N<all> 4E<with> H A<eyes>
figureCaption ||| R hJ <cast> # A<Hong Kong> " with
figureCaption ||| "People from all over the world are cast-
figureCaption ||| ing their eyes on Hong Kong" as its English
figureCaption ||| translation.
bodyText ||| because these trees are "misleading" training in-
bodyText ||| stances. The number of removed trees will be de-
bodyText ||| termined by cross validation on development set.
bodyText ||| Score Interpolation Unlabeled dependency
bodyText ||| f-scores used in Section 2.1 measure the quality of
bodyText ||| converted trees from the perspective of the source
bodyText ||| grammar only. In extreme cases, the top best
bodyText ||| parses in the N-best list are good conversion can-
bodyText ||| didates but we might select a parse ranked quite
bodyText ||| low in the N-best list since there might be con-
bodyText ||| flicts of syntactic structure definition between the
bodyText ||| source grammar and the target grammar.
bodyText ||| Figure 1 shows an example for illustration of
bodyText ||| a conflict between the grammar of CDT and
bodyText ||| that of CTB. According to Chinese head percola-
bodyText ||| tion tables used in the PS to DS conversion tool
bodyText ||| "Penn2Malt" 3 and Charniak’s parser4, the head
bodyText ||| of VP-2 is the word " 4E " (a preposition, with
bodyText ||| "BA" as its POS tag in CTB), and the head of
bodyText ||| IP-OBJ is R hJ " . Therefore the word " R
bodyText ||| hJ" depends on the word "4E" . But according
bodyText ||| to the annotation scheme in CDT (Liu et al., 2006),
bodyText ||| the word "4E" is a dependent of the word "R
bodyText ||| hJ " . The conflicts between the two grammars
bodyText ||| may lead to the problem that the selected parses
bodyText ||| based on the information of the source grammar
bodyText ||| might not be preferred from the perspective of the
footnote ||| 3Available at http://w3.msi.vxu.se/—nivre/.
footnote ||| 4Available at http://www.cs.brown.edu/—ec/.
bodyText ||| target grammar.
bodyText ||| Therefore we modified the selection metric in
bodyText ||| Section 2.1 by interpolating two scores, the prob-
bodyText ||| ability of a conversion candidate from the parser
bodyText ||| and its unlabeled dependency f-score, shown as
bodyText ||| follows:
equation ||| Score(xi,t) = AxProb(xi,t)+(1—A)xScore(xi,t). (1)
bodyText ||| The intuition behind this equation is that converted
bodyText ||| trees should be preferred from the perspective of
bodyText ||| both the source grammar and the target grammar.
bodyText ||| Here 0 < A < 1. Prob(xi,t) is a probability pro-
bodyText ||| duced by the parser for xi,t (0 < Prob(xi,t) < 1).
bodyText ||| The value of A will be tuned by cross validation on
bodyText ||| development set.
bodyText ||| After grammar formalism conversion, the prob-
bodyText ||| lem now we face has been limited to how to build
bodyText ||| parsing models on multiple homogeneous tree-
bodyText ||| bank. A possible solution is to simply concate-
bodyText ||| nate the two treebanks as training data. However
bodyText ||| this method may lead to a problem that if the size
bodyText ||| of CPS is significantly less than that of converted
bodyText ||| CDS, converted CDS may weaken the effect CPS
bodyText ||| might have. One possible solution is to reduce the
bodyText ||| weight of examples from converted CDS in parser
bodyText ||| training. Corpus weighting is exactly such an ap-
bodyText ||| proach, with the weight tuned on development set,
bodyText ||| that will be used for parsing on homogeneous tree-
bodyText ||| banks in this paper.
sectionHeader ||| 3 Experiments of Grammar Formalism
sectionHeader ||| Conversion
subsectionHeader ||| 3.1 Evaluation on WSJ section 22
bodyText ||| Xia et al. (2008) used WSJ section 19 from the
bodyText ||| Penn Treebank to extract DS to PS conversion
bodyText ||| rules and then produced dependency trees from
bodyText ||| WSJ section 22 for evaluation of their DS to PS
bodyText ||| conversion algorithm. They showed that their
bodyText ||| conversion algorithm outperformed existing meth-
bodyText ||| ods on the WSJ data. For comparison with their
bodyText ||| work, we conducted experiments in the same set-
bodyText ||| ting as theirs: using WSJ section 19 (1844 sen-
bodyText ||| tences) as CPS, producing dependency trees from
bodyText ||| WSJ section 22 (1700 sentences) as CDS5, and
bodyText ||| using labeled bracketing f-scores from the tool
bodyText ||| "EVALB" on WSJ section 22 for performance
bodyText ||| evaluation.
footnote ||| 5We used the tool "Penn2Malt" to produce dependency
footnote ||| structures from the Penn Treebank, which was also used for
footnote ||| PS to DS conversion in our conversion algorithm.
page ||| 49
table ||| 	DevScore	All the sentences
table ||| 		LR	LP	F
table ||| Models	(%)	(%)	(%)	(%)
table ||| The best result of
table ||| Xia et al. (2008)	-	90.7	88.1	89.4
table ||| Q-0-method	86.8	92.2	92.8	92.5
table ||| Q-10-method	88.0	93.4	94.1	93.8
tableCaption ||| Table 2: Comparison with the work of Xia et al.
table ||| (2008) on WSJ section 22.
table ||| 		All the sentences
table ||| 	DevScore	LR	LP	F
table ||| Models	(%)	(%)	(%)	(%)
table ||| Q-0-method	91.0	91.6	92.5	92.1
table ||| Q-10-method	91.6	93.1	94.1	93.6
tableCaption ||| Table 3: Results of our algorithm on WSJ section
tableCaption ||| 2-18 and 20-22.
bodyText ||| We employed Charniak’s maximum entropy in-
bodyText ||| spired parser (Charniak, 2000) to generate N-best
bodyText ||| (N=200) parses. Xia et al. (2008) used POS
bodyText ||| tag information, dependency structures and depen-
bodyText ||| dency tags in test set for conversion. Similarly, we
bodyText ||| used POS tag information in the test set to restrict
bodyText ||| search space of the parser for generation of better
bodyText ||| N-best parses.
bodyText ||| We evaluated two variants of our DS to PS con-
bodyText ||| version algorithm:
bodyText ||| Q-0-method: We set the value of Q as 0 for a
bodyText ||| baseline method.
bodyText ||| Q-10-method: We set the value of Q as 10 to
bodyText ||| see whether it is helpful for conversion to retrain
bodyText ||| the parser on converted trees.
bodyText ||| Table 2 shows the results of our conversion al-
bodyText ||| gorithm on WSJ section 22. In the experiment
bodyText ||| of Q-10-method, DevScore reached the highest
bodyText ||| value of 88.0% when q was 1. Then we used
bodyText ||| Cps,1 as the conversion result. Finally Q-10-
bodyText ||| method achieved an f-score of 93.8% on WSJ sec-
bodyText ||| tion 22, an absolute 4.4% improvement (42% er-
bodyText ||| ror reduction) over the best result of Xia et al.
bodyText ||| (2008). Moreover, Q-10-method outperformed Q-
bodyText ||| 0-method on the same test set. These results indi-
bodyText ||| cate that it is feasible to use a parser for DS to PS
bodyText ||| conversion and the conversion benefits from the
bodyText ||| use of converted trees for parser retraining.
subsectionHeader ||| 3.2 Evaluation on WSJ section 2-18 and
subsectionHeader ||| 20-22
bodyText ||| In this experiment we evaluated our conversion al-
bodyText ||| gorithm on a larger test set, WSJ section 2-18 and
bodyText ||| 20-22 (totally 39688 sentences). Here we also
bodyText ||| used WSJ section 19 as CPS. Other settings for
table ||| Training data	All the sentences
table ||| 	LR	LP	F
table ||| 	(%)	(%)	(%)
table ||| 1 x CTB + CDTPS	84.7	85.1	84.9
table ||| 2 x CTB + CDTPS	85.1	85.6	85.3
table ||| 5 x CTB + CDTPS	85.0	85.5	85.3
table ||| 10 x CTB +CDTPS	85.3	85.8	85.6
table ||| 20 x CTB +CDTPS	85.1	85.3	85.2
table ||| 50 x CTB +CDTPS	84.9	85.3	85.1
tableCaption ||| Table 4: Results of the generative parser on the de-
tableCaption ||| velopment set, when trained with various weight-
tableCaption ||| ing of CTB training set and CDTPS.
bodyText ||| this experiment are as same as that in Section 3. 1,
bodyText ||| except that here we used a larger test set.
bodyText ||| Table 3 provides the f-scores of our method with
bodyText ||| Q equal to 0 or 10 on WSJ section 2-18 and
bodyText ||| 20-22.
bodyText ||| With Q-10-method, DevScore reached the high-
bodyText ||| est value of 91.6% when q was 1. Finally Q-
bodyText ||| 10-method achieved an f-score of 93.6% on WSJ
bodyText ||| section 2-18 and 20-22, better than that of Q-0-
bodyText ||| method and comparable with that of Q-10-method
bodyText ||| in Section 3.1. It confirms our previous finding
bodyText ||| that the conversion benefits from the use of con-
bodyText ||| verted trees for parser retraining.
sectionHeader ||| 4 Experiments of Parsing
bodyText ||| We investigated our two-step solution on two ex-
bodyText ||| isting treebanks, CDT and CTB, and we used CDT
bodyText ||| as the source treebank and CTB as the target tree-
bodyText ||| bank.
bodyText ||| CDT consists of 60k Chinese sentences, anno-
bodyText ||| tated with POS tag information and dependency
bodyText ||| structure information (including 28 POS tags, and
bodyText ||| 24 dependency tags) (Liu et al., 2006). We did not
bodyText ||| use POS tag information as inputs to the parser in
bodyText ||| our conversion method due to the difficulty of con-
bodyText ||| version from CDT POS tags to CTB POS tags.
bodyText ||| We used a standard split of CTB for perfor-
bodyText ||| mance evaluation, articles 1-270 and 400-1151 as
bodyText ||| training set, articles 301-325 as development set,
bodyText ||| and articles 271-300 as test set.
bodyText ||| We used Charniak’s maximum entropy inspired
bodyText ||| parser and their reranker (Charniak and Johnson,
bodyText ||| 2005) for target grammar parsing, called a gener-
bodyText ||| ative parser (GP) and a reranking parser (RP) re-
bodyText ||| spectively. We reported ParseVal measures from
bodyText ||| the EVALB tool.
page ||| 50
table ||| 		All the sentences
table ||| 		LR	LP	F
table ||| Models	Training data	(%)	(%)	(%)
table ||| GP	CTB	79.9	82.2	81.0
table ||| RP	CTB	82.0	84.6	83.3
table ||| GP	10 x CTB + CDTPS	80.4	82.7	81.5
table ||| RP	10 x CTB + CDTPS	82.8	84.7	83.8
tableCaption ||| Table 5: Results of the generative parser (GP) and
tableCaption ||| the reranking parser (RP) on the test set, when
tableCaption ||| trained on only CTB training set or an optimal
tableCaption ||| combination of CTB training set and CDTPS.
subsectionHeader ||| 4.1 Results of a Baseline Method to Use CDT
bodyText ||| We used our conversion algorithm6 to convert the
bodyText ||| grammar formalism of CDT to that of CTB. Let
bodyText ||| CDTPS denote the converted CDT by our method.
bodyText ||| The average unlabeled dependency f-score of trees
bodyText ||| in CDTPS was 74.4%, and their average index in
bodyText ||| 200-best list was 48.
bodyText ||| We tried the corpus weighting method when
bodyText ||| combining CDTPS with CTB training set (abbre-
bodyText ||| viated as CTB for simplicity) as training data, by
bodyText ||| gradually increasing the weight (including 1, 2, 5,
bodyText ||| 10, 20, 50) of CTB to optimize parsing perfor-
bodyText ||| mance on the development set. Table 4 presents
bodyText ||| the results of the generative parser with various
bodyText ||| weights of CTB on the development set. Consid-
bodyText ||| ering the performance on the development set, we
bodyText ||| decided to give CTB a relative weight of 10.
bodyText ||| Finally we evaluated two parsing models, the
bodyText ||| generative parser and the reranking parser, on the
bodyText ||| test set, with results shown in Table 5. When
bodyText ||| trained on CTB only, the generative parser and the
bodyText ||| reranking parser achieved f-scores of 81.0% and
bodyText ||| 83.3%. The use of CDTPS as additional training
bodyText ||| data increased f-scores of the two models to 81.5%
bodyText ||| and 83.8%.
subsectionHeader ||| 4.2 Results of Two Strategies for a Better Use
subsectionHeader ||| of CDT
subsubsectionHeader ||| 4.2.1 Instance Pruning
bodyText ||| We used unlabeled dependency f-score of each
bodyText ||| converted tree as the criterion to rank trees in
bodyText ||| CDTPS and then kept only the top M trees
bodyText ||| with high f-scores as training data for pars-
bodyText ||| ing, resulting in a corpus CDTPMS. M var-
bodyText ||| ied from 100% xICDTPSI to 10% xICDTPSI
bodyText ||| with 10%xICDTPSI as the interval. ICDTPSI
footnote ||| 6The setting for our conversion algorithm in this experi-
footnote ||| ment was as same as that in Section 3.1. In addition, we used
footnote ||| CTB training set as CPS,tr�i�, and CTB development set as
footnote ||| CPS,dev.
table ||| 		All the sentences
table ||| 		LR	LP	F
table ||| Models	Training data	(%)	(%)	(%)
table ||| GP	CTB + CDTa S	81.4	82.8	82.1
table ||| RP	CTB + CDTa S	83.0	85.4	84.2
tableCaption ||| Table 6: Results of the generative parser and the
tableCaption ||| reranking parser on the test set, when trained on
tableCaption ||| an optimal combination of CTB training set and
tableCaption ||| converted CDT.
bodyText ||| is the number of trees in CDTPS. Then
bodyText ||| we tuned the value of M by optimizing the
bodyText ||| parser’s performance on the development set with
bodyText ||| 10 x CTB+CDTPMS as training data. Finally the op-
bodyText ||| timal value of M was 100%x I CDT I. It indicates
bodyText ||| that even removing very few converted trees hurts
bodyText ||| the parsing performance. A possible reason is that
bodyText ||| most of non-perfect parses can provide useful syn-
bodyText ||| tactic structure information for building parsing
bodyText ||| models.
subsubsectionHeader ||| 4.2.2 Score Interpolation
bodyText ||| We used �Score(xj,t)7 to replace Score(xj,t) in
bodyText ||| our conversion algorithm and then ran the updated
bodyText ||| algorithm on CDT. Let CDTP S denote the con-
bodyText ||| verted CDT by this updated conversion algorithm.
bodyText ||| The values of A (varying from 0.0 to 1.0 with 0.1
bodyText ||| as the interval) and the CTB weight (including 1,
bodyText ||| 2, 5, 10, 20, 50) were simultaneously tuned on the
bodyText ||| development set8. Finally we decided that the op-
bodyText ||| timal value of A was 0.4 and the optimal weight of
bodyText ||| CTB was 1, which brought the best performance
bodyText ||| on the development set (an f-score of 86.1%). In
bodyText ||| comparison with the results in Section 4.1, the
bodyText ||| average index of converted trees in 200-best list
bodyText ||| increased to 2, and their average unlabeled depen-
bodyText ||| dency f-score dropped to 65.4%. It indicates that
bodyText ||| structures of converted trees become more consis-
bodyText ||| tent with the target grammar, as indicated by the
bodyText ||| increase of average index of converted trees, fur-
bodyText ||| ther away from the source grammar.
bodyText ||| Table 6 provides f-scores of the generative
bodyText ||| parser and the reranker on the test set, when
bodyText ||| trained on CTB and CDTP S. We see that the
bodyText ||| performance of the reranking parser increased to
footnote ||| 7Before calculating	�Score(xi,t),	we normal-
footnote ||| ized the values of Prob(xi,t) for each N-best list
footnote ||| by	(1)	Prob(xi,t)=Prob(xi,t)-Min(Prob(xi,*)),
footnote ||| (2)Prob(xi,t)=Prob(xi,t)/Max(Prob(xi,*)),	resulting
footnote ||| in that their maximum value was 1 and their minimum value
footnote ||| was 0.
footnote ||| 8Due to space constraint, we do not show f-scores of the
footnote ||| parser with different values of A and the CTB weight.
page ||| 51
table ||| 		All the sentences
table ||| 		LR	LP	F
table ||| Models	Training data	(%)	(%)	(%)
table ||| Self-trained GP	10 � T+10 � D+P	83.0	84.5	83.7
table ||| Updated RP	CTB+CDT. S	84.3	86.1	85.2
tableCaption ||| Table 7: Results of the self-trained gen-
tableCaption ||| erative parser and updated reranking parser
tableCaption ||| on the test set. 10 x T+10 x D+P stands for
tableCaption ||| 10 x CTB+10 x CDTP s+PDC.
bodyText ||| 84.2% f-score, better than the result of the rerank-
bodyText ||| ing parser with CTB and CDTPS as training data
bodyText ||| (shown in Table 5). It indicates that the use of
bodyText ||| probability information from the parser for tree
bodyText ||| conversion helps target grammar parsing.
subsectionHeader ||| 4.3 Using Unlabeled Data for Parsing
bodyText ||| Recent studies on parsing indicate that the use of
bodyText ||| unlabeled data by self-training can help parsing
bodyText ||| on the WSJ data, even when labeled data is rel-
bodyText ||| atively large (McClosky et al., 2006a; Reichart
bodyText ||| and Rappoport, 2007). It motivates us to em-
bodyText ||| ploy self-training technique for Chinese parsing.
bodyText ||| We used the POS tagged People Daily corpus9
bodyText ||| (Jan. 1998—Jun. 1998, and Jan. 2000—Dec.
bodyText ||| 2000) (PDC) as unlabeled data for parsing. First
bodyText ||| we removed the sentences with less than 3 words
bodyText ||| or more than 40 words from PDC to ease pars-
bodyText ||| ing, resulting in 820k sentences. Then we ran the
bodyText ||| reranking parser in Section 4.2.2 on PDC and used
bodyText ||| the parses on PDC as additional training data for
bodyText ||| the generative parser. Here we tried the corpus
bodyText ||| weighting technique for an optimal combination
bodyText ||| of CTB, CDTP s and parsed PDC, and chose the
bodyText ||| relative weight of both CTB and CDTP s as 10
bodyText ||| by cross validation on the development set. Fi-
bodyText ||| nally we retrained the generative parser on CTB,
bodyText ||| CDTP s and parsed PDC. Furthermore, we used
bodyText ||| this self-trained generative parser as a base parser
bodyText ||| to retrain the reranker on CTB and CDTP s.
bodyText ||| Table 7 shows the performance of self-trained
bodyText ||| generative parser and updated reranker on the test
bodyText ||| set, with CTB and CDTP s as labeled data. We see
bodyText ||| that the use of unlabeled data by self-training fur-
bodyText ||| ther increased the reranking parser’s performance
bodyText ||| from 84.2% to 85.2%. Our results on Chinese data
bodyText ||| confirm previous findings on English data shown
bodyText ||| in (McClosky et al., 2006a; Reichart and Rap-
bodyText ||| poport, 2007).
footnote ||| 9Available at http://icl.pku.edu.cn/.
subsectionHeader ||| 4.4 Comparison with Previous Studies for
subsectionHeader ||| Chinese Parsing
bodyText ||| Table 8 and 9 present the results of previous stud-
bodyText ||| ies on CTB. All the works in Table 8 used CTB
bodyText ||| articles 1-270 as labeled data. In Table 9, Petrov
bodyText ||| and Klein (2007) trained their model on CTB ar-
bodyText ||| ticles 1-270 and 400-1151, and Burkett and Klein
bodyText ||| (2008) used the same CTB articles and parse trees
bodyText ||| of their English translation (from the English Chi-
bodyText ||| nese Translation Treebank) as training data. Com-
bodyText ||| paring our result in Table 6 with that of Petrov
bodyText ||| and Klein (2007), we see that CDTP s helps pars-
bodyText ||| ing on CTB, which brought 0.9% f-score improve-
bodyText ||| ment. Moreover, the use of unlabeled data further
bodyText ||| boosted the parsing performance to 85.2%, an ab-
bodyText ||| solute 1.0% improvement over the previous best
bodyText ||| result presented in Burkett and Klein (2008).
sectionHeader ||| 5 Related Work
bodyText ||| Recently there have been some studies address-
bodyText ||| ing how to use treebanks with same grammar for-
bodyText ||| malism for domain adaptation of parsers. Roark
bodyText ||| and Bachiani (2003) presented count merging and
bodyText ||| model interpolation techniques for domain adap-
bodyText ||| tation of parsers. They showed that their sys-
bodyText ||| tem with count merging achieved a higher perfor-
bodyText ||| mance when in-domain data was weighted more
bodyText ||| heavily than out-of-domain data. McClosky et al.
bodyText ||| (2006b) used self-training and corpus weighting to
bodyText ||| adapt their parser trained on WSJ corpus to Brown
bodyText ||| corpus. Their results indicated that both unla-
bodyText ||| beled in-domain data and labeled out-of-domain
bodyText ||| data can help domain adaptation. In comparison
bodyText ||| with these works, we conduct our study in a dif-
bodyText ||| ferent setting where we work with multiple het-
bodyText ||| erogeneous treebanks.
bodyText ||| Grammar formalism conversion makes it possi-
bodyText ||| ble to reuse existing source treebanks for the study
bodyText ||| of target grammar parsing. Wang et al. (1994)
bodyText ||| employed a parser to help conversion of a tree-
bodyText ||| bank from a simple phrase structure to a more in-
bodyText ||| formative phrase structure and then used this con-
bodyText ||| verted treebank to train their parser. Collins et al.
bodyText ||| (1999) performed statistical constituency parsing
bodyText ||| of Czech on a treebank that was converted from
bodyText ||| the Prague Dependency Treebank under the guid-
bodyText ||| ance of conversion rules and heuristic rules, e.g.,
bodyText ||| one level of projection for any category, minimal
bodyText ||| projection for any dependents, and fixed position
bodyText ||| of attachment. Xia and Palmer (2001) adopted bet-
bodyText ||| ter heuristic rules to build converted trees, which
page ||| 52
table ||| Models	< 40 words			All the sentences
table ||| 	LR	LP	F	LR	LP	F
table ||| 	(%)	(%)	(%)	(%)	(%)	(%)
table ||| Bikel & Chiang (2000)	76.8	77.8	77.3	-	-	-
table ||| Chiang & Bikel (2002)	78.8	81.1	79.9	-	-	-
table ||| Levy & Manning (2003)	79.2	78.4	78.8	-	-	-
table ||| Bikel’s thesis (2004)	78.0	81.2	79.6	-	-	-
table ||| Xiong et. al. (2005)	78.7	80.1	79.4	-	-	-
table ||| Chen et. al. (2005)	81.0	81.7	81.2	76.3	79.2	77.7
table ||| Wang et. al. (2006)	79.2	81.1	80.1	76.2	78.0	77.1
tableCaption ||| Table 8: Results of previous studies on CTB with CTB articles 1-270 as labeled data.
table ||| 	< 40 words			All the sentences
table ||| 	LR	LP	F	LR	LP	F
table ||| Models	(%)	(%)	(%)	(%)	(%)	(%)
table ||| Petrov & Klein (2007)	85.7	86.9	86.3	81.9	84.8	83.3
table ||| Burkett & Klein (2008)	-	-	-	-	-	84.2
tableCaption ||| Table 9: Results of previous studies on CTB with more labeled data.
bodyText ||| reflected the structural preference in their target
bodyText ||| grammar. For acquisition of better conversion
bodyText ||| rules, Xia et al. (2008) proposed to automati-
bodyText ||| cally extract conversion rules from a target tree-
bodyText ||| bank. Moreover, they presented two strategies to
bodyText ||| solve the problem that there might be multiple
bodyText ||| conversion rules matching the same input depen-
bodyText ||| dency tree pattern: (1) choosing the most frequent
bodyText ||| rules, (2) preferring rules that add fewer number
bodyText ||| of nodes and attach the subtree lower.
bodyText ||| In comparison with the works of Wang et al.
bodyText ||| (1994) and Collins et al. (1999), we went fur-
bodyText ||| ther by combining the converted treebank with the
bodyText ||| existing target treebank for parsing. In compar-
bodyText ||| ison with previous conversion methods (Collins
bodyText ||| et al., 1999; Covington, 1994; Xia and Palmer,
bodyText ||| 2001; Xia et al., 2008) in which for each head-
bodyText ||| dependent pair, only one locally optimal conver-
bodyText ||| sion was kept during tree-building process, we
bodyText ||| employed a parser to generate globally optimal
bodyText ||| syntactic structures, eliminating heuristic rules for
bodyText ||| conversion. In addition, we used converted trees to
bodyText ||| retrain the parser for better conversion candidates,
bodyText ||| while Wang et al. (1994) did not exploit the use of
bodyText ||| converted trees for parser retraining.
sectionHeader ||| 6 Conclusion
bodyText ||| We have proposed a two-step solution to deal with
bodyText ||| the issue of using heterogeneous treebanks for
bodyText ||| parsing. First we present a parser based method
bodyText ||| to convert grammar formalisms of the treebanks to
bodyText ||| the same one, without applying predefined heuris-
bodyText ||| tic rules, thus turning the original problem into the
bodyText ||| problem of parsing on homogeneous treebanks.
bodyText ||| Then we present two strategies, instance pruning
bodyText ||| and score interpolation, to refine conversion re-
bodyText ||| sults. Finally we adopt the corpus weighting tech-
bodyText ||| nique to combine the converted source treebank
bodyText ||| with the existing target treebank for parser train-
bodyText ||| ing.
bodyText ||| The study on the WSJ data shows the benefits of
bodyText ||| our parser based approach for grammar formalism
bodyText ||| conversion. Moreover, experimental results on the
bodyText ||| Penn Chinese Treebank indicate that a converted
bodyText ||| dependency treebank helps constituency parsing,
bodyText ||| and it is better to exploit probability information
bodyText ||| produced by the parser through score interpolation
bodyText ||| than to prune low quality trees for the use of the
bodyText ||| converted treebank.
bodyText ||| Future work includes further investigation of
bodyText ||| our conversion method for other pairs of grammar
bodyText ||| formalisms, e.g., from the grammar formalism of
bodyText ||| the Penn Treebank to more deep linguistic formal-
bodyText ||| ism like CCG, HPSG, or LFG.
sectionHeader ||| References
reference ||| Anne Abeille, Lionel Clement and Francois Toussenel. 2000.
reference ||| Building a Treebank for French. In Proceedings of LREC
reference ||| 2000, pages 87-94.
reference ||| Daniel Bikel and David Chiang. 2000. Two Statistical Pars-
reference ||| ing Models Applied to the Chinese Treebank. In Proceed-
reference ||| ings of the Second SIGHAN workshop, pages 1-6.
reference ||| Daniel Bikel. 2004. On the Parameter Space of Generative
reference ||| Lexicalized Statistical Parsing Models. Ph.D. thesis, Uni-
reference ||| versity of Pennsylvania.
reference ||| Alena Bohmova, Jan Hajic, Eva Hajicova and Barbora
reference ||| Vidova-Hladka. 2003. The Prague Dependency Tree-
reference ||| bank: A Three-Level Annotation Scenario. Treebanks:
page ||| 53
reference ||| Building and Using Annotated Corpora. Kluwer Aca-
reference ||| demic Publishers, pages 103-127.
reference ||| Thorsten Brants, Wojciech Skut and Hans Uszkoreit. 1999.
reference ||| Syntactic Annotation of a German Newspaper Corpus. In
reference ||| Proceedings of the ATALA Treebank Workshop, pages 69-
reference ||| 76.
reference ||| David Burkett and Dan Klein. 2008. Two Languages are
reference ||| Better than One (for Syntactic Parsing). In Proceedings of
reference ||| EMNLP 2008, pages 877-886.
reference ||| Eugene Charniak. 2000. A Maximum Entropy Inspired
reference ||| Parser. In Proceedings of NAACL 2000, pages 132-139.
reference ||| Eugene Charniak and Mark Johnson. 2005. Coarse-to-Fine
reference ||| N-Best Parsing and MaxEnt Discriminative Reranking. In
reference ||| Proceedings ofACL 2005, pages 173-180.
reference ||| Ying Chen, Hongling Sun and Dan Jurafsky. 2005. A Cor-
reference ||| rigendum to Sun and Jurafsky (2004) Shallow Semantic
reference ||| Parsing of Chinese. University of Colorado at Boulder
reference ||| CSLR Tech Report TR-CSLR-2005-01.
reference ||| David Chiang and Daniel M. Bikel. 2002. Recovering La-
reference ||| tent Information in Treebanks. In Proceedings of COL-
reference ||| ING 2002, pages 1-7.
reference ||| Micheal Collins, Lance Ramshaw, Jan Hajic and Christoph
reference ||| Tillmann. 1999. A Statistical Parser for Czech. In Pro-
reference ||| ceedings ofACL 1999, pages 505-512.
reference ||| Micheal Covington. 1994. GB Theory as Dependency
reference ||| Grammar. Research Report AI-1992-03.
reference ||| Martin Forst. 2003. Treebank Conversion - Establishing
reference ||| a Testsuite for a Broad-Coverage LFG from the TIGER
reference ||| Treebank. In Proceedings of LINC at EACL 2003, pages
reference ||| 25-32.
reference ||| Chunghye Han, Narae Han, Eonsuk Ko and Martha Palmer.
reference ||| 2002. Development and Evaluation of a Korean Treebank
reference ||| and its Application to NLP. In Proceedings ofLREC 2002,
reference ||| pages 1635-1642.
reference ||| Sadao Kurohashi and Makato Nagao. 1998. Building a
reference ||| Japanese Parsed Corpus While Improving the Parsing Sys-
reference ||| tem. In Proceedings of LREC 1998, pages 719-724.
reference ||| Roger Levy and Christopher Manning. 2003. Is It Harder to
reference ||| Parse Chinese, or the Chinese Treebank? In Proceedings
reference ||| ofACL 2003, pages 439-446.
reference ||| Ting Liu, Jinshan Ma and Sheng Li. 2006. Building a Depen-
reference ||| dency Treebank for Improving Chinese Parser. Journal of
reference ||| Chinese Language and Computing, 16(4):207-224.
reference ||| Mitchell P. Marcus, Beatrice Santorini and Mary Ann
reference ||| Marcinkiewicz. 1993. Building a Large Annotated Cor-
reference ||| pus of English: The Penn Treebank. Computational Lin-
reference ||| guistics, 19(2):313-330.
reference ||| David McClosky, Eugene Charniak and Mark Johnson.
reference ||| 2006a. Effective Self-Training for Parsing. In Proceed-
reference ||| ings of NAACL 2006, pages 152-159.
reference ||| David McClosky, Eugene Charniak and Mark Johnson.
reference ||| 2006b. Reranking and Self-Training for Parser Adapta-
reference ||| tion. In Proceedings of COLING/ACL 2006, pages 337-
reference ||| 344.
reference ||| Antonio Moreno, Susana Lopez, Fernando Sanchez and
reference ||| Ralph Grishman. 2003. Developing a Syntactic Anno-
reference ||| tation Scheme and Tools for a Spanish Treebank. Tree-
reference ||| banks: Building and Using Annotated Corpora. Kluwer
reference ||| Academic Publishers, pages 149-163.
reference ||| Slav Petrov and Dan Klein. 2007. Improved Inference for
reference ||| Unlexicalized Parsing. In Proceedings of HLT/NAACL
reference ||| 2007, pages 404-411.
reference ||| Roi Reichart and Ari Rappoport. 2007. Self-Training for En-
reference ||| hancement and Domain Adaptation of Statistical Parsers
reference ||| Trained on Small Datasets. In Proceedings of ACL 2007,
reference ||| pages 616-623.
reference ||| Brian Roark and Michiel Bacchiani. 2003. Supervised and
reference ||| Unsupervised PCFG Adaptation to Novel Domains. In
reference ||| Proceedings of HLT/NAACL 2003, pages 126-133.
reference ||| Jong-Nae Wang, Jing-Shin Chang and Keh-Yih Su. 1994.
reference ||| An Automatic Treebank Conversion Algorithm for Corpus
reference ||| Sharing. In Proceedings ofACL 1994, pages 248-254.
reference ||| Mengqiu Wang, Kenji Sagae and Teruko Mitamura. 2006. A
reference ||| Fast, Accurate Deterministic Parser for Chinese. In Pro-
reference ||| ceedings of COLING/ACL 2006, pages 425-432.
reference ||| Stephen Watkinson and Suresh Manandhar. 2001. Translat-
reference ||| ing Treebank Annotation for Evaluation. In Proceedings
reference ||| of ACL Workshop on Evaluation Methodologies for Lan-
reference ||| guage and Dialogue Systems, pages 1-8.
reference ||| Fei Xia and Martha Palmer. 2001. Converting Dependency
reference ||| Structures to Phrase Structures. In Proceedings of HLT
reference ||| 2001, pages 1-5.
reference ||| Fei Xia, Rajesh Bhatt, Owen Rambow, Martha Palmer
reference ||| and Dipti Misra. Sharma. 2008. Towards a Multi-
reference ||| Representational Treebank. In Proceedings of the 7th In-
reference ||| ternational Workshop on Treebanks and Linguistic Theo-
reference ||| ries, pages 159-170.
reference ||| Deyi Xiong, Shuanglong Li, Qun Liu, Shouxun Lin and
reference ||| Yueliang Qian. 2005. Parsing the Penn Chinese Tree-
reference ||| bank with Semantic Knowledge. In Proceedings of IJC-
reference ||| NLP 2005, pages 70-81.
reference ||| Nianwen Xue, Fei Xia, Fu-Dong Chiou and Martha Palmer.
reference ||| 2005. The Penn Chinese TreeBank: Phrase Structure An-
reference ||| notation of a Large Corpus. Natural Language Engineer-
reference ||| ing, 11(2):207-238.
page ||| 54

title ||| Cross Language Dependency Parsing using a Bilingual Lexicon*
author ||| Hai Zhao(O— )tt, Yan Song(*,,O)t, Chunyu Kitt, Guodong Zhout
affiliation ||| tDepartment of Chinese, Translation and Linguistics
affiliation ||| City University of Hong Kong
address ||| 83 Tat Chee Avenue, Kowloon, Hong Kong, China
affiliation ||| $School of Computer Science and Technology
address ||| Soochow University, Suzhou, China 2'5006
email ||| {haizhao,yansong,ctckit}@cityu.edu.hk, gdzhou@suda.edu.cn
sectionHeader ||| Abstract
bodyText ||| This paper proposes an approach to en-
bodyText ||| hance dependency parsing in a language
bodyText ||| by using a translated treebank from an-
bodyText ||| other language. A simple statistical ma-
bodyText ||| chine translation method, word-by-word
bodyText ||| decoding, where not a parallel corpus but
bodyText ||| a bilingual lexicon is necessary, is adopted
bodyText ||| for the treebank translation. Using an en-
bodyText ||| semble method, the key information ex-
bodyText ||| tracted from word pairs with dependency
bodyText ||| relations in the translated text is effectively
bodyText ||| integrated into the parser for the target lan-
bodyText ||| guage. The proposed method is evaluated
bodyText ||| in English and Chinese treebanks. It is
bodyText ||| shown that a translated English treebank
bodyText ||| helps a Chinese parser obtain a state-of-
bodyText ||| the-art result.
sectionHeader ||| 1 Introduction
bodyText ||| Although supervised learning methods bring state-
bodyText ||| of-the-art outcome for dependency parser infer-
bodyText ||| ring (McDonald et al., 2005; Hall et al., 2007), a
bodyText ||| large enough data set is often required for specific
bodyText ||| parsing accuracy according to this type of meth-
bodyText ||| ods. However, to annotate syntactic structure, ei-
bodyText ||| ther phrase- or dependency-based, is a costly job.
bodyText ||| Until now, the largest treebanks' in various lan-
bodyText ||| guages for syntax learning are with around one
bodyText ||| million words (or some other similar units). Lim-
bodyText ||| ited data stand in the way of further performance
bodyText ||| enhancement. This is the case for each individual
bodyText ||| language at least. But, this is not the case as we
bodyText ||| observe all treebanks in different languages as a
bodyText ||| whole. For example, of ten treebanks for CoNLL-
bodyText ||| 2007 shared task, none includes more than 500K
footnote ||| �The study is partially supported by City University of
footnote ||| Hong Kong through the Strategic Research Grant 7002037
footnote ||| and 7002388. The first author is sponsored by a research fel-
footnote ||| lowship from CTL, City University of Hong Kong.
footnote ||| 'It is a tradition to call an annotated syntactic corpus as
footnote ||| treebank in parsing community.
bodyText ||| tokens, while the sum of tokens from all treebanks
bodyText ||| is about two million (Nivre et al., 2007).
bodyText ||| As different human languages or treebanks
bodyText ||| should share something common, this makes it
bodyText ||| possible to let dependency parsing in multiple lan-
bodyText ||| guages be beneficial with each other. In this pa-
bodyText ||| per, we study how to improve dependency parsing
bodyText ||| by using (automatically) translated texts attached
bodyText ||| with transformed dependency information. As a
bodyText ||| case study, we consider how to enhance a Chinese
bodyText ||| dependency parser by using a translated English
bodyText ||| treebank. What our method relies on is not the
bodyText ||| close relation of the chosen language pair but the
bodyText ||| similarity of two treebanks, this is the most differ-
bodyText ||| ent from the previous work.
bodyText ||| Two main obstacles are supposed to confront in
bodyText ||| a cross-language dependency parsing task. The
bodyText ||| first is the cost of translation. Machine translation
bodyText ||| has been shown one of the most expensive lan-
bodyText ||| guage processing tasks, as a great deal of time and
bodyText ||| space is required to perform this task. In addition,
bodyText ||| a standard statistical machine translation method
bodyText ||| based on a parallel corpus will not work effec-
bodyText ||| tively if it is not able to find a parallel corpus that
bodyText ||| right covers source and target treebanks. How-
bodyText ||| ever, dependency parsing focuses on the relations
bodyText ||| of word pairs, this allows us to use a dictionary-
bodyText ||| based translation without assuming a parallel cor-
bodyText ||| pus available, and the training stage of translation
bodyText ||| may be ignored and the decoding will be quite fast
bodyText ||| in this case. The second difficulty is that the out-
bodyText ||| puts of translation are hardly qualified for the pars-
bodyText ||| ing purpose. The most challenge in this aspect is
bodyText ||| morphological preprocessing. We regard that the
bodyText ||| morphological issue should be handled aiming at
bodyText ||| the specific language, our solution here is to use
bodyText ||| character-level features for a target language like
bodyText ||| Chinese.
bodyText ||| The rest of the paper is organized as follows.
bodyText ||| The next section presents some related existing
bodyText ||| work. Section 3 describes the procedure on tree-
page ||| 55
note ||| Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 55–63,
note ||| Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP
bodyText ||| bank translation and dependency transformation.
bodyText ||| Section 4 describes a dependency parser for Chi-
bodyText ||| nese as a baseline. Section 5 describes how a
bodyText ||| parser can be strengthened from the translated
bodyText ||| treebank. The experimental results are reported in
bodyText ||| Section 6. Section 7 looks into a few issues con-
bodyText ||| cerning the conditions that the proposed approach
bodyText ||| is suitable for. Section 8 concludes the paper.
sectionHeader ||| 2 The Related Work
bodyText ||| As this work is about exploiting extra resources to
bodyText ||| enhance an existing parser, it is related to domain
bodyText ||| adaption for parsing that has been draw some in-
bodyText ||| terests in recent years. Typical domain adaptation
bodyText ||| tasks often assume annotated data in new domain
bodyText ||| absent or insufficient and a large scale unlabeled
bodyText ||| data available. As unlabeled data are concerned,
bodyText ||| semi-supervised or unsupervised methods will be
bodyText ||| naturally adopted. In previous works, two basic
bodyText ||| types of methods can be identified to enhance an
bodyText ||| existing parser from additional resources. The first
bodyText ||| is usually focus on exploiting automatic generated
bodyText ||| labeled data from the unlabeled data (Steedman
bodyText ||| et al., 2003; McClosky et al., 2006; Reichart and
bodyText ||| Rappoport, 2007; Sagae and Tsujii, 2007; Chen
bodyText ||| et al., 2008), the second is on combining super-
bodyText ||| vised and unsupervised methods, and only unla-
bodyText ||| beled data are considered (Smith and Eisner, 2006;
bodyText ||| Wang and Schuurmans, 2008; Koo et al., 2008).
bodyText ||| Our purpose in this study is to obtain a further
bodyText ||| performance enhancement by exploiting treebanks
bodyText ||| in other languages. This is similar to the above
bodyText ||| first type of methods, some assistant data should
bodyText ||| be automatically generated for the subsequent pro-
bodyText ||| cessing. The differences are what type of data are
bodyText ||| concerned with and how they are produced. In our
bodyText ||| method, a machine translation method is applied
bodyText ||| to tackle golden-standard treebank, while all the
bodyText ||| previous works focus on the unlabeled data.
bodyText ||| Although cross-language technique has been
bodyText ||| used in other natural language processing tasks,
bodyText ||| it is basically new for syntactic parsing as few
bodyText ||| works were concerned with this issue. The rea-
bodyText ||| son is straightforward, syntactic structure is too
bodyText ||| complicated to be properly translated and the cost
bodyText ||| of translation cannot be afforded in many cases.
bodyText ||| However, we empirically find this difficulty may
bodyText ||| be dramatically alleviated as dependencies rather
bodyText ||| than phrases are used for syntactic structure repre-
bodyText ||| sentation. Even the translation outputs are not so
bodyText ||| good as the expected, a dependency parser for the
bodyText ||| target language can effectively make use of them
bodyText ||| by only considering the most related information
bodyText ||| extracted from the translated text.
bodyText ||| The basic idea to support this work is to make
bodyText ||| use of the semantic connection between different
bodyText ||| languages. In this sense, it is related to the work of
bodyText ||| (Merlo et al., 2002) and (Burkett and Klein, 2008).
bodyText ||| The former showed that complementary informa-
bodyText ||| tion about English verbs can be extracted from
bodyText ||| their translations in a second language (Chinese)
bodyText ||| and the use of multilingual features improves clas-
bodyText ||| sification performance of the English verbs. The
bodyText ||| latter iteratively trained a model to maximize the
bodyText ||| marginal likelihood of tree pairs, with alignments
bodyText ||| treated as latent variables, and then jointly parsing
bodyText ||| bilingual sentences in a translation pair. The pro-
bodyText ||| posed parser using features from monolingual and
bodyText ||| mutual constraints helped its log-linear model to
bodyText ||| achieve better performance for both monolingual
bodyText ||| parsers and machine translation system. In this
bodyText ||| work, cross-language features will be also adopted
bodyText ||| as the latter work. However, although it is not es-
bodyText ||| sentially different, we only focus on dependency
bodyText ||| parsing itself, while the parsing scheme in (Bur-
bodyText ||| kett and Klein, 2008) based on a constituent rep-
bodyText ||| resentation.
bodyText ||| Among of existing works that we are aware of,
bodyText ||| we regard that the most similar one to ours is (Ze-
bodyText ||| man and Resnik, 2008), who adapted a parser to a
bodyText ||| new language that is much poorer in linguistic re-
bodyText ||| sources than the source language. However, there
bodyText ||| are two main differences between their work and
bodyText ||| ours. The first is that they considered a pair of suf-
bodyText ||| ficiently related languages, Danish and Swedish,
bodyText ||| and made full use of the similar characteristics of
bodyText ||| two languages. Here we consider two quite dif-
bodyText ||| ferent languages, English and Chinese. As fewer
bodyText ||| language properties are concerned, our approach
bodyText ||| holds the more possibility to be extended to other
bodyText ||| language pairs than theirs. The second is that a
bodyText ||| parallel corpus is required for their work and a
bodyText ||| strict statistical machine translation procedure was
bodyText ||| performed, while our approach holds a merit of
bodyText ||| simplicity as only a bilingual lexicon is required.
sectionHeader ||| 3 Treebank Translation and Dependency
sectionHeader ||| Transformation
subsectionHeader ||| 3.1 Data
bodyText ||| As a case study, this work will be conducted be-
bodyText ||| tween the source language, English, and the tar-
bodyText ||| get language, Chinese, namely, we will investigate
page ||| 56
bodyText ||| how a translated English treebank enhances a Chi-
bodyText ||| nese dependency parser.
bodyText ||| For English data, the Penn Treebank (PTB) 3
bodyText ||| is used. The constituency structures is converted
bodyText ||| to dependency trees by using the same rules as
bodyText ||| (Yamada and Matsumoto, 2003) and the standard
bodyText ||| training/development/test split is used. However,
bodyText ||| only training corpus (sections 2-21) is used for
bodyText ||| this study. For Chinese data, the Chinese Treebank
bodyText ||| (CTB) version 4.0 is used in our experiments. The
bodyText ||| same rules for conversion and the same data split
bodyText ||| is adopted as (Wang et al., 2007): files 1-270 and
bodyText ||| 400-931 as training, 271-300 as testing and files
bodyText ||| 301-325 as development. We use the gold stan-
bodyText ||| dard segmentation and part-of-speech (POS) tags
bodyText ||| in both treebanks.
bodyText ||| As a bilingual lexicon is required for our task
bodyText ||| and none of existing lexicons are suitable for trans-
bodyText ||| lating PTB, two lexicons, LDC Chinese-English
bodyText ||| Translation Lexicon Version 2.0 (LDC2002L27),
bodyText ||| and an English to Chinese lexicon in StarDict2,
bodyText ||| are conflated, with some necessary manual exten-
bodyText ||| sions, to cover 99% words appearing in the PTB
bodyText ||| (the most part of the untranslated words are named
bodyText ||| entities.). This lexicon includes 123K entries.
subsectionHeader ||| 3.2 Translation
bodyText ||| A word-by-word statistical machine translation
bodyText ||| strategy is adopted to translate words attached
bodyText ||| with the respective dependency information from
bodyText ||| the source language to the target one. In detail, a
bodyText ||| word-based decoding is used, which adopts a log-
bodyText ||| linear framework as in (Och and Ney, 2002) with
bodyText ||| only two features, translation model and language
bodyText ||| model,
equation ||| exp[E2i� 1 Aihi(c, e)]
equation ||| E, exp[E2i� 1 Aihi(c, e)]
equation ||| Where
equation ||| h1 (c, e) = log(p .y(c�e))
bodyText ||| is the translation model, which is converted from
bodyText ||| the bilingual lexicon, and
equation ||| h2 (c, e) = log (pO (c))
bodyText ||| is the language model, a word trigram model
bodyText ||| trained from the CTB. In our experiment, we set
bodyText ||| two weights A1 = A2 = 1.
footnote ||| 2StarDict is an open source dictionary software, available
footnote ||| at http://stardict.sourceforge.net/.
bodyText ||| The conversion process of the source treebank
bodyText ||| is completed by three steps as the following:
listItem ||| 1. Bind POS tag and dependency relation of a
listItem ||| word with itself;
listItem ||| 2. Translate the PTB text into Chinese word by
bodyText ||| word. Since we use a lexicon rather than a parallel
bodyText ||| corpus to estimate the translation probabilities, we
bodyText ||| simply assign uniform probabilities to all transla-
bodyText ||| tion options. Thus the decoding process is actu-
bodyText ||| ally only determined by the language model. Sim-
bodyText ||| ilar to the “bag translation” experiment in (Brown
bodyText ||| et al., 1990), the candidate target sentences made
bodyText ||| up by a sequence of the optional target words are
bodyText ||| ranked by the trigram language model. The output
bodyText ||| sentence will be generated only if it is with maxi-
bodyText ||| mum probability as follows,
equation ||| c = argmax{pO(c)p.y(c�e)}
equation ||| = argmax pO (c)
equation ||| = argmaxn pO (w,)
bodyText ||| A beam search algorithm is used for this process
bodyText ||| to find the best path from all the translation op-
bodyText ||| tions; As the training stage, especially, the most
bodyText ||| time-consuming alignment sub-stage, is skipped,
bodyText ||| the translation only includes a decoding procedure
bodyText ||| that takes about 4.5 hours for about one million
bodyText ||| words of the PTB in a 2.8GHz PC.
listItem ||| 3. After the target sentence is generated, the at-
bodyText ||| tached POS tags and dependency information of
bodyText ||| each English word will also be transferred to each
bodyText ||| corresponding Chinese word. As word order is of-
bodyText ||| ten changed after translation, the pointer of each
bodyText ||| dependency relationship, represented by a serial
bodyText ||| number, should be re-calculated.
bodyText ||| Although we try to perform an exact word-by-
bodyText ||| word translation, this aim cannot be fully reached
bodyText ||| in fact, as the following case is frequently encoun-
bodyText ||| tered, multiple English words have to be translated
bodyText ||| into one Chinese word. To solve this problem,
bodyText ||| we use a policy that lets the output Chinese word
bodyText ||| only inherits the attached information of the high-
bodyText ||| est syntactic head in the original multiple English
bodyText ||| words.
sectionHeader ||| 4 Dependency Parsing: Baseline
subsectionHeader ||| 4.1 Learning Model and Features
bodyText ||| According to (McDonald and Nivre, 2007), all
bodyText ||| data-driven models for dependency parsing that
bodyText ||| have been proposed in recent years can be de-
bodyText ||| scribed as either graph-based or transition-based.
equation ||| P(cle) =
page ||| 57
tableCaption ||| Table 1: Feature Notations
bodyText ||| Although the former will be also used as compari-
bodyText ||| son, the latter is chosen as the main parsing frame-
bodyText ||| work by this study for the sake of efficiency. In de-
bodyText ||| tail, a shift-reduce method is adopted as in (Nivre,
bodyText ||| 2003), where a classifier is used to make a parsing
bodyText ||| decision step by step. In each step, the classifier
bodyText ||| checks a word pair, namely, s, the top of a stack
bodyText ||| that consists of the processed words, and, i, the
bodyText ||| first word in the (input) unprocessed sequence, to
bodyText ||| determine if a dependent relation should be estab-
bodyText ||| lished between them. Besides two dependency arc
bodyText ||| building actions, a shift action and a reduce ac-
bodyText ||| tion are also defined to maintain the stack and the
bodyText ||| unprocessed sequence. In this work, we adopt a
bodyText ||| left-to-right arc-eager parsing model, that means
bodyText ||| that the parser scans the input sequence from left
bodyText ||| to right and right dependents are attached to their
bodyText ||| heads as soon as possible (Hall et al., 2007).
bodyText ||| While memory-based and margin-based learn-
bodyText ||| ing approaches such as support vector machines
bodyText ||| are popularly applied to shift-reduce parsing, we
bodyText ||| apply maximum entropy model as the learning
bodyText ||| model for efficient training and adopting over-
bodyText ||| lapped features as our work in (Zhao and Kit,
bodyText ||| 2008), especially, those character-level ones for
bodyText ||| Chinese parsing. Our implementation of maxi-
bodyText ||| mum entropy adopts L-BFGS algorithm for pa-
bodyText ||| rameter optimization as usual.
bodyText ||| With notations defined in Table 1, a feature set
bodyText ||| as shown in Table 2 is adopted. Here, we explain
bodyText ||| some terms in Tables 1 and 2. We used a large
bodyText ||| scale feature selection approach as in (Zhao et al.,
bodyText ||| 2009) to obtain the feature set in Table 2. Some
bodyText ||| feature notations in this paper are also borrowed
bodyText ||| from that work.
bodyText ||| The feature curroot returns the root of a par-
bodyText ||| tial parsing tree that includes a specified node.
bodyText ||| The feature charseq returns a character sequence
bodyText ||| whose members are collected from all identified
bodyText ||| children for a specified word.
bodyText ||| In Table 2, as for concatenating multiple sub-
bodyText ||| strings into a feature string, there are two ways,
bodyText ||| seq and bag. The former is to concatenate all sub-
bodyText ||| strings without do something special. The latter
bodyText ||| will remove all duplicated substrings, sort the rest
bodyText ||| and concatenate all at last.
bodyText ||| Note that we systemically use a group of
bodyText ||| character-level features. Surprisingly, as to our
bodyText ||| best knowledge, this is the first report on using this
bodyText ||| type of features in Chinese dependency parsing.
bodyText ||| Although (McDonald et al., 2005) used the pre-
bodyText ||| fix of each word form instead of word form itself
bodyText ||| as features, character-level features here for Chi-
bodyText ||| nese is essentially different from that. As Chinese
bodyText ||| is basically a character-based written language.
bodyText ||| Character plays an important role in many means,
bodyText ||| most characters can be formed as single-character
bodyText ||| words, and Chinese itself is character-order free
bodyText ||| rather than word-order free to some extent. In ad-
bodyText ||| dition, there is often a close connection between
bodyText ||| the meaning of a Chinese word and its first or last
bodyText ||| character.
subsectionHeader ||| 4.2 Parsing using a Beam Search Algorithm
bodyText ||| In Table 2, the feature preact� returns the previous
bodyText ||| parsing action type, and the subscript n stands for
bodyText ||| the action order before the current action. These
bodyText ||| are a group of Markovian features. Without this
bodyText ||| type of features, a shift-reduce parser may directly
bodyText ||| scan through an input sequence in linear time.
bodyText ||| Otherwise, following the work of (Duan et al.,
bodyText ||| 2007) and (Zhao, 2009), the parsing algorithm is
bodyText ||| to search a parsing action sequence with the max-
bodyText ||| imal probability.
equation ||| Y5di = argmax p(di �di-1di-2...)�
equation ||| i
bodyText ||| where 5di is the object parsing action sequence,
bodyText ||| p(di � di-1...) is the conditional probability, and di
table ||| Meaning
table ||| The word in the top of stack
table ||| The first word below the top of stack.
table ||| The first word before(after) the word
table ||| in the top of stack.
table ||| The first (second) word in the
table ||| unprocessed sequence, etc.
table ||| Dependent direction
table ||| Head
table ||| Leftmost child
table ||| Rightmost child
table ||| Right nearest child
table ||| word form
table ||| POS tag of word
table ||| coarse POS: the first letter of POS tag of word
table ||| coarse POS: the first two POS tags of word
table ||| the left nearest verb
table ||| The first character of a word
table ||| The first two characters of a word
table ||| The last character of a word
table ||| The last two characters of a word
table ||| ’s, i.e., ‘s.dprel’ means dependent label
table ||| of character in the top of stack
table ||| Feature combination, i.e., ‘s.char+i.char’
table ||| means both s.char and i.char work as a
table ||| feature function.
table ||| Notation
table ||| s
table ||| s'
table ||| s-1,s1...
table ||| i, i+1,...
table ||| dir
table ||| h
table ||| lm
table ||| rm
table ||| rn
table ||| form
table ||| pos
table ||| cpos1
table ||| cpos2
table ||| lnverb
table ||| char1
table ||| char2
table ||| char-1
table ||| char-2
table ||| .
table ||| +
page ||| 58
figureCaption ||| Figure 1: A comparison before and after translation
figureCaption ||| is i-th parsing action. We use a beam search algo-
figureCaption ||| rithm to find the object parsing action sequence.
table ||| Table 2: Features for Parsing
table ||| 	in . f orm, n = 0, 1 i.f orm + i1.form
table ||| 	in.char2 + in+1.char2, n = —1, 0
table ||| 	i.char_1 + i1.char_1
table ||| 	in.char_2 n = 0, 3
table ||| 	i1.char_2 +i2.char_2 +i3.char_2 i.lnverb.char_2
table ||| 	i3.pos
table ||| 	in.pos + in+1.pos, n = 0, 1
table ||| 	i_2.cpos1 + i_1.cpos1
table ||| 	i1 .cpos1 + i2.cpos1 + i3.cpos1
table ||| 	s'2.char1
table ||| 	s'.char_2 + s'1.char_2 s'_2.cpos2
table ||| 	s'_1.cpos2 + s'1.cpos2 s'.cpos2 + s'1.cpos2 s’. children.cpos2.seq s’. children. dprel.seq s’.subtree.depth
table ||| 	s'.h. f orm + s'.rm.cpos1 s'.lm.char2 + s'.char2 s.h. children.dprel.seq s.lm.dprel
table ||| 	s.char_2 + i1.char_2
table ||| 	s.charn + i.charn, n = —1,1
table ||| 	s _ 1.pos + i1 .pos
table ||| 	s.pos + in.pos, n = —1, 0, 1
table ||| 	s : illinePath. f orm.bag s'.form + i.form
table ||| 	s'.char2 + in.char2, n = —1, 0, 1
table ||| 	s.curroot.pos + i.pos
table ||| 	s.curroot.char2 + i.char2 s.children.cpos2.seq + i.children.cpos2.seq s.children.cpos2.seq + i.children.cpos2.seq + s.cpos2 + i.cpos2
table ||| 	s'.children.dprel.seq + i.children.dprel.seq
table ||| 	preact_ 1 preact_2 preact_2+preact_ 1
sectionHeader ||| 5 Exploiting the Translated Treebank
bodyText ||| As we cannot expect too much for a word-by-word
bodyText ||| translation, only word pairs with dependency rela-
bodyText ||| tion in translated text are extracted as useful and
bodyText ||| reliable information. Then some features based
bodyText ||| on a query in these word pairs according to the
bodyText ||| current parsing state (namely, words in the cur-
bodyText ||| rent stack and input) will be derived to enhance
bodyText ||| the Chinese parser.
bodyText ||| A translation sample can be seen in Figure 1.
bodyText ||| Although most words are satisfactorily translated,
bodyText ||| to generate effective features, what we still have to
bodyText ||| consider at first is the inconsistence between the
bodyText ||| translated text and the target text.
bodyText ||| In Chinese, word lemma is always its word form
bodyText ||| itself, this is a convenient characteristic in com-
bodyText ||| putational linguistics and makes lemma features
bodyText ||| unnecessary for Chinese parsing at all. However,
bodyText ||| Chinese has a special primary processing task, i.e.,
bodyText ||| word segmentation. Unfortunately, word defini-
bodyText ||| tions for Chinese are not consistent in various lin-
bodyText ||| guistical views, for example, seven segmentation
bodyText ||| conventions for computational purpose are for-
bodyText ||| mally proposed since the first Bakeoff3.
bodyText ||| Note that CTB or any other Chinese treebank
bodyText ||| has its own word segmentation guideline. Chi-
bodyText ||| nese word should be strictly segmented according
bodyText ||| to the guideline before POS tags and dependency
bodyText ||| relations are annotated. However, as we say the
footnote ||| 3Bakeoff is a Chinese processing share task held by
footnote ||| SIGHAN.
page ||| 59
bodyText ||| English treebank is translated into Chinese word
bodyText ||| by word, Chinese words in the translated text are
bodyText ||| exactly some entries from the bilingual lexicon,
bodyText ||| they are actually irregular phrases, short sentences
bodyText ||| or something else rather than words that follows
bodyText ||| any existing word segmentation convention. If the
bodyText ||| bilingual lexicon is not carefully selected or re-
bodyText ||| fined according to the treebank where the Chinese
bodyText ||| parser is trained from, then there will be a serious
bodyText ||| inconsistence on word segmentation conventions
bodyText ||| between the translated and the target treebanks.
bodyText ||| As all concerned feature values here are calcu-
bodyText ||| lated from the searching result in the translated
bodyText ||| word pair list according to the current parsing
bodyText ||| state, and a complete and exact match cannot be
bodyText ||| always expected, our solution to the above seg-
bodyText ||| mentation issue is using a partial matching strat-
bodyText ||| egy based on characters that the words include.
bodyText ||| Above all, a translated word pair list, L, is ex-
bodyText ||| tracted from the translated treebank. Each item in
bodyText ||| the list consists of three elements, dependant word
bodyText ||| (dp), head word (hd) and the frequency of this pair
bodyText ||| in the translated treebank, f .
bodyText ||| There are two basic strategies to organize the
bodyText ||| features derived from the translated word pair list.
bodyText ||| The first is to find the most matching word pair
bodyText ||| in the list and extract some properties from it,
bodyText ||| such as the matched length, part-of-speech tags
bodyText ||| and so on, to generate features. Note that a
bodyText ||| matching priority serial should be defined afore-
bodyText ||| hand in this case. The second is to check every
bodyText ||| matching models between the current parsing state
bodyText ||| and the partially matched word pair. In an early
bodyText ||| version of our approach, the former was imple-
bodyText ||| mented. However, It is proven to be quite inef-
bodyText ||| ficient in computation. Thus we adopt the sec-
bodyText ||| ond strategy at last. Two matching model fea-
bodyText ||| ture functions, 0(•) and 0(•), are correspondingly
bodyText ||| defined as follows. The return value of 0(•) or
bodyText ||| 0(•) is the logarithmic frequency of the matched
bodyText ||| item. There are four input parameters required
bodyText ||| by the function 0(•). Two parameters of them
bodyText ||| are about which part of the stack(input) words is
bodyText ||| chosen, and other two are about which part of
bodyText ||| each item in the translated word pair is chosen.
bodyText ||| These parameters could be set to full or charn as
bodyText ||| shown in Table 1, where n = ..., —2, —1, 1, 2, ....
bodyText ||| For example, a possible feature could be
bodyText ||| �(s. f ull, i.chari, dp. f ull, hd.char1 ), it tries to
bodyText ||| find a match in L by comparing stack word and
bodyText ||| dp word, and the first character of input word
tableCaption ||| Table 3: Features based on the translated treebank
bodyText ||| and the first character of hd word. If such
bodyText ||| a match item in L is found, then 0(•) returns
bodyText ||| log(f ). There are three input parameters required
bodyText ||| by the function 0(•). One parameter is about
bodyText ||| which part of the stack(input) words is chosen,
bodyText ||| and the other is about which part of each item
bodyText ||| in the translated word pair is chosen. The third
bodyText ||| is about the matching type that may be set to
bodyText ||| dependant, head, or root. For example, the
bodyText ||| function 0(i.chari, hd. f ull, root) tries to find a
bodyText ||| match in L by comparing the first character of in-
bodyText ||| put word and the whole dp word. If such a match
bodyText ||| item in L is found, then �(•) returns log(f) as hd
bodyText ||| occurs as ROOT f times.
bodyText ||| As having observed that CTB and PTB share a
bodyText ||| similar POS guideline. A POS pair list from PTB
bodyText ||| is also extract. Two types of features, rootscore
bodyText ||| and pairscore are used to make use of such infor-
bodyText ||| mation. Both of them returns the logarithmic value
bodyText ||| of the frequency for a given dependent event. The
bodyText ||| difference is, rootscore counts for the given POS
bodyText ||| tag occurring as ROOT, and pairscore counts for
bodyText ||| two POS tag combination occurring for a depen-
bodyText ||| dent relationship.
bodyText ||| A full adapted feature list that is derived from
bodyText ||| the translated word pairs is in Table 3.
sectionHeader ||| 6 Evaluation Results
bodyText ||| The quality of the parser is measured by the pars-
bodyText ||| ing accuracy or the unlabeled attachment score
bodyText ||| (UAS), i.e., the percentage of tokens with correct
bodyText ||| head. Two types of scores are reported for compar-
bodyText ||| ison: “UAS without p” is the UAS score without
bodyText ||| all punctuation tokens and “UAS with p” is the one
bodyText ||| with all punctuation tokens.
bodyText ||| The results with different feature sets are in Ta-
bodyText ||| ble 4. As the features preactn are involved, a
table ||| 0(i.char3, s'. f ull, dp.char3, hd. f ull)+i.char3
table ||| +s'. f orm
table ||| 0(i.char3, s.char2, dp.char3, hd.char2)+s.char2
table ||| 0(i.char3, s. f ull, dp.char3, hd.char2)+s. form
table ||| ,O(s'.char-2, hd.char-2, head)+i.pos+s'.pos
table ||| 0(i.char3, s. f ull, dp.char3, hd.char2)+s. f ull
table ||| 0(s'. f ull, i.char4, dp. f ull, hd.char4)+s'.pos+i.pos
table ||| ,O(i. f ull, hd.char2, root)+i.pos+s.pos
table ||| ,O(i. f ull, hd.char2, root)+i.pos+s'.pos
table ||| ,O(s. f ull, dp. f ull, dependant)+i.pos
table ||| pairscore(s'.pos, i.pos)+s'. f orm+i. f orm
table ||| rootscore(s'.pos)+s'. f orm+i. f orm
table ||| rootscore (s'.pos)+i.pos
page ||| 60
bodyText ||| beam search algorithm with width 5 is used for
bodyText ||| parsing, otherwise, a simple shift-reduce decoding
bodyText ||| is used. It is observed that the features derived
bodyText ||| from the translated text bring a significant perfor-
bodyText ||| mance improvement as high as 1.3%.
tableCaption ||| Table 4: The results with different feature sets
tableCaption ||| features with p without p
table ||| baseline	-d	0.846	0.858
table ||| +d°	0.848	0.860
table ||| +Tb	-d	0.859	0.869
table ||| +d	0.861	0.870
table ||| °+d: using three Markovian features preact and
table ||| beam search decoding.
table ||| b+T: using features derived from the translated text
table ||| as in Table 3.
figureCaption ||| Figure 2: Performance vs. dependency length
bodyText ||| To compare our parser to the state-of-the-art
bodyText ||| counterparts, we use the same testing data as
bodyText ||| (Wang et al., 2005) did, selecting the sentences
bodyText ||| length up to 40. Table 5 shows the results achieved
bodyText ||| by other researchers and ours (UAS with p), which
bodyText ||| indicates that our parser outperforms any other
bodyText ||| ones 4. However, our results is only slightly better
bodyText ||| than that of (Chen et al., 2008) as only sentences
bodyText ||| whose lengths are less than 40 are considered. As
bodyText ||| our full result is much better than the latter, this
bodyText ||| comparison indicates that our approach improves
bodyText ||| the performance for those longer sentences.
tableCaption ||| Table 5: Comparison against the state-of-the-art
tableCaption ||| 	full	up to 40
table ||| (McDonald and Pereira, 2006)°	-	0.825
table ||| (Wang et al., 2007)	-	0.866
table ||| (Chen et al., 2008)	0.852	0.884
table ||| Ours	0.861	0.889
table ||| °This results was reported in (Wang et al., 2007).
bodyText ||| The experimental results in (McDonald and
bodyText ||| Nivre, 2007) show a negative impact on the pars-
bodyText ||| ing accuracy from too long dependency relation.
bodyText ||| For the proposed method, the improvement rela-
bodyText ||| tive to dependency length is shown in Figure 2.
bodyText ||| From the figure, it is seen that our method gives
bodyText ||| observable better performance when dependency
bodyText ||| lengths are larger than 4. Although word order is
bodyText ||| changed, the results here show that the useful in-
bodyText ||| formation from the translated treebank still help
bodyText ||| those long distance dependencies.
footnote ||| 4There is a slight exception: using the same data splitting,
footnote ||| (Yu et al., 2008) reported UAS without p as 0.873 versus ours,
footnote ||| 0.870.
sectionHeader ||| 7 Discussion
bodyText ||| If a treebank in the source language can help im-
bodyText ||| prove parsing in the target language, then there
bodyText ||| must be something common between these two
bodyText ||| languages, or more precisely, these two corre-
bodyText ||| sponding treebanks. (Zeman and Resnik, 2008)
bodyText ||| assumed that the morphology and syntax in the
bodyText ||| language pair should be very similar, and that is
bodyText ||| so for the language pair that they considered, Dan-
bodyText ||| ish and Swedish, two very close north European
bodyText ||| languages. Thus it is somewhat surprising that
bodyText ||| we show a translated English treebank may help
bodyText ||| Chinese parsing, as English and Chinese even be-
bodyText ||| long to two different language systems. However,
bodyText ||| it will not be so strange if we recognize that PTB
bodyText ||| and CTB share very similar guidelines on POS and
bodyText ||| syntactics annotation. Since it will be too abstract
bodyText ||| in discussing the details of the annotation guide-
bodyText ||| lines, we look into the similarities of two treebanks
bodyText ||| from the matching degree of two word pair lists.
bodyText ||| The reason is that the effectiveness of the proposed
bodyText ||| method actually relies on how many word pairs at
bodyText ||| every parsing states can find their full or partial
bodyText ||| matched partners in the translated word pair list.
bodyText ||| Table 6 shows such a statistics on the matching
bodyText ||| degree distribution from all training samples for
bodyText ||| Chinese parsing. The statistics in the table suggest
bodyText ||| that most to-be-check word pairs during parsing
bodyText ||| have a full or partial hitting in the translated word
bodyText ||| pair list. The latter then obtains an opportunity to
bodyText ||| provide a great deal of useful guideline informa-
bodyText ||| tion to help determine how the former should be
bodyText ||| tackled. Therefore we have cause for attributing
bodyText ||| the effectiveness of the proposed method to the
bodyText ||| similarity of these two treebanks. From Table 6,
page ||| 61
bodyText ||| we also find that the partial matching strategy de-
bodyText ||| fined in Section 5 plays a very important role in
bodyText ||| improving the whole matching degree. Note that
bodyText ||| our approach is not too related to the characteris-
bodyText ||| tics of two languages. Our discussion here brings
bodyText ||| an interesting issue, which difference is more im-
bodyText ||| portant in cross language processing, between two
bodyText ||| languages themselves or the corresponding anno-
bodyText ||| tated corpora? This may be extensively discussed
bodyText ||| in the future work.
tableCaption ||| Table 6: Matching degree distribution
table ||| dependant-match head-match Percent (%)
table ||| None	None	9.6
table ||| None	Partial	16.2
table ||| None	Full	9.9
table ||| Partial	None	12.4
table ||| Partial	Partial	42.6
table ||| Partial	Full	7.3
table ||| Full	None	3.7
table ||| Full	Partial	7.0
table ||| Full	Full	0.2
bodyText ||| Note that only a bilingual lexicon is adopted in
bodyText ||| our approach. We regard it one of the most mer-
bodyText ||| its for our approach. A lexicon is much easier to
bodyText ||| be obtained than an annotated corpus. One of the
bodyText ||| remained question about this work is if the bilin-
bodyText ||| gual lexicon should be very specific for this kind
bodyText ||| of tasks. According to our experiences, actually, it
bodyText ||| is not so sensitive to choose a highly refined lexi-
bodyText ||| con or not. We once found many words, mostly
bodyText ||| named entities, were outside the lexicon. Thus
bodyText ||| we managed to collect a named entity translation
bodyText ||| dictionary to enhance the original one. However,
bodyText ||| this extra effort did not receive an observable per-
bodyText ||| formance improvement in return. Finally we re-
bodyText ||| alize that a lexicon that can guarantee two word
bodyText ||| pair lists highly matched is sufficient for this work,
bodyText ||| and this requirement may be conveniently satis-
bodyText ||| fied only if the lexicon consists of adequate high-
bodyText ||| frequent words from the source treebank.
sectionHeader ||| 8 Conclusion and Future Work
bodyText ||| We propose a method to enhance dependency
bodyText ||| parsing in one language by using a translated tree-
bodyText ||| bank from another language. A simple statisti-
bodyText ||| cal machine translation technique, word-by-word
bodyText ||| decoding, where only a bilingual lexicon is nec-
bodyText ||| essary, is used to translate the source treebank.
bodyText ||| As dependency parsing is concerned with the re-
bodyText ||| lations of word pairs, only those word pairs with
bodyText ||| dependency relations in the translated treebank are
bodyText ||| chosen to generate some additional features to en-
bodyText ||| hance the parser for the target language. The ex-
bodyText ||| perimental results in English and Chinese tree-
bodyText ||| banks show the proposed method is effective and
bodyText ||| helps the Chinese parser in this work achieve a
bodyText ||| state-of-the-art result.
bodyText ||| Note that our method is evaluated in two tree-
bodyText ||| banks with a similar annotation style and it avoids
bodyText ||| using too many linguistic properties. Thus the
bodyText ||| method is in the hope of being used in other simi-
bodyText ||| larly annotated treebanks 5. For an immediate ex-
bodyText ||| ample, we may adopt a translated Chinese tree-
bodyText ||| bank to improve English parsing. Although there
bodyText ||| are still something to do, the remained key work
bodyText ||| has been as simple as considering how to deter-
bodyText ||| mine the matching strategy for searching the trans-
bodyText ||| lated word pair list in English according to the
bodyText ||| framework of our method. .
sectionHeader ||| Acknowledgements
bodyText ||| We’d like to give our thanks to three anonymous
bodyText ||| reviewers for their insightful comments, Dr. Chen
bodyText ||| Wenliang for for helpful discussions and Mr. Liu
bodyText ||| Jun for helping us fix a bug in our scoring pro-
bodyText ||| gram.
sectionHeader ||| References
reference ||| Peter F. Brown, John Cocke, Stephen A. Della Pietra,
reference ||| Vincent J. Della Pietra, Fredrick Jelinek, John D.
reference ||| Lafferty, Robert L. Mercer, and Paul S. Roossin.
reference ||| 1990. A statistical approach to machine translation.
reference ||| Computational Linguistics, 16(2):79–85.
reference ||| David Burkett and Dan Klein. 2008. Two lan-
reference ||| guages are better than one (for syntactic parsing). In
reference ||| EMNLP-2008, pages 877–886, Honolulu, Hawaii,
reference ||| USA.
reference ||| Wenliang Chen, Daisuke Kawahara, Kiyotaka Uchi-
reference ||| moto, Yujie Zhang, and Hitoshi Isahara. 2008. De-
reference ||| pendency parsing with short dependency relations
reference ||| in unlabeled data. In Proceedings of IJCNLP-2008,
reference ||| Hyderabad, India, January 8-10.
reference ||| Xiangyu Duan, Jun Zhao, and Bo Xu. 2007. Proba-
reference ||| bilistic parsing action models for multi-lingual de-
reference ||| pendency parsing. In Proceedings of the CoNLL
reference ||| Shared Task Session of EMNLP-CoNLL 2007, pages
reference ||| 940–946, Prague, Czech, June 28-30.
reference ||| Johan Hall, Jens Nilsson, Joakim Nivre,
reference ||| G¨ulsen Eryiˇgit, Be´ata Megyesi, Mattias Nils-
reference ||| son, and Markus Saers. 2007. Single malt or
footnote ||| 5For example, Catalan and Spanish treebanks from the
footnote ||| AnCora(-Es/Ca) Multilevel Annotated Corpus that are an-
footnote ||| notated by the Universitat de Barcelona (CLiC-UB) and the
footnote ||| Universitat Politecnica de Catalunya (UPC).
page ||| 62
reference ||| blended? a study in multilingual parser optimiza-
reference ||| tion. In Proceedings of the CoNLL Shared Task
reference ||| Session of EMNLP-CoNLL 2007, pages 933–939,
reference ||| Prague, Czech, June.
reference ||| Terry Koo, Xavier Carreras, and Michael Collins.
reference ||| 2008. Simple semi-supervised dependency parsing.
reference ||| In Proceedings of ACL-08: HLT, pages 595–603,
reference ||| Columbus, Ohio, USA, June.
reference ||| David McClosky, Eugene Charniak, and Mark John-
reference ||| son. 2006. Reranking and self-training for parser
reference ||| adaptation. In Proceedings of ACL-COLING 2006,
reference ||| pages 337–344, Sydney, Australia, July.
reference ||| Ryan McDonald and Joakim Nivre. 2007. Charac-
reference ||| terizing the errors of data-driven dependency pars-
reference ||| ing models. In Proceedings of the 2007 Joint Con-
reference ||| ference on Empirical Methods in Natural Language
reference ||| Processing and Computational Natural Language
reference ||| Learning (EMNLP-CoNLL 2007), pages 122–131,
reference ||| Prague, Czech, June 28-30.
reference ||| Ryan McDonald and Fernando Pereira. 2006. Online
reference ||| learning of approximate dependency parsing algo-
reference ||| rithms. In Proceedings of EACL-2006, pages 81–88,
reference ||| Trento, Italy, April.
reference ||| Ryan McDonald, Koby Crammer, and Fernando
reference ||| Pereira. 2005. Online large-margin training of de-
reference ||| pendency parsers. In Proceedings of ACL-2005,
reference ||| pages 91–98, Ann Arbor, Michigan, USA, June 25-
reference ||| 30.
reference ||| Paola Merlo, Suzanne Stevenson, Vivian Tsang, and
reference ||| Gianluca Allaria. 2002. A multilingual paradigm
reference ||| for automatic verb classification. In ACL-2002,
reference ||| pages 207–214, Philadelphia, Pennsylvania, USA.
reference ||| Joakim Nivre, Johan Hall, Sandra K¨ubler, Ryan Mc-
reference ||| Donald, Jens Nilsson, Sebastian Riedel, and Deniz
reference ||| Yuret. 2007. The conll 2007 shared task on de-
reference ||| pendency parsing. In Proceedings of the CoNLL
reference ||| Shared Task Session of EMNLP-CoNLL 2007, page
reference ||| 915 - 932, Prague, Czech, June.
reference ||| Joakim Nivre. 2003. An efficient algorithm for projec-
reference ||| tive dependency parsing. In Proceedings of IWPT-
reference ||| 2003), pages 149–160, Nancy, France, April 23-25.
reference ||| Franz Josef Och and Hermann Ney. 2002. Discrimina-
reference ||| tive training and maximum entropy models for sta-
reference ||| tistical machine translation. In Proceedings ofACL-
reference ||| 2002, pages 295–302, Philadelphia, USA, July.
reference ||| Roi Reichart and Ari Rappoport. 2007. Self-training
reference ||| for enhancement and domain adaptation of statistical
reference ||| parsers trained on small datasets. In Proceedings of
reference ||| ACL-2007, pages 616–623, Prague, Czech Republic,
reference ||| June.
reference ||| Kenji Sagae and Jun' ichi Tsujii. 2007. Dependency
reference ||| parsing and domain adaptation with lr models and
reference ||| parser ensembles. In Proceedings of the CoNLL
reference ||| Shared Task Session of EMNLP-CoNLL 2007, page
reference ||| 1044 - 1050, Prague, Czech, June 28-30.
reference ||| Noah A. Smith and Jason Eisner. 2006. Annealing
reference ||| structural bias in multilingual weighted grammar in-
reference ||| duction. In Proceedings of ACL-COLING 2006,
reference ||| page 569 - 576, Sydney, Australia, July.
reference ||| Mark Steedman, Miles Osborne, Anoop Sarkar,
reference ||| Stephen Clark, Rebecca Hwa, Julia Hockenmaier,
reference ||| Paul Ruhlen, Steven Baker, and Jeremiah Crim.
reference ||| 2003. Bootstrapping statistical parsers from small
reference ||| datasets. In Proceedings of EACL-2003, page
reference ||| 331 - 338, Budapest, Hungary, April.
reference ||| Qin Iris Wang and Dale Schuurmans. 2008. Semi-
reference ||| supervised convex training for dependency parsing.
reference ||| In Proceedings of ACL-08: HLT, pages 532–540,
reference ||| Columbus, Ohio, USA, June.
reference ||| Qin Iris Wang, Dale Schuurmans, and Dekang Lin.
reference ||| 2005. Strictly lexical dependency parsing. In Pro-
reference ||| ceedings of IWPT-2005, pages 152–159, Vancouver,
reference ||| BC, Canada, October.
reference ||| Qin Iris Wang, Dekang Lin, and Dale Schuurmans.
reference ||| 2007. Simple training of dependency parsers via
reference ||| structured boosting. In Proceedings of IJCAI 2007,
reference ||| pages 1756–1762, Hyderabad, India, January.
reference ||| Hiroyasu Yamada and Yuji Matsumoto. 2003. Sta-
reference ||| tistical dependency analysis with support vector
reference ||| machines. In Proceedings of IWPT-2003), page
reference ||| 195 - 206, Nancy, France, April.
reference ||| Kun Yu, Daisuke Kawahara, and Sadao Kurohashi.
reference ||| 2008. Chinese dependency parsing with large
reference ||| scale automatically constructed case structures. In
reference ||| Proceedings of COLING-2008, pages 1049–1056,
reference ||| Manchester, UK, August.
reference ||| Daniel Zeman and Philip Resnik. 2008. Cross-
reference ||| language parser adaptation between related lan-
reference ||| guages. In Proceedings of IJCNLP 2008 Workshop
reference ||| on NLP for Less Privileged Languages, pages 35–
reference ||| 42, Hyderabad, India, January.
reference ||| Hai Zhao and Chunyu Kit. 2008. Parsing syntactic and
reference ||| semantic dependencies with two single-stage max-
reference ||| imum entropy models. In Proceeding of CoNLL-
reference ||| 2008, pages 203–207, Manchester, UK.
reference ||| Hai Zhao, Wenliang Chen, Chunyu Kit, and Guodong
reference ||| Zhou. 2009. Multilingual dependency learning:
reference ||| A huge feature engineering method to semantic de-
reference ||| pendency parsing. In Proceedings of CoNLL-2009,
reference ||| Boulder, Colorado, USA.
reference ||| Hai Zhao. 2009. Character-level dependencies in
reference ||| chinese: Usefulness and learning. In EACL-2009,
reference ||| pages 879–887, Athens, Greece.
page ||| 63

title ||| Topological Field Parsing of German
author ||| Jackie Chi Kit Cheung
affiliation ||| Department of Computer Science
affiliation ||| University of Toronto
address ||| Toronto, ON, M5S 3G4, Canada
email ||| jcheung@cs.toronto.edu
author ||| Gerald Penn
affiliation ||| Department of Computer Science
affiliation ||| University of Toronto
address ||| Toronto, ON, M5S 3G4, Canada
email ||| gpenn@cs.toronto.edu
sectionHeader ||| Abstract
bodyText ||| Freer-word-order languages such as Ger-
bodyText ||| man exhibit linguistic phenomena that
bodyText ||| present unique challenges to traditional
bodyText ||| CFG parsing. Such phenomena produce
bodyText ||| discontinuous constituents, which are not
bodyText ||| naturally modelled by projective phrase
bodyText ||| structure trees. In this paper, we exam-
bodyText ||| ine topological field parsing, a shallow
bodyText ||| form of parsing which identifies the ma-
bodyText ||| jor sections of a sentence in relation to
bodyText ||| the clausal main verb and the subordinat-
bodyText ||| ing heads. We report the results of topo-
bodyText ||| logical field parsing of German using the
bodyText ||| unlexicalized, latent variable-based Berke-
bodyText ||| ley parser (Petrov et al., 2006) Without
bodyText ||| any language- or model-dependent adapta-
bodyText ||| tion, we achieve state-of-the-art results on
bodyText ||| the T¨uBa-D/Z corpus, and a modified NE-
bodyText ||| GRA corpus that has been automatically
bodyText ||| annotated with topological fields (Becker
bodyText ||| and Frank, 2002). We also perform a qual-
bodyText ||| itative error analysis of the parser output,
bodyText ||| and discuss strategies to further improve
bodyText ||| the parsing results.
sectionHeader ||| 1 Introduction
bodyText ||| Freer-word-order languages such as German ex-
bodyText ||| hibit linguistic phenomena that present unique
bodyText ||| challenges to traditional CFG parsing. Topic focus
bodyText ||| ordering and word order constraints that are sen-
bodyText ||| sitive to phenomena other than grammatical func-
bodyText ||| tion produce discontinuous constituents, which are
bodyText ||| not naturally modelled by projective (i.e., with-
bodyText ||| out crossing branches) phrase structure trees. In
bodyText ||| this paper, we examine topological field parsing, a
bodyText ||| shallow form of parsing which identifies the ma-
bodyText ||| jor sections of a sentence in relation to the clausal
bodyText ||| main verb and subordinating heads, when present.
bodyText ||| We report the results of parsing German using
bodyText ||| the unlexicalized, latent variable-based Berkeley
bodyText ||| parser (Petrov et al., 2006). Without any language-
bodyText ||| or model-dependent adaptation, we achieve state-
bodyText ||| of-the-art results on the T¨uBa-D/Z corpus (Telljo-
bodyText ||| hann et al., 2004), with a Fl-measure of 95.15%
bodyText ||| using gold POS tags. A further reranking of
bodyText ||| the parser output based on a constraint involv-
bodyText ||| ing paired punctuation produces a slight additional
bodyText ||| performance gain. To facilitate comparison with
bodyText ||| previous work, we also conducted experiments on
bodyText ||| a modified NEGRA corpus that has been automat-
bodyText ||| ically annotated with topological fields (Becker
bodyText ||| and Frank, 2002), and found that the Berkeley
bodyText ||| parser outperforms the method described in that
bodyText ||| work. Finally, we perform a qualitative error anal-
bodyText ||| ysis of the parser output on the T¨uBa-D/Z corpus,
bodyText ||| and discuss strategies to further improve the pars-
bodyText ||| ing results.
bodyText ||| German syntax and parsing have been studied
bodyText ||| using a variety of grammar formalisms. Hocken-
bodyText ||| maier (2006) has translated the German TIGER
bodyText ||| corpus (Brants et al., 2002) into a CCG-based
bodyText ||| treebank to model word order variations in Ger-
bodyText ||| man. Foth et al. (2004) consider a version of de-
bodyText ||| pendency grammars known as weighted constraint
bodyText ||| dependency grammars for parsing German sen-
bodyText ||| tences. On the NEGRA corpus (Skut et al., 1998),
bodyText ||| they achieve an accuracy of 89.0% on parsing de-
bodyText ||| pendency edges. In Callmeier (2000), a platform
bodyText ||| for efficient HPSG parsing is developed. This
bodyText ||| parser is later extended by Frank et al. (2003)
bodyText ||| with a topological field parser for more efficient
bodyText ||| parsing of German. The system by Rohrer and
bodyText ||| Forst (2006) produces LFG parses using a manu-
bodyText ||| ally designed grammar and a stochastic parse dis-
bodyText ||| ambiguation process. They test on the TIGER cor-
bodyText ||| pus and achieve an Fl-measure of 84.20%. In
bodyText ||| Dubey and Keller (2003), PCFG parsing of NE-
bodyText ||| GRA is improved by using sister-head dependen-
bodyText ||| cies, which outperforms standard head lexicaliza-
bodyText ||| tion as well as an unlexicalized model. The best
page ||| 64
note ||| Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 64–72,
note ||| Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP
bodyText ||| performing model with gold tags achieve an F1
bodyText ||| of 75.60%. Sister-head dependencies are useful in
bodyText ||| this case because of the flat structure of NEGRA’s
bodyText ||| trees.
bodyText ||| In contrast to the deeper approaches to parsing
bodyText ||| described above, topological field parsing identi-
bodyText ||| fies the major sections of a sentence in relation
bodyText ||| to the clausal main verb and subordinating heads,
bodyText ||| when present. Like other forms of shallow pars-
bodyText ||| ing, topological field parsing is useful as the first
bodyText ||| stage to further processing and eventual seman-
bodyText ||| tic analysis. As mentioned above, the output of
bodyText ||| a topological field parser is used as a guide to
bodyText ||| the search space of a HPSG parsing algorithm in
bodyText ||| Frank et al. (2003). In Neumann et al. (2000),
bodyText ||| topological field parsing is part of a divide-and-
bodyText ||| conquer strategy for shallow analysis of German
bodyText ||| text with the goal of improving an information ex-
bodyText ||| traction system.
bodyText ||| Existing work in identifying topological fields
bodyText ||| can be divided into chunkers, which identify the
bodyText ||| lowest-level non-recursive topological fields, and
bodyText ||| parsers, which also identify sentence and clausal
bodyText ||| structure.
bodyText ||| Veenstra et al. (2002) compare three approaches
bodyText ||| to topological field chunking based on finite state
bodyText ||| transducers, memory-based learning, and PCFGs
bodyText ||| respectively. It is found that the three techniques
bodyText ||| perform about equally well, with F1 of 94.1% us-
bodyText ||| ing POS tags from the TnT tagger, and 98.4% with
bodyText ||| gold tags. In Liepert (2003), a topological field
bodyText ||| chunker is implemented using a multi-class ex-
bodyText ||| tension to the canonically two-class support vec-
bodyText ||| tor machine (SVM) machine learning framework.
bodyText ||| Parameters to the machine learning algorithm are
bodyText ||| fine-tuned by a genetic search algorithm, with a
bodyText ||| resulting F1-measure of 92.25%. Training the pa-
bodyText ||| rameters to SVM does not have a large effect on
bodyText ||| performance, increasing the F1-measure in the test
bodyText ||| set by only 0.11%.
bodyText ||| The corpus-based, stochastic topological field
bodyText ||| parser of Becker and Frank (2002) is based on
bodyText ||| a standard treebank PCFG model, in which rule
bodyText ||| probabilities are estimated by frequency counts.
bodyText ||| This model includes several enhancements, which
bodyText ||| are also found in the Berkeley parser. First,
bodyText ||| they use parameterized categories, splitting non-
bodyText ||| terminals according to linguistically based intu-
bodyText ||| itions, such as splitting different clause types (they
bodyText ||| do not distinguish different clause types as basic
bodyText ||| categories, unlike T¨uBa-D/Z). Second, they take
bodyText ||| into account punctuation, which may help iden-
bodyText ||| tify clause boundaries. They also binarize the very
bodyText ||| flat topological tree structures, and prune rules
bodyText ||| that only occur once. They test their parser on a
bodyText ||| version of the NEGRA corpus, which has been
bodyText ||| annotated with topological fields using a semi-
bodyText ||| automatic method.
bodyText ||| Ule (2003) proposes a process termed Directed
bodyText ||| Treebank Refinement (DTR). The goal of DTR is
bodyText ||| to refine a corpus to improve parsing performance.
bodyText ||| DTR is comparable to the idea of latent variable
bodyText ||| grammars on which the Berkeley parser is based,
bodyText ||| in that both consider the observed treebank to be
bodyText ||| less than ideal and both attempt to refine it by split-
bodyText ||| ting and merging nonterminals. In this work, split-
bodyText ||| ting and merging nonterminals are done by consid-
bodyText ||| ering the nonterminals’ contexts (i.e., their parent
bodyText ||| nodes) and the distribution of their productions.
bodyText ||| Unlike in the Berkeley parser, splitting and merg-
bodyText ||| ing are distinct stages, rather than parts of a sin-
bodyText ||| gle iteration. Multiple splits are found first, then
bodyText ||| multiple rounds of merging are performed. No
bodyText ||| smoothing is done. As an evaluation, DTR is ap-
bodyText ||| plied to topological field parsing of the T¨uBa-D/Z
bodyText ||| corpus. We discuss the performance of these topo-
bodyText ||| logical field parsers in more detail below.
bodyText ||| All of the topological parsing proposals pre-
bodyText ||| date the advent of the Berkeley parser. The exper-
bodyText ||| iments of this paper demonstrate that the Berke-
bodyText ||| ley parser outperforms previous methods, many of
bodyText ||| which are specialized for the task of topological
bodyText ||| field chunking or parsing.
sectionHeader ||| 2 Topological Field Model of German
bodyText ||| Topological fields are high-level linear fields in
bodyText ||| an enclosing syntactic region, such as a clause
bodyText ||| (H¨ohle, 1983). These fields may have constraints
bodyText ||| on the number of words or phrases they contain,
bodyText ||| and do not necessarily form a semantically co-
bodyText ||| herent constituent. Although it has been argued
bodyText ||| that a few languages have no word-order con-
bodyText ||| straints whatsoever, most “free word-order” lan-
bodyText ||| guages (even Warlpiri) have at the very least some
bodyText ||| sort of sentence- or clause-initial topic field fol-
bodyText ||| lowed by a second position that is occupied by
bodyText ||| clitics, a finite verb or certain complementizers
bodyText ||| and subordinating conjunctions. In a few Ger-
bodyText ||| manic languages, including German, the topology
bodyText ||| is far richer than that, serving to identify all of
bodyText ||| the components of the verbal head of a clause,
bodyText ||| except for some cases of long-distance dependen-
page ||| 65
bodyText ||| cies. Topological fields are useful, because while
bodyText ||| Germanic word order is relatively free with respect
bodyText ||| to grammatical functions, the order of the topolog-
bodyText ||| ical fields is strict and unvarying.
table ||| Type	Fields
table ||| VL	(KOORD) (C) (MF) VC (NF)
table ||| V1	(KOORD) (LV) LK (MF) (VC) (NF)
table ||| V2	(KOORD) (LV) VF LK (MF) (VC) (NF)
tableCaption ||| Table 1: Topological field model of German.
tableCaption ||| Simplified from T¨uBa-D/Z corpus’s annotation
tableCaption ||| schema (Telljohann et al., 2006).
bodyText ||| In the German topological field model, clauses
bodyText ||| belong to one of three types: verb-last (VL), verb-
bodyText ||| second (V2), and verb-first (V 1), each with a spe-
bodyText ||| cific sequence of topological fields (Table 1). VL
bodyText ||| clauses include finite and non-finite subordinate
bodyText ||| clauses, V2 sentences are typically declarative
bodyText ||| sentences and WH-questions in matrix clauses,
bodyText ||| and V1 sentences include yes-no questions, and
bodyText ||| certain conditional subordinate clauses. Below,
bodyText ||| we give brief descriptions of the most common
bodyText ||| topological fields.
listItem ||| •	VF (Vorfeld or ‘pre-field’) is the first con-
bodyText ||| stituent in sentences of the V2 type. This is
bodyText ||| often the topic of the sentence, though as an
bodyText ||| anonymous reviewer pointed out, this posi-
bodyText ||| tion does not correspond to a single function
bodyText ||| with respect to information structure. (e.g.,
bodyText ||| the reviewer suggested this case, where VF
bodyText ||| contains the focus: –Wer kommt zur Party?
bodyText ||| –Peter kommt zur Party. –Who is coming to
bodyText ||| the Party? –Peter is coming to the party.)
listItem ||| •	LK (Linke Klammer or ‘left bracket’) is the
bodyText ||| position for finite verbs in V1 and V2 sen-
bodyText ||| tences. It is replaced by a complementizer
bodyText ||| with the field label C in VL sentences.
listItem ||| •	MF (Mittelfeld or ‘middle field’) is an op-
bodyText ||| tional field bounded on the left by LK and
bodyText ||| on the right by the verbal complex VC or
bodyText ||| by NF. Most verb arguments, adverbs, and
bodyText ||| prepositional phrases are found here, unless
bodyText ||| they have been fronted and put in the VF, or
bodyText ||| are prosodically heavy and postposed to the
bodyText ||| NF field.
listItem ||| •	VC is the verbal complex field. It includes
listItem ||| infinite verbs, as well as finite verbs in VL
listItem ||| sentences.
listItem ||| •	NF (Nachfeld or ‘post-field’) contains
listItem ||| prosodically heavy elements such as post-
listItem ||| posed prepositional phrases or relative
listItem ||| clauses.
listItem ||| •	KOORD1 (Koordinationsfeld or ‘coordina-
listItem ||| tion field’) is a field for clause-level conjunc-
listItem ||| tions.
listItem ||| •
bodyText ||| LV (Linksversetzung or ‘left dislocation’) is
bodyText ||| used for resumptive constructions involving
bodyText ||| left dislocation. For a detailed linguistic
bodyText ||| treatment, see (Frey, 2004).
bodyText ||| Exceptions to the topological field model as de-
bodyText ||| scribed above do exist. For instance, parenthetical
bodyText ||| constructions exist as a mostly syntactically inde-
bodyText ||| pendent clause inside another sentence. In our cor-
bodyText ||| pus, they are attached directly underneath a clausal
bodyText ||| node without any intervening topological field, as
bodyText ||| in the following example. In this example, the par-
bodyText ||| enthetical construction is highlighted in bold print.
bodyText ||| Some clause and topological field labels under the
bodyText ||| NF field are omitted for clarity.
listItem ||| (1) (a) (SIMPX “(VF Man) (LK muft) (VC verstehen) ”
listItem ||| , (SIMPX sagte er), “ (NF daft diese
listItem ||| Minderheiten seit langer Zeit massiv von den
listItem ||| Nazis bedroht werden)). ”
listItem ||| (b) Translation: “One must understand,” he said,
listItem ||| “that these minorities have been massively
listItem ||| threatened by the Nazis for a long time.”
sectionHeader ||| 3 A Latent Variable Parser
bodyText ||| For our experiments, we used the latent variable-
bodyText ||| based Berkeley parser (Petrov et al., 2006). La-
bodyText ||| tent variable parsing assumes that an observed
bodyText ||| treebank represents a coarse approximation of
bodyText ||| an underlying, optimally refined grammar which
bodyText ||| makes more fine-grained distinctions in the syn-
bodyText ||| tactic categories. For example, the noun phrase
bodyText ||| category NP in a treebank could be viewed as a
bodyText ||| coarse approximation of two noun phrase cate-
bodyText ||| gories corresponding to subjects and object, NPˆS,
bodyText ||| and NPˆVP.
bodyText ||| The Berkeley parser automates the process of
bodyText ||| finding such distinctions. It starts with a simple bi-
bodyText ||| narized X-bar grammar style backbone, and goes
bodyText ||| through iterations of splitting and merging non-
bodyText ||| terminals, in order to maximize the likelihood of
bodyText ||| the training set treebank. In the splitting stage,
footnote ||| 1The T¨uBa-D/Z corpus distinguishes coordinating and
footnote ||| non-coordinating particles, as well as clausal and field co-
footnote ||| ordination. These distinctions need not concern us for this
footnote ||| explanation.
page ||| 66
figureCaption ||| Figure 1: “I could never have done that just for aesthetic reasons.” Sample T¨uBa-D/Z tree, with topolog-
figureCaption ||| ical field annotations and edge labels. Topological field layer in bold.
bodyText ||| an Expectation-Maximization algorithm is used to
bodyText ||| find a good split for each nonterminal. In the
bodyText ||| merging stage, categories that have been over-
bodyText ||| split are merged together to keep the grammar size
bodyText ||| tractable and reduce sparsity. Finally, a smoothing
bodyText ||| stage occurs, where the probabilities of rules for
bodyText ||| each nonterminal are smoothed toward the prob-
bodyText ||| abilities of the other nonterminals split from the
bodyText ||| same syntactic category.
bodyText ||| The Berkeley parser has been applied to the
bodyText ||| T¨uBaD/Z corpus in the constituent parsing shared
bodyText ||| task of the ACL-2008 Workshop on Parsing Ger-
bodyText ||| man (Petrov and Klein, 2008), achieving an Fl-
bodyText ||| measure of 85.10% and 83.18% with and without
bodyText ||| gold standard POS tags respectively2. We chose
bodyText ||| the Berkeley parser for topological field parsing
bodyText ||| because it is known to be robust across languages,
bodyText ||| and because it is an unlexicalized parser. Lexi-
bodyText ||| calization has been shown to be useful in more
bodyText ||| general parsing applications due to lexical depen-
bodyText ||| dencies in constituent parsing (e.g. (K¨ubler et al.,
bodyText ||| 2006; Dubey and Keller, 2003) in the case of Ger-
bodyText ||| man). However, topological fields explain a higher
bodyText ||| level of structure pertaining to clause-level word
bodyText ||| order, and we hypothesize that lexicalization is un-
bodyText ||| likely to be helpful.
sectionHeader ||| 4 Experiments
subsectionHeader ||| 4.1 Data
bodyText ||| For our experiments, we primarily used the T¨uBa-
bodyText ||| D/Z (T¨ubinger Baumbank des Deutschen / Schrift-
bodyText ||| sprache) corpus, consisting of 26116 sentences
bodyText ||| (20894 training, 2611 development, 2089 test,
bodyText ||| with a further 522 sentences held out for future ex-
footnote ||| 2 This evaluation considered grammatical functions as
footnote ||| well as the syntactic category.
bodyText ||| periments)3 taken from the German newspaper die
bodyText ||| tageszeitung. The corpus consists of four levels
bodyText ||| of annotation: clausal, topological, phrasal (other
bodyText ||| than clausal), and lexical. We define the task of
bodyText ||| topological field parsing to be recovering the first
bodyText ||| two levels of annotation, following Ule (2003).
bodyText ||| We also tested the parser on a version of the NE-
bodyText ||| GRA corpus derived by Becker and Frank (2002),
bodyText ||| in which syntax trees have been made projec-
bodyText ||| tive and topological fields have been automatically
bodyText ||| added through a series of linguistically informed
bodyText ||| tree modifications. All internal phrasal structure
bodyText ||| nodes have also been removed. The corpus con-
bodyText ||| sists of 20596 sentences, which we split into sub-
bodyText ||| sets of the same size as described by Becker and
bodyText ||| Frank (2002)4. The set of topological fields in
bodyText ||| this corpus differs slightly from the one used in
bodyText ||| T¨uBa-D/Z, making no distinction between clause
bodyText ||| types, nor consistently marking field or clause
bodyText ||| conjunctions. Because of the automatic anno-
bodyText ||| tation of topological fields, this corpus contains
bodyText ||| numerous annotation errors. Becker and Frank
bodyText ||| (2002) manually corrected their test set and eval-
bodyText ||| uated the automatic annotation process, reporting
bodyText ||| labelled precision and recall of 93.0% and 93.6%
bodyText ||| compared to their manual annotations. There are
bodyText ||| also punctuation-related errors, including miss-
bodyText ||| ing punctuation, sentences ending in commas, and
bodyText ||| sentences composed of single punctuation marks.
bodyText ||| We test on this data in order to provide a bet-
bodyText ||| ter comparison with previous work. Although we
bodyText ||| could have trained the model in Becker and Frank
bodyText ||| (2002) on the T¨uBa-D/Z corpus, it would not have
footnote ||| 3These are the same splits into training, development, and
footnote ||| test sets as in the ACL-08 Parsing German workshop. This
footnote ||| corpus does not include sentences of length greater than 40.
footnote ||| 416476 training sentences, 1000 development, 1058 test-
footnote ||| ing, and 2062 as held-out data. We were unable to obtain
footnote ||| the exact subsets used by Becker and Frank (2002). We will
footnote ||| discuss the ramifications of this on our evaluation procedure.
page ||| 67
table ||| Gold tags	Edge labels	LP%	LR%	F1%	CB	CB0%	CB < 2%	EXACT%
table ||| -	-	93.53	93.17	93.35	0.08	94.59	99.43	79.50
table ||| +	-	95.26	95.04	95.15	0.07	95.35	99.52	83.86
table ||| -	+	92.38	92.67	92.52	0.11	92.82	99.19	77.79
table ||| +	+	92.36	92.60	92.48	0.11	92.82	99.19	77.64
tableCaption ||| Table 2: Parsing results for topological fields and clausal constituents on the T¨uBa-D/Z corpus.
bodyText ||| been a fair comparison, as the parser depends quite
bodyText ||| heavily on NEGRA’s annotation scheme. For ex-
bodyText ||| ample, T¨uBa-D/Z does not contain an equiva-
bodyText ||| lent of the modified NEGRA’s parameterized cat-
bodyText ||| egories; there exist edge labels in T¨uBaD/Z, but
bodyText ||| they are used to mark head-dependency relation-
bodyText ||| ships, not subtypes of syntactic categories.
sectionHeader ||| 4.2 Results
bodyText ||| We first report the results of our experiments on
bodyText ||| the T¨uBa-D/Z corpus. For the T¨uBa-D/Z corpus,
bodyText ||| we trained the Berkeley parser using the default
bodyText ||| parameter settings. The grammar trainer attempts
bodyText ||| six iterations of splitting, merging, and smoothing
bodyText ||| before returning the final grammar. Intermediate
bodyText ||| grammars after each step are also saved. There
bodyText ||| were training and test sentences without clausal
bodyText ||| constituents or topological fields, which were ig-
bodyText ||| nored by the parser and by the evaluation. As
bodyText ||| part of our experiment design, we investigated the
bodyText ||| effect of providing gold POS tags to the parser,
bodyText ||| and the effect of incorporating edge labels into the
bodyText ||| nonterminal labels for training and parsing. In all
bodyText ||| cases, gold annotations which include gold POS
bodyText ||| tags were used when training the parser.
bodyText ||| We report the standard PARSEVAL measures
bodyText ||| of parser performance in Table 2, obtained by the
bodyText ||| evalb program by Satoshi Sekine and Michael
bodyText ||| Collins. This table shows the results after five it-
bodyText ||| erations of grammar modification, parameterized
bodyText ||| over whether we provide gold POS tags for pars-
bodyText ||| ing, and edge labels for training and parsing. The
bodyText ||| number of iterations was determined by experi-
bodyText ||| ments on the development set. In the evaluation,
bodyText ||| we do not consider edge labels in determining
bodyText ||| correctness, but do consider punctuation, as Ule
bodyText ||| (2003) did. If we ignore punctuation in our evalu-
bodyText ||| ation, we obtain an F1-measure of 95.42% on the
bodyText ||| best model (+ Gold tags, - Edge labels).
bodyText ||| Whether supplying gold POS tags improves
bodyText ||| performance depends on whether edge labels are
bodyText ||| considered in the grammar. Without edge labels,
bodyText ||| gold POS tags improve performance by almost
bodyText ||| two points, corresponding to a relative error reduc-
bodyText ||| tion of 33%. In contrast, performance is negatively
bodyText ||| affected when edge labels are used and gold POS
bodyText ||| tags are supplied (i.e., + Gold tags, + Edge la-
bodyText ||| bels), making the performance worse than not sup-
bodyText ||| plying gold tags. Incorporating edge label infor-
bodyText ||| mation does not appear to improve performance,
bodyText ||| possibly because it oversplits the initial treebank
bodyText ||| and interferes with the parser’s ability to determine
bodyText ||| optimal splits for refining the grammar.
table ||| Parser	LP%	LR%	Fl%
table ||| T¨uBa-D/Z
table ||| This work	95.26	95.04	95.15
table ||| Ule	unknown	unknown	91.98
table ||| NEGRA - from Becker and Frank (2002)
table ||| BF02 (len. < 40)	92.1	91.6	91.8
table ||| NEGRA - our experiments
table ||| This work (len. < 40)	90.74	90.87	90.81
table ||| BF02 (len. < 40)	89.54	88.14	88.83
table ||| This work (all)	90.29	90.51	90.40
table ||| BF02 (all)	89.07	87.80	88.43
tableCaption ||| Table 3: BF02 = (Becker and Frank, 2002). Pars-
tableCaption ||| ing results for topological fields and clausal con-
tableCaption ||| stituents. Results from Ule (2003) and our results
tableCaption ||| were obtained using different training and test sets.
tableCaption ||| The first row of results of Becker and Frank (2002)
tableCaption ||| are from that paper; the rest were obtained by our
tableCaption ||| own experiments using that parser. All results con-
tableCaption ||| sider punctuation in evaluation.
bodyText ||| To facilitate a more direct comparison with pre-
bodyText ||| vious work, we also performed experiments on the
bodyText ||| modified NEGRA corpus. In this corpus, topo-
bodyText ||| logical fields are parameterized, meaning that they
bodyText ||| are labelled with further syntactic and semantic in-
bodyText ||| formation. For example, VF is split into VF-REL
bodyText ||| for relative clauses, and VF-TOPIC for those con-
bodyText ||| taining topics in a verb-second sentence, among
bodyText ||| others. All productions in the corpus have also
bodyText ||| been binarized. Tuning the parameter settings on
bodyText ||| the development set, we found that parameterized
bodyText ||| categories, binarization, and including punctua-
bodyText ||| tion gave the best F1 performance. First-order
bodyText ||| horizontal and zeroth order vertical markoviza-
page ||| 68
bodyText ||| tion after six iterations of splitting, merging, and
bodyText ||| smoothing gave the best F1 result of 91.78%. We
bodyText ||| parsed the corpus with both the Berkeley parser
bodyText ||| and the best performing model of Becker and
bodyText ||| Frank (2002).
bodyText ||| The results of these experiments on the test set
bodyText ||| for sentences of length 40 or less and for all sen-
bodyText ||| tences are shown in Table 3. We also show other
bodyText ||| results from previous work for reference. We
bodyText ||| find that we achieve results that are better than
bodyText ||| the model in Becker and Frank (2002) on the test
bodyText ||| set. The difference is statistically significant (p =
bodyText ||| 0.0029, Wilcoxon signed-rank).
bodyText ||| The results we obtain using the parser of Becker
bodyText ||| and Frank (2002) are worse than the results de-
bodyText ||| scribed in that paper. We suggest the following
bodyText ||| reasons for this discrepancy. While the test set
bodyText ||| used in the paper was manually corrected for eval-
bodyText ||| uation, we did not correct our test set, because it
bodyText ||| would be difficult to ensure that we adhered to the
bodyText ||| same correction guidelines. No details of the cor-
bodyText ||| rection process were provided in the paper, and de-
bodyText ||| scriptive grammars of German provide insufficient
bodyText ||| guidance on many of the examples in NEGRA on
bodyText ||| issues such as ellipses, short infinitival clauses,
bodyText ||| and expanded participial constructions modifying
bodyText ||| nouns. Also, because we could not obtain the ex-
bodyText ||| act sets used for training, development, and test-
bodyText ||| ing, we had to recreate the sets by randomly split-
bodyText ||| ting the corpus.
subsectionHeader ||| 4.3 Category Specific Results
bodyText ||| We now return to the T¨uBa-D/Z corpus for a
bodyText ||| more detailed analysis, and examine the category-
bodyText ||| specific results for our best performing model (+
bodyText ||| Gold tags, - Edge labels). Overall, Table 4 shows
bodyText ||| that the best performing topological field cate-
bodyText ||| gories are those that have constraints on the type
bodyText ||| of word that is allowed to fill it (finite verbs in
bodyText ||| LK, verbs in VC, complementizers and subordi-
bodyText ||| nating conjunctions in C). VF, in which only one
bodyText ||| constituent may appear, also performs relatively
bodyText ||| well. Topological fields that can contain a vari-
bodyText ||| able number of heterogeneous constituents, on the
bodyText ||| other hand, have poorer F1-measure results. MF,
bodyText ||| which is basically defined relative to the positions
bodyText ||| of fields on either side of it, is parsed several points
bodyText ||| below LK, C, and VC in accuracy. NF, which
bodyText ||| contains different kinds of extraposed elements, is
bodyText ||| parsed at a substantially worse level.
bodyText ||| Poorly parsed categories tend to occur infre-
bodyText |||  quently, including LV, which marks a rare re-
bodyText ||| sumptive construction; FKOORD, which marks
bodyText ||| topological field coordination; and the discourse
bodyText ||| marker DM. The other clause-level constituents
bodyText ||| (PSIMPX for clauses in paratactic constructions,
bodyText ||| RSIMPX for relative clauses, and SIMPX for
bodyText ||| other clauses) also perform below average.
table ||| Topological Fields
table ||| Category	#	LP%	LR%	Fl%
table ||| PARORD	20	100.00	100.00	100.00
table ||| VCE	3	100.00	100.00	100.00
table ||| LK	2186	99.68	99.82	99.75
table ||| C	642	99.53	98.44	98.98
table ||| VC	1777	98.98	98.14	98.56
table ||| VF	2044	96.84	97.55	97.20
table ||| KOORD	99	96.91	94.95	95.92
table ||| MF	2931	94.80	95.19	94.99
table ||| NF	643	83.52	81.96	82.73
table ||| FKOORD	156	75.16	73.72	74.43
table ||| LV	17	10.00	5.88	7.41
table ||| Clausal Constituents
table ||| Category	#	LP%	LR%	Fl%
table ||| SIMPX	2839	92.46	91.97	92.21
table ||| RSIMPX	225	91.23	92.44	91.83
table ||| PSIMPX	6	100.00	66.67	80.00
table ||| DM	28	59.26	57.14	58.18
tableCaption ||| Table 4: Category-specific results using grammar
tableCaption ||| with no edge labels and passing in gold POS tags.
subsectionHeader ||| 4.4 Reranking for Paired Punctuation
bodyText ||| While experimenting with the development set
bodyText ||| of T¨uBa-D/Z, we noticed that the parser some-
bodyText ||| times returns parses, in which paired punctuation
bodyText ||| (e.g. quotation marks, parentheses, brackets) is
bodyText ||| not placed in the same clause–a linguistically im-
bodyText ||| plausible situation. In these cases, the high-level
bodyText ||| information provided by the paired punctuation is
bodyText ||| overridden by the overall likelihood of the parse
bodyText ||| tree. To rectify this problem, we performed a sim-
bodyText ||| ple post-hoc reranking of the 50-best parses pro-
bodyText ||| duced by the best parameter settings (+ Gold tags,
bodyText ||| - Edge labels), selecting the first parse that places
bodyText ||| paired punctuation in the same clause, or return-
bodyText ||| ing the best parse if none of the 50 parses satisfy
bodyText ||| the constraint. This procedure improved the F1-
bodyText ||| measure to 95.24% (LP = 95.39%, LR = 95.09%).
bodyText ||| Overall, 38 sentences were parsed with paired
bodyText ||| punctuation in different clauses, of which 16 were
bodyText ||| reranked. Of the 38 sentences, reranking improved
bodyText ||| performance in 12 sentences, did not affect perfor-
bodyText ||| mance in 23 sentences (of which 10 already had a
bodyText ||| perfect parse), and hurt performance in three sen-
bodyText ||| tences. A two-tailed sign test suggests that rerank-
page ||| 69
bodyText ||| ing improves performance (p = 0.0352). We dis-
bodyText ||| cuss below why sentences with paired punctuation
bodyText ||| in different clauses can have perfect parse results.
bodyText ||| To investigate the upper-bound in performance
bodyText ||| that this form of reranking is able to achieve, we
bodyText ||| calculated some statistics on our (+ Gold tags, -
bodyText ||| Edge labels) 50-best list. We found that the aver-
bodyText ||| age rank of the best scoring parse by F1-measure
bodyText ||| is 2.61, and the perfect parse is present for 1649
bodyText ||| of the 2088 sentences at an average rank of 1.90.
bodyText ||| The oracle F1-measure is 98.12%, indicating that
bodyText ||| a more comprehensive reranking procedure might
bodyText ||| allow further performance gains.
subsectionHeader ||| 4.5 Qualitative Error Analysis
bodyText ||| As a further analysis, we extracted the worst scor-
bodyText ||| ing fifty sentences by F1-measure from the parsed
bodyText ||| test set (+ Gold tags, - Edge labels), and compared
bodyText ||| them against the gold standard trees, noting the
bodyText ||| cause of the error. We analyze the parses before
bodyText ||| reranking, to see how frequently the paired punc-
bodyText ||| tuation problem described above severely affects a
bodyText ||| parse. The major mistakes made by the parser are
bodyText ||| summarized in Table 5.
table ||| Problem	Freq.
table ||| Misidentification of Parentheticals	19
table ||| Coordination problems	13
table ||| Too few SIMPX	10
table ||| Paired punctuation problem	9
table ||| Other clause boundary errors	7
table ||| Other	6
table ||| Too many SIMPX	3
table ||| Clause type misidentification	2
table ||| MF/NF boundary	2
table ||| LV	2
table ||| VF/MF boundary	2
tableCaption ||| Table 5: Types and frequency of parser errors in
tableCaption ||| the fifty worst scoring parses by F1-measure, us-
tableCaption ||| ing parameters (+ Gold tags, - Edge labels).
bodyText ||| Misidentification of Parentheticals Parentheti-
bodyText ||| cal constructions do not have any dependencies on
bodyText ||| the rest of the sentence, and exist as a mostly syn-
bodyText ||| tactically independent clause inside another sen-
bodyText ||| tence. They can occur at the beginning, end, or
bodyText ||| in the middle of sentences, and are often set off
bodyText ||| orthographically by punctuation. The parser has
bodyText ||| problems identifying parenthetical constructions,
bodyText ||| often positing a parenthetical construction when
bodyText ||| that constituent is actually attached to a topolog-
bodyText ||| ical field in a neighbouring clause. The follow-
bodyText ||| ing example shows one such misidentification in
bodyText ||| bracket notation. Clause internal topological fields
bodyText ||| are omitted for clarity.
listItem ||| (2) (a) T¨uBa-D/Z: (SIMPX Weder das Ausmafi der
bodyText ||| Sch¨onheit noch der fr¨uhere oder sp¨atere
bodyText ||| Zeitpunkt der Geburt macht einen der Zwillinge
bodyText ||| f¨ur eine Mutter mehr oder weniger echt /
bodyText ||| authentisch / ¨uberlegen).
listItem ||| (b) Parser: (SIMPX Weder das Ausmafi der
bodyText ||| Sch¨onheit noch der fr¨uhere oder sp¨atere
bodyText ||| Zeitpunkt der Geburt macht einen der Zwillinge
bodyText ||| f¨ur eine Mutter mehr oder weniger echt)
bodyText ||| (PARENTHETICAL / authentisch /
bodyText ||| ¨uberlegen.)
listItem ||| (c) Translation: “Neither the degree of beauty nor
bodyText ||| the earlier or later time of birth makes one of the
bodyText ||| twins any more or less real/authentic/superior to
bodyText ||| a mother.”
bodyText ||| We hypothesized earlier that lexicalization is
bodyText ||| unlikely to give us much improvement in perfor-
bodyText ||| mance, because topological fields work on a do-
bodyText ||| main that is higher than that of lexical dependen-
bodyText ||| cies such as subcategorization frames. However,
bodyText ||| given the locally independent nature of legitimate
bodyText ||| parentheticals, a limited form of lexicalization or
bodyText ||| some other form of stronger contextual informa-
bodyText ||| tion might be needed to improve identification per-
bodyText ||| formance.
bodyText ||| Coordination Problems The second most com-
bodyText ||| mon type of error involves field and clause coordi-
bodyText ||| nations. This category includes missing or incor-
bodyText ||| rect FKOORD fields, and conjunctions of clauses
bodyText ||| that are misidentified. In the following example,
bodyText ||| the conjoined MFs and following NF in the cor-
bodyText ||| rect parse tree are identified as a single long MF.
listItem ||| (3)	(a) T¨uBa-D/Z: Auf dem europ¨aischen Kontinent
bodyText ||| aber hat (FKOORD (MF kein Land und keine
bodyText ||| Macht ein derartiges Interesse an guten
bodyText ||| Beziehungen zu Ruf land) und (MF auch kein
bodyText ||| Land solche Erfahrungen im Umgang mit
bodyText ||| Ruf land)) (NF wie Deutschland).
listItem ||| (b) Parser: Auf dem europ¨aischen Kontinent aber
bodyText ||| hat (MF kein Land und keine Macht ein
bodyText ||| derartiges Interesse an guten Beziehungen zu
bodyText ||| Ruf land und auch kein Land solche
bodyText ||| Erfahrungen im Umgang mit Ruf land wie
bodyText ||| Deutschland).
listItem ||| (c) Translation: “On the European continent,
bodyText ||| however, no land and no power has such an
bodyText ||| interest in good relations with Russia (as
bodyText ||| Germany), and also no land (has) such
bodyText ||| experience in dealing with Russia as Germany.”
bodyText ||| Other Clause Errors Other clause-level errors
bodyText ||| include the parser predicting too few or too many
bodyText ||| clauses, or misidentifying the clause type. Clauses
bodyText ||| are sometimes confused with NFs, and there is one
bodyText ||| case of a relative clause being misidentified as a
page ||| 70
bodyText ||| main clause with an intransitive verb, as the finite
bodyText ||| verb appears at the end of the clause in both cases.
bodyText ||| Some clause errors are tied to incorrect treatment
bodyText ||| of elliptical constructions, in which an element
bodyText ||| that is inferable from context is missing.
bodyText ||| Paired Punctuation Problems with paired
bodyText ||| punctuation are the fourth most common type of
bodyText ||| error. Punctuation is often a marker of clause
bodyText ||| or phrase boundaries. Thus, predicting paired
bodyText ||| punctuation incorrectly can lead to incorrect
bodyText ||| parses, as in the following example.
listItem ||| (4) (a) “ Auch (SIMPX wenn der Krieg heute ein
bodyText ||| Mobilisierungsfaktor ist) ” , so Pau, “ (SIMPX
bodyText ||| die Leute sehen , dafi man f¨ur die Arbeit wieder
bodyText ||| auf die Strafie gehen mufi) . ”
listItem ||| (b) Parser: (SIMPX “ (LV Auch (SIMPX wenn der
bodyText ||| Krieg heute ein Mobilisierungsfaktor ist)) ” , so
bodyText ||| Pau, “ (SIMPX die Leute sehen , dafi man f¨ur
bodyText ||| die Arbeit wieder auf die Strafie gehen mufi)) . ”
listItem ||| (c) Translation: “Even if the war is a factor for
bodyText ||| mobilization,” said Pau, “the people see, that
bodyText ||| one must go to the street for employment again.”
bodyText ||| Here, the parser predicts a spurious SIMPX
bodyText ||| clause spanning the text of the entire sentence, but
bodyText ||| this causes the second pair of quotation marks to
bodyText ||| be parsed as belonging to two different clauses.
bodyText ||| The parser also predicts an incorrect LV field. Us-
bodyText ||| ing the paired punctuation constraint, our rerank-
bodyText ||| ing procedure was able to correct these errors.
bodyText ||| Surprisingly, there are cases in which paired
bodyText ||| punctuation does not belong inside the same
bodyText ||| clause in the gold parses. These cases are ei-
bodyText ||| ther extended quotations, in which each of the
bodyText ||| quotation mark pair occurs in a different sen-
bodyText ||| tence altogether, or cases where the second of the
bodyText ||| quotation mark pair must be positioned outside
bodyText ||| of other sentence-final punctuation due to ortho-
bodyText ||| graphic conventions. Sentence-final punctuation
bodyText ||| is typically placed outside a clause in this version
bodyText ||| of T¨uBa-D/Z.
bodyText ||| Other Issues Other incorrect parses generated
bodyText ||| by the parser include problems with the infre-
bodyText ||| quently occurring topological fields like LV and
bodyText ||| DM, inability to determine the boundary between
bodyText ||| MF and NF in clauses without a VC field sepa-
bodyText ||| rating the two, and misidentifying appositive con-
bodyText ||| structions. Another issue is that although the
bodyText ||| parser output may disagree with the gold stan-
bodyText ||| dard tree in T¨uBa-D/Z, the parser output may be
bodyText ||| a well-formed topological field parse for the same
bodyText ||| sentence with a different interpretation, for ex-
bodyText ||| ample because of attachment ambiguity. Each of
bodyText ||| the authors independently checked the fifty worst-
bodyText ||| scoring parses, and determined whether each parse
bodyText ||| produced by the Berkeley parser could be a well-
bodyText ||| formed topological parse. Where there was dis-
bodyText ||| agreement, we discussed our judgments until we
bodyText ||| came to a consensus. Of the fifty parses, we de-
bodyText ||| termined that nine, or 18%, could be legitimate
bodyText ||| parses. Another five, or 10%, differ from the gold
bodyText ||| standard parse only in the placement of punctua-
bodyText ||| tion. Thus, the Fl-measures we presented above
bodyText ||| may be underestimating the parser’s performance.
sectionHeader ||| 5 Conclusion and Future Work
bodyText ||| In this paper, we examined applying the latent-
bodyText ||| variable Berkeley parser to the task of topological
bodyText ||| field parsing of German, which aims to identify the
bodyText ||| high-level surface structure of sentences. Without
bodyText ||| any language or model-dependent adaptation, we
bodyText ||| obtained results which compare favourably to pre-
bodyText ||| vious work in topological field parsing. We further
bodyText ||| examined the results of doing a simple reranking
bodyText ||| process, constraining the output parse to put paired
bodyText ||| punctuation in the same clause. This reranking
bodyText ||| was found to result in a minor performance gain.
bodyText ||| Overall, the parser performs extremely well in
bodyText ||| identifying the traditional left and right brackets
bodyText ||| of the topological field model; that is, the fields
bodyText ||| C, LK, and VC. The parser achieves basically per-
bodyText ||| fect results on these fields in the T¨uBa-D/Z corpus,
bodyText ||| with Fl-measure scores for each at over 98.5%.
bodyText ||| These scores are higher than previous work in the
bodyText ||| simpler task of topological field chunking. The fo-
bodyText ||| cus of future research should thus be on correctly
bodyText ||| identifying the infrequently occuring fields and
bodyText ||| constructions, with parenthetical constructions be-
bodyText ||| ing a particular concern. Possible avenues of fu-
bodyText ||| ture research include doing a more comprehensive
bodyText ||| discriminative reranking of the parser output. In-
bodyText ||| corporating more contextual information might be
bodyText ||| helpful to identify discourse-related constructions
bodyText ||| such as parentheses, and the DM and LV topolog-
bodyText ||| ical fields.
sectionHeader ||| Acknowledgements
bodyText ||| We are grateful to Markus Becker, Anette Frank,
bodyText ||| Sandra Kuebler, and Slav Petrov for their invalu-
bodyText ||| able help in gathering the resources necessary for
bodyText ||| our experiments. This work is supported in part
bodyText ||| by the Natural Sciences and Engineering Research
bodyText ||| Council of Canada.
page ||| 71
sectionHeader ||| References
reference ||| M. Becker and A. Frank. 2002. A stochastic topo-
reference ||| logical parser for German. In Proceedings of the
reference ||| 19th International Conference on Computational
reference ||| Linguistics, pages 71–77.
reference ||| S. Brants, S. Dipper, S. Hansen, W. Lezius, and
reference ||| G. Smith. 2002. The TIGER Treebank. In Proceed-
reference ||| ings of the Workshop on Treebanks and Linguistic
reference ||| Theories, pages 24–41.
reference ||| U. Callmeier. 2000. PET–a platform for experimen-
reference ||| tation with efficient HPSG processing techniques.
reference ||| Natural Language Engineering, 6(01):99–107.
reference ||| A. Dubey and F. Keller. 2003. Probabilistic parsing
reference ||| for German using sister-head dependencies. In Pro-
reference ||| ceedings of the 41st Annual Meeting of the Associa-
reference ||| tion for Computational Linguistics, pages 96–103.
reference ||| K.A. Foth, M. Daum, and W. Menzel. 2004. A
reference ||| broad-coverage parser for German based on defea-
reference ||| sible constraints. Constraint Solving and Language
reference ||| Processing.
reference ||| A. Frank, M. Becker, B. Crysmann, B. Kiefer, and
reference ||| U. Schaefer. 2003. Integrated shallow and deep
reference ||| parsing: TopP meets HPSG. In Proceedings of the
reference ||| 41st Annual Meeting of the Association for Compu-
reference ||| tational Linguistics, pages 104–111.
reference ||| W. Frey. 2004. Notes on the syntax and the pragmatics
reference ||| of German Left Dislocation. In H. Lohnstein and
reference ||| S. Trissler, editors, The Syntax and Semantics of the
reference ||| Left Periphery, pages 203–233. Mouton de Gruyter,
reference ||| Berlin.
reference ||| J. Hockenmaier. 2006. Creating a CCGbank and a
reference ||| Wide-Coverage CCG Lexicon for German. In Pro-
reference ||| ceedings of the 21st International Conference on
reference ||| Computational Linguistics and 44th Annual Meet-
reference ||| ing of the Association for Computational Linguis-
reference ||| tics, pages 505–512.
reference ||| T.N. H¨ohle. 1983. Topologische Felder. Ph.D. thesis,
reference ||| K¨oln.
reference ||| S. K¨ubler, E.W. Hinrichs, and W. Maier. 2006. Is it re-
reference ||| ally that difficult to parse German? In Proceedings
reference ||| of EMNLP.
reference ||| M. Liepert. 2003. Topological Fields Chunking for
reference ||| German with SVM’s: Optimizing SVM-parameters
reference ||| with GA’s. In Proceedings of the International Con-
reference ||| ference on Recent Advances in Natural Language
reference ||| Processing (RANLP), Bulgaria.
reference ||| G. Neumann, C. Braun, and J. Piskorski. 2000. A
reference ||| Divide-and-Conquer Strategy for Shallow Parsing
reference ||| of German Free Texts. In Proceedings of the sixth
reference ||| conference on Applied natural language processing,
reference ||| pages 239–246. Morgan Kaufmann Publishers Inc.
reference ||| San Francisco, CA, USA.
reference ||| S. Petrov and D. Klein. 2008. Parsing German with
reference ||| Latent Variable Grammars. In Proceedings of the
reference ||| ACL-08: HLT Workshop on Parsing German (PaGe-
reference ||| 08), pages 33–39.
reference ||| S. Petrov, L. Barrett, R. Thibaux, and D. Klein. 2006.
reference ||| Learning accurate, compact, and interpretable tree
reference ||| annotation. In Proceedings of the 21st Interna-
reference ||| tional Conference on Computational Linguistics and
reference ||| 44th Annual Meeting of the Association for Compu-
reference ||| tational Linguistics, pages 433–440, Sydney, Aus-
reference ||| tralia, July. Association for Computational Linguis-
reference ||| tics.
reference ||| C. Rohrer and M. Forst. 2006. Improving coverage
reference ||| and parsing quality of a large-scale LFG for Ger-
reference ||| man. In Proceedings of the Language Resources
reference ||| and Evaluation Conference (LREC-2006), Genoa,
reference ||| Italy.
reference ||| W. Skut, T. Brants, B. Krenn, and H. Uszkoreit.
reference ||| 1998. A Linguistically Interpreted Corpus of Ger-
reference ||| man Newspaper Text. Proceedings of the ESSLLI
reference ||| Workshop on Recent Advances in Corpus Annota-
reference ||| tion.
reference ||| H. Telljohann, E. Hinrichs, and S. Kubler. 2004.
reference ||| The T¨uBa-D/Z treebank: Annotating German with a
reference ||| context-free backbone. In Proceedings of the Fourth
reference ||| International Conference on Language Resources
reference ||| and Evaluation (LREC 2004), pages 2229–2235.
reference ||| H. Telljohann, E.W. Hinrichs, S. Kubler, and H. Zins-
reference ||| meister. 2006. Stylebook for the Tubingen Tree-
reference ||| bank of Written German (T¨uBa-D/Z). Seminar fur
reference ||| Sprachwissenschaft, Universitat Tubingen, Tubin-
reference ||| gen, Germany.
reference ||| T. Ule. 2003. Directed Treebank Refinement for PCFG
reference ||| Parsing. In Proceedings of Workshop on Treebanks
reference ||| and Linguistic Theories (TLT) 2003, pages 177–188.
reference ||| J. Veenstra, F.H. M¨uller, and T. Ule. 2002. Topolog-
reference ||| ical field chunking for German. In Proceedings of
reference ||| the Sixth Conference on Natural Language Learn-
reference ||| ing, pages 56–62.
page ||| 72

title ||| Unsupervised Multilingual Grammar Induction
author ||| Benjamin Snyder, Tahira Naseem, and Regina Barzilay
affiliation ||| Computer Science and Artificial Intelligence Laboratory
affiliation ||| Massachusetts Institute of Technology
email ||| {bsnyder, tahira, regina}@csail.mit.edu
sectionHeader ||| Abstract
bodyText ||| We investigate the task of unsupervised
bodyText ||| constituency parsing from bilingual par-
bodyText ||| allel corpora. Our goal is to use bilin-
bodyText ||| gual cues to learn improved parsing mod-
bodyText ||| els for each language and to evaluate these
bodyText ||| models on held-out monolingual test data.
bodyText ||| We formulate a generative Bayesian model
bodyText ||| which seeks to explain the observed par-
bodyText ||| allel data through a combination of bilin-
bodyText ||| gual and monolingual parameters. To this
bodyText ||| end, we adapt a formalism known as un-
bodyText ||| ordered tree alignment to our probabilistic
bodyText ||| setting. Using this formalism, our model
bodyText ||| loosely binds parallel trees while allow-
bodyText ||| ing language-specific syntactic structure.
bodyText ||| We perform inference under this model us-
bodyText ||| ing Markov Chain Monte Carlo and dy-
bodyText ||| namic programming. Applying this model
bodyText ||| to three parallel corpora (Korean-English,
bodyText ||| Urdu-English, and Chinese-English) we
bodyText ||| find substantial performance gains over
bodyText ||| the CCM model, a strong monolingual
bodyText ||| baseline. On average, across a variety of
bodyText ||| testing scenarios, our model achieves an
bodyText ||| 8.8 absolute gain in F-measure. 1
sectionHeader ||| 1 Introduction
bodyText ||| In this paper we investigate the task of unsuper-
bodyText ||| vised constituency parsing when bilingual paral-
bodyText ||| lel text is available. Our goal is to improve pars-
bodyText ||| ing performance on monolingual test data for each
bodyText ||| language by using unsupervised bilingual cues at
bodyText ||| training time. Multilingual learning has been suc-
bodyText ||| cessful for other linguistic induction tasks such as
bodyText ||| lexicon acquisition, morphological segmentation,
bodyText ||| and part-of-speech tagging (Genzel, 2005; Snyder
bodyText ||| and Barzilay, 2008; Snyder et al., 2008; Snyder
footnote ||| 1Code and the outputs of our experiments are available at
footnote ||| http://groups.csail.mit.edu/rbg/code/multiling induction.
bodyText ||| et al., 2009). We focus here on the unsupervised
bodyText ||| induction of unlabeled constituency brackets. This
bodyText ||| task has been extensively studied in a monolingual
bodyText ||| setting and has proven to be difficult (Charniak
bodyText ||| and Carroll, 1992; Klein and Manning, 2002).
bodyText ||| The key premise of our approach is that am-
bodyText ||| biguous syntactic structures in one language may
bodyText ||| correspond to less uncertain structures in the other
bodyText ||| language. For instance, the English sentence I
bodyText ||| saw [the student [from MIT]] exhibits the classic
bodyText ||| problem of PP-attachment ambiguity. However,
bodyText ||| its Urdu translation, literally glossed as I [[MIT of]
bodyText ||| student] saw, uses a genitive phrase that may only
bodyText ||| be attached to the adjacent noun phrase. Know-
bodyText ||| ing the correspondence between these sentences
bodyText ||| should help us resolve the English ambiguity.
bodyText ||| One of the main challenges of unsupervised
bodyText ||| multilingual learning is to exploit cross-lingual
bodyText ||| patterns discovered in data, while still allowing
bodyText ||| a wide range of language-specific idiosyncrasies.
bodyText ||| To this end, we adapt a formalism known as un-
bodyText ||| ordered tree alignment (Jiang et al., 1995) to
bodyText ||| a probabilistic setting. Under this formalism,
bodyText ||| any two trees can be embedded in an alignment
bodyText ||| tree. This alignment tree allows arbitrary parts
bodyText ||| of the two trees to diverge in structure, permitting
bodyText ||| language-specific grammatical structure to be pre-
bodyText ||| served. Additionally, a computational advantage
bodyText ||| of this formalism is that the marginalized probabil-
bodyText ||| ity over all possible alignments for any two trees
bodyText ||| can be efficiently computed with a dynamic pro-
bodyText ||| gram in linear time.
bodyText ||| We formulate a generative Bayesian model
bodyText ||| which seeks to explain the observed parallel data
bodyText ||| through a combination of bilingual and mono-
bodyText ||| lingual parameters. Our model views each pair
bodyText ||| of sentences as having been generated as fol-
bodyText ||| lows: First an alignment tree is drawn. Each
bodyText ||| node in this alignment tree contains either a soli-
bodyText ||| tary monolingual constituent or a pair of coupled
bodyText ||| bilingual constituents. For each solitary mono-
page ||| 73
note ||| Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 73–81,
note ||| Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP
bodyText ||| lingual constituent, a sequence of part-of-speech
bodyText ||| tags is drawn from a language-specific distribu-
bodyText ||| tion. For each pair of coupled bilingual con-
bodyText ||| stituents, a pair of part-of-speech sequences are
bodyText ||| drawn jointly from a cross-lingual distribution.
bodyText ||| Word-level alignments are then drawn based on
bodyText ||| the tree alignment. Finally, parallel sentences are
bodyText ||| assembled from these generated part-of-speech se-
bodyText ||| quences and word-level alignments.
bodyText ||| To perform inference under this model, we use
bodyText ||| a Metropolis-Hastings within-Gibbs sampler. We
bodyText ||| sample pairs of trees and then compute marginal-
bodyText ||| ized probabilities over all possible alignments us-
bodyText ||| ing dynamic programming.
bodyText ||| We test the effectiveness of our bilingual gram-
bodyText ||| mar induction model on three corpora of parallel
bodyText ||| text: English-Korean, English-Urdu and English-
bodyText ||| Chinese. The model is trained using bilingual
bodyText ||| data with automatically induced word-level align-
bodyText ||| ments, but is tested on purely monolingual data
bodyText ||| for each language. In all cases, our model out-
bodyText ||| performs a state-of-the-art baseline: the Con-
bodyText ||| stituent Context Model (CCM) (Klein and Man-
bodyText ||| ning, 2002), sometimes by substantial margins.
bodyText ||| On average, over all the testing scenarios that we
bodyText ||| studied, our model achieves an absolute increase
bodyText ||| in F-measure of 8.8 points, and a 19% reduction
bodyText ||| in error relative to a theoretical upper bound.
sectionHeader ||| 2 Related Work
bodyText ||| The unsupervised grammar induction task has
bodyText ||| been studied extensively, mostly in a monolin-
bodyText ||| gual setting (Charniak and Carroll, 1992; Stolcke
bodyText ||| and Omohundro, 1994; Klein and Manning, 2002;
bodyText ||| Seginer, 2007). While PCFGs perform poorly on
bodyText ||| this task, the CCM model (Klein and Manning,
bodyText ||| 2002) has achieved large gains in performance and
bodyText ||| is among the state-of-the-art probabilistic models
bodyText ||| for unsupervised constituency parsing. We there-
bodyText ||| fore use CCM as our basic model of monolingual
bodyText ||| syntax.
bodyText ||| While there has been some previous work on
bodyText ||| bilingual CFG parsing, it has mainly focused on
bodyText ||| improving MT systems rather than monolingual
bodyText ||| parsing accuracy. Research in this direction was
bodyText ||| pioneered by (Wu, 1997), who developed Inver-
bodyText ||| sion Transduction Grammars to capture cross-
bodyText ||| lingual grammar variations such as phrase re-
bodyText ||| orderings. More general formalisms for the same
bodyText ||| purpose were later developed (Wu and Wong,
bodyText ||| 1998; Chiang, 2005; Melamed, 2003; Eisner,
bodyText ||| 2003; Zhang and Gildea, 2005; Blunsom et al.,
bodyText ||| 2008). We know of only one study which eval-
bodyText ||| uates these bilingual grammar formalisms on the
bodyText ||| task of grammar induction itself (Smith and Smith,
bodyText ||| 2004). Both our model and even the monolingual
bodyText ||| CCM baseline yield far higher performance on the
bodyText ||| same Korean-English corpus.
bodyText ||| Our approach is closer to the unsupervised
bodyText ||| bilingual parsing model developed by Kuhn
bodyText ||| (2004), which aims to improve monolingual per-
bodyText ||| formance. Assuming that trees induced over paral-
bodyText ||| lel sentences have to exhibit certain structural reg-
bodyText ||| ularities, Kuhn manually specifies a set of rules
bodyText ||| for determining when parsing decisions in the two
bodyText ||| languages are inconsistent with GIZA++ word-
bodyText ||| level alignments. By incorporating these con-
bodyText ||| straints into the EM algorithm he was able to im-
bodyText ||| prove performance over a monolingual unsuper-
bodyText ||| vised PCFG. Still, the performance falls short of
bodyText ||| state-of-the-art monolingual models such as the
bodyText ||| CCM.
bodyText ||| More recently, there has been a body of work
bodyText ||| attempting to improve parsing performance by ex-
bodyText ||| ploiting syntactically annotated parallel data. In
bodyText ||| one strand of this work, annotations are assumed
bodyText ||| only in a resource-rich language and are projected
bodyText ||| onto a resource-poor language using the parallel
bodyText ||| data (Hwa et al., 2005; Xi and Hwa, 2005). In
bodyText ||| another strand of work, syntactic annotations are
bodyText ||| assumed on both sides of the parallel data, and a
bodyText ||| model is trained to exploit the parallel data at test
bodyText ||| time as well (Smith and Smith, 2004; Burkett and
bodyText ||| Klein, 2008). In contrast to this work, our goal
bodyText ||| is to explore the benefits of multilingual grammar
bodyText ||| induction in a fully unsupervised setting.
bodyText ||| We finally note a recent paper which uses pa-
bodyText ||| rameter tying to improve unsupervised depen-
bodyText ||| dency parse induction (Cohen and Smith, 2009).
bodyText ||| While the primary performance gains occur when
bodyText ||| tying related parameters within a language, some
bodyText ||| additional benefit is observed through bilingual ty-
bodyText ||| ing, even in the absence of a parallel corpus.
sectionHeader ||| 3 Model
bodyText ||| We propose an unsupervised Bayesian model for
bodyText ||| learning bilingual syntactic structure using paral-
bodyText ||| lel corpora. Our key premise is that difficult-to-
bodyText ||| learn syntactic structures of one language may cor-
bodyText ||| respond to simpler or less uncertain structures in
bodyText ||| the other language. We treat the part-of-speech
bodyText ||| tag sequences of parallel sentences, as well as their
page ||| 74
figure ||| (ii)
figure ||| (iii)
figure ||| (i)
figureCaption ||| Figure 1: A pair of trees (i) and two possible alignment trees. In (ii), no empty spaces are inserted, but
figureCaption ||| the order of one of the original tree’s siblings has been reversed. In (iii), only two pairs of nodes have
figureCaption ||| been aligned (indicated by arrows) and many empty spaces inserted.
bodyText ||| word-level alignments, as observed data. We ob-
bodyText ||| tain these word-level alignments using GIZA++
bodyText ||| (Och and Ney, 2003).
bodyText ||| Our model seeks to explain this observed data
bodyText ||| through a generative process whereby two aligned
bodyText ||| parse trees are produced jointly. Though they
bodyText ||| are aligned, arbitrary parts of the two trees are
bodyText ||| permitted to diverge, accommodating language-
bodyText ||| specific grammatical structure. In effect, our
bodyText ||| model loosely binds the two trees: node-to-node
bodyText ||| alignments need only be used where repeated
bodyText ||| bilingual patterns can be discovered in the data.
subsectionHeader ||| 3.1 Tree Alignments
bodyText ||| We achieve this loose binding of trees by adapting
bodyText ||| unordered tree alignment (Jiang et al., 1995) to a
bodyText ||| probabilistic setting. Under this formalism, any
bodyText ||| two trees can be aligned using an alignment tree.
bodyText ||| The alignment tree embeds the original two trees
bodyText ||| within it: each node is labeled by a pair (x, y),
bodyText ||| (A, y), or (x, A) where x is a node from the first
bodyText ||| tree, y is a node from the second tree, and A is an
bodyText ||| empty space. The individual structure of each tree
bodyText ||| must be preserved under the embedding with the
bodyText ||| exception of sibling order (to allow variations in
bodyText ||| phrase and word order).
bodyText ||| The flexibility of this formalism can be demon-
bodyText ||| strated by two extreme cases: (1) an alignment be-
bodyText ||| tween two trees may actually align none of their
bodyText ||| individual nodes, instead inserting an empty space
bodyText ||| A for each of the original two trees’ nodes. (2)
bodyText ||| if the original trees are isomorphic to one an-
bodyText ||| other, the alignment may match their nodes ex-
bodyText ||| actly, without inserting any empty spaces. See
bodyText ||| Figure 1 for an example.
subsectionHeader ||| 3.2 Model overview
bodyText ||| As our basic model of syntactic structure, we
bodyText ||| adopt the Constituent-Context Model (CCM) of
bodyText ||| Klein and Manning (2002). Under this model,
bodyText ||| the part-of-speech sequence of each span in a sen-
bodyText ||| tence is generated either as a constituent yield
bodyText ||| — if it is dominated by a node in the tree —
bodyText ||| or otherwise as a distituent yield. For example,
bodyText ||| in the bracketed sentence [John/NNP [climbed/VB
bodyText ||| [the/DT tree/NN]]], the sequence VB DT NN is gen-
bodyText ||| erated as a constituent yield, since it constitutes a
bodyText ||| complete bracket in the tree. On the other hand,
bodyText ||| the sequence VB DT is generated as a distituent,
bodyText ||| since it does not. Besides these yields, the con-
bodyText ||| texts (two surrounding POS tags) of constituents
bodyText ||| and distituents are generated as well. In this exam-
bodyText ||| ple, the context of the constituent VB DT NN would
bodyText ||| be (NNP, #), while the context of the distituent VB
bodyText ||| DT would be (NNP, NN). The CCM model em-
bodyText ||| ploys separate multinomial distributions over con-
bodyText ||| stituents, distituents, constituent contexts, and dis-
bodyText ||| tituent contexts. While this model is deficient —
bodyText ||| each observed subsequence of part-of-speech tags
bodyText ||| is generated many times over — its performance
bodyText ||| is far higher than that of unsupervised PCFGs.
bodyText ||| Under our bilingual model, each pair of sen-
bodyText ||| tences is assumed to have been generated jointly in
bodyText ||| the following way: First, an unlabeled alignment
bodyText ||| tree is drawn uniformly from the set of all such
bodyText ||| trees. This alignment tree specifies the structure
bodyText ||| of each of the two individual trees, as well as the
bodyText ||| pairs of nodes which are aligned and those which
bodyText ||| are not aligned (i.e. paired with a A).
bodyText ||| For each pair of aligned nodes, a correspond-
bodyText ||| ing pair of constituents and contexts are jointly
bodyText ||| drawn from a bilingual distribution. For unaligned
bodyText ||| nodes (i.e. nodes paired with a A in the alignment
page ||| 75
bodyText ||| tree), a single constituent and context are drawn,
bodyText ||| from language-specific distributions. Distituents
bodyText ||| and their contexts are also drawn from language-
bodyText ||| specific distributions. Finally, word-level align-
bodyText ||| ments are drawn based on the structure of the
bodyText ||| alignment tree.
bodyText ||| In the next two sections, we describe our model
bodyText ||| in more formal detail by specifying the parame-
bodyText ||| ters and generative process by which sentences are
bodyText ||| formed.
subsectionHeader ||| 3.3 Parameters
bodyText ||| Our model employs a number of multinomial dis-
bodyText ||| tributions:
listItem ||| •	7r�D : over constituent yields of language i,
listItem ||| •	7r�D : over distituent yields of language i,
listItem ||| •	��D : over constituent contexts of language i,
listItem ||| •	��D : over distituent contexts of language i,
listItem ||| •	w : over pairs of constituent yields, one from
listItem ||| the first language and the other from the sec-
listItem ||| ond language,
listItem ||| •	Gzpair : over a finite set of integer val-
listItem ||| ues {—m, ... , —2, —1, 0,1, 2, ... , m}, mea-
listItem ||| suring the Giza-score of aligned tree node
listItem ||| pairs (see below),
listItem ||| •	Gznode : over a finite set of integer values
listItem ||| {—m, . . ., —2, —1, 01, measuring the Giza-
listItem ||| score of unaligned tree nodes (see below).
bodyText ||| The first four distributions correspond exactly to
bodyText ||| the parameters of the CCM model. Parameter w is
bodyText ||| a “coupling parameter” which measures the com-
bodyText ||| patibility of tree-aligned constituent yield pairs.
bodyText ||| The final two parameters measure the compatibil-
bodyText ||| ity of syntactic alignments with the observed lexi-
bodyText ||| cal GIZA++ alignments. Intuitively, aligned nodes
bodyText ||| should have a high density of word-level align-
bodyText ||| ments between them, and unaligned nodes should
bodyText ||| have few lexical alignments.
bodyText ||| More formally, consider a tree-aligned node
bodyText ||| pair (n1, n2) with corresponding yields (y1, y2).
bodyText ||| We call a word-level alignment good if it aligns
bodyText ||| a word in y1 with a word in y2. We call a word-
bodyText ||| level alignment bad if it aligns a word in y1 with
bodyText ||| a word outside y2, or vice versa. The Giza-
bodyText ||| score for (n1, n2) is the number of good word
bodyText ||| alignments minus the number of bad word align-
bodyText ||| ments. For example, suppose the constituent my
bodyText ||| long name is node-aligned to its Urdu translation
bodyText ||| mera lamba naam. If only the word-pairs my/mera
bodyText ||| and name/naam are aligned, then the Giza-score
bodyText ||| for this node-alignment would be 2. If however,
bodyText ||| the English word long were (incorrectly) aligned
bodyText ||| under GIZA++ to some Urdu word outside the cor-
bodyText ||| responding constituent, then the score would drop
bodyText ||| to 1. This score could even be negative if the num-
bodyText ||| ber of bad alignments exceeds those that are good.
bodyText ||| Distribution Gzpair provides a probability for these
bodyText ||| scores (up to some fixed absolute value).
bodyText ||| For an unaligned node n with corresponding
bodyText ||| yield y, only bad GIZA++ alignments are possible,
bodyText ||| thus the Giza-score for these nodes will always be
bodyText ||| zero or negative. Distribution Gznode provides a
bodyText ||| probability for these scores (down to some fixed
bodyText ||| value). We want our model to find tree alignments
bodyText ||| such that both aligned node pairs and unaligned
bodyText ||| nodes have high Giza-score.
sectionHeader ||| 3.4 Generative Process
bodyText ||| Now we describe the stochastic process whereby
bodyText ||| the observed parallel sentences and their word-
bodyText ||| level alignments are generated, according to our
bodyText ||| model.
bodyText ||| As the first step in the Bayesian generative pro-
bodyText ||| cess, all the multinomial parameters listed in the
bodyText ||| previous section are drawn from their conjugate
bodyText ||| priors — Dirichlet distributions of appropriate di-
bodyText ||| mension. Then, each pair of word-aligned parallel
bodyText ||| sentences is generated through the following pro-
bodyText ||| cess:
listItem ||| 1. A pair of binary trees T1 and T2 along with
bodyText ||| an alignment tree A are drawn according to
bodyText ||| P(T1, T2, A). A is an alignment tree for T1
bodyText ||| and T2 if it can be obtained by the follow-
bodyText ||| ing steps: First insert blank nodes (labeled by
bodyText ||| A) into T1 and T2. Then permute the order
bodyText ||| of sibling nodes such that the two resulting
bodyText ||| trees T10 and T20 are identical in structure. Fi-
bodyText ||| nally, overlay T10 and T20 to obtain A. We ad-
bodyText ||| ditionally require that A contain no extrane-
bodyText ||| ous nodes – that is no nodes with two blank
bodyText ||| labels (A, A). See Figure 1 for an example.
bodyText ||| We define the distribution P(T1, T2, A) to be
bodyText ||| uniform over all pairs of binary trees and their
bodyText ||| alignments.
listItem ||| 2. For each node in A of the form (n1, A) (i.e.
listItem ||| nodes in T1 left unaligned by A), draw
listItem ||| (i) a constituent yield according to 7r�1 ,
listItem ||| 76
listItem ||| (ii) a constituent context according to 0C1,
listItem ||| (iii) a Giza-score according to Gznode.
listItem ||| 3. For each node in A of the form (A, n2) (i.e.
listItem ||| nodes in T2 left unaligned by A), draw
listItem ||| (i) a constituent yield according to 7rC2 ,
listItem ||| (ii) a constituent context according to 0C2,
listItem ||| (iii) a Giza-score according to Gznode.
listItem ||| 4. For each node in A of the form (n1, n2) (i.e.
listItem ||| tree-aligned node pairs), draw
listItem ||| (i) a pair of constituent yields (y1, y2) ac-
listItem ||| cording to:
equation ||| 0C1 (y1) - 0C2(y2) - W (y1, y2)	(1)
equation ||| Z
bodyText ||| which is a product of experts combining
bodyText ||| the language specific context-yield dis-
bodyText ||| tributions as well as the coupling distri-
bodyText ||| bution W with normalization constant Z,
listItem ||| (ii) a pair of contexts according to the ap-
listItem ||| propriate language-specific parameters,
listItem ||| (iii) a Giza-score according to Gzpair.
listItem ||| 5. For each span in TZ not dominated by a node
bodyText ||| (for each language i E 11, 2}), draw a dis-
bodyText ||| tituent yield according to 7r�Z and a distituent
bodyText ||| context according to 0�Z.
listItem ||| 6. Draw actual word-level alignments consis-
bodyText ||| tent with the Giza-scores, according to a uni-
bodyText ||| form distribution.
bodyText ||| In the next section we turn to the problem of
bodyText ||| inference under this model when only the part-
bodyText ||| of-speech tag sequences of parallel sentences and
bodyText ||| their word-level alignments are observed.
sectionHeader ||| 3.5 Inference
bodyText ||| Given a corpus of paired part-of-speech tag se-
bodyText ||| quences (s1, s2) and their GIZA++ alignments
bodyText ||| g, we would ideally like to predict the set of
bodyText ||| tree pairs (T1, T2) which have highest proba-
bodyText ||| bility when conditioned on the observed data:
bodyText ||| P(T1, T2Is1, s2, g). We could rewrite this by
bodyText ||| explicitly integrating over the yield, context, cou-
bodyText ||| pling, Giza-score parameters as well as the align-
bodyText ||| ment trees. However, since maximizing this in-
bodyText ||| tegral directly would be intractable, we resort to
bodyText ||| standard Markov chain sampling techniques. We
bodyText ||| use Gibbs sampling (Hastings, 1970) to draw trees
bodyText ||| for each sentence conditioned on those drawn for
bodyText ||| all other sentences. The samples form a Markov
bodyText ||| chain which is guaranteed to converge to the true
bodyText ||| joint distribution over all sentences.
bodyText ||| In the monolingual setting, there is a well-
bodyText ||| known tree sampling algorithm (Johnson et al.,
bodyText ||| 2007). This algorithm proceeds in top-down fash-
bodyText ||| ion by sampling individual split points using the
bodyText ||| marginal probabilities of all possible subtrees.
bodyText ||| These marginals can be efficiently pre-computed
bodyText ||| and form the “inside” table of the famous Inside-
bodyText ||| Outside algorithm. However, in our setting, trees
bodyText ||| come in pairs, and their joint probability crucially
bodyText ||| depends on their alignment.
bodyText ||| For the i1h parallel sentence, we wish to jointly
bodyText ||| sample the pair of trees (T1,T2)Z together with
bodyText ||| their alignment AZ. To do so directly would in-
bodyText ||| volve simultaneously marginalizing over all pos-
bodyText ||| sible subtrees as well as all possible alignments
bodyText ||| between such subtrees when sampling upper-level
bodyText ||| split points. We know of no obvious algorithm
bodyText ||| for computing this marginal. We instead first sam-
bodyText ||| ple the pair of trees (T1, T2)Z from a simpler pro-
bodyText ||| posal distribution Q. Our proposal distribution as-
bodyText ||| sumes that no nodes of the two trees are aligned
bodyText ||| and therefore allows us to use the recursive top-
bodyText ||| down sampling algorithm mentioned above. After
bodyText ||| a new tree pair T* _ (T1*, T2* )Z is drawn from Q,
bodyText ||| we accept the pair with the following probability:
equation ||| � �
equation ||| min 1,
equation ||| P(T* T—Z, A—Z) Q(TIT—Z, A—Z)
equation ||| P(T IT—Z, A—Z) Q(T* IT—Z, A—Z)
bodyText ||| where T is the previously sampled tree-pair for
bodyText ||| sentence i, P is the true model probability, and
bodyText ||| Q is the probability under the proposal distribu-
bodyText ||| tion. This use of a tractable proposal distribution
bodyText ||| and acceptance ratio is known as the Metropolis-
bodyText ||| Hastings algorithm and it preserves the conver-
bodyText ||| gence guarantee of the Gibbs sampler (Hastings,
bodyText ||| 1970). To compute the terms P(T*IT—Z,A—Z)
bodyText ||| and P(T IT—Z, A—Z) in the acceptance ratio above,
bodyText ||| we need to marginalize over all possible align-
bodyText ||| ments between tree pairs.
bodyText ||| Fortunately, for any given pair of trees T1 and
bodyText ||| T2 this marginalization can be computed using
bodyText ||| a dynamic program in time O (I T1 I I T2 I) . Here
bodyText ||| we provide a very brief sketch. For every pair
bodyText ||| of nodes n1 E T1, n2 E T2, a table stores the
bodyText ||| marginal probability of the subtrees rooted at n1
bodyText ||| and n2, respectively. A dynamic program builds
bodyText ||| this table from the bottom up: For each node pair
bodyText ||| n1, n2, we sum the probabilities of all local align-
bodyText ||| ment configurations, each multiplied by the appro-
page ||| 77
bodyText ||| priate marginals already computed in the table for
bodyText ||| lower-level node pairs. This algorithm is an adap-
bodyText ||| tation of the dynamic program presented in (Jiang
bodyText ||| et al., 1995) for finding minimum cost alignment
bodyText ||| trees (Fig. 5 of that publication).
bodyText ||| Once a pair of trees (T1, T2) has been sam-
bodyText ||| pled, we can proceed to sample an alignment tree
bodyText ||| AIT1, T2.2 We sample individual alignment deci-
bodyText ||| sions from the top down, at each step using the
bodyText ||| alignment marginals for the remaining subtrees
bodyText ||| (already computed using the afore-mentioned dy-
bodyText ||| namic program). Once the triple (T1, T2, A) has
bodyText ||| been sampled, we move on to the next parallel sen-
bodyText ||| tence.
bodyText ||| We avoid directly sampling parameter val-
bodyText ||| ues, instead using the marginalized closed forms
bodyText ||| for multinomials with Dirichlet conjugate-priors
bodyText ||| using counts and hyperparameter pseudo-counts
bodyText ||| (Gelman et al., 2004). Note that in the case of
bodyText ||| yield pairs produced according to Distribution 1
bodyText ||| (in step 4 of the generative process) conjugacy is
bodyText ||| technically broken, since the yield pairs are no
bodyText ||| longer produced by a single multinomial distribu-
bodyText ||| tion. Nevertheless, we count the produced yields
bodyText ||| as if they had been generated separately by each
bodyText ||| of the distributions involved in the numerator of
bodyText ||| Distribution 1.
sectionHeader ||| 4 Experimental setup
bodyText ||| We test our model on three corpora of bilin-
bodyText ||| gual parallel sentences: English-Korean, English-
bodyText ||| Urdu, and English-Chinese. Though the model is
bodyText ||| trained using parallel data, during testing it has ac-
bodyText ||| cess only to monolingual data. This set-up ensures
bodyText ||| that we are testing our model’s ability to learn bet-
bodyText ||| ter parameters at training time, rather than its abil-
bodyText ||| ity to exploit parallel data at test time. Following
bodyText ||| (Klein and Manning, 2002), we restrict our model
bodyText ||| to binary trees, though we note that the alignment
bodyText ||| trees do not follow this restriction.
bodyText ||| Data The Penn Korean Treebank (Han et al.,
bodyText ||| 2002) consists of 5,083 Korean sentences trans-
bodyText ||| lated into English for the purposes of language
bodyText ||| training in a military setting. Both the Korean
bodyText ||| and English sentences are annotated with syntactic
bodyText ||| trees. We use the first 4,000 sentences for training
bodyText ||| and the last 1,083 sentences for testing. We note
bodyText ||| that in the Korean data, a separate tag is given for
footnote ||| 2Sampling the alignment tree is important, as it provides
footnote ||| us with counts of aligned constituents for the coupling pa-
footnote ||| rameter.
bodyText ||| each morpheme. We simply concatenate all the
bodyText ||| morpheme tags given for each word and treat the
bodyText ||| concatenation as a single tag. This procedure re-
bodyText ||| sults in 199 different tags. The English-Urdu par-
bodyText ||| allel corpus3 consists of 4,325 sentences from the
bodyText ||| first three sections of the Penn Treebank and their
bodyText ||| Urdu translations annotated at the part-of-speech
bodyText ||| level. The Urdu side of this corpus does not pro-
bodyText ||| vide tree annotations so here we can test parse ac-
bodyText ||| curacy only on English. We use the remaining
bodyText ||| sections of the Penn Treebank for English test-
bodyText ||| ing. The English-Chinese treebank (Bies et al.,
bodyText ||| 2007) consists of 3,850 Chinese newswire sen-
bodyText ||| tences translated into English. Both the English
bodyText ||| and Chinese sentences are annotated with parse
bodyText ||| trees. We use the first 4/5 for training and the final
bodyText ||| 1/5 for testing.
bodyText ||| During preprocessing of the corpora we remove
bodyText ||| all punctuation marks and special symbols, fol-
bodyText ||| lowing the setup in previous grammar induction
bodyText ||| work (Klein and Manning, 2002). To obtain lex-
bodyText ||| ical alignments between the parallel sentences we
bodyText ||| employ GIZA++ (Och and Ney, 2003). We use in-
bodyText ||| tersection alignments, which are one-to-one align-
bodyText ||| ments produced by taking the intersection of one-
bodyText ||| to-many alignments in each direction. These one-
bodyText ||| to-one intersection alignments tend to have higher
bodyText ||| precision.
bodyText ||| We initialize the trees by making uniform split
bodyText ||| decisions recursively from the top down for sen-
bodyText ||| tences in both languages. Then for each pair of
bodyText ||| parallel sentences we randomly sample an initial
bodyText ||| alignment tree for the two sampled trees.
bodyText ||| Baseline We implement a Bayesian version of
bodyText ||| the CCM as a baseline. This model uses the same
bodyText ||| inference procedure as our bilingual model (Gibbs
bodyText ||| sampling). In fact, our model reduces to this
bodyText ||| Bayesian CCM when it is assumed that no nodes
bodyText ||| between the two parallel trees are ever aligned
bodyText ||| and when word-level alignments are ignored. We
bodyText ||| also reimplemented the original EM version of
bodyText ||| CCM and found virtually no difference in perfor-
bodyText ||| mance when using EM or Gibbs sampling. In both
bodyText ||| cases our implementation achieves F-measure in
bodyText ||| the range of 69-70% on WSJ10, broadly in line
bodyText ||| with the performance reported by Klein and Man-
bodyText ||| ning (2002).
bodyText ||| Hyperparameters Klein (2005) reports using
bodyText ||| smoothing pseudo-counts of 2 for constituent
footnote ||| 3 http://www.crulp.org
page ||| 78
figureCaption ||| Figure 2: The F-measure of the CCM baseline (dotted line) and bilingual model (solid line) plotted on
figureCaption ||| the y-axis, as the maximum sentence length in the test set is increased (x-axis). Results are averaged over
figureCaption ||| all training scenarios given in Table 1.
bodyText ||| yields and contexts and 8 for distituent yields and
bodyText ||| contexts. In our Bayesian model, these similar
bodyText ||| smoothing counts occur as the parameters of the
bodyText ||| Dirichlet priors. For Korean we found that the
bodyText ||| baseline performed well using these values. How-
bodyText ||| ever, on our English and Chinese data, we found
bodyText ||| that somewhat higher smoothing values worked
bodyText ||| best, so we utilized values of 20 and 80 for con-
bodyText ||| stituent and distituent smoothing counts, respec-
bodyText ||| tively.
bodyText ||| Our model additionally requires hyperparam-
bodyText ||| eter values for w (the coupling distribution for
bodyText ||| aligned yields), Gzpair and Gznode (the distribu-
bodyText ||| tions over Giza-scores for aligned nodes and un-
bodyText ||| aligned nodes, respectively). For w we used a
bodyText ||| symmetric Dirichlet prior with parameter 1. For
bodyText ||| Gzpair and Gznode, in order to create a strong bias
bodyText ||| towards high Giza-scores, we used non-symmetric
bodyText ||| Dirichlet priors. In both cases, we capped the ab-
bodyText ||| solute value of the scores at 3, to prevent count
bodyText ||| sparsity. In the case of Gzpair we gave pseudo-
bodyText ||| counts of 1,000 for negative values and zero, and
bodyText ||| pseudo-counts of 1,000,000 for positive scores.
bodyText ||| For Gznode we gave a pseudo-count of 1,000,000
bodyText ||| for a score of zero, and 1,000 for all nega-
bodyText ||| tive scores. This very strong prior bias encodes
bodyText ||| our intuition that syntactic alignments which re-
bodyText ||| spect lexical alignments should be preferred. Our
bodyText ||| method is not sensitive to these exact values and
bodyText ||| any reasonably strong bias gave similar results.
bodyText ||| In all our experiments, we consider the hyper-
bodyText ||| parameters fixed and observed values.
bodyText ||| Testing and evaluation As mentioned above,
bodyText ||| we test our model only on monolingual data,
bodyText ||| where the parallel sentences are not provided to
bodyText ||| the model. To predict the bracketings of these
bodyText ||| monolingual test sentences, we take the smoothed
bodyText ||| counts accumulated in the final round of sampling
bodyText ||| over the training data and perform a maximum
bodyText ||| likelihood estimate of the monolingual CCM pa-
bodyText ||| rameters. These parameters are then used to pro-
bodyText ||| duce the highest probability bracketing of the test
bodyText ||| set.
bodyText ||| To evaluate both our model as well as the base-
bodyText ||| line, we use (unlabeled) bracket precision, re-
bodyText ||| call, and F-measure (Klein and Manning, 2002).
bodyText ||| Following previous work, we include the whole-
bodyText ||| sentence brackets but ignore single-word brack-
bodyText ||| ets. We perform experiments on different subsets
bodyText ||| of training and testing data based on the sentence-
bodyText ||| length. In particular we experimented with sen-
bodyText ||| tence length limits of 10, 20, and 30 for both the
bodyText ||| training and testing sets. We also report the upper
bodyText ||| bound on F-measure for binary trees. We average
bodyText ||| the results over 10 separate sampling runs.
sectionHeader ||| 5 Results
bodyText ||| Table 1 reports the full results of our experiments.
bodyText ||| In all testing scenarios the bilingual model out-
bodyText ||| performs its monolingual counterpart in terms of
bodyText ||| both precision and recall. On average, the bilin-
bodyText ||| gual model gains 10.2 percentage points in preci-
bodyText ||| sion, 7.7 in recall, and 8.8 in F-measure. The gap
bodyText ||| between monolingual performance and the binary
bodyText ||| tree upper bound is reduced by over 19%.
bodyText ||| The extent of the gain varies across pairings.
bodyText ||| For instance, the smallest improvement is ob-
bodyText ||| served for English when trained with Urdu. The
bodyText ||| Korean-English pairing results in substantial im-
bodyText ||| provements for Korean and quite large improve-
bodyText ||| ments for English, for which the absolute gain
bodyText ||| reaches 28 points in F-measure. In the case of Chi-
bodyText ||| nese and English, the gains for English are fairly
bodyText ||| minimal whereas those for Chinese are quite sub-
page ||| 79
table ||| 	Max Sent. Length		Monolingual			Bilingual			Upper Bound
table ||| 	Test	Train	Precision	Recall	F1	Precision	Recall	F1	F1
table ||| 		10	52.74	39.53	45.19	57.76	43.30	49.50	85.6
table ||| 	10	20	41.87	31.38	35.87	61.66	46.22	52.83	85.6
table ||| 		30	33.43	25.06	28.65	64.41	48.28	55.19	85.6
table ||| 	20	20	35.12	25.12	29.29	56.96	40.74	47.50	83.3
table ||| 		30	26.26	18.78	21.90	60.07	42.96	50.09	83.3
table ||| 	30	30	23.95	16.81	19.76	58.01	40.73	47.86	82.4
table ||| 		10	71.07	62.55	66.54	75.63	66.56	70.81	93.6
table ||| 	10	20	71.35	62.79	66.80	77.61	68.30	72.66	93.6
table ||| 		30	71.37	62.81	66.82	77.87	68.53	72.91	93.6
table ||| 	20	20	64.28	54.73	59.12	70.44	59.98	64.79	91.9
table ||| 		30	64.29	54.75	59.14	70.81	60.30	65.13	91.9
table ||| 	30	30	63.63	54.17	58.52	70.11	59.70	64.49	91.9
table ||| 		10	50.09	34.18	40.63	37.46	25.56	30.39	81.0
table ||| 	10	20	58.86	40.17	47.75	50.24	34.29	40.76	81.0
table ||| 		30	64.81	44.22	52.57	68.24	46.57	55.36	81.0
table ||| 	20	20	41.90	30.52	35.31	38.64	28.15	32.57	84.3
table ||| 		30	52.83	38.49	44.53	58.50	42.62	49.31	84.3
table ||| 	30	30	46.35	33.67	39.00	51.40	37.33	43.25	84.1
table ||| 		10	39.87	27.71	32.69	40.62	28.23	33.31	81.9
table ||| 	10	20	43.44	30.19	35.62	47.54	33.03	38.98	81.9
table ||| 		30	43.63	30.32	35.77	54.09	37.59	44.36	81.9
table ||| 	20	20	29.80	23.46	26.25	36.93	29.07	32.53	88.0
table ||| 		30	30.05	23.65	26.47	43.99	34.63	38.75	88.0
table ||| 	30	30	24.46	19.41	21.64	39.61	31.43	35.05	88.4
table ||| 		10	57.98	45.68	51.10	73.43	57.85	64.71	88.1
table ||| 	10	20	70.57	55.60	62.20	80.24	63.22	70.72	88.1
table ||| 		30	75.39	59.40	66.45	79.04	62.28	69.67	88.1
table ||| 	20	20	57.78	43.86	49.87	67.26	51.06	58.05	86.3
table ||| 		30	63.12	47.91	54.47	64.45	48.92	55.62	86.3
table ||| 	30	30	57.36	43.02	49.17	57.97	43.48	49.69	85.7
tableCaption ||| Table 1: Unlabeled precision, recall and F-measure for the monolingual baseline and the bilingual model
tableCaption ||| on several test sets. We report results for different combinations of maximum sentence length in both the
tableCaption ||| training and test sets. The right most column, in all cases, contains the maximum F-measure achievable
tableCaption ||| using binary trees. The best performance for each test-length is highlighted in bold.
bodyText ||| stantial. This asymmetry should not be surprising,
bodyText ||| as Chinese on its own seems to be quite a bit more
bodyText ||| difficult to parse than English.
bodyText ||| We also investigated the impact of sentence
bodyText ||| length for both the training and testing sets. For
bodyText ||| our model, adding sentences of greater length to
bodyText ||| the training set leads to increases in parse accu-
bodyText ||| racy for short sentences. For the baseline, how-
bodyText ||| ever, adding this additional training data degrades
bodyText ||| performance in the case of English paired with Ko-
bodyText ||| rean. Figure 2 summarizes the performance of
bodyText ||| our model for different sentence lengths on sev-
bodyText ||| eral of the test-sets. As shown in the figure, the
bodyText ||| largest improvements tend to occur at longer sen-
bodyText ||| tence lengths.
sectionHeader ||| 6 Conclusion
bodyText ||| We have presented a probabilistic model for bilin-
bodyText ||| gual grammar induction which uses raw parallel
bodyText ||| text to learn tree pairs and their alignments. Our
bodyText ||| formalism loosely binds the two trees, using bilin-
bodyText ||| gual patterns when possible, but allowing substan-
bodyText ||| tial language-specific variation. We tested our
bodyText ||| model on three test sets and showed substantial
bodyText ||| improvement over a state-of-the-art monolingual
bodyText ||| baseline.4
footnote ||| 4The authors acknowledge the support of the NSF (CA-
footnote ||| REER grant IIS-0448168, grant IIS-0835445, and grant IIS-
footnote ||| 0835652). Thanks to Amir Globerson and members of the
footnote ||| MIT NLP group for their helpful suggestions. Any opinions,
footnote ||| findings, or conclusions are those of the authors, and do not
footnote ||| necessarily reflect the views of the funding organizations
page ||| 80
sectionHeader ||| References
reference ||| Ann Bies, Martha Palmer, Justin Mott, and Colin
reference ||| Warner. 2007. English Chinese translation treebank
reference ||| v 1.0. LDC2007T02.
reference ||| Phil Blunsom, Trevor Cohn, and Miles Osborne. 2008.
reference ||| Bayesian synchronous grammar induction. In Pro-
reference ||| ceedings of NIPS.
reference ||| David Burkett and Dan Klein. 2008. Two languages
reference ||| are better than one (for syntactic parsing). In Pro-
reference ||| ceedings of EMNLP, pages 877–886.
reference ||| Eugene Charniak and Glen Carroll. 1992. Two exper-
reference ||| iments on learning probabilistic dependency gram-
reference ||| mars from corpora. In Proceedings of the AAAI
reference ||| Workshop on Statistically-Based NLP Techniques,
reference ||| pages 1–13.
reference ||| David Chiang. 2005. A hierarchical phrase-based
reference ||| model for statistical machine translation. In Pro-
reference ||| ceedings of the ACL, pages 263–270.
reference ||| Shay B. Cohen and Noah A. Smith. 2009. Shared lo-
reference ||| gistic normal distributions for soft parameter tying
reference ||| in unsupervised grammar induction. In Proceedings
reference ||| of the NAACL/HLT.
reference ||| Jason Eisner. 2003. Learning non-isomorphic tree
reference ||| mappings for machine translation. In The Compan-
reference ||| ion Volume to the Proceedings of the ACL, pages
reference ||| 205–208.
reference ||| Andrew Gelman, John B. Carlin, Hal S. Stern, and
reference ||| Donald B. Rubin. 2004. Bayesian data analysis.
reference ||| Chapman and Hall/CRC.
reference ||| Dmitriy Genzel. 2005. Inducing a multilingual dictio-
reference ||| nary from a parallel multitext in related languages.
reference ||| In Proceedings of EMNLP/HLT, pages 875–882.
reference ||| C. Han, N.R. Han, E.S. Ko, H. Yi, and M. Palmer.
reference ||| 2002. Penn Korean Treebank: Development and
reference ||| evaluation. In Proc. Pacific Asian Conf. Language
reference ||| and Comp.
reference ||| W. K. Hastings. 1970. Monte carlo sampling meth-
reference ||| ods using Markov chains and their applications.
reference ||| Biometrika, 57:97–109.
reference ||| R. Hwa, P. Resnik, A. Weinberg, C. Cabezas, and
reference ||| O. Kolak. 2005. Bootstrapping parsers via syntactic
reference ||| projection across parallel texts. Journal of Natural
reference ||| Language Engineering, 11(3):311–325.
reference ||| T. Jiang, L. Wang, and K. Zhang. 1995. Alignment of
reference ||| trees – an alternative to tree edit. Theoretical Com-
reference ||| puter Science, 143(1):137–148.
reference ||| M. Johnson, T. Griffiths, and S. Goldwater. 2007.
reference ||| Bayesian inference for PCFGs via Markov chain
reference ||| Monte Carlo. In Proceedings of the NAACL/HLT,
reference ||| pages 139–146.
reference ||| Dan Klein and Christopher D. Manning. 2002. A
reference ||| generative constituent-context model for improved
reference ||| grammar induction. In Proceedings of the ACL,
reference ||| pages 128–135.
reference ||| D. Klein. 2005. The Unsupervised Learning of Natu-
reference ||| ral Language Structure. Ph.D. thesis, Stanford Uni-
reference ||| versity.
reference ||| Jonas Kuhn. 2004. Experiments in parallel-text based
reference ||| grammar induction. In Proceedings of the ACL,
reference ||| pages 470–477.
reference ||| I. Dan Melamed. 2003. Multitext grammars
reference ||| and synchronous parsers. In Proceedings of the
reference ||| NAACL/HLT, pages 79–86.
reference ||| Franz Josef Och and Hermann Ney. 2003. A sys-
reference ||| tematic comparison of various statistical alignment
reference ||| models. Computational Linguistics, 29(1):19–51.
reference ||| Yoav Seginer. 2007. Fast unsupervised incremental
reference ||| parsing. In Proceedings of the ACL, pages 384–391.
reference ||| David A. Smith and Noah A. Smith. 2004. Bilingual
reference ||| parsing with factored estimation: Using English to
reference ||| parse Korean. In Proceeding of EMNLP, pages 49–
reference ||| 56.
reference ||| Benjamin Snyder and Regina Barzilay. 2008. Un-
reference ||| supervised multilingual learning for morphological
reference ||| segmentation. In Proceedings of the ACL/HLT,
reference ||| pages 737–745.
reference ||| Benjamin Snyder, Tahira Naseem, Jacob Eisenstein,
reference ||| and Regina Barzilay. 2008. Unsupervised multi-
reference ||| lingual learning for POS tagging. In Proceedings of
reference ||| EMNLP, pages 1041–1050.
reference ||| Benjamin Snyder, Tahira Naseem, Jacob Eisenstein,
reference ||| and Regina Barzilay. 2009. Adding more languages
reference ||| improves unsupervised multilingual part-of-speech
reference ||| tagging: A Bayesian non-parametric approach. In
reference ||| Proceedings of the NAACL/HLT.
reference ||| Andreas Stolcke and Stephen M. Omohundro. 1994.
reference ||| Inducing probabilistic grammars by Bayesian model
reference ||| merging. In Proceedings of ICGI, pages 106–118.
reference ||| Dekai Wu and Hongsing Wong. 1998. Machine
reference ||| translation with a stochastic grammatical channel.
reference ||| In Proceedings of the ACL/COLING, pages 1408–
reference ||| 1415.
reference ||| Dekai Wu. 1997. Stochastic inversion transduction
reference ||| grammars and bilingual parsing of parallel corpora.
reference ||| Computational Linguistics, 23(3):377–403.
reference ||| Chenhai Xi and Rebecca Hwa. 2005. A backoff
reference ||| model for bootstrapping resources for non-english
reference ||| languages. In Proceedings of EMNLP, pages 851 –
reference ||| 858.
reference ||| Hao Zhang and Daniel Gildea. 2005. Stochastic lex-
reference ||| icalized inversion transduction grammar for align-
reference ||| ment. In Proceedings of the ACL, pages 475–482.
page ||| 81

title ||| Reinforcement Learning for Mapping Instructions to Actions
author ||| S.R.K. Branavan, Harr Chen, Luke S. Zettlemoyer, Regina Barzilay
affiliation ||| Computer Science and Artificial Intelligence Laboratory
affiliation ||| Massachusetts Institute of Technology
email ||| {branavan, harr, lsz, regina}@csail.mit.edu
sectionHeader ||| Abstract
bodyText ||| In this paper, we present a reinforce-
bodyText ||| ment learning approach for mapping nat-
bodyText ||| ural language instructions to sequences of
bodyText ||| executable actions. We assume access to
bodyText ||| a reward function that defines the qual-
bodyText ||| ity of the executed actions. During train-
bodyText ||| ing, the learner repeatedly constructs ac-
bodyText ||| tion sequences for a set of documents, ex-
bodyText ||| ecutes those actions, and observes the re-
bodyText ||| sulting reward. We use a policy gradient
bodyText ||| algorithm to estimate the parameters of a
bodyText ||| log-linear model for action selection. We
bodyText ||| apply our method to interpret instructions
bodyText ||| in two domains — Windows troubleshoot-
bodyText ||| ing guides and game tutorials. Our results
bodyText ||| demonstrate that this method can rival su-
bodyText ||| pervised learning techniques while requir-
bodyText ||| ing few or no annotated training exam-
bodyText ||| ples.1
sectionHeader ||| 1 Introduction
bodyText ||| The problem of interpreting instructions written
bodyText ||| in natural language has been widely studied since
bodyText ||| the early days of artificial intelligence (Winograd,
bodyText ||| 1972; Di Eugenio, 1992). Mapping instructions to
bodyText ||| a sequence of executable actions would enable the
bodyText ||| automation of tasks that currently require human
bodyText ||| participation. Examples include configuring soft-
bodyText ||| ware based on how-to guides and operating simu-
bodyText ||| lators using instruction manuals. In this paper, we
bodyText ||| present a reinforcement learning framework for in-
bodyText ||| ducing mappings from text to actions without the
bodyText ||| need for annotated training examples.
bodyText ||| For concreteness, consider instructions from a
bodyText ||| Windows troubleshooting guide on deleting tem-
bodyText ||| porary folders, shown in Figure 1. We aim to map
footnote ||| 1Code, data, and annotations used in this work are avail-
footnote ||| able at http://groups.csail.mit.edu/rbg/code/rl/
figureCaption ||| Figure 1: A Windows troubleshooting article de-
figureCaption ||| scribing how to remove the “msdownld.tmp” tem-
figureCaption ||| porary folder.
bodyText ||| this text to the corresponding low-level commands
bodyText ||| and parameters. For example, properly interpret-
bodyText ||| ing the third instruction requires clicking on a tab,
bodyText ||| finding the appropriate option in a tree control, and
bodyText ||| clearing its associated checkbox.
bodyText ||| In this and many other applications, the valid-
bodyText ||| ity of a mapping can be verified by executing the
bodyText ||| induced actions in the corresponding environment
bodyText ||| and observing their effects. For instance, in the
bodyText ||| example above we can assess whether the goal
bodyText ||| described in the instructions is achieved, i.e., the
bodyText ||| folder is deleted. The key idea of our approach
bodyText ||| is to leverage the validation process as the main
bodyText ||| source of supervision to guide learning. This form
bodyText ||| of supervision allows us to learn interpretations
bodyText ||| of natural language instructions when standard su-
bodyText ||| pervised techniques are not applicable, due to the
bodyText ||| lack of human-created annotations.
bodyText ||| Reinforcement learning is a natural framework
bodyText ||| for building models using validation from an envi-
bodyText ||| ronment (Sutton and Barto, 1998). We assume that
bodyText ||| supervision is provided in the form of a reward
bodyText ||| function that defines the quality of executed ac-
bodyText ||| tions. During training, the learner repeatedly con-
bodyText ||| structs action sequences for a set of given docu-
bodyText ||| ments, executes those actions, and observes the re-
bodyText ||| sulting reward. The learner’s goal is to estimate a
page ||| 82
note ||| Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 82–90,
note ||| Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP
bodyText ||| policy — a distribution over actions given instruc-
bodyText ||| tion text and environment state — that maximizes
bodyText ||| future expected reward. Our policy is modeled in a
bodyText ||| log-linear fashion, allowing us to incorporate fea-
bodyText ||| tures of both the instruction text and the environ-
bodyText ||| ment. We employ a policy gradient algorithm to
bodyText ||| estimate the parameters of this model.
bodyText ||| We evaluate our method on two distinct applica-
bodyText ||| tions: Windows troubleshooting guides and puz-
bodyText ||| zle game tutorials. The key findings of our ex-
bodyText ||| periments are twofold. First, models trained only
bodyText ||| with simple reward signals achieve surprisingly
bodyText ||| high results, coming within 11% of a fully su-
bodyText ||| pervised method in the Windows domain. Sec-
bodyText ||| ond, augmenting unlabeled documents with even
bodyText ||| a small fraction of annotated examples greatly re-
bodyText ||| duces this performance gap, to within 4% in that
bodyText ||| domain. These results indicate the power of learn-
bodyText ||| ing from this new form of automated supervision.
sectionHeader ||| 2 Related Work
bodyText ||| Grounded Language Acquisition Our work
bodyText ||| fits into a broader class of approaches that aim to
bodyText ||| learn language from a situated context (Mooney,
bodyText ||| 2008a; Mooney, 2008b; Fleischman and Roy,
bodyText ||| 2005; Yu and Ballard, 2004; Siskind, 2001; Oates,
bodyText ||| 2001). Instances of such approaches include
bodyText ||| work on inferring the meaning of words from
bodyText ||| video data (Roy and Pentland, 2002; Barnard and
bodyText ||| Forsyth, 2001), and interpreting the commentary
bodyText ||| of a simulated soccer game (Chen and Mooney,
bodyText ||| 2008). Most of these approaches assume some
bodyText ||| form of parallel data, and learn perceptual co-
bodyText ||| occurrence patterns. In contrast, our emphasis
bodyText ||| is on learning language by proactively interacting
bodyText ||| with an external environment.
bodyText ||| Reinforcement Learning for Language Pro-
bodyText ||| cessing Reinforcement learning has been previ-
bodyText ||| ously applied to the problem of dialogue manage-
bodyText ||| ment (Scheffler and Young, 2002; Roy et al., 2000;
bodyText ||| Litman et al., 2000; Singh et al., 1999). These
bodyText ||| systems converse with a human user by taking ac-
bodyText ||| tions that emit natural language utterances. The
bodyText ||| reinforcement learning state space encodes infor-
bodyText ||| mation about the goals of the user and what they
bodyText ||| say at each time step. The learning problem is to
bodyText ||| find an optimal policy that maps states to actions,
bodyText ||| through a trial-and-error process of repeated inter-
bodyText ||| action with the user.
bodyText ||| Reinforcement learning is applied very differ-
bodyText ||| ently in dialogue systems compared to our setup.
bodyText ||| In some respects, our task is more easily amenable
bodyText ||| to reinforcement learning. For instance, we are not
bodyText ||| interacting with a human user, so the cost of inter-
bodyText ||| action is lower. However, while the state space can
bodyText ||| be designed to be relatively small in the dialogue
bodyText ||| management task, our state space is determined by
bodyText ||| the underlying environment and is typically quite
bodyText ||| large. We address this complexity by developing
bodyText ||| a policy gradient algorithm that learns efficiently
bodyText ||| while exploring a small subset of the states.
sectionHeader ||| 3 Problem Formulation
bodyText ||| Our task is to learn a mapping between documents
bodyText ||| and the sequence of actions they express. Figure 2
bodyText ||| shows how one example sentence is mapped to
bodyText ||| three actions.
bodyText ||| Mapping Text to Actions As input, we are
bodyText ||| given a document d, comprising a sequence of sen-
bodyText ||| tences (u1, ... , ut), where each ui is a sequence
bodyText ||| of words. Our goal is to map d to a sequence of
bodyText ||| actions a� = (a0, ... , a,1). Actions are predicted
bodyText ||| and executed sequentially.2
bodyText ||| An action a = (c, R, W') encompasses a com-
bodyText ||| mand c, the command’s parameters R, and the
bodyText ||| words W' specifying c and R. Elements of R re
bodyText ||| fer to objects available in the environment state, as
bodyText ||| described below. Some parameters can also refer
bodyText ||| to words in document d. Additionally, to account
bodyText ||| for words that do not describe any actions, c can
bodyText ||| be a null command.
bodyText ||| The Environment The environment state £
bodyText ||| specifies the set of objects available for interac-
bodyText ||| tion, and their properties. In Figure 2, £ is shown
bodyText ||| on the right. The environment state £ changes
bodyText ||| in response to the execution of command c with
bodyText ||| parameters R according to a transition distribu-
bodyText ||| tion p(£'J£, c, R). This distribution is a priori un-
bodyText ||| known to the learner. As we will see in Section 5,
bodyText ||| our approach avoids having to directly estimate
bodyText ||| this distribution.
bodyText ||| State To predict actions sequentially, we need to
bodyText ||| track the state of the document-to-actions map-
bodyText ||| ping over time. A mapping state s is a tuple
bodyText ||| (£, d, j, W), where £ refers to the current environ-
bodyText ||| ment state; j is the index of the sentence currently
bodyText ||| being interpreted in document d; and W contains
bodyText ||| words that were mapped by previous actions for
footnote ||| 2That is, action ai is executed before ai+1 is predicted.
page ||| 83
figureCaption ||| Figure 2: A three-step mapping from an instruction sentence to a sequence of actions in Windows 2000.
figureCaption ||| For each step, the figure shows the words selected by the action, along with the corresponding system
figureCaption ||| command and its parameters. The words of W' are underlined, and the words of W are highlighted in
figureCaption ||| grey.
bodyText ||| the same sentence. The mapping state s is ob-
bodyText ||| served after each action.
bodyText ||| The initial mapping state s0 for document d is
bodyText ||| (£d, d, 0, 0); £d is the unique starting environment
bodyText ||| state for d. Performing action a in state s =
bodyText ||| (£, d, j, W) leads to a new state s' according to
bodyText ||| distribution p(s'Is, a), defined as follows: £ tran-
bodyText ||| sitions according to p(£'I£, c, R), W is updated
bodyText ||| with a’s selected words, and j is incremented if
bodyText ||| all words of the sentence have been mapped. For
bodyText ||| the applications we consider in this work, environ-
bodyText ||| ment state transitions, and consequently mapping
bodyText ||| state transitions, are deterministic.
bodyText ||| Training During training, we are provided with
bodyText ||| a set D of documents, the ability to sample from
bodyText ||| the transition distribution, and a reward function
bodyText ||| r(h). Here, h = (s0, a0, ... , sn—1, an—1, sn) is
bodyText ||| a history of states and actions visited while in-
bodyText ||| terpreting one document. r(h) outputs a real-
bodyText ||| valued score that correlates with correct action
bodyText ||| selection.3 We consider both immediate reward,
bodyText ||| which is available after each action, and delayed
bodyText ||| reward, which does not provide feedback until the
bodyText ||| last action. For example, task completion is a de-
bodyText ||| layed reward that produces a positive value after
bodyText ||| the final action only if the task was completed suc-
bodyText ||| cessfully. We will also demonstrate how manu-
bodyText ||| ally annotated action sequences can be incorpo-
bodyText ||| rated into the reward.
footnote ||| 3In most reinforcement learning problems, the reward
footnote ||| function is defined over state-action pairs, as r(s, a) — in this
footnote ||| case, r(h) _ Et r(st, at), and our formulation becomes a
footnote ||| standard finite-horizon Markov decision process. Policy gra-
footnote ||| dient approaches allow us to learn using the more general
footnote ||| case of history-based reward.
bodyText ||| The goal of training is to estimate parameters 0
bodyText ||| of the action selection distribution p(aI s, 0), called
bodyText ||| the policy. Since the reward correlates with ac-
bodyText ||| tion sequence correctness, the 0 that maximizes
bodyText ||| expected reward will yield the best actions.
sectionHeader ||| 4 A Log-Linear Model for Actions
bodyText ||| Our goal is to predict a sequence of actions. We
bodyText ||| construct this sequence by repeatedly choosing an
bodyText ||| action given the current mapping state, and apply-
bodyText ||| ing that action to advance to a new state.
bodyText ||| Given a state s = (£, d, j, W), the space of pos-
bodyText ||| sible next actions is defined by enumerating sub-
bodyText ||| spans of unused words in the current sentence (i.e.,
bodyText ||| subspans of the jth sentence of d not in W), and
bodyText ||| the possible commands and parameters in envi-
bodyText ||| ronment state £ .4 We model the policy distribu-
bodyText ||| tion p(aIs; 0) over this action space in a log-linear
bodyText ||| fashion (Della Pietra et al., 1997; Lafferty et al.,
bodyText ||| 2001), giving us the flexibility to incorporate a di-
bodyText ||| verse range of features. Under this representation,
bodyText ||| the policy distribution is:
equation ||| ee-�(s,a)
equation ||| p(aI s; 0) = � ee-0(s,a') ,	(1)
equation ||| a/
bodyText ||| where 0(s, a) E Rn is an n-dimensional feature
bodyText ||| representation. During test, actions are selected
bodyText ||| according to the mode of this distribution.
footnote ||| 4For parameters that refer to words, the space of possible
footnote ||| values is defined by the unused words in the current sentence.
page ||| 84
sectionHeader ||| 5 Reinforcement Learning
bodyText ||| During training, our goal is to find the optimal pol-
bodyText ||| icy p(aIs; 0). Since reward correlates with correct
bodyText ||| action selection, a natural objective is to maximize
bodyText ||| expected future reward — that is, the reward we
bodyText ||| expect while acting according to that policy from
bodyText ||| state s. Formally, we maximize the value function:
equation ||| Vo(s) = Ep(hJo) [r(h)] ,	(2)
bodyText ||| where the history h is the sequence of states and
bodyText ||| actions encountered while interpreting a single
bodyText ||| document d E D. This expectation is averaged
bodyText ||| over all documents in D. The distribution p(hI0)
bodyText ||| returns the probability of seeing history h when
bodyText ||| starting from state s and acting according to a pol-
bodyText ||| icy with parameters 0. This distribution can be de-
bodyText ||| composed into a product over time steps:
bodyText ||| Input: A document set D,
bodyText ||| Feature representation �,
bodyText ||| Reward function r(h),
bodyText ||| Number of iterations T
bodyText ||| Initialization: Set 0 to small random values.
listItem ||| 1 fori=1 ... Tdo
listItem ||| 2	foreach d E D do
listItem ||| 3	Sample history h — p(hl0) where
listItem ||| h = (s0, a0, ... , an-1, sn) as follows:
listItem ||| 3a	fort =0 ... n-1do
listItem ||| 3b	Sample action at — p(alst; 0)
listItem ||| 3c	Execute at on state st: st+1 — p(slst, at)
listItem ||| end
listItem ||| 4	A +- Et (O(st, at) — Ea, 0(st, a')p(a' l st; 0))
listItem ||| 5	0+-0+r(h)A
listItem ||| end
listItem ||| end
listItem ||| Output: Estimate of parameters 0
listItem ||| Algorithm 1: A policy gradient algorithm.
equation ||| p(hI0) = n�1 H p(atIst; 0)p(st+1 Ist, at).	(3)
equation ||| t=0
subsectionHeader ||| 5.1 A Policy Gradient Algorithm
bodyText ||| Our reinforcement learning problem is to find the
bodyText ||| parameters 0 that maximize Vo from equation 2.
bodyText ||| Although there is no closed form solution, policy
bodyText ||| gradient algorithms (Sutton et al., 2000) estimate
bodyText ||| the parameters 0 by performing stochastic gradi-
bodyText ||| ent ascent. The gradient of Vo is approximated by
bodyText ||| interacting with the environment, and the resulting
bodyText ||| reward is used to update the estimate of 0. Policy
bodyText ||| gradient algorithms optimize a non-convex objec-
bodyText ||| tive and are only guaranteed to find a local opti-
bodyText ||| mum. However, as we will see, they scale to large
bodyText ||| state spaces and can perform well in practice.
bodyText ||| To find the parameters 0 that maximize the ob-
bodyText ||| jective, we first compute the derivative of Vo. Ex-
bodyText ||| panding according to the product rule, we have:
equation ||| a0Vo(s) = Ep(hJo) Lr(h)	�0 log p(atI st; 0) ,
equation ||| t
bodyText ||| (4)  where the inner sum is over all time steps t in
bodyText ||| the current history h. Expanding the inner partial
bodyText ||| derivative we observe that:
equation ||| �a0 log p(aIs; 0) = 0(s, a)—	0(s, a')p(a'Is; 0),
equation ||| a/
bodyText ||| (5)  which is the derivative of a log-linear distribution.
bodyText ||| Equation 5 is easy to compute directly. How-
bodyText ||| ever, the complete derivative of Vo in equation 4
bodyText ||| is intractable, because computing the expectation
bodyText ||| would require summing over all possible histo-
bodyText ||| ries. Instead, policy gradient algorithms employ
bodyText ||| stochastic gradient ascent by computing a noisy
bodyText ||| estimate of the expectation using just a subset of
bodyText ||| the histories. Specifically, we draw samples from
bodyText ||| p(hI0) by acting in the target environment, and
bodyText ||| use these samples to approximate the expectation
bodyText ||| in equation 4. In practice, it is often sufficient to
bodyText ||| sample a single history h for this approximation.
bodyText ||| Algorithm 1 details the complete policy gradi-
bodyText ||| ent algorithm. It performs T iterations over the
bodyText ||| set of documents D. Step 3 samples a history that
bodyText ||| maps each document to actions. This is done by
bodyText ||| repeatedly selecting actions according to the cur-
bodyText ||| rent policy, and updating the state by executing the
bodyText ||| selected actions. Steps 4 and 5 compute the empir-
bodyText ||| ical gradient and update the parameters 0.
bodyText ||| In many domains, interacting with the environ-
bodyText ||| ment is expensive. Therefore, we use two tech-
bodyText ||| niques that allow us to take maximum advantage
bodyText ||| of each environment interaction. First, a his-
bodyText ||| tory h = (s0, a0, ... , sn) contains subsequences
bodyText ||| (si, ai,... sn) for i = 1 to n — 1, each with its
bodyText ||| own reward value given by the environment as a
bodyText ||| side effect of executing h. We apply the update
bodyText ||| from equation 5 for each subsequence. Second,
bodyText ||| for a sampled history h, we can propose alterna-
bodyText ||| tive histories h' that result in the same commands
bodyText ||| and parameters with different word spans. We can
bodyText ||| again apply equation 5 for each h', weighted by its
bodyText ||| probability under the current policy, P�h'Jl1 .
page ||| 85
bodyText ||| The algorithm we have presented belongs to
bodyText ||| a family of policy gradient algorithms that have
bodyText ||| been successfully used for complex tasks such as
bodyText ||| robot control (Ng et al., 2003). Our formulation is
bodyText ||| unique in how it represents natural language in the
bodyText ||| reinforcement learning framework.
subsectionHeader ||| 5.2 Reward Functions and ML Estimation
bodyText ||| We can design a range of reward functions to guide
bodyText ||| learning, depending on the availability of anno-
bodyText ||| tated data and environment feedback. Consider the
bodyText ||| case when every training document d E D is an-
bodyText ||| notated with its correct sequence of actions, and
bodyText ||| state transitions are deterministic. Given these ex-
bodyText ||| amples, it is straightforward to construct a reward
bodyText ||| function that connects policy gradient to maxi-
bodyText ||| mum likelihood. Specifically, define a reward
bodyText ||| function r(h) that returns one when h matches the
bodyText ||| annotation for the document being analyzed, and
bodyText ||| zero otherwise. Policy gradient performs stochas-
bodyText ||| tic gradient ascent on the objective from equa-
bodyText ||| tion 2, performing one update per document. For
bodyText ||| document d, this objective becomes:
equation ||| Ep(h�e)[r(h)] = X r(h)p(h� e) = p(hd� e),
equation ||| h
bodyText ||| where hd is the history corresponding to the an-
bodyText ||| notated action sequence. Thus, with this reward
bodyText ||| policy gradient is equivalent to stochastic gradient
bodyText ||| ascent with a maximum likelihood objective.
bodyText ||| At the other extreme, when annotations are
bodyText ||| completely unavailable, learning is still possi-
bodyText ||| ble given informative feedback from the environ-
bodyText ||| ment. Crucially, this feedback only needs to cor-
bodyText ||| relate with action sequence quality. We detail
bodyText ||| environment-based reward functions in the next
bodyText ||| section. As our results will show, reward func-
bodyText ||| tions built using this kind of feedback can provide
bodyText ||| strong guidance for learning. We will also con-
bodyText ||| sider reward functions that combine annotated su-
bodyText ||| pervision with environment feedback.
sectionHeader ||| 6 Applying the Model
bodyText ||| We study two applications of our model: follow-
bodyText ||| ing instructions to perform software tasks, and
bodyText ||| solving a puzzle game using tutorial guides.
subsectionHeader ||| 6.1 Microsoft Windows Help and Support
subsectionHeader ||| On its Help and Support website,5 Microsoft pub-
subsectionHeader ||| lishes a number of articles describing how to per-
footnote ||| 5support.microsoft.com
table ||| Notation
table ||| o Parameter referring to an environment object
table ||| L Set of object class names (e.g. “button”)
table ||| V Vocabulary
table ||| Features on W and object o
table ||| Test if o is visible in s
table ||| Test if o has input focus
table ||| Test if o is in the foreground
table ||| Test if o was previously interacted with
table ||| Test if o came into existence since last action
table ||| Min. edit distance between w E W and object labels in s
table ||| Features on words in W, command c, and object o
table ||| `dc' EC,wEV:test ifc'=cand wEW
table ||| `dc' E C, l E L: test if c' = c and l is the class of o
tableCaption ||| Table 1: Example features in the Windows do-
tableCaption ||| main. All features are binary, except for the nor-
tableCaption ||| malized edit distance which is real-valued.
bodyText ||| form tasks and troubleshoot problems in the Win-
bodyText ||| dows operating systems. Examples of such tasks
bodyText ||| include installing patches and changing security
bodyText ||| settings. Figure 1 shows one such article.
bodyText ||| Our goal is to automatically execute these sup-
bodyText ||| port articles in the Windows 2000 environment.
bodyText ||| Here, the environment state is the set of visi-
bodyText ||| ble user interface (UI) objects, and object prop-
bodyText ||| erties such as label, location, and parent window.
bodyText ||| Possible commands include left-click, right-click,
bodyText ||| double-click, and type-into, all of which take a UI
bodyText ||| object as a parameter; type-into additionally re-
bodyText ||| quires a parameter for the input text.
bodyText ||| Table 1 lists some of the features we use for this
bodyText ||| domain. These features capture various aspects of
bodyText ||| the action under consideration, the current Win-
bodyText ||| dows UI state, and the input instructions. For ex-
bodyText ||| ample, one lexical feature measures the similar-
bodyText ||| ity of a word in the sentence to the UI labels of
bodyText ||| objects in the environment. Environment-specific
bodyText ||| features, such as whether an object is currently in
bodyText ||| focus, are useful when selecting the object to ma-
bodyText ||| nipulate. In total, there are 4,438 features.
bodyText ||| Reward Function Environment feedback can
bodyText ||| be used as a reward function in this domain. An
bodyText ||| obvious reward would be task completion (e.g.,
bodyText ||| whether the stated computer problem was fixed).
bodyText ||| Unfortunately, verifying task completion is a chal-
bodyText ||| lenging system issue in its own right.
bodyText ||| Instead, we rely on a noisy method of check-
bodyText ||| ing whether execution can proceed from one sen-
bodyText ||| tence to the next: at least one word in each sen-
bodyText ||| tence has to correspond to an object in the envi-
page ||| 86
figureCaption ||| Figure 3: Crossblock puzzle with tutorial. For this
figureCaption ||| level, four squares in a row or column must be re-
figureCaption ||| moved at once. The first move specified by the
figureCaption ||| tutorial is greyed in the puzzle.
bodyText ||| ronment.6 For instance, in the sentence from Fig-
bodyText ||| ure 2 the word “Run” matches the Run... menu
bodyText ||| item. If no words in a sentence match a current
bodyText ||| environment object, then one of the previous sen-
bodyText ||| tences was analyzed incorrectly. In this case, we
bodyText ||| assign the history a reward of -1. This reward is
bodyText ||| not guaranteed to penalize all incorrect histories,
bodyText ||| because there may be false positive matches be-
bodyText ||| tween the sentence and the environment. When
bodyText ||| at least one word matches, we assign a positive
bodyText ||| reward that linearly increases with the percentage
bodyText ||| of words assigned to non-null commands, and lin-
bodyText ||| early decreases with the number of output actions.
bodyText ||| This reward signal encourages analyses that inter-
bodyText ||| pret all of the words without producing spurious
bodyText ||| actions.
subsectionHeader ||| 6.2 Crossblock: A Puzzle Game
bodyText ||| Our second application is to a puzzle game called
bodyText ||| Crossblock, available online as a Flash game.7
bodyText ||| Each of 50 puzzles is played on a grid, where some
bodyText ||| grid positions are filled with squares. The object
bodyText ||| of the game is to clear the grid by drawing vertical
bodyText ||| or horizontal line segments that remove groups of
bodyText ||| squares. Each segment must exactly cross a spe-
bodyText ||| cific number of squares, ranging from two to seven
bodyText ||| depending on the puzzle. Humans players have
bodyText ||| found this game challenging and engaging enough
bodyText ||| to warrant posting textual tutorials.8 A sample
bodyText ||| puzzle and tutorial are shown in Figure 3.
bodyText ||| The environment is defined by the state of the
bodyText ||| grid. The only command is clear, which takes a
bodyText ||| parameter specifying the orientation (row or col-
bodyText ||| umn) and grid location of the line segment to be
footnote ||| 6We assume that a word maps to an environment object if
footnote ||| the edit distance between the word and the object’s name is
footnote ||| below a threshold value.
footnote ||| 7hexaditidom.deviantart.com/art/Crossblock-108669149
footnote ||| 8www.jayisgames.com/archives/2009/01/crossblock.php
bodyText ||| removed. The challenge in this domain is to seg-
bodyText ||| ment the text into the phrases describing each ac-
bodyText ||| tion, and then correctly identify the line segments
bodyText ||| from references such as “the bottom four from the
bodyText ||| second column from the left.”
bodyText ||| For this domain, we use two sets of binary fea-
bodyText ||| tures on state-action pairs (s, a). First, for each
bodyText ||| vocabulary word w, we define a feature that is one
bodyText ||| if w is the last word of a’s consumed words W'.
bodyText ||| These features help identify the proper text seg-
bodyText ||| mentation points between actions. Second, we in-
bodyText ||| troduce features for pairs of vocabulary word w
bodyText ||| and attributes of action a, e.g., the line orientation
bodyText ||| and grid locations of the squares that a would re-
bodyText ||| move. This set of features enables us to match
bodyText ||| words (e.g., “row”) with objects in the environ-
bodyText ||| ment (e.g., a move that removes a horizontal series
bodyText ||| of squares). In total, there are 8,094 features.
bodyText ||| Reward Function For Crossblock it is easy to
bodyText ||| directly verify task completion, which we use as
bodyText ||| the basis of our reward function. The reward r(h)
bodyText ||| is -1 if h ends in a state where the puzzle cannot
bodyText ||| be completed. For solved puzzles, the reward is
bodyText ||| a positive value proportional to the percentage of
bodyText ||| words assigned to non-null commands.
sectionHeader ||| 7 Experimental Setup
bodyText ||| Datasets For the Windows domain, our dataset
bodyText ||| consists of 128 documents, divided into 70 for
bodyText ||| training, 18 for development, and 40 for test. In
bodyText ||| the puzzle game domain, we use 50 tutorials,
bodyText ||| divided into 40 for training and 10 for test.9
bodyText ||| Statistics for the datasets are shown below.
table ||| 	Windows	Puzzle
table ||| Total # of documents	128	50
table ||| Total # of words	5562	994
table ||| Vocabulary size	610	46
table ||| Avg. words per sentence	9.93	19.88
table ||| Avg. sentences per document	4.38	1.00
table ||| Avg. actions per document	10.37	5.86
bodyText ||| The data exhibits certain qualities that make
bodyText ||| for a challenging learning problem. For instance,
bodyText ||| there are a surprising variety of linguistic con-
bodyText ||| structs — as Figure 4 shows, in the Windows do-
bodyText ||| main even a simple command is expressed in at
bodyText ||| least six different ways.
footnote ||| 9For Crossblock, because the number of puzzles is lim-
footnote ||| ited, we did not hold out a separate development set, and re-
footnote ||| port averaged results over five training/test splits.
page ||| 87
figureCaption ||| Figure 4: Variations of “click internet options on
figureCaption ||| the tools menu” present in the Windows corpus.
bodyText ||| Experimental Framework To apply our algo-
bodyText ||| rithm to the Windows domain, we use the Win32
bodyText ||| application programming interface to simulate hu-
bodyText ||| man interactions with the user interface, and to
bodyText ||| gather environment state information. The operat-
bodyText ||| ing system environment is hosted within a virtual
bodyText ||| machine,10 allowing us to rapidly save and reset
bodyText ||| system state snapshots. For the puzzle game do-
bodyText ||| main, we replicated the game with an implemen-
bodyText ||| tation that facilitates automatic play.
bodyText ||| As is commonly done in reinforcement learn-
bodyText ||| ing, we use a softmax temperature parameter to
bodyText ||| smooth the policy distribution (Sutton and Barto,
bodyText ||| 1998), set to 0.1 in our experiments. For Windows,
bodyText ||| the development set is used to select the best pa-
bodyText ||| rameters. For Crossblock, we choose the parame-
bodyText ||| ters that produce the highest reward during train-
bodyText ||| ing. During evaluation, we use these parameters
bodyText ||| to predict mappings for the test documents.
bodyText ||| Evaluation Metrics For evaluation, we com-
bodyText ||| pare the results to manually constructed sequences
bodyText ||| of actions. We measure the number of correct ac-
bodyText ||| tions, sentences, and documents. An action is cor-
bodyText ||| rect if it matches the annotations in terms of com-
bodyText ||| mand and parameters. A sentence is correct if all
bodyText ||| of its actions are correctly identified, and analo-
bodyText ||| gously for documents.11 Statistical significance is
bodyText ||| measured with the sign test.
bodyText ||| Additionally, we compute a word alignment
bodyText ||| score to investigate the extent to which the input
bodyText ||| text is used to construct correct analyses. This
bodyText ||| score measures the percentage of words that are
bodyText ||| aligned to the corresponding annotated actions in
bodyText ||| correctly analyzed documents.
bodyText ||| Baselines We consider the following baselines
bodyText ||| to characterize the performance of our approach.
footnote ||| 10VMware Workstation, available at www.vmware.com
footnote ||| 11In these tasks, each action depends on the correct execu-
footnote ||| tion of all previous actions, so a single error can render the
footnote ||| remainder of that document’s mapping incorrect. In addition,
footnote ||| due to variability in document lengths, overall action accu-
footnote ||| racy is not guaranteed to be higher than document accuracy.
listItem ||| •	Full Supervision Sequence prediction prob-
bodyText ||| lems like ours are typically addressed us-
bodyText ||| ing supervised techniques. We measure how
bodyText ||| a standard supervised approach would per-
bodyText ||| form on this task by using a reward signal
bodyText ||| based on manual annotations of output ac-
bodyText ||| tion sequences, as defined in Section 5.2. As
bodyText ||| shown there, policy gradient with this re-
bodyText ||| ward is equivalent to stochastic gradient as-
bodyText ||| cent with a maximum likelihood objective.
listItem ||| •	Partial Supervision We consider the case
bodyText ||| when only a subset of training documents is
bodyText ||| annotated, and environment reward is used
bodyText ||| for the remainder. Our method seamlessly
bodyText ||| combines these two kinds of rewards.
listItem ||| •	Random and Majority (Windows) We con-
bodyText ||| sider two naive baselines. Both scan through
bodyText ||| each sentence from left to right. A com-
bodyText ||| mand c is executed on the object whose name
bodyText ||| is encountered first in the sentence. This
bodyText ||| command c is either selected randomly, or
bodyText ||| set to the majority command, which is left-
bodyText ||| click. This procedure is repeated until no
bodyText ||| more words match environment objects.
listItem ||| •	Random (Puzzle) We consider a baseline
listItem ||| that randomly selects among the actions that
listItem ||| are valid in the current game state.12
sectionHeader ||| 8 Results
bodyText ||| Table 2 presents evaluation results on the test sets.
bodyText ||| There are several indicators of the difficulty of this
bodyText ||| task. The random and majority baselines’ poor
bodyText ||| performance in both domains indicates that naive
bodyText ||| approaches are inadequate for these tasks. The
bodyText ||| performance of the fully supervised approach pro-
bodyText ||| vides further evidence that the task is challenging.
bodyText ||| This difficulty can be attributed in part to the large
bodyText ||| branching factor of possible actions at each step —
bodyText ||| on average, there are 27.14 choices per action in
bodyText ||| the Windows domain, and 9.78 in the Crossblock
bodyText ||| domain.
bodyText ||| In both domains, the learners relying only
bodyText ||| on environment reward perform well. Although
bodyText ||| the fully supervised approach performs the best,
bodyText ||| adding just a few annotated training examples
bodyText ||| to the environment-based learner significantly re-
bodyText ||| duces the performance gap.
footnote ||| 12 Since action selection is among objects, there is no natu-
footnote ||| ral majority baseline for the puzzle.
page ||| 88
table ||| 			Windows					Puzzle
table ||| 	Action		Sent.		Doc.	Word	Action		Doc.		Word
table ||| Random baseline	0.128		0.101		0.000	—–		0.081		0.111	—–
table ||| Majority baseline	0.287		0.197		0.100	—–		—–		—–	—–
table ||| Environment reward	* 0.647	*	0.590	*	0.375	0.819	*	0.428	*	0.453	0.686
table ||| Partial supervision	*0.723	*	0.702		0.475	0.989		0.575	*	0.523	0.850
table ||| Full supervision	*0.756		0.714		0.525	0.991		0.632		0.630	0.869
tableCaption ||| Table 2: Performance on the test set with different reward signals and baselines. Our evaluation measures
tableCaption ||| the proportion of correct actions, sentences, and documents. We also report the percentage of correct
tableCaption ||| word alignments for the successfully completed documents. Note the puzzle domain has only single-
tableCaption ||| sentence documents, so its sentence and document scores are identical. The partial supervision line
tableCaption ||| refers to 20 out of 70 annotated training documents for Windows, and 10 out of 40 for the puzzle. Each
tableCaption ||| result marked with * or o is a statistically significant improvement over the result immediately above it;
tableCaption ||| * indicates p < 0.01 and o indicates p < 0.05.
figureCaption ||| Figure 5: Comparison of two training scenarios where training is done using a subset of annotated
figureCaption ||| documents, with and without environment reward for the remaining unannotated documents.
bodyText ||| Figure 5 shows the overall tradeoff between an-
bodyText ||| notation effort and system performance for the two
bodyText ||| domains. The ability to make this tradeoff is one
bodyText ||| of the advantages of our approach. The figure also
bodyText ||| shows that augmenting annotated documents with
bodyText ||| additional environment-reward documents invari-
bodyText ||| ably improves performance.
bodyText ||| The word alignment results from Table 2 in-
bodyText ||| dicate that the learners are mapping the correct
bodyText ||| words to actions for documents that are success-
bodyText ||| fully completed. For example, the models that per-
bodyText ||| form best in the Windows domain achieve nearly
bodyText ||| perfect word alignment scores.
bodyText ||| To further assess the contribution of the instruc-
bodyText ||| tion text, we train a variant of our model without
bodyText ||| access to text features. This is possible in the game
bodyText ||| domain, where all of the puzzles share a single
bodyText ||| goal state that is independent of the instructions.
bodyText ||| This variant solves 34% of the puzzles, suggest-
bodyText ||| ing that access to the instructions significantly im-
bodyText ||| proves performance.
sectionHeader ||| 9 Conclusions
bodyText ||| In this paper, we presented a reinforcement learn-
bodyText ||| ing approach for inducing a mapping between in-
bodyText ||| structions and actions. This approach is able to use
bodyText ||| environment-based rewards, such as task comple-
bodyText ||| tion, to learn to analyze text. We showed that hav-
bodyText ||| ing access to a suitable reward function can signif-
bodyText ||| icantly reduce the need for annotations.
sectionHeader ||| Acknowledgments
bodyText ||| The authors acknowledge the support of the NSF
bodyText ||| (CAREER grant IIS-0448168, grant IIS-0835445,
bodyText ||| grant IIS-0835652, and a Graduate Research Fel-
bodyText ||| lowship) and the ONR. Thanks to Michael Collins,
bodyText ||| Amir Globerson, Tommi Jaakkola, Leslie Pack
bodyText ||| Kaelbling, Dina Katabi, Martin Rinard, and mem-
bodyText ||| bers of the MIT NLP group for their suggestions
bodyText ||| and comments. Any opinions, findings, conclu-
bodyText ||| sions, or recommendations expressed in this paper
bodyText ||| are those of the authors, and do not necessarily re-
bodyText ||| flect the views of the funding organizations.
page ||| 89
bodyText ||| Jeffrey Mark Siskind. 2001. Grounding the lexical se-
bodyText ||| mantics of verbs in visual perception using force dy-
bodyText ||| namics and event logic. J. Artif. Intell. Res. (JAIR),
bodyText ||| 15:31–90.
sectionHeader ||| References
reference ||| Kobus Barnard and David A. Forsyth. 2001. Learning
reference ||| the semantics of words and pictures. In Proceedings
reference ||| of ICCV.
reference ||| David L. Chen and Raymond J. Mooney. 2008. Learn-
reference ||| ing to sportscast: a test of grounded language acqui-
reference ||| sition. In Proceedings of ICML.
reference ||| Stephen Della Pietra, Vincent J. Della Pietra, and
reference ||| John D. Lafferty. 1997. Inducing features of ran-
reference ||| dom fields. IEEE Trans. Pattern Anal. Mach. Intell.,
reference ||| 19(4):380–393.
reference ||| Barbara Di Eugenio. 1992. Understanding natural lan-
reference ||| guage instructions: the case of purpose clauses. In
reference ||| Proceedings of ACL.
reference ||| Michael Fleischman and Deb Roy. 2005. Intentional
reference ||| context in situated language learning. In Proceed-
reference ||| ings of CoNLL.
reference ||| John Lafferty, Andrew McCallum, and Fernando
reference ||| Pereira. 2001. Conditional random fields: Prob-
reference ||| abilistic models for segmenting and labeling se-
reference ||| quence data. In Proceedings of ICML.
reference ||| Diane J. Litman, Michael S. Kearns, Satinder Singh,
reference ||| and Marilyn A. Walker. 2000. Automatic optimiza-
reference ||| tion of dialogue management. In Proceedings of
reference ||| COLING.
reference ||| Raymond J. Mooney. 2008a. Learning language
reference ||| from its perceptual context. In Proceedings of
reference ||| ECML/PKDD.
reference ||| Raymond J. Mooney. 2008b. Learning to connect lan-
reference ||| guage and perception. In Proceedings ofAAAI.
reference ||| Andrew Y. Ng, H. Jin Kim, Michael I. Jordan, and
reference ||| Shankar Sastry. 2003. Autonomous helicopter flight
reference ||| via reinforcement learning. In Advances in NIPS.
reference ||| James Timothy Oates. 2001. Grounding knowledge
reference ||| in sensors: Unsupervised learning for language and
reference ||| planning. Ph.D. thesis, University of Massachusetts
reference ||| Amherst.
reference ||| Deb K. Roy and Alex P. Pentland. 2002. Learn-
reference ||| ing words from sights and sounds: a computational
reference ||| model. Cognitive Science 26, pages 113–146.
reference ||| Nicholas Roy, Joelle Pineau, and Sebastian Thrun.
reference ||| 2000. Spoken dialogue management using proba-
reference ||| bilistic reasoning. In Proceedings of ACL.
reference ||| Konrad Scheffler and Steve Young. 2002. Automatic
reference ||| learning of dialogue strategy using dialogue simula-
reference ||| tion and reinforcement learning. In Proceedings of
reference ||| HLT.
reference ||| Satinder P. Singh, Michael J. Kearns, Diane J. Litman,
reference ||| and Marilyn A. Walker. 1999. Reinforcement learn-
reference ||| ing for spoken dialogue systems. In Advances in
reference ||| NIPS.
reference ||| Richard S. Sutton and Andrew G. Barto. 1998. Re-
reference ||| inforcement Learning: An Introduction. The MIT
reference ||| Press.
reference ||| Richard S. Sutton, David McAllester, Satinder Singh,
reference ||| and Yishay Mansour. 2000. Policy gradient meth-
reference ||| ods for reinforcement learning with function approx-
reference ||| imation. In Advances in NIPS.
reference ||| Terry Winograd. 1972. Understanding Natural Lan-
reference ||| guage. Academic Press.
reference ||| Chen Yu and Dana H. Ballard. 2004. On the integra-
reference ||| tion of grounding language and learning objects. In
reference ||| Proceedings ofAAAI.
page ||| 90

title ||| 2-Source Dispersers for Sub-Polynomial Entropy and
title ||| Ramsey Graphs Beating the Frankl-Wilson Construction
none ||| ∗
author ||| Boaz Barak
affiliation ||| Department of Computer Science
affiliation ||| Princeton University
email ||| boaz@cs.princeton.edu
author ||| Ronen Shaltiel ‡
affiliation ||| University of Haifa
address ||| Mount Carmel
address ||| Haifa, Israel
email ||| ronen@cs.haifa.ac.il
sectionHeader ||| ABSTRACT
bodyText ||| The main result of this paper is an explicit disperser for two
bodyText ||| independent sources on n bits, each of entropy k = no(1).
bodyText ||| Put differently, setting N = 2n and K = 2k, we construct
bodyText ||| explicit N × N Boolean matrices for which no K × K sub-
bodyText ||| matrix is monochromatic. Viewed as adjacency matrices of
bodyText ||| bipartite graphs, this gives an explicit construction of K-
bodyText ||| Ramsey bipartite graphs of size N.
bodyText ||| This greatly improves the previous bound of k = o(n) of
bodyText ||| Barak, Kindler, Shaltiel, Sudakov and Wigderson [4]. It also
bodyText ||| significantly improves the 25-year record of k = ~O(√n) on
bodyText ||| the special case of Ramsey graphs, due to Frankl and Wilson
bodyText ||| [9].
bodyText ||| The construction uses (besides ”classical” extractor ideas)
bodyText ||| almost all of the machinery developed in the last couple of
bodyText ||| years for extraction from independent sources, including:
bodyText ||| •	Bourgain’s extractor for 2 independent sources of some
bodyText ||| entropy rate < 1/2 [5]
bodyText ||| •	Raz’s extractor for 2 independent sources, one of which
bodyText ||| has any entropy rate > 1/2 [18]
footnote ||| ∗Supported by a Princeton University startup grant.
footnote ||| †Most of this work was done while the author was visiting
footnote ||| Princeton University and the Institute for Advanced Study.
footnote ||| Supported in part by an MCD fellowship from UT Austin
footnote ||| and NSF Grant CCR-0310960.
footnote ||| ‡This research was supported by the United States-Israel
footnote ||| Binational Science Foundation (BSF) grant 2004329.
footnote ||| §This research was supported by NSF Grant CCR-0324906.
copyright ||| Permission to make digital or hard copies of all or part of this work for
copyright ||| personal or classroom use is granted without fee provided that copies are
copyright ||| not made or distributed for profit or commercial advantage and that copies
copyright ||| bear this notice and the full citation on the first page. To copy otherwise, to
copyright ||| republish, to post on servers or to redistribute to lists, requires prior specific
copyright ||| permission and/or a fee.
note ||| STOC’06, May 21–23, 2006, Seattle, Washington, USA.
copyright ||| Copyright 2006 ACM 1-59593-134-1/06/0005 ...$5.00.
author ||| Anup Rao †
affiliation ||| Department of Computer Science
affiliation ||| University of Texas at Austin
email ||| arao@cs.utexas.edu
author ||| Avi Wigderson §
affiliation ||| Institute for Advanced Study
address ||| Princeton
address ||| New Jersey
email ||| avi@math.ias.edu
bodyText ||| •	Rao’s extractor for 2 independent block-sources of en-
bodyText ||| tropy no(1) [17]
bodyText ||| •	The “Challenge-Response” mechanism for detecting
bodyText ||| “entropy concentration” of [4].
bodyText ||| The main novelty comes in a bootstrap procedure which
bodyText ||| allows the Challenge-Response mechanism of [4] to be used
bodyText ||| with sources of less and less entropy, using recursive calls
bodyText ||| to itself. Subtleties arise since the success of this mecha-
bodyText ||| nism depends on restricting the given sources, and so re-
bodyText ||| cursion constantly changes the original sources. These are
bodyText ||| resolved via a new construct, in between a disperser and
bodyText ||| an extractor, which behaves like an extractor on sufficiently
bodyText ||| large subsources of the given ones.
note ||| This version is only an extended abstract, please see the
note ||| full version, available on the authors’ homepages, for more
note ||| details.
sectionHeader ||| Categories and Subject Descriptors
category ||| G.2.2 [Mathematics of Computing]: Discrete Mathe-
category ||| matics—Graph algorithms
sectionHeader ||| General Terms
keyword ||| Theory, Algorithms
sectionHeader ||| Keywords
keyword ||| Dispersers, Ramsey Graphs, Independent Sources, Extrac-
keyword ||| tors
sectionHeader ||| 1. INTRODUCTION
bodyText ||| This paper deals with randomness extraction from weak
bodyText ||| random sources. Here a weak random source is a distribu-
bodyText ||| tion which contains some entropy. The extraction task is to
bodyText ||| design efficient algorithms (called extractors) to convert this
bodyText ||| entropy into useful form, namely a sequence of independent
bodyText ||| unbiased bits. Beyond the obvious motivations (potential
bodyText ||| use of physical sources in pseudorandom generators and in
bodyText ||| derandomization), extractors have found applications in a
page ||| 671
bodyText ||| variety of areas in theoretical computer science where ran-
bodyText ||| domness does not seem an issue, such as in efficient con-
bodyText ||| structions of communication networks [24, 7], error correct-
bodyText ||| ing codes [22, 12], data structures [14] and more.
bodyText ||| Most work in this subject over the last 20 years has fo-
bodyText ||| cused on what is now called seeded extraction, in which the
bodyText ||| extractor is given as input not only the (sample from the)
bodyText ||| defective random source, but also a few truly random bits
bodyText ||| (called the seed). A comprehensive survey of much of this
bodyText ||| body of work is [21].
bodyText ||| Another direction, which has been mostly dormant till
bodyText ||| about two years ago, is (seedless, deterministic) extraction
bodyText ||| from a few independent weak sources. This kind of extrac-
bodyText ||| tion is important in several applications where it is unrealis-
bodyText ||| tic to have a short random seed or deterministically enumer-
bodyText ||| ate over its possible values. However, it is easily shown to be
bodyText ||| impossible when only one weak source is available. When at
bodyText ||| least 2 independent sources are available extraction becomes
bodyText ||| possible in principle. The 2-source case is the one we will
bodyText ||| focus on in this work.
bodyText ||| The rest of the introduction is structured as follows. We’ll
bodyText ||| start by describing our main result in the context of Ramsey
bodyText ||| graphs. We then move to the context of extractors and dis-
bodyText ||| perser, describing the relevant background and stating our
bodyText ||| result in this language. Then we give an overview of the
bodyText ||| construction of our dispersers, describing the main building
bodyText ||| blocks we construct along the way. As the construction is
bodyText ||| quite complex and its analysis quite subtle, in this proceed-
bodyText ||| ings version we try to abstract away many of the technical
bodyText ||| difficulties so that the main ideas, structure and tools used
bodyText ||| are highlighted. For that reason we also often state defini-
bodyText ||| tions and theorems somewhat informally.
subsectionHeader ||| 1.1 Ramsey Graphs
construct ||| DefInItIOn 1.1. A graph on N vertices is called a K-
construct ||| Ramsey Graph if it contains no clique or independent set of
construct ||| size K.
bodyText ||| In 1947 Erd}os published his paper inaugurating the Prob-
bodyText ||| abilistic Method with a few examples, including a proof that
bodyText ||| most graphs on N = 2n vertices are 2n-Ramsey. The quest
bodyText ||| for constructing such graphs explicitly has existed ever since
bodyText ||| and lead to some beautiful mathematics.
bodyText ||| The best record to date was obtained in 1981 by Frankl
bodyText ||| and Wilson [9], who used intersection theorems for set sys-
bodyText ||| tems to construct N-vertex graphs which are 21�n log n-Ramsey.
bodyText ||| This bound was matched by Alon [1] using the Polynomial
bodyText ||| Method, by Grolmusz [11] using low rank matrices over rings,
bodyText ||| and also by Barak [2] boosting Abbot’s method with almost
bodyText ||| k-wise independent random variables (a construction that
bodyText ||| was independently discovered by others as well). Remark-
bodyText ||| ably all of these different approaches got stuck at essentially
bodyText ||| the same bound. In recent work, Gopalan [10] showed that
bodyText ||| other than the last construction, all of these can be viewed
bodyText ||| as coming from low-degree symmetric representations of the
bodyText ||| OR function. He also shows that any such symmetric rep-
bodyText ||| resentation cannot be used to give a better Ramsey graph,
bodyText ||| which gives a good indication of why these constructions
bodyText ||| had similar performance. Indeed, as we will discuss in a
bodyText ||| later section, the √n entropy bound initially looked like a
bodyText ||| natural obstacle even for our techniques, though eventually
bodyText ||| we were able to surpass it.
bodyText ||| The analogous question for bipartite graphs seemed much
bodyText ||| harder.
construct ||| DefInItIOn 1.2. A bipartite graph on two sets of N ver-
construct ||| tices is a K-Ramsey Bipartite Graph if it has no K × K
construct ||| complete or empty bipartite subgraph.
bodyText ||| While Erd}os’ result on the abundance of 2n-Ramsey graphs
bodyText ||| holds as is for bipartite graphs, until recently the best ex-
bodyText ||| plicit construction of bipartite Ramsey graphs was 2n/2-
bodyText ||| Ramsey, using the Hadamard matrix. This was improved
bodyText ||| last year, first to o(2n/2) by Pudlak and R}odl [16] and then
bodyText ||| to 2o(n) by Barak, Kindler, Shaltiel, Sudakov and Wigderson
bodyText ||| [4] .
bodyText ||| It is convenient to view such graphs as functions f :
bodyText ||| ({0, 1}n)2 → {0, 1}. This then gives exactly the definition
bodyText ||| of a disperser.
construct ||| DefInItIOn 1.3. A function f : ({0, 1}n)2 → {0, 1} is
construct ||| called a 2-source disperser for entropy k if for any two sets
construct ||| X, Y ⊂ {0, 1}n with | X | = |Y| = 2k, we have that the image
construct ||| f (X, Y) is {0, 1}.
bodyText ||| This allows for a more formal definition of explicitness: we
bodyText ||| simply demand that the function f is computable in polyno-
bodyText ||| mial time. Most of the constructions mentioned above are
bodyText ||| explicit in this sense.'
bodyText ||| Our main result (stated informally) significantly improves
bodyText ||| the bounds in both the bipartite and non-bipartite settings:
construct ||| TheOrem 1.4. For every N we construct polynomial time
construct ||| computable bipartite graphs which are 2n'(1)-Ramsey. A stan-
construct ||| dard transformation of these graphs also yields polynomial
construct ||| time computable ordinary Ramsey Graphs with the same pa-
construct ||| rameters.
subsectionHeader ||| 1.2 Extractors and Dispersers from indepen-
subsectionHeader ||| dent sources
bodyText ||| Now we give a brief review of past relevant work (with the
bodyText ||| goal of putting this paper in proper context) and describe
bodyText ||| some of the tools from these past works that we will use.
bodyText ||| We start with the basic definitions of k-sources by Nisan
bodyText ||| and Zuckerman [15] and of extractors and dispersers for in-
bodyText ||| dependent sources by Santha and Vazirani [20].
construct ||| DefInItIOn 1.5 ([15], See alSO [8]). The min-entropy
construct ||| of a distribution X is the maximum k such that for every
construct ||| element x in its support, Pr[X = x] ≤ 2-k. If X is a dis-
construct ||| tribution on strings with min-entropy at least k, we will call
construct ||| X a k-source 2.
bodyText ||| To simplify the presentation, in this version of the paper
bodyText ||| we will assume that we are working with entropy as opposed
bodyText ||| to min-entropy.
construct ||| DefInItIOn 1.6 ([20]). A function f : ({0,1}n)c →
construct ||| {0, 1}m is a c-source (k, ǫ) extractor if for every family of c
construct ||| independent k-sources X', • • • , Xc, the output f (X', • • • , Xc)
footnote ||| 'The Abbot’s product based Ramsey-graph construction of
footnote ||| [3] and the bipartite Ramsey construction of [16] only satisfy
footnote ||| a weaker notion of explicitness.
footnote ||| 2It is no loss of generality to imagine that X is uniformly
footnote ||| distributed over some (unknown) set of size 2k.
page ||| 672
bodyText ||| is a ǫ-close 3 to uniformly distributed on m bits. f is a dis-
bodyText ||| perser for the same parameters if the output is simply re-
bodyText ||| quired to have a support of relative size (1 − ǫ).
bodyText ||| To simplify the presentation, in this version of the paper,
bodyText ||| we will assume that ǫ = 0 for all of our constructions.
bodyText ||| In this language, Erd}os’ theorem says that most functions
bodyText ||| f : ({0, 1}n)2 → {0, 1} are dispersers for entropy 1 + logn
bodyText ||| (treating f as the characteristic function for the set of edges
bodyText ||| of the graph). The proof easily extends to show that indeed
bodyText ||| most such functions are in fact extractors. This naturally
bodyText ||| challenges us to find explicit functions f that are 2-source
bodyText ||| extractors.
bodyText ||| Until one year ago, essentially the only known explicit
bodyText ||| construction was the Hadamard extractor Had defined by
bodyText ||| Had(x,y)
bodyText ||| k > n/2 as observed by Chor and Goldreich [8] and can
bodyText ||| be extended to give m = Q(n) output bits as observed by
bodyText ||| Vazirani [23]. Over 20 years later, a recent breakthrough
bodyText ||| of Bourgain [5] broke this “1/2 barrier” and can handle 2
bodyText ||| sources of entropy .4999n, again with linear output length
bodyText ||| m = 0(n). This seemingly minor improvement will be cru-
bodyText ||| cial for our work!
construct ||| TheOrem 1.7 ([5] ). There is a polynomial time com-
construct ||| putable 2-source extractor f : ({0, 1}n)2 → {0, 1}m for en-
construct ||| tropy .4999n and m = 0(n).
bodyText ||| No better bounds are known for 2-source extractors. Now
bodyText ||| we turn our attention to 2-source dispersers. It turned out
bodyText ||| that progress for building good 2-source dispersers came via
bodyText ||| progress on extractors for more than 2 sources, all happening
bodyText ||| in fast pace in the last 2 years. The seminal paper of Bour-
bodyText ||| gain, Katz and Tao [6] proved the so-called ”sum-product
bodyText ||| theorem” in prime fields, a result in arithmetic combina-
bodyText ||| torics. This result has already found applications in diverse
bodyText ||| areas of mathematics, including analysis, number theory,
bodyText ||| group theory and ... extractor theory. Their work implic-
bodyText ||| itly contained dispersers for c = O(log(n/k)) independent
bodyText ||| sources of entropy k (with output m = Q(k)). The use of
bodyText ||| the ”sum-product” theorem was then extended by Barak et
bodyText ||| al. [3] to give extractors with similar parameters. Note that
bodyText ||| for linear entropy k = 0(n), the number of sources needed
bodyText ||| for extraction c is a constant!
bodyText ||| Relaxing the independence assumptions via the idea of
bodyText ||| repeated condensing, allowed the reduction of the number
bodyText ||| of independent sources to c = 3, for extraction from sources
bodyText ||| of any linear entropy k = 0(n), by Barak et al. [4] and
bodyText ||| independently by Raz [18].
bodyText ||| For 2 sources Barak et al. [4] were able to construct dis-
bodyText ||| persers for sources of entropy o(n). To do this, they first
bodyText ||| showed that if the sources have extra structure (block-source
bodyText ||| structure, defined below), even extraction is possible from 2
bodyText ||| sources. The notion of block-sources, capturing ”semi inde-
bodyText ||| pendence” of parts of the source, was introduced by Chor
bodyText ||| and Goldreich [8]. It has been fundamental in the develop-
bodyText ||| ment of seeded extractors and as we shall see, is essential
bodyText ||| for us as well.
construct ||| DefInItIOn 1.8 ([8] ). A distribution X = X1, ... , Xc
construct ||| is a c-block-source of (block) entropy k if every block Xi
construct ||| has entropy k even conditioned on fixing the previous blocks
construct ||| X1, • • • , Xi_1 to arbitrary constants.
footnote ||| 3The error is usually measured in terms of ℓ1 distance or
footnote ||| variation distance.
bodyText ||| This definition allowed Barak et al. [4] to show that their
bodyText ||| extractor for 4 independent sources, actually performs as
bodyText ||| well with only 2 independent sources, as long as both are
bodyText ||| 2-block-sources.
construct ||| TheOrem 1.9 ([4] ). There exists a polynomial time com-
construct ||| putable extractor f : ({0, 1}n)2 → {0, 1} for 2 independent
construct ||| 2-block-sources with entropy o(n).
bodyText ||| There is no reason to assume that the given sources are
bodyText ||| block-sources, but it is natural to try and reduce to this
bodyText ||| case. This approach has been one of the most successful in
bodyText ||| the extractor literature. Namely try to partition a source
bodyText ||| X into two blocks X = X1, X2 such that X1, X2 form a
bodyText ||| 2-block-source. Barak et al. introduced a new technique to
bodyText ||| do this reduction called the Challenge-Response mechanism,
bodyText ||| which is crucial for this paper. This method gives a way to
bodyText ||| “find” how entropy is distributed in a source X, guiding the
bodyText ||| choice of such a partition. This method succeeds only with
bodyText ||| small probability, dashing the hope for an extractor, but still
bodyText ||| yielding a disperser.
construct ||| TheOrem 1.10 ([4] ). There exists a polynomial time
construct ||| computable 2-source disperser f : ({0, 1}n)2 → {0, 1} for
construct ||| entropy o(n).
bodyText ||| Reducing the entropy requirement of the above 2-source
bodyText ||| disperser, which is what we achieve in this paper, again
bodyText ||| needed progress on achieving a similar reduction for extrac-
bodyText ||| tors with more independent sources. A few months ago Rao
bodyText ||| [?] was able to significantly improve all the above results
bodyText ||| for c ≥ 3 sources. Interestingly, his techniques do not use
bodyText ||| arithmetic combinatorics, which seemed essential to all the
bodyText ||| papers above. He improves the results of Barak et al. [3] to
bodyText ||| give c = O((logn)/(logk))-source extractors for entropy k.
bodyText ||| Note that now the number c of sources needed for extraction
bodyText ||| is constant, even when the entropy is as low as nδ for any
bodyText ||| constant δ!
bodyText ||| Again, when the input sources are block-sources with suf-
bodyText ||| ficiently many blocks, Rao proves that 2 independent sources
bodyText ||| suffice (though this result does rely on arithmetic combina-
bodyText ||| torics, in particular, on Bourgain’s extractor).
construct ||| TheOrem 1.11 ([?] ). There is a polynomial time com-
construct ||| putable extractor f : ({0, 1}n)2 → {0, 1}m for 2 independent
construct ||| c-block-sources with block entropy k and m = 0(k), as long
construct ||| as c = O((log n)/(log k)).
bodyText ||| In this paper (see Theorem 2.7 below) we improve this
bodyText ||| result to hold even when only one of the 2 sources is a c-
bodyText ||| block-source. The other source can be an arbitrary source
bodyText ||| with sufficient entropy. This is a central building block in
bodyText ||| our construction. This extractor, like Rao’s above, critically
bodyText ||| uses Bourgain’s extractor mentioned above. In addition it
bodyText ||| uses a theorem of Raz [18] allowing seeded extractors to have
bodyText ||| ”weak” seeds, namely instead of being completely random
bodyText ||| they work as long as the seed has entropy rate > 1/2.
sectionHeader ||| 2. MAIN NOTIONS AND NEW RESULTS
bodyText ||| The main result of this paper is a polynomial time com-
bodyText ||| putable disperser for 2 sources of entropy no(1), significantly
bodyText ||| improving both the results of Barak et al. [4] (o(n) entropy).
bodyText ||| It also improves on Frankl and Wilson [9], who only built
bodyText ||| Ramsey Graphs and only for entropy ~O(√n).
bodyText ||| = (x, y)( mod 2). It is an extractor for entropy
page ||| 673
construct ||| ThEOREm 2.1 (MaIn thEOREm, REStatEd). There ex-
construct ||| ists a polynomial time computable 2-source disperser D :
construct ||| ({0, 1}n)2 → {0, 1} for entropy no(1).
bodyText ||| The construction of this disperser will involve the con-
bodyText ||| struction of an object which in some sense is stronger and
bodyText ||| in another weaker than a disperser: a subsource somewhere
bodyText ||| extractor. We first define a related object: a somewhere ex-
bodyText ||| tractor, which is a function producing several outputs, one of
bodyText ||| which must be uniform. Again we will ignore many technical
bodyText ||| issues such as error, min-entropy vs. entropy and more, in
bodyText ||| definitions and results, which are deferred to the full version
bodyText ||| of this paper.
construct ||| DEfInItIOn 2.2. A function f : ({0, 1}n)2 → ({0,1}m)ℓ
construct ||| is a 2-source somewhere extractor with ℓ outputs, for entropy
construct ||| k, if for every 2 independent k-sources X, Y there exists an
construct ||| i ∈ [ℓ] such the ith output f (X, Y)i is a uniformly distributed
construct ||| string of m bits.
bodyText ||| Here is a simple construction of such a somewhere extrac-
bodyText ||| tor with ℓ as large as poly(n) (and the p in its name will
bodyText ||| stress the fact that indeed the number of outputs is that
bodyText ||| large). It will nevertheless be useful to us (though its de-
bodyText ||| scription in the next sentence may be safely skipped). Define
bodyText ||| pSE(x, y)i = V(E(x, i), E(y, i)) where E is a ”strong” loga-
bodyText ||| rithmic seed extractor, and V is the Hadamard/Vazirani 2-
bodyText ||| source extractor. Using this construction, it is easy to see
bodyText ||| that:
construct ||| PROPOSItIOn 2.3. For every n, k there is a polynomial
construct ||| time computable somewhere extractor pSE : ({0, 1}n)2 →
construct ||| ({0, 1}m)ℓ with ℓ = poly(n) outputs, for entropy k, and m =
construct ||| Q(k).
bodyText ||| Before we define subsource somewhere extractor, we must
bodyText ||| first define a subsource.
construct ||| DEfInItIOn 2.4 (SUBSOURCES). Given random variables
construct ||| Z and Z^ on {0, 1}n we say that Z^ is a deficiency d subsource
construct ||| of Z and write Z^ ⊆ Z if there exists a set A ⊆ {0,1}n such
construct ||| that (Z|Z ∈ A) = Z^ and Pr[Z ∈ A] ≥ 2-d.
bodyText ||| A subsource somewhere extractor guarantees the ”some-
bodyText ||| where extractor” property only on subsources X', Y' of the
bodyText ||| original input distributions X, Y (respectively). It will be
bodyText ||| extremely important for us to make these subsources as large
bodyText ||| as possible (i.e. we have to lose as little entropy as possible).
bodyText ||| Controlling these entropy deficiencies is a major technical
bodyText ||| complication we have to deal with. However we will be in-
bodyText ||| formal with it here, mentioning it only qualitatively when
bodyText ||| needed. We discuss this issue a little more in Section 6.
construct ||| DEfInItIOn 2.5. A function f : ({0, 1}n)2 → ({0,1}m)ℓ
construct ||| is a 2-source subsource somewhere extractor with ℓ outputs
construct ||| for entropy k, if for every 2 independent k-sources X, Y there
construct ||| exists a subsource X^ of X, a subsource Y^ of Y and an i ∈ [ℓ]
construct ||| such the ith output f (^X, Y^)i is a uniformly distributed string
construct ||| of m bits.
bodyText ||| A central technical result for us is that with this ”sub-
bodyText ||| source” relaxation, we can have much fewer outputs – in-
bodyText ||| deed we’ll replace poly(n) outputs in our first construction
bodyText ||| above with no(1) outputs.
construct ||| ThEOREm 2.6 (SUBSOURCE SOmEWhERE ExtRaCtOR).
construct ||| For every δ > 0 there is a polynomial time computable sub-
construct ||| source somewhere extractor SSE : ({0, 1}n)2 → ({0, 1}m)ℓ
construct ||| with ℓ = no(1) outputs, for entropy k = nδ, with output
construct ||| m=√k.
bodyText ||| We will describe the ideas used for constructing this im-
bodyText ||| portant object and analyzing it in the next section, where
bodyText ||| we will also indicate how it is used in the construction of
bodyText ||| the final disperser. Here we state a central building block,
bodyText ||| mentioned in the previous section (as an improvement of the
bodyText ||| work of Rao [?]). We construct an extractor for 2 indepen-
bodyText ||| dent sources one of which is a block-sources with sufficient
bodyText ||| number of blocks.
construct ||| ThEOREm 2.7 (BlOCK SOURCE ExtRaCtOR). There is
construct ||| a polynomial time computable extractor B : ({0, 1}n)2 →
construct ||| {0,1}m for 2 independent sources, one of which is a c-block-
construct ||| sources with block entropy k and the other a source of en-
construct ||| tropy k, with m = 0(k), and c = O((log n)/(log k)).
bodyText ||| A simple corollary of this block-source extractor B, is the
bodyText ||| following weaker (though useful) somewhere block-source
bodyText ||| extractor SB. A source Z = Z1, Z2, • • • , Zt is a somewhere
bodyText ||| c-block-source of block entropy k if for some c indices i1 <
bodyText ||| i2 < • • • < ic the source Zi1, Zi2, • • • , Zic is a c-block-source.
bodyText ||| Collecting the outputs of B on every c-subset of blocks re-
bodyText ||| sults in that somewhere extractor.
construct ||| COROllaRY 2.8. There is a polynomial time computable
construct ||| somewhere extractorSB : ({0, 1}n)2 → ({0, 1}m)ℓ for2 inde-
construct ||| pendent sources, one of which is a somewhere c-block-sources
construct ||| with block entropy k and t blocks total and the other a source
construct ||| of entropy k, with m = 0(k), c = O((log n)/(log k)), and
construct ||| ℓ ≤ tc.
bodyText ||| In both the theorem and corollary above, the values of
bodyText ||| entropy k we will be interested in are k = no(1). It follows
bodyText ||| that a block-source with a constant c = O(1) suffices.
sectionHeader ||| 3. THE CHALLENGE-RESPONSE MECH-
sectionHeader ||| ANISM
bodyText ||| We now describe abstractly a mechanism which will be
bodyText ||| used in the construction of the disperser as well as the sub-
bodyText ||| source somewhere extractor. Intuitively, this mechanism al-
bodyText ||| lows us to identify parts of a source which contain large
bodyText ||| amounts of entropy. One can hope that using such a mech-
bodyText ||| anism one can partition a given source into blocks in a way
bodyText ||| which make it a block-source, or alternatively focus on a part
bodyText ||| of the source which is unusually condensed with entropy -
bodyText ||| two cases which may simplify the extraction problem.
bodyText ||| The reader may decide, now or in the middle of this
bodyText ||| section, to skip ahead to the next section which describes
bodyText ||| the construction of the subsource somewhere extractor SSE,
bodyText ||| which extensively uses this mechanism. Then this section
bodyText ||| may seem less abstract, as it will be clearer where this mech-
bodyText ||| anism is used.
bodyText ||| This mechanism was introduced by Barak et al. [4], and
bodyText ||| was essential in their 2-source disperser. Its use in this paper
bodyText ||| is far more involved (in particular it calls itself recursively,
bodyText ||| a fact which creates many subtleties). However, at a high
bodyText ||| level, the basic idea behind the mechanism is the same:
bodyText ||| Let Z be a source and Z' a part of Z (Z projected on a
bodyText ||| subset of the coordinates). We know that Z has entropy k,
page ||| 674
bodyText ||| and want to distinguish two possibilities: Z′ has no entropy
bodyText ||| (it is fixed) or it has at least k′ entropy. Z′ will get a pass
bodyText ||| or fail grade, hopefully corresponding to the cases of high or
bodyText ||| no entropy in Z′.
bodyText ||| Anticipating the use of this mechanism, it is a good idea
bodyText ||| to think of Z as a ”parent” of Z′, which wants to check if
bodyText ||| this ”child” has sufficient entropy. Moreover, in the context
bodyText ||| of the initial 2 sources X, Y we will operate on, think of Z
bodyText ||| as a part of X, and thus that Y is independent of Z and Z′.
bodyText ||| To execute this ”test” we will compute two sets of strings
bodyText ||| (all of length m, say): the Challenge C = C(Z′,Y) and
bodyText ||| the Response R = R(Z, Y). Z′ fails if C C R and passes
bodyText ||| otherwise.
bodyText ||| The key to the usefulness of this mechanism is the follow-
bodyText ||| ing lemma, which states that what ”should” happen, indeed
bodyText ||| happens after some restriction of the 2 sources Z and Y.
bodyText ||| We state it and then explain how the functions C and R are
bodyText ||| defined to accommodate its proof.
construct ||| Lemma 3.1. Assume Z, Y are sources of entropy k.
listItem ||| 1. If Z′ has entropy k′+O(m), then there are subsources
listItem ||| Z^ of Z and Y^ of Y, such that
listItem ||| Pr[^Z′ passes] = Pr[C(^Z′, Y^) C R(^Z, Y^)] > 1—nO(1)2−m
listItem ||| 2. If Z′ is fixed (namely, has zero entropy), then for some
listItem ||| subsources Z^ of Z and Y^ of Y, we have
listItem ||| Pr[Z′ fails] = Pr[C(^Z′, Y^) C R(^Z, Y^)] = 1
bodyText ||| Once we have such a mechanism, we will design our dis-
bodyText ||| perser algorithm assuming that the challenge response mech-
bodyText ||| anism correctly identifies parts of the source with high or
bodyText ||| low levels of entropy. Then in the analysis, we will ensure
bodyText ||| that our algorithm succeeds in making the right decisions,
bodyText ||| at least on subsources of the original input sources.
bodyText ||| Now let us explain how to compute the sets C and R. We
bodyText ||| will use some of the constructs above with parameters which
bodyText ||| don’t quite fit.
bodyText ||| The response set R(Z, Y) = pSE(Z, Y) is chosen to be the
bodyText ||| output of the somewhere extractor of Proposition 2.3. The
bodyText ||| challenge set C(Z′, Y) = SSE(Z′, Y) is chosen to be the out-
bodyText ||| put of the subsource somewhere extractor of Theorem 2.6.
bodyText ||| Why does it work? We explain each of the two claims
bodyText ||| in the lemma in turn (and after each comment on the im-
bodyText ||| portant parameters and how they differ from Barak et al.
bodyText ||| [4]).
listItem ||| 1. Z′ has entropy. We need to show that Z′ passes the
listItem ||| test with high probability. We will point to the out-
listItem ||| put string in C(^Z′, Y^′) which avoids R(^Z, Y^) with high
listItem ||| probability as follows. In the analysis we will use the
listItem ||| union bound on several events, one associated with
listItem ||| each (poly(n) many) string in pSE(^Z, Y^). We note
listItem ||| that by the definition of the response function, if we
listItem ||| want to fix a particular element in the response set to
listItem ||| a particular value, we can do this by fixing E(Z, i) and
listItem ||| E(Y, i). This fixing keeps the restricted sources inde-
listItem ||| pendent and loses only O(m) entropy. In the subsource
listItem ||| of Z′ guaranteed to exist by Theorem 2.6 we can afford
listItem ||| to lose this entropy in Z′. Thus we conclude that one
listItem ||| of its outputs is uniform. The probability that this
listItem ||| output will equal any fixed value is thus 2−m, com-
listItem ||| pleting the argument. We note that we can handle
listItem ||| the polynomial output size of pSE, since the uniform
listItem ||| string has length m = no(1) (something which could
listItem ||| not be done with the technology available to Barak et
listItem ||| al. [4]).
listItem ||| 2. Z′ has no entropy. We now need to guarantee that
listItem ||| in the chosen subsources (which we choose) ^Z, Y^, all
listItem ||| strings in C = C(^Z′, Y^) are in R(^Z, Y^). First notice
listItem ||| that as Z′ is fixed, C is only a function of Y. We
listItem ||| set Y~ to be the subsource of Y that fixes all strings
listItem ||| in C = C(Y) to their most popular values (losing
listItem ||| only ℓm entropy from Y). We take care of includ-
listItem ||| ing these fixed strings in R(Z, Y~) one at a time, by
listItem ||| restricting to subsources assuring that. Let σ be any
listItem ||| m-bit string we want to appear in R(Z, Y~). Recall that
listItem ||| R(z, y) = V(E(z, i), E(y, i)). We pick a ”good” seed i,
listItem ||| and restrict Z, Y~ to subsources with only O(m) less
listItem ||| entropy by fixing E(Z, i) = a and E(Y~, i) = b to values
listItem ||| (a, b) for which V(a, b) = σ. This is repeated suc-
listItem ||| cessively ℓ times, and results in the final subsources
listItem ||| ^Z, Y^ on which ^Z′ fails with probability 1. Note that
listItem ||| we keep reducing the entropy of our sources ℓ times,
listItem ||| which necessitates that this ℓ be tiny (here we could
listItem ||| not tolerate poly(n), and indeed can guarantee no(1),
listItem ||| at least on a subsource – this is one aspect of how cru-
listItem ||| cial the subsource somewhere extractor SSE is to the
listItem ||| construction.
bodyText ||| We note that initially it seemed like the Challenge-Response
bodyText ||| mechanism as used in [4] could not be used to handle en-
bodyText ||| tropy that is significantly less than -,/n (which is approxi-
bodyText ||| mately the bound that many of the previous constructions
bodyText ||| got stuck at). The techniques of [4] involved partitioning
bodyText ||| the sources into t pieces of length n/t each, with the hope
bodyText ||| that one of those parts would have a significant amount of
bodyText ||| entropy, yet there’d be enough entropy left over in the rest
bodyText ||| of the source (so that the source can be partitioned into a
bodyText ||| block source).
bodyText ||| However it is not clear how to do this when the total
bodyText ||| entropy is less than -,/n. On the one hand we will have
bodyText ||| to partition our sources into blocks of length significantly
bodyText ||| more than -,/n (or the adversary could distribute a negligible
bodyText ||| fraction of entropy in all blocks). On the other hand, if
bodyText ||| our blocks are so large, a single block could contain all the
bodyText ||| entropy. Thus it was not clear how to use the challenge
bodyText ||| response mechanism to find a block source.
sectionHeader ||| 4. THE SUBSOURCE SOMEWHERE
sectionHeader ||| EXTRACTOR SSE
bodyText ||| We now explain some of the ideas behind the construction
bodyText ||| of the subsource somewhere extractor SSE of Theorem 2.6.
bodyText ||| Consider the source X. We are seeking to find in it a some-
bodyText ||| where c-block-source, so that we can use it (together with Y)
bodyText ||| in the block-source extractor of Theorem 2.8. Like in previ-
bodyText ||| ous works in the extractor literature (e.g. [19, 13]) we use a
bodyText ||| ”win-win” analysis which shows that either X is already a
bodyText ||| somewhere c-block-source, or it has a condensed part which
bodyText ||| contains a lot of the entropy of the source. In this case we
bodyText ||| proceed recursively on that part. Continuing this way we
bodyText ||| eventually reach a source so condensed that it must be a
bodyText ||| somewhere block source. Note that in [4], the challenge re-
bodyText ||| sponse mechanism was used to find a block source also, but
bodyText ||| there the entropy was so high that they could afford to use
page ||| 675
figure ||| Not Somewhere block source	n bits total
figure ||| 		t blocks			Outputs
figure ||| < k’
figure ||| Challenge Challenge
figure ||| responded responded
figure ||| X
figure ||| low
figure ||| med
figure ||| high
figure ||| n/t bits total
figure ||| t blocks
figure ||| Challenge Unresponded
figure ||| SB
figure ||| Somewhere Block Source!
figure ||| med
figure ||| med
figure ||| low
figure ||| 0< low < k’/t
figure ||| k’/t < med < k’/c
figure ||| k’/c < high < k’
figure ||| high
figure ||| med
figure ||| Random Row
figure ||| med
figure ||| SB
figureCaption ||| Figure 1: Analysis of the subsource somewhere extractor.
figureCaption ||| a tree of depth 1. They did not need to recurse or condense
figureCaption ||| the sources.
bodyText ||| Consider the tree of parts of the source X evolved by
bodyText ||| such recursion. Each node in the tree corresponds to some
bodyText ||| interval of bit locations of the source, with the root node
bodyText ||| corresponding to the entire source. A node is a child of an-
bodyText ||| other if its interval is a subinterval of the parent. It can be
bodyText ||| shown that some node in the tree is ”good”; it corresponds
bodyText ||| to a somewhere c-source, but we don’t know which node is
bodyText ||| good. Since we only want a somewhere extractor, we can
bodyText ||| apply to each node the somewhere block-source extractor of
bodyText ||| Corollary 2.8 – this will give us a random output in every
bodyText ||| ”good” node of the tree. The usual idea is output all these
bodyText ||| values (and in seeded extractors, merge them using the ex-
bodyText ||| ternally given random seed). However, we cannot afford to
bodyText ||| do that here as there is no external seed and the number of
bodyText ||| these outputs (the size of the tree) is far too large.
bodyText ||| Our aim then will be to significantly prune this number
bodyText ||| of candidates and in fact output only the candidates on one
bodyText ||| path to a canonical”good” node. First we will give a very in-
bodyText ||| formal description of how to do this (Figure 1). Before call-
bodyText ||| ing SSE recursively on a subpart of a current part of X, we’ll
bodyText ||| use the ”Challenge-Response” mechanism described above
bodyText ||| to check if ”it has entropy”.4 We will recurse only with the
bodyText ||| first (in left-to-right order) part which passes the ”entropy
bodyText ||| test”. Thus note that we will follow a single path on this
bodyText ||| tree. The algorithm SSE will output only the sets of strings
bodyText ||| produced by applying the somewhere c-block-extractor SB
bodyText ||| on the parts visited along this path.
bodyText ||| Now let us describe the algorithm for SSE. SSE will be
bodyText ||| initially invoked as SSE(x, y), but will recursively call itself
bodyText ||| with different inputs z which will always be substrings of x.
footnote ||| 4We note that we ignore the additional complication that
footnote ||| SSE will actually use recursion also to compute the challenge
footnote ||| in the challenge-response mechanism.
construct ||| Algorithm: SSE(z, y)
bodyText ||| Let pSE(., .) be the somewhere extractor with a polyno-
bodyText ||| mial number of outputs of Proposition 2.3.
bodyText ||| Let SB be the somewhere block source extractor of Corol-
bodyText ||| lary 2.8.
bodyText ||| Global Parameters: t, the branching factor of the tree. k
bodyText ||| the original entropy of the sources.
bodyText ||| Output will be a set of strings.
listItem ||| 1. If z is shorter than √k, return the empty set, else
listItem ||| continue.
listItem ||| 2. Partition z into t equal parts z = z1, z2, ... ,zt.
listItem ||| 3. Compute the response set R(z, y) which is the set of
listItem ||| strings output by pSE(z, y).
listItem ||| 4. For i E [t], compute the challenge set C(zi, y), which
listItem ||| is the set of outputs of SSE(zi, y).
listItem ||| 5. Let h be the smallest index for which the challenge set
listItem ||| C(zh, y) is not contained in the response set (set h = t
listItem ||| if no such index exists).
listItem ||| 6. Output SB(z, y) concatenated with SSE(zh, y).
listItem ||| Proving that indeed there are subsources on which SSE
listItem ||| will follow a path to a ”good” (for these subsources) node,
listItem ||| is the heart of the analysis. It is especially complex due
listItem ||| to the fact that the recursive call to SSE on subparts of
listItem ||| the current part is used to generate the Challenges for the
listItem ||| Challenge-Response mechanism. Since SSE works only on
listItem ||| a subsources we have to guarantee that restriction to these
listItem ||| does not hamper the behavior of SSE in past and future calls
listItem ||| to it.
listItem ||| Let us turn to the highlights of the analysis, for the proof
listItem ||| of Theorem 2.6. Let k' be the entropy of the source Z at
listItem ||| some place in this recursion. Either one of its blocks Zi has
page ||| 676
bodyText ||| entropy k'/c, in which case it is very condensed, since its
bodyText ||| size is n/t for t ≫ c), or it must be that c of its blocks form
bodyText ||| a c-block source with block entropy k'/t (which is sufficient
bodyText ||| for the extractor B used by SB). In the 2nd case the fact
bodyText ||| that SB(z, y) is part of the output of of our SSE guarantees
bodyText ||| that we are somewhere random. If the 2nd case doesn’t hold,
bodyText ||| let Zi be the leftmost condensed block. We want to ensure
bodyText ||| that (on appropriate subsources) SSE calls itself on that ith
bodyText ||| subpart. To do so, we fix all Zj for j < i to constants zj. We
bodyText ||| are now in the position described in the Challenge-Response
bodyText ||| mechanism section, that (in each of the first i parts) there
bodyText ||| is either no entropy or lots of entropy. We further restrict
bodyText ||| to subsources as explained there which make all first i − 1
bodyText ||| blocks fail the ”entropy test”, and the fact that Zi still has
bodyText ||| lots of entropy after these restrictions (which we need to
bodyText ||| prove) ensures that indeed SSE will be recursively applied
bodyText ||| to it.
bodyText ||| We note that while the procedure SSE can be described re-
bodyText ||| cursively, the formal analysis of fixing subsources is actually
bodyText ||| done globally, to ensure that indeed all entropy requirements
bodyText ||| are met along the various recursive calls.
bodyText ||| Let us remark on the choice of the branching parameter t.
bodyText ||| On the one hand, we’d like to keep it small, as it dominates
bodyText ||| the number of outputs tc of SB, and thus the total number of
bodyText ||| outputs (which is tc logt n). For this purpose, any t = no(1)
bodyText ||| will do. On the other hand, t should be large enough so that
bodyText ||| condensing is faster than losing entropy. Here note that if
bodyText ||| Z is of length n, its child has length n/t, while the entropy
bodyText ||| shrinks only from k' to k'/c. A simple calculation shows that
bodyText ||| if k(lo9t)/lo9c) > n2 then a c block-source must exist along
bodyText ||| such a path before the length shrinks to √k. Note that for
bodyText ||| k = nΩ(1) a (large enough) constant t suffices (resulting in
bodyText ||| only logarithmic number of outputs of SSE). This analysis
bodyText ||| is depicted pictorially in Figure 1.
sectionHeader ||| 5. THE FINAL DISPERSER D
bodyText ||| Following is a rough description of our disperser D proving
bodyText ||| Theorem 2.1. The high level structure of D will resemble the
bodyText ||| structure of SSE - we will recursively split the source X and
bodyText ||| look for entropy in the parts. However now we must output
bodyText ||| a single value (rather than a set) which can take both values
bodyText ||| 0 and 1. This was problematic in SSE, even knowing where
bodyText ||| the ”good” part (containing a c-block-source) was! How can
bodyText ||| we do so now?
bodyText ||| We now have at our disposal a much more powerful tool
bodyText ||| for generating challenges (and thus detecting entropy), namely
bodyText ||| the subsource somewhere disperser SSE. Note that in con-
bodyText ||| structing SSE we only had essentially the somewhere c-block-
bodyText ||| source extractor SB to (recursively) generate the challenges,
bodyText ||| but it depended on a structural property of the block it was
bodyText ||| applied on. Now SSE does not assume any structure on its
bodyText ||| input sources except sufficient entropy 5.
bodyText ||| Let us now give a high level description of the disperser
bodyText ||| D. It too will be a recursive procedure. If when processing
bodyText ||| some part Z of X it ”realizes” that a subpart Zi of Z has
bodyText ||| entropy, but not all the entropy of Z (namely Zi, Z is a
bodyText ||| 2-block-source) then we will halt and produce the output
bodyText ||| of D. Intuitively, thinking about the Challenge-Response
bodyText ||| mechanism described above, the analysis implies that we
footnote ||| 5There is a catch – it only works on subsources of them!
footnote ||| This will cause us a lot of head ache; we will elaborate on it
footnote ||| later.
footnote ||| can either pass or fail Zi (on appropriate subsources). But
footnote ||| this means that the outcome of this ”entropy test” is a 1-bit
footnote ||| disperser!
footnote ||| To capitalize on this idea, we want to use SSE to identify
footnote ||| such a block-source in the recursion tree. As before, we scan
footnote ||| the blocks from left to right, and want to distinguish three
footnote ||| possibilities.
footnote ||| low Zi has low entropy. In this case we proceed to i + 1.
footnote ||| medium Zi has ”medium” entropy (Zi, Z is a block-source).
footnote ||| In which case we halt and produce an output (zero or
footnote ||| one).
footnote ||| high Zi has essentially all entropy of Z. In this case we
footnote ||| recurse on the condensed block Zi.
footnote ||| As before, we use the Challenge-Response mechanism (with
footnote ||| a twist). We will compute challenges C(Zi, Y) and responses
footnote ||| R(Z, Y), all strings of length m. The responses are computed
footnote ||| exactly as before, using the somewhere extractor pSE. The
footnote ||| Challenges are computed using our subsource somewhere
footnote ||| extractor SSE.
footnote ||| We really have 4 possibilities to distinguish, since when we
footnote ||| halt we also need to decide which output bit we give. We will
footnote ||| do so by deriving three tests from the above challenges and
footnote ||| responses: (CH, RH), (CM, RM), (CL, RL) for high, medium
footnote ||| and low respectively, as follows. Let m ≥ mH >> mM >>
footnote ||| mL be appropriate integers: then in each of the tests above
footnote ||| we restrict ourselves to prefixes of all strings of the appro-
footnote ||| priate lengths only. So every string in CM will be a prefix
footnote ||| of length mM of some string in CH. Similarly, every string
footnote ||| in RL is the length mL prefix of some string in RH. Now
footnote ||| it is immediately clear that if CM is contained in RM, then
footnote ||| CL is contained in RL. Thus these tests are monotone, if
footnote ||| our sample fails the high test, it will definitely fail all tests.
construct ||| Algorithm: D(z, y)
bodyText ||| Let pSE(., .) be the somewhere extractor with a polyno-
bodyText ||| mial number of outputs of Proposition 2.3.
bodyText ||| Let SSE(.,.) be the subsource somewhere extractor of The-
bodyText ||| orem 2.6.
bodyText ||| Global Parameters: t, the branching factor of the tree. k
bodyText ||| the original entropy of the sources.
bodyText ||| Local Parameters for recursive level: mL ≪ mM ≪ mH.
bodyText ||| Output will be an element of {0, 1}.
listItem ||| 1. If z is shorter than √k, return 0.
listItem ||| 2. Partition z into t equal parts z = z1, z2, ... , zt.
listItem ||| 3. Compute three response sets RL, RM, RH using pSE(z, y).
listItem ||| Rj will be the prefixes of length mj of the strings in
listItem ||| pSE(z, y).
listItem ||| 4. For each i ∈ [t], compute three challenge sets CiL, CiM, CiH
listItem ||| using SSE(zi, y). Cij will be the prefixes of length mj
listItem ||| of the strings in SSE(zi, y).
listItem ||| 5. Let h be the smallest index for which the challenge set
listItem ||| CL is not contained in the response set RL, if there is
listItem ||| no such index, output 0 and halt.
listItem ||| 6. If ChH is contained in RH and ChH is contained in RM,
listItem ||| output 0 and halt. If ChH is contained in RH but ChH
listItem ||| is not contained in RM, output 1 and halt.
page ||| 677
figure ||| t blocks
figure ||| X
figure ||| low
figure ||| fail
figure ||| fail
figure ||| fail
figure ||| X_3
figure ||| (X_3)_4
figure ||| low
figure ||| low
figure ||| fail
figure ||| fail
figure ||| fail
figure ||| fail
figure ||| fail
figure ||| fail
figure ||| low
figure ||| low
figure ||| pass
figure ||| pass
figure ||| pass
figure ||| high
figure ||| low
figure ||| low
figure ||| t blocks
figure ||| low
figure ||| high
figure ||| t blocks
figure ||| med
figure ||| n bits total
figure ||| n/t bits total
figure ||| n/t^2 bits total
figure ||| fail
figure ||| fail
figure ||| fail
figure ||| fail
figure ||| fail
figure ||| fail
figure ||| pass
figure ||| pass
figure ||| fail
figure ||| pass
figure ||| fail
figure ||| fail
figure ||| Output 0	Output 1
figureCaption ||| Figure 2: Analysis of the disperser.
listItem ||| 7. Output D(zh, y),
bodyText ||| First note the obvious monotonicity of the tests. If Zi fails
bodyText ||| one of the tests it will certainly fail for shorter strings. Thus
bodyText ||| there are only four outcomes to the three tests, written in the
bodyText ||| order (low, medium, high): (pass, pass, pass), (pass, pass, fail),
bodyText ||| (pass, fail, fail) and (fail, fail, fail). Conceptually, the algo-
bodyText ||| rithm is making the following decisions using the four tests:
listItem ||| 1. (fail, fail, fail): Assume Zi has low entropy and proceed
listItem ||| to block i + 1.
listItem ||| 2. (pass, fail, fail): Assume Zi is medium, halt and output
listItem ||| 0.
listItem ||| 3. (pass, pass, fail): Assume Zi is medium, halt and out-
listItem ||| put 1.
listItem ||| 4. (pass, pass, pass): Assume Zi is high and recurse on Zi.
bodyText ||| The analysis of this idea (depicted in Figure 2).turns out
bodyText ||| to be more complex than it seems. There are two reasons for
bodyText ||| that. Now we briefly explain them and the way to overcome
bodyText ||| them in the construction and analysis.
bodyText ||| The first reason is the fact mentioned above, that SSE
bodyText ||| which generates the challenges, works only on a subsources
bodyText ||| of the original sources. Restricting to these subsources at
bodyText ||| some level of the recursion (as required by the analysis of of
bodyText ||| the test) causes entropy loss which affects both definitions
bodyText ||| (such as these entropy thresholds for decisions) and correct-
bodyText ||| ness of SSE in higher levels of recursion. Controlling this en-
bodyText ||| tropy loss is achieved by calling SSE recursively with smaller
bodyText ||| and smaller entropy requirements, which in turn limits the
bodyText ||| entropy which will be lost by these restrictions. In order not
bodyText ||| to lose all the entropy for this reason alone, we must work
bodyText ||| with special parameters of SSE, essentially requiring that at
bodyText ||| termination it has almost all the entropy it started with.
bodyText ||| The second reason is the analysis of the test when we are
bodyText ||| in a medium block. In contrast with the above situation, we
bodyText ||| cannot consider the value of Zi fixed when we need it to fail
bodyText ||| on the Medium and Low tests. We need to show that for
bodyText ||| these two tests (given a pass for High), they come up both
bodyText ||| (pass, fail) and (fail, fail) each with positive probability.
bodyText ||| Since the length of Medium challenges and responses is
bodyText ||| mM, the probability of failure is at least exp(−Q(mM)) (this
bodyText ||| follows relatively easily from the fact that the responses are
bodyText ||| somewhere random). If the Medium test fails so does the
bodyText ||| Low test, and thus (fail, fail) has a positive probability and
bodyText ||| our disperser D outputs 0 with positive probability.
bodyText ||| To bound (pass, fail) we first observe (with a similar
bodyText ||| reasoning) that the low test fails with probability at least
bodyText ||| exp(−Q(mL)). But we want the medium test to pass at the
bodyText ||| same time. This probability is at least the probability that
bodyText ||| low fails minus the probability that medium fails. We already
bodyText ||| have a bound on the latter: it is at most poly(n)exp(−ℓmM).
bodyText ||| Here comes our control of the different length into play - we
bodyText ||| can make the mL sufficiently smaller than mM to yield this
bodyText ||| difference positive. We conclude that our disperser D out-
bodyText ||| puts 1 with positive probability as well.
bodyText ||| Finally, we need to take care of termination: we have to
bodyText ||| ensure that the recurrence always arrives at a medium sub-
bodyText ||| part, but it is easy to chose entropy thresholds for low, medium
bodyText ||| and high to ensure that this happens.
page ||| 678
sectionHeader ||| 6. RESILIENCY AND DEFICIENCY
bodyText ||| In this section we will breifly discuss an issue which arises
bodyText ||| in our construction that we glossed over in the previous sec-
bodyText ||| tions. Recall our definition of subsources:
construct ||| DEfInItIOn 6.1 (SUBSOURCES). Given random variables
construct ||| Z and Zˆ on {0,1}n we say that Zˆ is a deficiency d subsource
construct ||| of Z and write Zˆ ⊆ Z if there exists a set A ⊆ {0,1}n such
construct ||| that (Z|A) = Zˆ and Pr[Z ∈ A] ≥ 2—d.
bodyText ||| Recall that we were able to guarantee that our algorithms
bodyText ||| made the right decisions only on subsources of the original
bodyText ||| source. For example, in the construction of our final dis-
bodyText ||| perser, to ensure that our algorithms correctly identify the
bodyText ||| right high block to recurse on, we were only able to guar-
bodyText ||| antee that there are subsources of the original sources in
bodyText ||| which our algorithm makes the correct decision with high
bodyText ||| probability. Then, later in the analysis we had to further
bodyText ||| restrict the source to even smaller subsources. This leads to
bodyText ||| complications, since the original event of picking the correct
bodyText ||| high block, which occurred with high probability, may be-
bodyText ||| come an event which does not occur with high probability
bodyText ||| in the current subsource. To handle these kinds of issues,
bodyText ||| we will need to be very careful in measuring how small our
bodyText ||| subsources are.
bodyText ||| In the formal analysis we introduce the concept of re-
bodyText ||| siliency to deal with this. To give an idea of how this works,
bodyText ||| here is the actual definition of somewhere subsource extrac-
bodyText ||| tor that we use in the formal analysis.
construct ||| DEfInItIOn 6.2 (SUBSOURCE SOmEWhERE ExtRaCtOR).
bodyText ||| A function SSE : {0, 1}n × {0, 1}n → ({0, 1}m)ℓ is a sub-
bodyText ||| source somewhere extractor with nrows output rows, entropy
bodyText ||| threshold k, deficiency def, resiliency res and error ǫ if for
bodyText ||| every (n, k)-sources X, Y there exist a deficiency def sub-
bodyText ||| source Xgood of X and a deficiency def subsource Ygood of
bodyText ||| Y such that for every deficiency res subsource X' of Xgood
bodyText ||| and deficiency res subsource Y' of Ygood, the random vari-
bodyText ||| able SSE(X',Y') is ǫ-close to a ℓ × m somewhere random
bodyText ||| distribution.
bodyText ||| It turns out that our subsource somewhere extractor does
bodyText ||| satisfy this stronger definition. The advantage of this defi-
bodyText ||| nition is that it says that once we restrict our attention to
bodyText ||| the good subsources Xgood, Ygood, we have the freedom to fur-
bodyText ||| ther restrict these subsources to smaller subsources, as long
bodyText ||| as our final subsources do not lose more entropy than the
bodyText ||| resiliency permits.
bodyText ||| This issue of managing the resiliency for the various ob-
bodyText ||| jects that we construct is one of the major technical chal-
bodyText ||| lenges that we had to overcome in our construction.
sectionHeader ||| 7. OPEN PROBLEMS
bodyText ||| Better Independent Source Extractors A bottleneck to
bodyText ||| improving our disperser is the block versus general
bodyText ||| source extractor of Theorem 2.7. A good next step
bodyText ||| would be to try to build an extractor for one block
bodyText ||| source (with only a constant number of blocks) and
bodyText ||| one other independent source which works for polylog-
bodyText ||| arithmic entropy, or even an extractor for a constant
bodyText ||| number of sources that works for sub-polynomial en-
bodyText ||| tropy.
bodyText ||| Simple Dispersers While our disperser is polynomial time
bodyText ||| computable, it is not as explicit as one might have
bodyText ||| hoped. For instance the Ramsey Graph construction
bodyText ||| of Frankl-Wilson is extremely simple: For a prime p,
bodyText ||| let the vertices of the graph be all subsets of [p3] of
bodyText ||| size p2 − 1. Two vertices S, T are adjacent if and only
bodyText ||| if |S ∩ T | ≡ −1 mod p. It would be nice to find a good
bodyText ||| disperser that beats the Frankl-Wilson construction,
bodyText ||| yet is comparable in simplicity.
sectionHeader ||| 8. REFERENCES
reference ||| [1] N. Alon. The shannon capacity of a union.
reference ||| Combinatorica, 18, 1998.
reference ||| [2] B. Barak. A simple explicit construction of an
reference ||| n˜o(logn )-ramsey graph. Technical report, Arxiv, 2006.
reference ||| http://arxiv.org/abs/math.CO/0601651.
reference ||| [3] B. Barak, R. Impagliazzo, and A. Wigderson.
reference ||| Extracting randomness using few independent sources.
reference ||| In Proceedings of the 45th Annual IEEE Symposium
reference ||| on Foundations of Computer Science, pages 384–393,
reference ||| 2004.
reference ||| [4] B. Barak, G. Kindler, R. Shaltiel, B. Sudakov, and
reference ||| A. Wigderson. Simulating independence: New
reference ||| constructions of condensers, Ramsey graphs,
reference ||| dispersers, and extractors. In Proceedings of the 37th
reference ||| Annual ACM Symposium on Theory of Computing,
reference ||| pages 1–10, 2005.
reference ||| [5] J. Bourgain. More on the sum-product phenomenon in
reference ||| prime fields and its applications. International Journal
reference ||| of Number Theory, 1:1–32, 2005.
reference ||| [6] J. Bourgain, N. Katz, and T. Tao. A sum-product
reference ||| estimate in finite fields, and applications. Geometric
reference ||| and Functional Analysis, 14:27–57, 2004.
reference ||| [7] M. Capalbo, O. Reingold, S. Vadhan, and
reference ||| A. Wigderson. Randomness conductors and
reference ||| constant-degree lossless expanders. In Proceedings of
reference ||| the 34th Annual ACM Symposium on Theory of
reference ||| Computing, pages 659–668, 2002.
reference ||| [8] B. Chor and O. Goldreich. Unbiased bits from sources
reference ||| of weak randomness and probabilistic communication
reference ||| complexity. SIAM Journal on Computing,
reference ||| 17(2):230–261, 1988.
reference ||| [9] P. Frankl and R. M. Wilson. Intersection theorems
reference ||| with geometric consequences. Combinatorica,
reference ||| 1(4):357–368, 1981.
reference ||| [10] P. Gopalan. Constructing ramsey graphs from boolean
reference ||| function representations. In Proceedings of the 21th
reference ||| Annual IEEE Conference on Computational
reference ||| Complexity, 2006.
reference ||| [11] V. Grolmusz. Low rank co-diagonal matrices and
reference ||| ramsey graphs. Electr. J. Comb, 7, 2000.
reference ||| [12] V. Guruswami. Better extractors for better codes?
reference ||| Electronic Colloquium on Computational Complexity
reference ||| (ECCC), (080), 2003.
reference ||| [13] C. J. Lu, O. Reingold, S. Vadhan, and A. Wigderson.
reference ||| Extractors: Optimal up to constant factors. In
reference ||| Proceedings of the 35th Annual ACM Symposium on
reference ||| Theory of Computing, pages 602–611, 2003.
reference ||| [14] P. Miltersen, N. Nisan, S. Safra, and A. Wigderson.
reference ||| On data structures and asymmetric communication
reference ||| complexity. Journal of Computer and System
reference ||| Sciences, 57:37–49, 1 1998.
page ||| 679
reference ||| [15] N. Nisan and D. Zuckerman. More deterministic
reference ||| simulation in logspace. In Proceedings of the 25th
reference ||| Annual ACM Symposium on Theory of Computing,
reference ||| pages 235–244, 1993.
reference ||| [16] P. Pudlak and V. Rodl. Pseudorandom sets and
reference ||| explicit constructions of ramsey graphs. Submitted for
reference ||| publication, 2004.
reference ||| [17] A. Rao. Extractors for a constant number of
reference ||| polynomially small min-entropy independent sources.
reference ||| In Proceedings of the 38th Annual ACM Symposium
reference ||| on Theory of Computing, 2006.
reference ||| [18] R. Raz. Extractors with weak random seeds. In
reference ||| Proceedings of the 37th Annual ACM Symposium on
reference ||| Theory of Computing, pages 11–20, 2005.
reference ||| [19] O. Reingold, R. Shaltiel, and A. Wigderson.
reference ||| Extracting randomness via repeated condensing. In
reference ||| Proceedings of the 41st Annual IEEE Symposium on
reference ||| Foundations of Computer Science, pages 22–31, 2000.
reference ||| [20] M. Santha and U. V. Vazirani. Generating
reference ||| quasi-random sequences from semi-random sources.
reference ||| Journal of Computer and System Sciences, 33:75–87,
reference ||| 1986.
reference ||| [21] R. Shaltiel. Recent developments in explicit
reference ||| constructions of extractors. Bulletin of the European
reference ||| Association for Theoretical Computer Science,
reference ||| 77:67–95, 2002.
reference ||| [22] A. Ta-Shma and D. Zuckerman. Extractor codes.
reference ||| IEEE Transactions on Information Theory, 50, 2004.
reference ||| [23] U. Vazirani. Towards a strong communication
reference ||| complexity theory or generating quasi-random
reference ||| sequences from two communicating slightly-random
reference ||| sources (extended abstract). In Proceedings of the 17th
reference ||| Annual ACM Symposium on Theory of Computing,
reference ||| pages 366–378, 1985.
reference ||| [24] A. Wigderson and D. Zuckerman. Expanders that
reference ||| beat the eigenvalue bound: Explicit construction and
reference ||| applications. Combinatorica, 19(1):125–138, 1999.
page ||| 680

title ||| A Frequency-based and a Poisson-based Definition of the
title ||| Probability of Being Informative
author ||| Thomas Roelleke
affiliation ||| Department of Computer Science
affiliation ||| Queen Mary University of London
email ||| thor@dcs.qmul.ac.uk
sectionHeader ||| ABSTRACT
bodyText ||| This paper reports on theoretical investigations about the
bodyText ||| assumptions underlying the inverse document frequency (idf ).
bodyText ||| We show that an intuitive idf-based probability function for
bodyText ||| the probability of a term being informative assumes disjoint
bodyText ||| document events. By assuming documents to be indepen-
bodyText ||| dent rather than disjoint, we arrive at a Poisson-based prob-
bodyText ||| ability of being informative. The framework is useful for
bodyText ||| understanding and deciding the parameter estimation and
bodyText ||| combination in probabilistic retrieval models.
sectionHeader ||| Categories and Subject Descriptors
category ||| H.3.3 [Information Search and Retrieval]: Retrieval
category ||| models
sectionHeader ||| General Terms
keyword ||| Theory
sectionHeader ||| Keywords
keyword ||| Probabilistic information retrieval, inverse document fre-
keyword ||| quency (idf), Poisson distribution, information theory, in-
keyword ||| dependence assumption
sectionHeader ||| 1. INTRODUCTION AND BACKGROUND
bodyText ||| The inverse document frequency (idf) is one of the most
bodyText ||| successful parameters for a relevance-based ranking of re-
bodyText ||| trieved objects. With N being the total number of docu-
bodyText ||| ments, and n(t) being the number of documents in which
bodyText ||| term t occurs, the idf is defined as follows:
equation ||| idf(t) := −log n(tt) , 0 <= idf(t) < ∞
bodyText ||| Ranking based on the sum of the idf-values of the query
bodyText ||| terms that occur in the retrieved documents works well, this
bodyText ||| has been shown in numerous applications. Also, it is well
bodyText ||| known that the combination of a document-specific term
copyright ||| Permission to make digital or hard copies of all or part of this work for
copyright ||| personal or classroom use is granted without fee provided that copies are
copyright ||| not made or distributed for profit or commercial advantage and that copies
copyright ||| bear this notice and the full citation on the first page. To copy otherwise, to
copyright ||| republish, to post on servers or to redistribute to lists, requires prior specific
copyright ||| permission and/or a fee.
note ||| SIGIR’03, July 28–August 1, 2003, Toronto, Canada.
copyright ||| Copyright 2003 ACM 1-58113-646-3/03/0007 ...$5.00.
bodyText ||| weight and idf works better than idf alone. This approach
bodyText ||| is known as tf-idf, where tf(t, d) (0 <= tf(t, d) <= 1) is
bodyText ||| the so-called term frequency of term t in document d. The
bodyText ||| idf reflects the discriminating power (informativeness) of a
bodyText ||| term, whereas the tf reflects the occurrence of a term.
bodyText ||| The idf alone works better than the tf alone does. An ex-
bodyText ||| planation might be the problem of tf with terms that occur
bodyText ||| in many documents; let us refer to those terms as “noisy”
bodyText ||| terms. We use the notion of “noisy” terms rather than “fre-
bodyText ||| quent” terms since frequent terms leaves open whether we
bodyText ||| refer to the document frequency of a term in a collection or
bodyText ||| to the so-called term frequency (also referred to as within-
bodyText ||| document frequency) of a term in a document. We asso-
bodyText ||| ciate “noise” with the document frequency of a term in a
bodyText ||| collection, and we associate “occurrence” with the within-
bodyText ||| document frequency of a term. The tf of a noisy term might
bodyText ||| be high in a document, but noisy terms are not good candi-
bodyText ||| dates for representing a document. Therefore, the removal
bodyText ||| of noisy terms (known as “stopword removal”) is essential
bodyText ||| when applying tf. In a tf-idf approach, the removal of stop-
bodyText ||| words is conceptually obsolete, if stopwords are just words
bodyText ||| with a low idf.
bodyText ||| From a probabilistic point of view, tf is a value with a
bodyText ||| frequency-based probabilistic interpretation whereas idf has
bodyText ||| an “informative” rather than a probabilistic interpretation.
bodyText ||| The missing probabilistic interpretation of idf is a problem
bodyText ||| in probabilistic retrieval models where we combine uncertain
bodyText ||| knowledge of different dimensions (e.g.: informativeness of
bodyText ||| terms, structure of documents, quality of documents, age
bodyText ||| of documents, etc.) such that a good estimate of the prob-
bodyText ||| ability of relevance is achieved. An intuitive solution is a
bodyText ||| normalisation of idf such that we obtain values in the inter-
bodyText ||| val [0; 1]. For example, consider a normalisation based on
bodyText ||| the maximal idf-value. Let T be the set of terms occurring
bodyText ||| in a collection.
equation ||| Pf,Q (t is informative) :=  idf(t)
equation ||| maxidf
equation ||| maxidf := max({idf(t)|t ∈ T}), maxidf <= −log(1/N)
equation ||| minidf := min({idf(t)|t ∈ T}), minidf >= 0
equation ||| minidf < Pf,Q (t is informative) ≤ 1.0
equation ||| maxidf —
bodyText ||| This frequency-based probability function covers the interval
bodyText ||| [0; 1] if the minimal idf is equal to zero, which is the case
bodyText ||| if we have at least one term that occurs in all documents.
bodyText ||| Can we interpret Pf� Q , the normalised idf, as the probability
bodyText ||| that the term is informative?
bodyText ||| When investigating the probabilistic interpretation of the
page ||| 227
bodyText ||| normalised idf, we made several observations related to dis-
bodyText ||| jointness and independence of document events. These ob-
bodyText ||| servations are reported in section 3. We show in section 3.1
bodyText ||| that the frequency-based noise probability n(t) Nused in the
bodyText ||| classic idf-definition can be explained by three assumptions:
bodyText ||| binary term occurrence, constant document containment and
bodyText ||| disjointness of document containment events. In section 3.2
bodyText ||| we show that by assuming independence of documents, we
bodyText ||| obtain 1 — e-1 Pz� 1 — 0.37 as the upper bound of the noise
bodyText ||| probability of a term. The value e−1 is related to the loga-
bodyText ||| rithm and we investigate in section 3.3 the link to informa-
bodyText ||| tion theory. In section 4, we link the results of the previous
bodyText ||| sections to probability theory. We show the steps from possi-
bodyText ||| ble worlds to binomial distribution and Poisson distribution.
bodyText ||| In section 5, we emphasise that the theoretical framework
bodyText ||| of this paper is applicable for both idf and tf. Finally, in
bodyText ||| section 6, we base the definition of the probability of be-
bodyText ||| ing informative on the results of the previous sections and
bodyText ||| compare frequency-based and Poisson-based definitions.
sectionHeader ||| 2. BACKGROUND
bodyText ||| The relationship between frequencies, probabilities and
bodyText ||| information theory (entropy) has been the focus of many
bodyText ||| researchers. In this background section, we focus on work
bodyText ||| that investigates the application of the Poisson distribution
bodyText ||| in IR since a main part of the work presented in this paper
bodyText ||| addresses the underlying assumptions of Poisson.
bodyText ||| [4] proposes a 2-Poisson model that takes into account
bodyText ||| the different nature of relevant and non-relevant documents,
bodyText ||| rare terms (content words) and frequent terms (noisy terms,
bodyText ||| function words, stopwords). [9] shows experimentally that
bodyText ||| most of the terms (words) in a collection are distributed
bodyText ||| according to a low dimension n-Poisson model. [10] uses a
bodyText ||| 2-Poisson model for including term frequency-based proba-
bodyText ||| bilities in the probabilistic retrieval model. The non-linear
bodyText ||| scaling of the Poisson function showed significant improve-
bodyText ||| ment compared to a linear frequency-based probability. The
bodyText ||| Poisson model was here applied to the term frequency of a
bodyText ||| term in a document. We will generalise the discussion by
bodyText ||| pointing out that document frequency and term frequency
bodyText ||| are dual parameters in the collection space and the docu-
bodyText ||| ment space, respectively. Our discussion of the Poisson dis-
bodyText ||| tribution focuses on the document frequency in a collection
bodyText ||| rather than on the term frequency in a document.
bodyText ||| [7] and [6] address the deviation of idf and Poisson, and
bodyText ||| apply Poisson mixtures to achieve better Poisson-based esti-
bodyText ||| mates. The results proved again experimentally that a one-
bodyText ||| dimensional Poisson does not work for rare terms, therefore
bodyText ||| Poisson mixtures and additional parameters are proposed.
bodyText ||| [3], section 3.3, illustrates and summarises comprehen-
bodyText ||| sively the relationships between frequencies, probabilities
bodyText ||| and Poisson. Different definitions of idf are put into con-
bodyText ||| text and a notion of “noise” is defined, where noise is viewed
bodyText ||| as the complement of idf. We use in our paper a different
bodyText ||| notion of noise: we consider a frequency-based noise that
bodyText ||| corresponds to the document frequency, and we consider a
bodyText ||| term noise that is based on the independence of document
bodyText ||| events.
bodyText ||| [11], [12], [8] and [1] link frequencies and probability esti-
bodyText ||| mation to information theory. [12] establishes a framework
bodyText ||| in which information retrieval models are formalised based
bodyText ||| on probabilistic inference. A key component is the use of a
bodyText ||| space of disjoint events, where the framework mainly uses
bodyText ||| terms as disjoint events. The probability of being informa-
bodyText ||| tive defined in our paper can be viewed as the probability
bodyText ||| of the disjoint terms in the term space of [12].
bodyText ||| [8] address entropy and bibliometric distributions. En-
bodyText ||| tropy is maximal if all events are equiprobable and the fre-
bodyText ||| quency-based Lotka law (N/iλ is the number of scientists
bodyText ||| that have written i publications, where N and λ are distri-
bodyText ||| bution parameters), Zipf and the Pareto distribution are re-
bodyText ||| lated. The Pareto distribution is the continuous case of the
bodyText ||| Lotka and Lotka and Zipf show equivalences. The Pareto
bodyText ||| distribution is used by [2] for term frequency normalisation.
bodyText ||| The Pareto distribution compares to the Poisson distribu-
bodyText ||| tion in the sense that Pareto is “fat-tailed”, i. e. Pareto as-
bodyText ||| signs larger probabilities to large numbers of events than
bodyText ||| Poisson distributions do. This makes Pareto interesting
bodyText ||| since Poisson is felt to be too radical on frequent events.
bodyText ||| We restrict in this paper to the discussion of Poisson, how-
bodyText ||| ever, our results show that indeed a smoother distribution
bodyText ||| than Poisson promises to be a good candidate for improving
bodyText ||| the estimation of probabilities in information retrieval.
bodyText ||| [1] establishes a theoretical link between tf-idf and infor-
bodyText ||| mation theory and the theoretical research on the meaning
bodyText ||| of tf-idf “clarifies the statistical model on which the different
bodyText ||| measures are commonly based”. This motivation matches
bodyText ||| the motivation of our paper: We investigate theoretically
bodyText ||| the assumptions of classical idf and Poisson for a better
bodyText ||| understanding of parameter estimation and combination.
sectionHeader ||| 3. FROM DISJOINT TO INDEPENDENT
bodyText ||| We define and discuss in this section three probabilities:
bodyText ||| The frequency-based noise probability (definition 1), the to-
bodyText ||| tal noise probability for disjoint documents (definition 2).
bodyText ||| and the noise probability for independent documents (defi-
bodyText ||| nition 3).
subsectionHeader ||| 3.1 Binary occurrence, constant containment
subsectionHeader ||| and disjointness of documents
bodyText ||| We show in this section, that the frequency-based noise
bodyText ||| probability nN(t) in the idf definition can be explained as
bodyText ||| a total probability with binary term occurrence, constant
bodyText ||| document containment and disjointness of document con-
bodyText ||| tainments.
bodyText ||| We refer to a probability function as binary if for all events
bodyText ||| the probability is either 1.0 or 0.0. The occurrence proba-
bodyText ||| bility P(t1d) is binary, if P(t1d) is equal to 1.0 if t E d, and
bodyText ||| P(t1d) is equal to 0.0, otherwise.
equation ||| P(t1d) is binary: P(t1d) = 1.0 V P(t1d) = 0.0
bodyText ||| We refer to a probability function as constant if for all
bodyText ||| events the probability is equal. The document containment
bodyText ||| probability reflect the chance that a document occurs in a
bodyText ||| collection. This containment probability is constant if we
bodyText ||| have no information about the document containment or
bodyText ||| we ignore that documents differ in containment. Contain-
bodyText ||| ment could be derived, for example, from the size, quality,
bodyText ||| age, links, etc. of a document. For a constant containment
bodyText ||| in a collection with N documents, N1 is often assumed as
bodyText ||| the containment probability. We generalise this definition
bodyText ||| and introduce the constant λ where 0 < λ < N. The con-
bodyText ||| tainment of a document d depends on the collection c, this
bodyText ||| is reflected by the notation P(d1c) used for the containment
page ||| 228
bodyText ||| of a document.
equation ||| P(d1c) is constant:	Vd : P(d1c) = λ
equation ||| N
bodyText ||| For disjoint documents that cover the whole event space,
bodyText ||| we set λ = 1 and obtain Ed P(d1c) = 1.0. Next, we define
bodyText ||| the frequency-based noise probability and the total noise
bodyText ||| probability for disjoint documents. We introduce the event
bodyText ||| notation t is noisy and t occurs for making the difference
bodyText ||| between the noise probability P(t is noisy1c) in a collection
bodyText ||| and the occurrence probability P(t occurs 1d) in a document
bodyText ||| more explicit, thereby keeping in mind that the noise prob-
bodyText ||| ability corresponds to the occurrence probability of a term
bodyText ||| in a collection.
construct ||| DefInItIOn 1. The frequency-based term noise prob-
construct ||| ability:
equation ||| Pfr q(t is noisy1c) := n(t)
equation ||| N
construct ||| DefInItIOn 2. The total term noise probability for
construct ||| disjoint documents:
equation ||| Pdi9(t is noisy1c) := E P(t occurs1d) • P(d1c)
equation ||| d
bodyText ||| Now, we can formulate a theorem that makes assumptions
bodyText ||| explicit that explain the classical idf.
construct ||| TheOrem 1. IDF assumptions: If the occurrence prob-
construct ||| ability P(t1d) of term t over documents d is binary, and
construct ||| the containment probability P(d1c) of documents d is con-
construct ||| stant, and document containments are disjoint events, then
construct ||| the noise probability for disjoint documents is equal to the
construct ||| frequency-based noise probability.
equation ||| Pdi9(t is noisy1c) = Pfr q(t is noisy1c)
bodyText ||| PrOOf. The assumptions are:
equation ||| Vd : (P(t occurs1d) = 1 V P(t occurs1d) = 0) n
equation ||| P(d1c) = N n
equation ||| E P(d1c) = 1.0
bodyText ||| d
bodyText ||| the containment for small documents tends to be smaller
bodyText ||| than for large documents. From that point of view, idf
bodyText ||| means that P(t n d1c) is constant for all d in which t occurs,
bodyText ||| and P(t n d1c) is zero otherwise. The occurrence and con-
bodyText ||| tainment can be term specific. For example, set P(t nd1c) =
bodyText ||| 1/ND(c) if t occurs in d, where ND(c) is the number of doc-
bodyText ||| uments in collection c (we used before just N). We choose a
bodyText ||| document-dependent occurrence P(t1d) := 1/NT(d), i. e. the
bodyText ||| occurrence probability is equal to the inverse of NT (d), which
bodyText ||| is the total number of terms in document d. Next, we choose
bodyText ||| the containment P(d1c) := NT(d)/NT(c)•NT(c)/ND(c) where
bodyText ||| NT(d)/NT(c) is a document length normalisation (number
bodyText ||| of terms in document d divided by the number of terms in
bodyText ||| collection c), and NT (c)/ND (c) is a constant factor of the
bodyText ||| collection (number of terms in collection c divided by the
bodyText ||| number of documents in collection c). We obtain P(tnd1c) =
bodyText ||| 1/ND (c).
bodyText ||| In a tf-idf-retrieval function, the tf-component reflects
bodyText ||| the occurrence probability of a term in a document. This is
bodyText ||| a further explanation why we can estimate the idf with a
bodyText ||| simple P(t1d), since the combined tf-idf contains the occur-
bodyText ||| rence probability. The containment probability corresponds
bodyText ||| to a document normalisation (document length normalisa-
bodyText ||| tion, pivoted document length) and is normally attached to
bodyText ||| the tf-component or the tf-idf-product.
bodyText ||| The disjointness assumption is typical for frequency-based
bodyText ||| probabilities. From a probability theory point of view, we
bodyText ||| can consider documents as disjoint events, in order to achieve
bodyText ||| a sound theoretical model for explaining the classical idf.
bodyText ||| But does disjointness reflect the real world where the con-
bodyText ||| tainment of a document appears to be independent of the
bodyText ||| containment of another document? In the next section, we
bodyText ||| replace the disjointness assumption by the independence as-
bodyText ||| sumption.
subsectionHeader ||| 3.2 The upper bound of the noise probability
subsectionHeader ||| for independent documents
bodyText ||| For independent documents, we compute the probability
bodyText ||| of a disjunction as usual, namely as the complement of the
bodyText ||| probability of the conjunction of the negated events:
equation ||| P(di V ... V dN) = 1 — P(-di n ... n �dN)
equation ||| (1 — P(d))
equation ||| = 1—rl
equation ||| d
equation ||| 1
equation ||| N
equation ||| =
equation ||| n(t)
equation ||| N
equation ||| = Pfr q(t is noisy1c)
equation ||| We obtain:
equation ||| Pdi9(t is noisy1c) = E
equation ||| dt∈d
bodyText ||| The noise probability can be considered as the conjunction
bodyText ||| of the term occurrence and the document containment.
bodyText ||| The above result is not a surprise but it is a mathemati-
bodyText ||| cal formulation of assumptions that can be used to explain
bodyText ||| the classical idf. The assumptions make explicit that the
bodyText ||| different types of term occurrence in documents (frequency
bodyText ||| of a term, importance of a term, position of a term, doc-
bodyText ||| ument part where the term occurs, etc.) and the different
bodyText ||| types of document containment (size, quality, age, etc.) are
bodyText ||| ignored, and document containments are considered as dis-
bodyText ||| joint events.
bodyText ||| From the assumptions, we can conclude that idf (frequency-
bodyText ||| based noise, respectively) is a relatively simple but strict
bodyText ||| estimate. Still, idf works well. This could be explained
bodyText ||| by a leverage effect that justifies the binary occurrence and
bodyText ||| constant containment: The term occurrence for small docu-
bodyText ||| ments tends to be larger than for large documents, whereas
equation ||| P(t is noisy1c) := P(t occurs n (dl V ... V dN)1c)
bodyText ||| For disjoint documents, this view of the noise probability
bodyText ||| led to definition 2. For independent documents, we use now
bodyText ||| the conjunction of negated events.
construct ||| DefInItIOn 3. The term noise probability for inde-
construct ||| pendent documents:
construct ||| Pin(t is noisy1c) := rl (1 — P(t occurs1d) • P(d1c))
construct ||| d
bodyText ||| With binary occurrence and a constant containment P(d1c) :=
bodyText ||| λ/N, we obtain the term noise of a term t that occurs in n(t)
bodyText ||| documents:
equation ||| Pin(t is noisy1c) = 1 — (1 — λN1n(t)
page ||| 229
bodyText ||| For binary occurrence and disjoint documents, the contain-
bodyText ||| ment probability was 1/N. Now, with independent docu-
bodyText ||| ments, we can use λ as a collection parameter that controls
bodyText ||| the average containment probability. We show through the
bodyText ||| next theorem that the upper bound of the noise probability
bodyText ||| depends on λ.
construct ||| TheOrem 2. The upper bound of being noisy: If the
construct ||| occurrence P(t|d) is binary, and the containment P(d|c)
construct ||| is constant, and document containments are independent
construct ||| events, then 1 − e−λ is the upper bound of the noise proba-
construct ||| bility.
equation ||| ∀t : Pin (t is noisy|c) < 1 − e−λ
bodyText ||| PrOOf. The upper bound of the independent noise prob-
bodyText ||| ability follows from the limit limN→∞(1 + xN)N = ex (see
bodyText ||| any comprehensive math book, for example, [5], for the con-
bodyText ||| vergence equation of the Euler function). With x = −λ, we
bodyText ||| obtain:
equation ||| N
equation ||| lim C1 − λN) = e−λ
equation ||| N→
bodyText ||| For the term noise, we have:
equation ||| Pin(t is noisy|c) = 1 − C1 − λN)n(t)
bodyText ||| Pin (t is noisy |c) is strictly monotonous: The noise of a term
bodyText ||| tn is less than the noise of a term tn+1, where tn occurs in
bodyText ||| n documents and tn+1 occurs in n + 1 documents. There-
bodyText ||| fore, a term with n = N has the largest noise probability.
bodyText ||| For a collection with infinite many documents, the upper
bodyText ||| bound of the noise probability for terms tN that occur in all
bodyText ||| documents becomes:
equation ||| 1−C1−λN)N
equation ||| = 1−e−λ
bodyText ||| By applying an independence rather a disjointness assump-
bodyText ||| tion, we obtain the probability e−1 that a term is not noisy
bodyText ||| even if the term does occur in all documents. In the disjoint
bodyText ||| case, the noise probability is one for a term that occurs in
bodyText ||| all documents.
bodyText ||| If we view P(d|c) := λ/N as the average containment,
bodyText ||| then λ is large for a term that occurs mostly in large docu-
bodyText ||| ments, and λ is small for a term that occurs mostly in small
bodyText ||| documents. Thus, the noise of a term t is large if t occurs in
bodyText ||| n(t) large documents and the noise is smaller if t occurs in
bodyText ||| small documents. Alternatively, we can assume a constant
bodyText ||| containment and a term-dependent occurrence. If we as-
bodyText ||| sume P(d|c) := 1, then P(t|d) := λ/N can be interpreted as
bodyText ||| the average probability that t represents a document. The
bodyText ||| common assumption is that the average containment or oc-
bodyText ||| currence probability is proportional to n(t). However, here
bodyText ||| is additional potential: The statistical laws (see [3] on Luhn
bodyText ||| and Zipf) indicate that the average probability could follow
bodyText ||| a normal distribution, i. e. small probabilities for small n(t)
bodyText ||| and large n(t), and larger probabilities for medium n(t).
bodyText ||| For the monotonous case we investigate here, the noise of
bodyText ||| a term with n(t) = 1 is equal to 1 − (1 − λ/N) = λ/N and
bodyText ||| the noise of a term with n(t) = N is close to 1− e−λ. In the
bodyText ||| next section, we relate the value e−λ to information theory.
subsectionHeader ||| 3.3 The probability of a maximal informative
subsectionHeader ||| signal
bodyText ||| The probability e−1 is special in the sense that a signal
bodyText ||| with that probability is a signal with maximal information as
bodyText ||| derived from the entropy definition. Consider the definition
bodyText ||| of the entropy contribution H(t) of a signal t.
equation ||| H(t) := P(t) · − ln P(t)
bodyText ||| We form the first derivation for computing the optimum.
equation ||| − ln P(t) + P(t) · P(t)
equation ||| = −(1+lnP(t))
equation ||| For obtaining optima, we use:
equation ||| 0 = −(1 + ln P(t))
bodyText ||| The entropy contribution H(t) is maximal for P(t) = e−1.
bodyText ||| This result does not depend on the base of the logarithm as
bodyText ||| we see next:
equation ||| −1
equation ||| P(t) · ln b ·P(t)
equation ||| 1	1 + ln P(t)
equation ||| ln b + log P(t)	ln b	)
bodyText ||| We summarise this result in the following theorem:
bodyText ||| TheOrem 3. The probability of a maximal informa-
bodyText ||| tive signal: The probability Pmax = e−1 ≈ 0.37 is the prob-
bodyText ||| ability of a maximal informative signal. The entropy of a
bodyText ||| maximal informative signal is Hmax = e−1.
bodyText ||| PrOOf. The probability and entropy follow from the deriva-
bodyText ||| tion above.
bodyText ||| The complement of the maximal noise probability is e−λ
bodyText ||| and we are looking now for a generalisation of the entropy
bodyText ||| definition such that e−λ is the probability of a maximal in-
bodyText ||| formative signal. We can generalise the entropy definition
bodyText ||| by computing the integral of λ+ln P(t), i. e. this derivation
bodyText ||| is zero for e−λ. We obtain a generalised entropy:
equation ||| J −(λ + ln P(t)) d(P(t)) = P(t) · (1 − λ − ln P(t))
bodyText ||| The generalised entropy corresponds for λ = 1 to the classi-
bodyText ||| cal entropy. By moving from disjoint to independent docu-
bodyText ||| ments, we have established a link between the complement
bodyText ||| of the noise probability of a term that occurs in all docu-
bodyText ||| ments and information theory. Next, we link independent
bodyText ||| documents to probability theory.
sectionHeader ||| 4. THE LINK TO PROBABILITY THEORY
bodyText ||| We review for independent documents three concepts of
bodyText ||| probability theory: possible worlds, binomial distribution
bodyText ||| and Poisson distribution.
subsectionHeader ||| 4.1 Possible Worlds
bodyText ||| Each conjunction of document events (for each document,
bodyText ||| we consider two document events: the document can be
bodyText ||| true or false) is associated with a so-called possible world.
bodyText ||| For example, consider the eight possible worlds for three
bodyText ||| documents (N = 3).
equation ||| Pin (tN is noisy) = lim
equation ||| N→∞
equation ||| lim
equation ||| N→∞
equation ||| ∂H(t)
equation ||| ∂P(t)
equation ||| ∂H(t)
equation ||| ∂P(t)
equation ||| = − logb P(t)+
equation ||| = −C
page ||| 230
table ||| world w	conjunction
table ||| w7	d1 ∧ d2 ∧ d3
table ||| ws	d1 ∧ d2 ∧ ¬d3
table ||| w5	d1 ∧ ¬d2 ∧ d3
table ||| w4	d1 ∧ ¬d2 ∧ ¬d3
table ||| w3	¬d1 ∧ d2 ∧ d3
table ||| w2	¬d1 ∧ d2 ∧ ¬d3
table ||| w1	¬d1 ∧ ¬d2 ∧ d3
table ||| w0	¬d1 ∧ ¬d2 ∧ ¬d3
bodyText ||| With each world w, we associate a probability µ(w), which
bodyText ||| is equal to the product of the single probabilities of the doc-
bodyText ||| ument events.
table ||| world w	µ(w)
table ||| 	probability
table ||| w7	(λ·N)0
table ||| 	(N)3
table ||| ws	·	(1 − N)1
table ||| 	rrN)2
table ||| w5	\N)2·	(1 − N)1
table ||| w4	(N)1 ·	2
table ||| 		(1 − N)
table ||| w3	(N)2·	(1 − N)1
table ||| w2	(λ	(1 − N)2
table ||| w1	(N)1 ·
table ||| w0	(λ	N)3
bodyText ||| The sum over the possible worlds in which k documents are
bodyText ||| true and N−k documents are false is equal to the probabil-
bodyText ||| ity function of the binomial distribution, since the binomial
bodyText ||| coefficient yields the number of possible worlds in which k
bodyText ||| documents are true.
subsectionHeader ||| 4.2 Binomial distribution
bodyText ||| The binomial probability function yields the probability
bodyText ||| that k of N events are true where each event is true with
bodyText ||| the single event probability p.
equation ||| P(k) := binom(N, k, p) := (N k / pk (1 − p)N− k
bodyText ||| The single event probability is usually defined as p := λ/N,
bodyText ||| i. e. p is inversely proportional to N, the total number of
bodyText ||| events. With this definition of p, we obtain for an infinite
bodyText ||| number of documents the following limit for the product of
bodyText ||| the binomial coefficient and p k :
equation ||| lim N k
equation ||| N→∞k p
equation ||| N · (N−1) · ... · (N−k +1)
equation ||| k!
bodyText ||| The limit is close to the actual value for k << N. For large
bodyText ||| k, the actual value is smaller than the limit.
bodyText ||| The limit of (1−p)N−k follows from the limit limN→∞(1+ W=
bodyText ||| ex.
equation ||| N−k
equation ||| lim (1 −p)N −k = lim (1 − λN)
equation ||| N→∞	N→
bodyText ||| Again, the limit is close to the actual value for k << N. For
bodyText ||| large k, the actual value is larger than the limit.
subsectionHeader ||| 4.3 Poisson distribution
bodyText ||| For an infinite number of events, the Poisson probability
bodyText ||| function is the limit of the binomial probability function.
equation ||| Ak
equation ||| binom(N, k, p) = k! · e−λ
equation ||| P(k) = poisson(k, λ) := k! · e−λ
bodyText ||| The probability poisson(0, 1) is equal to e−1, which is the
bodyText ||| probability of a maximal informative signal. This shows
bodyText ||| the relationship of the Poisson distribution and information
bodyText ||| theory.
bodyText ||| After seeing the convergence of the binomial distribution,
bodyText ||| we can choose the Poisson distribution as an approximation
bodyText ||| of the independent term noise probability. First, we define
bodyText ||| the Poisson noise probability:
construct ||| DefInItIOn 4. The Poisson term noise probability:
construct ||| P,oi(t is noisy|c) := e−λ ·
bodyText ||| For independent documents, the Poisson distribution ap-
bodyText ||| proximates the probability of the disjunction for large n(t),
bodyText ||| since the independent term noise probability is equal to the
bodyText ||| sum over the binomial probabilities where at least one of
bodyText ||| n(t) document containment events is true.
equation ||| Pin (t is noisy | c) = n(t) (n(t)1 pk (1 − p)N−k
equation ||| 1. k J
equation ||| 1
equation ||| Pin (t is noisy | c) ≈ P,oi (t is noisy | c)
bodyText ||| We have defined a frequency-based and a Poisson-based prob-
bodyText ||| ability of being noisy, where the latter is the limit of the
bodyText ||| independence-based probability of being noisy. Before we
bodyText ||| present in the final section the usage of the noise proba-
bodyText ||| bility for defining the probability of being informative, we
bodyText ||| emphasise in the next section that the results apply to the
bodyText ||| collection space as well as to the the document space.
equation ||| k
equation |||  N) = e—λ
sectionHeader ||| 5. THE COLLECTION SPACE AND THE
sectionHeader ||| DOCUMENT SPACE
bodyText ||| Consider the dual definitions of retrieval parameters in
bodyText ||| table 1. We associate a collection space D × T with a col-
bodyText ||| lection c where D is the set of documents and T is the set
bodyText ||| of terms in the collection. Let ND := |D| and NT := |T|
bodyText ||| be the number of documents and terms, respectively. We
bodyText ||| consider a document as a subset of T and a term as a subset
bodyText ||| of D. Let nT(d) := |{t|d ∈ t}| be the number of terms that
bodyText ||| occur in the document d, and let nD(t) := | {d|t ∈ d}| be the
bodyText ||| number of documents that contain the term t.
bodyText ||| In a dual way, we associate a document space L × T with
bodyText ||| a document d where L is the set of locations (also referred
bodyText ||| to as positions, however, we use the letters L and l and not
bodyText ||| P and p for avoiding confusion with probabilities) and T is
bodyText ||| the set of terms in the document. The document dimension
bodyText ||| in a collection space corresponds to the location (position)
bodyText ||| dimension in a document space.
bodyText ||| The definition makes explicit that the classical notion of
bodyText ||| term frequency of a term in a document (also referred to as
bodyText ||| the within-document term frequency) actually corresponds
bodyText ||| to the location frequency of a term in a document. For the
equation ||| lime
equation ||| —
equation ||| λ(1−
equation ||| N→
equation ||| =lim
equation ||| N→∞
equation ||| (λ)k = λk
equation ||| N	k!
equation ||| lim
equation ||| N→∞
equation ||| λk
equation ||| k!
equation ||| n(t)�
equation ||| k=1
page ||| 231
table ||| space	collection	document
table ||| dimensions	documents and terms	locations and terms
table ||| document/location frequency	nD(t, c): Number of documents in which term t occurs in collection c	nL(t, d): Number of locations (positions) at which term t occurs in document d
table ||| 	ND(c): Number of documents in collection c	NL(d): Number of locations (positions) in docu-ment d
table ||| term frequency	nT(d,c): Number of terms that document d con- tains in collection c	nT(l,d): Number of terms that location l contains in document d
table ||| 	NT(c): Number of terms in collection c	NT(d): Number of terms in document d
table ||| noise/occurrence containment	P(t1c) (term noise) P(d1c) (document)	P(t1d) (term occurrence) P(l1d) (location)
table ||| informativeness conciseness	— ln P(t1c) — ln P(d1c)	— ln P(t1d) — ln P(l 1d)
table ||| P(informative) P(concise)	ln(P(t1c))/ ln(P(tm in, c)) ln(P(d1c))/ ln(P(dmin1c))	ln(P(t1d))/ ln(P(tm in, d)) ln(P(l1d))/ln(P(lm in1d))
tableCaption ||| Table 1: Retrieval parameters
bodyText ||| actual term frequency value, it is common to use the max-
bodyText ||| imal occurrence (number of locations; let lf be the location
bodyText ||| frequency).
equation ||| tf(t, d) := lf(t, d) :=  Pf, , (t occurs 1d) =  nL (t, d)
equation ||| Pf,,(t. occurs1d) nL(t,, ,d)
bodyText ||| A further duality is between informativeness and concise-
bodyText ||| ness (shortness of documents or locations): informativeness
bodyText ||| is based on occurrence (noise), conciseness is based on con-
bodyText ||| tainment.
bodyText ||| We have highlighted in this section the duality between
bodyText ||| the collection space and the document space. We concen-
bodyText ||| trate in this paper on the probability of a term to be noisy
bodyText ||| and informative. Those probabilities are defined in the col-
bodyText ||| lection space. However, the results regarding the term noise
bodyText ||| and informativeness apply to their dual counterparts: term
bodyText ||| occurrence and informativeness in a document. Also, the
bodyText ||| results can be applied to containment of documents and lo-
bodyText ||| cations.
sectionHeader ||| 6. THE PROBABILITY OF BEING INFOR-
sectionHeader ||| MATIVE
bodyText ||| We showed in the previous sections that the disjointness
bodyText ||| assumption leads to frequency-based probabilities and that
bodyText ||| the independence assumption leads to Poisson probabilities.
bodyText ||| In this section, we formulate a frequency-based definition
bodyText ||| and a Poisson-based definition of the probability of being
bodyText ||| informative and then we compare the two definitions.
construct ||| DefInItIOn 5. The frequency-based probability of be-
construct ||| ing informative:
bodyText ||| We define the Poisson-based probability of being informa-
bodyText ||| tive analogously to the frequency-based probability of being
bodyText ||| informative (see definition 5).
construct ||| DefInItIOn 6. The Poisson-based probability of be-
construct ||| ing informative:
bodyText ||| For λ >> 1, we can alter the noise and informativeness Pois-
bodyText ||| son by starting the sum from 0, since eλ >> 1. Then, the
bodyText ||| minimal Poisson informativeness is poisson(0, λ) = e−λ. We
bodyText ||| obtain a simplified Poisson probability of being informative:
equation ||| λ — ln En (to \k
equation ||| Ppoj(t is informative1c) �
equation ||| ln En(t) λk
equation ||| k=0 k!
equation ||| λ
bodyText ||| The computation of the Poisson sum requires an optimi-
bodyText ||| sation for large n(t). The implementation for this paper
bodyText ||| exploits the nature of the Poisson density: The Poisson den-
bodyText ||| sity yields only values significantly greater than zero in an
bodyText ||| interval around λ.
bodyText ||| Consider the illustration of the noise and informative-
bodyText ||| ness definitions in figure 1. The probability functions dis-
bodyText ||| played are summarised in figure 2 where the simplified Pois-
bodyText ||| son is used in the noise and informativeness graphs. The
bodyText ||| frequency-based noise corresponds to the linear solid curve
bodyText ||| in the noise figure. With an independence assumption, we
bodyText ||| obtain the curve in the lower triangle of the noise figure. By
bodyText ||| changing the parameter p := λ/N of the independence prob-
bodyText ||| ability, we can lift or lower the independence curve. The
bodyText ||| noise figure shows the lifting for the value λ := ln N �
bodyText ||| 9.2. The setting λ = ln N is special in the sense that the
bodyText ||| frequency-based and the Poisson-based informativeness have
bodyText ||| the same denominator, namely ln N, and the Poisson sum
bodyText ||| converges to λ. Whether we can draw more conclusions from
bodyText ||| this setting is an open question.
bodyText ||| We can conclude, that the lifting is desirable if we know
bodyText ||| for a collection that terms that occur in relatively few doc-
equation ||| — ln (e−λ	n(t) λk I
equation ||| Ek=1 k!
equation ||| — ln(e−λ • λ)
equation ||| λ —ln Ek=1 kk
equation ||| =
equation ||| λ — lnλ
bodyText ||| For the sum expression, the following limit holds:
bodyText ||| lim	n(t)�	λk	=eλ—1
bodyText ||| n(t)→∞	k=1	k!
bodyText ||| Ppoj(t is informative1c) :=
bodyText ||| — ln n(t)
bodyText ||| N
bodyText ||| —ln 1
bodyText ||| N
bodyText ||| — logN	N)= 1 — logN n(t) = 1 — ln In N
bodyText ||| N	N
bodyText ||| Pf, ,(t is informative1c) :=
bodyText ||| λ
bodyText ||| = 1
page ||| 232
figure ||| 0.8
figure ||| 0.6
figure ||| 0.4
figure ||| 0.2
figure ||| 0
figure ||| 1
figure ||| frequency
figure ||| independence: 1/N
figure ||| independence: ln(N)/N
figure ||| poisson: 1000
figure ||| poisson: 2000
figure ||| poisson: 1 000,2000
figure ||| frequency
figure ||| independence: 1/N
figure ||| 0.8	independence: ln(N)/N
figure ||| poisson: 1000
figure ||| poisson: 2000
figure ||| poisson: 1000,2000
figure ||| 0.6
figure ||| 0.4
figure ||| 0.2
figure ||| 0
figure ||| 1
figure ||| 0	2000 4000 6000 8000 10000
figure ||| n(t): Number of documents with term t
figure ||| 0	2000 4000 6000 8000 10000
figure ||| n(t): Number of documents with term t
figureCaption ||| Figure 1: Noise and Informativeness
figure ||| Probability function		Noise	Informativeness
figure ||| Frequency PfreQ	Def Interval	n(t)/N	ln(n(t)/N)/ln(1/N)
figure ||| 		1/N < PfreQ < 1.0	0.0 < PfreQ < 1.0
figure ||| Independence Pin	Def Interval	1 — (1 — p)n (t)	ln(1 — (1 — p)n(t))/ ln(p)
figure ||| 		p < Pin < 1 — e—λ	ln(p) < Pin < 1.0
figure ||| Poisson Ppoi	Def Interval Def	e—λEn(t) λk	(λ — ln En(t) \k )/(λ — ln λ)
figure ||| Poisson Ppoi simplified	Interval	k=1 k!	k=1
figure ||| 		e—λ • λ < Ppoi < 1 — e—λ	(λ — ln(eλ — 1))/(λ — ln λ) < Ppoi < 1.0
figure ||| 		e—λ Ek=0 kk	(λ — ln Ek=0 kk )/λ
figure ||| 		e—λ < Ppoi < 1.0	0.0 < Ppoi < 1.0
figureCaption ||| Figure 2: Probability functions
bodyText ||| uments are no guarantee for finding relevant documents,
bodyText ||| i. e. we assume that rare terms are still relatively noisy. On
bodyText ||| the opposite, we could lower the curve when assuming that
bodyText ||| frequent terms are not too noisy, i. e. they are considered as
bodyText ||| being still significantly discriminative.
bodyText ||| The Poisson probabilities approximate the independence
bodyText ||| probabilities for large n(t); the approximation is better for
bodyText ||| larger λ. For n(t) < λ, the noise is zero whereas for n(t) > λ
bodyText ||| the noise is one. This radical behaviour can be smoothened
bodyText ||| by using a multi-dimensional Poisson distribution. Figure 1
bodyText ||| shows a Poisson noise based on a two-dimensional Poisson:
equation ||| λkλk
equation ||| poisson(k, λ1, λ2) := π • e—λ1•k� +(1—π)•e- λ2 • 2
equation ||| k!
bodyText ||| The two dimensional Poisson shows a plateau between λ1 =
bodyText ||| 1000 and λ2 = 2000, we used here π = 0.5. The idea be-
bodyText ||| hind this setting is that terms that occur in less than 1000
bodyText ||| documents are considered to be not noisy (i.e. they are in-
bodyText ||| formative), that terms between 1000 and 2000 are half noisy,
bodyText ||| and that terms with more than 2000 are definitely noisy.
bodyText ||| For the informativeness, we observe that the radical be-
bodyText ||| haviour of Poisson is preserved. The plateau here is ap-
bodyText ||| proximately at 1/6, and it is important to realise that this
bodyText ||| plateau is not obtained with the multi-dimensional Poisson
bodyText ||| noise using π = 0.5. The logarithm of the noise is nor-
bodyText ||| malised by the logarithm of a very small number, namely
bodyText ||| 0.5 • e—1000 + 0.5 • e—2000. That is why the informativeness
bodyText ||| will be only close to one for very little noise, whereas for a
bodyText ||| bit of noise, informativeness will drop to zero. This effect
bodyText ||| can be controlled by using small values for π such that the
bodyText ||| noise in the interval [λ1; λ2] is still very little. The setting
bodyText ||| π = e—2000/6 leads to noise values of approximately e —2000/6
bodyText ||| in the interval [λ1; λ2], the logarithms lead then to 1/6 for
bodyText ||| the informativeness.
bodyText ||| The indepence-based and frequency-based informativeness
bodyText ||| functions do not differ as much as the noise functions do.
bodyText ||| However, for the indepence-based probability of being infor-
bodyText ||| mative, we can control the average informativeness by the
bodyText ||| definition p := λ/N whereas the control on the frequency-
bodyText ||| based is limited as we address next.
bodyText ||| For the frequency-based idf, the gradient is monotonously
bodyText ||| decreasing and we obtain for different collections the same
bodyText ||| distances of idf-values, i. e. the parameter N does not affect
bodyText ||| the distance. For an illustration, consider the distance be-
bodyText ||| tween the value idf(tn+1) of a term tn+1 that occurs in n+1
bodyText ||| documents, and the value idf(tn) of a term tn that occurs in
bodyText ||| n documents.
equation ||| idf(tn+1) — idf(tn) = ln  n
equation ||| n+ 1
bodyText ||| The first three values of the distance function are:
equation ||| idf(t2) — idf(t1) = ln(1/(1	+ 1))	=	0.69
equation ||| idf(t3) — idf(t2) = ln(1/(2	+ 1))	=	0.41
equation ||| idf(t4) — idf(t3) = ln(1/(3	+ 1))	=	0.29
bodyText ||| For the Poisson-based informativeness, the gradient decreases
bodyText ||| first slowly for small n(t), then rapidly near n(t) R� λ and
bodyText ||| then it grows again slowly for large n(t).
bodyText ||| In conclusion, we have seen that the Poisson-based defini-
bodyText ||| tion provides more control and parameter possibilities than
page ||| 233
bodyText ||| the frequency-based definition does. Whereas more control
bodyText ||| and parameter promises to be positive for the personalisa-
bodyText ||| tion of retrieval systems, it bears at the same time the dan-
bodyText ||| ger of just too many parameters. The framework presented
bodyText ||| in this paper raises the awareness about the probabilistic
bodyText ||| and information-theoretic meanings of the parameters. The
bodyText ||| parallel definitions of the frequency-based probability and
bodyText ||| the Poisson-based probability of being informative made
bodyText ||| the underlying assumptions explicit. The frequency-based
bodyText ||| probability can be explained by binary occurrence, constant
bodyText ||| containment and disjointness of documents. Independence
bodyText ||| of documents leads to Poisson, where we have to be aware
bodyText ||| that Poisson approximates the probability of a disjunction
bodyText ||| for a large number of events, but not for a small number.
bodyText ||| This theoretical result explains why experimental investiga-
bodyText ||| tions on Poisson (see [7]) show that a Poisson estimation
bodyText ||| does work better for frequent (bad, noisy) terms than for
bodyText ||| rare (good, informative) terms.
bodyText ||| In addition to the collection-wide parameter setting, the
bodyText ||| framework presented here allows for document-dependent
bodyText ||| settings, as explained for the independence probability. This
bodyText ||| is in particular interesting for heterogeneous and structured
bodyText ||| collections, since documents are different in nature (size,
bodyText ||| quality, root document, sub document), and therefore, bi-
bodyText ||| nary occurrence and constant containment are less appro-
bodyText ||| priate than in relatively homogeneous collections.
sectionHeader ||| 7. SUMMARY
bodyText ||| The definition of the probability of being informative trans-
bodyText ||| forms the informative interpretation of the idf into a proba-
bodyText ||| bilistic interpretation, and we can use the idf -based proba-
bodyText ||| bility in probabilistic retrieval approaches. We showed that
bodyText ||| the classical definition of the noise (document frequency) in
bodyText ||| the inverse document frequency can be explained by three
bodyText ||| assumptions: the term within-document occurrence prob-
bodyText ||| ability is binary, the document containment probability is
bodyText ||| constant, and the document containment events are disjoint.
bodyText ||| By explicitly and mathematically formulating the assump-
bodyText ||| tions, we showed that the classical definition of idf does not
bodyText ||| take into account parameters such as the different nature
bodyText ||| (size, quality, structure, etc.) of documents in a collection,
bodyText ||| or the different nature of terms (coverage, importance, po-
bodyText ||| sition, etc.) in a document. We discussed that the absence
bodyText ||| of those parameters is compensated by a leverage effect of
bodyText ||| the within-document term occurrence probability and the
bodyText ||| document containment probability.
bodyText ||| By applying an independence rather a disjointness as-
bodyText ||| sumption for the document containment, we could estab-
bodyText ||| lish a link between the noise probability (term occurrence
bodyText ||| in a collection), information theory and Poisson. From the
bodyText ||| frequency-based and the Poisson-based probabilities of be-
bodyText ||| ing noisy, we derived the frequency-based and Poisson-based
bodyText ||| probabilities of being informative. The frequency-based prob-
bodyText ||| ability is relatively smooth whereas the Poisson probability
bodyText ||| is radical in distinguishing between noisy or not noisy, and
bodyText ||| informative or not informative, respectively. We showed how
bodyText ||| to smoothen the radical behaviour of Poisson with a multi-
bodyText ||| dimensional Poisson.
bodyText ||| The explicit and mathematical formulation of idf- and
bodyText ||| Poisson-assumptions is the main result of this paper. Also,
bodyText ||| the paper emphasises the duality of idf and tf, collection
bodyText ||| space and document space, respectively. Thus, the result
bodyText ||| applies to term occurrence and document containment in a
bodyText ||| collection, and it applies to term occurrence and position
bodyText ||| containment in a document. This theoretical framework is
bodyText ||| useful for understanding and deciding the parameter estima-
bodyText ||| tion and combination in probabilistic retrieval models. The
bodyText ||| links between indepence-based noise as document frequency,
bodyText ||| probabilistic interpretation of idf, information theory and
bodyText ||| Poisson described in this paper may lead to variable proba-
bodyText ||| bilistic idf and tf definitions and combinations as required
bodyText ||| in advanced and personalised information retrieval systems.
bodyText ||| Acknowledgment: I would like to thank Mounia Lalmas,
bodyText ||| Gabriella Kazai and Theodora Tsikrika for their comments
bodyText ||| on the as they said “heavy” pieces. My thanks also go to the
bodyText ||| meta-reviewer who advised me to improve the presentation
bodyText ||| to make it less “formidable” and more accessible for those
bodyText ||| “without a theoretic bent”. This work was funded by a
bodyText ||| research fellowship from Queen Mary University of London.
sectionHeader ||| 8. REFERENCES
reference ||| [1] A. Aizawa. An information-theoretic perspective of
reference ||| tf-idf measures. Information Processing and
reference ||| Management, 39:45–65, January 2003.
reference ||| [2] G. Amati and C. J. Rijsbergen. Term frequency
reference ||| normalization via Pareto distributions. In 24th
reference ||| BCS-IRSG European Colloquium on IR Research,
reference ||| Glasgow, Scotland, 2002.
reference ||| [3] R. K. Belew. Finding out about. Cambridge University
reference ||| Press, 2000.
reference ||| [4] A. Bookstein and D. Swanson. Probabilistic models
reference ||| for automatic indexing. Journal of the American
reference ||| Society for Information Science, 25:312–318, 1974.
reference ||| [5] I. N. Bronstein. Taschenbuch der Mathematik. Harri
reference ||| Deutsch, Thun, Frankfurt am Main, 1987.
reference ||| [6] K. Church and W. Gale. Poisson mixtures. Natural
reference ||| Language Engineering, 1(2):163–190, 1995.
reference ||| [7] K. W. Church and W. A. Gale. Inverse document
reference ||| frequency: A measure of deviations from poisson. In
reference ||| Third Workshop on Very Large Corpora, ACL
reference ||| Anthology, 1995.
reference ||| [8] T. Lafouge and C. Michel. Links between information
reference ||| construction and information gain: Entropy and
reference ||| bibliometric distribution. Journal of Information
reference ||| Science, 27(1):39–49, 2001.
reference ||| [9] E. Margulis. N-poisson document modelling. In
reference ||| Proceedings of the 15th Annual International ACM
reference ||| SIGIR Conference on Research and Development in
reference ||| Information Retrieval, pages 177–189, 1992.
reference ||| [10] S. E. Robertson and S. Walker. Some simple effective
reference ||| approximations to the 2-poisson model for
reference ||| probabilistic weighted retrieval. In Proceedings of the
reference ||| 17th Annual International ACM SIGIR Conference on
reference ||| Research and Development in Information Retrieval,
reference ||| pages 232–241, London, et al., 1994. Springer-Verlag.
reference ||| [11] S. Wong and Y. Yao. An information-theoric measure
reference ||| of term specificity. Journal of the American Society
reference ||| for Information Science, 43(1):54–61, 1992.
reference ||| [12] S. Wong and Y. Yao. On modeling information
reference ||| retrieval with probabilistic inference. ACM
reference ||| Transactions on Information Systems, 13(1):38–68,
reference ||| 1995.
page ||| 234

title ||| A Geometric Constraint Library for
title ||| 3D Graphical Applications
author ||| Hiroshi Hosobe
affiliation ||| National Institute of Informatics
address ||| 2-1-2 Hitotsubashi, Chiyoda-ku, Tokyo 101-8430, Japan
email ||| hosobe@nii.ac.jp
sectionHeader ||| ABSTRACT
bodyText ||| Recent computer technologies have enabled fast high-quality
bodyText ||| 3D graphics on personal computers, and also have made
bodyText ||| the development of 3D graphical applications easier. How-
bodyText ||| ever, most of such technologies do not sufficiently support
bodyText ||| layout and behavior aspects of 3D graphics. Geometric con-
bodyText ||| straints are, in general, a powerful tool for specifying layouts
bodyText ||| and behaviors of graphical objects, and have been applied
bodyText ||| to 2D graphical user interfaces and specialized 3D graph-
bodyText ||| ics packages. In this paper, we present Chorus3D, a geo-
bodyText ||| metric constraint library for 3D graphical applications. It
bodyText ||| enables programmers to use geometric constraints for vari-
bodyText ||| ous purposes such as geometric layout, constrained dragging,
bodyText ||| and inverse kinematics. Its novel feature is to handle scene
bodyText ||| graphs by processing coordinate transformations in geomet-
bodyText ||| ric constraint satisfaction. We demonstrate the usefulness of
bodyText ||| Chorus3D by presenting sample constraint-based 3D graph-
bodyText ||| ical applications.
sectionHeader ||| Keywords
keyword ||| geometric constraints, constraint satisfaction, geometric lay-
keyword ||| out, 3D graphics, scene graphs
sectionHeader ||| 1. INTRODUCTION
bodyText ||| Recent advances in commodity hardware have enabled fast
bodyText ||| high-quality 3D graphics on personal computers. Also, soft-
bodyText ||| ware technologies such as VRML and Java 3D have made the
bodyText ||| development of 3D graphical applications easier. However,
bodyText ||| most of such technologies mainly focus on rendering aspects
bodyText ||| of 3D graphics, and do not sufficiently support layout and
bodyText ||| behavior aspects.
bodyText ||| Constraints are, in general, a powerful tool for specifying
bodyText ||| layouts and behaviors of graphical objects. It is widely
bodyText ||| recognized that constraints facilitate describing geometric
bodyText ||| layouts and behaviors of diagrams in 2D graphical user in-
bodyText ||| terfaces such as drawing editors, and therefore constraint
bodyText ||| solvers for this purpose have been extensively studied [3, 7,
copyright ||| Permission to make digital or hard copies of all or part of this work for
copyright ||| personal or classroom use is granted without fee provided that copies are
copyright ||| not made or distributed for profit or commercial advantage and that copies
copyright ||| bear this notice and the full citation on the first page. To copy otherwise, to
copyright ||| republish, to post on servers or to distribute to lists, requires prior specific
copyright ||| permission and/or fee.
note ||| Int. Symp. on Smart Graphics, June 11-13, 2002, Hawthorne, NY, USA.
note ||| Copyright 2002 ACM 1-58113-555-6/02/0600...$5.00
bodyText ||| 8, 9, 11, 12, 13, 17, 18]. Also, many specialized 3D graph-
bodyText ||| ics packages enable the specification of object layouts and
bodyText ||| behaviors by using constraints or similar functions.
bodyText ||| It is natural to consider that various 3D graphical applica-
bodyText ||| tions can also be enhanced by incorporating constraints. It
bodyText ||| might seem sufficient for this purpose to modify existing 2D
bodyText ||| geometric constraint solvers to support 3D geometry. It is,
bodyText ||| however, insufficient in reality because of the essential dif-
bodyText ||| ference between the ways of specifying 2D and 3D graphics;
bodyText ||| typical 2D graphics handles only simple coordinate systems,
bodyText ||| whereas most 3D graphics requires multiple coordinate sys-
bodyText ||| tems with complex relations such as rotations to treat scene
bodyText ||| graphs. It means that we need to additionally support coor-
bodyText ||| dinate transformations in 3D geometric constraint solvers.
bodyText ||| In this paper, we present Chorus3D, a geometric constraint
bodyText ||| library for 3D graphical applications. The novel feature of
bodyText ||| Chorus3D is to handle scene graphs by processing coordi-
bodyText ||| nate transformations in geometric constraint satisfaction.
bodyText ||| We have realized Chorus3D by adding this feature to our
bodyText ||| previous 2D geometric constraint library Chorus [13].
bodyText ||| Another important point of Chorus3D is that it inherits from
bodyText ||| Chorus the capability to handle “soft” constraints with hier-
bodyText ||| archical strengths or preferences (i.e., constraint hierarchies
bodyText ||| [7]), which are useful for specifying default layouts and be-
bodyText ||| haviors of graphical objects. It determines solutions so that
bodyText ||| they satisfy as many strong constraints as possible, leaving
bodyText ||| weaker inconsistent constraints unsatisfied.
bodyText ||| Chorus3D also inherits from Chorus a module mechanism
bodyText ||| which allows user-defined kinds of geometric constraints.
bodyText ||| This feature enables programmers to use geometric con-
bodyText ||| straints for various purposes including the following:
listItem ||| Geometric layout: A typical use of Chorus3D is to lay
listItem ||| out graphical objects. For example, it allows putting
listItem ||| objects parallel or perpendicular to others without re-
listItem ||| quiring predetermined positioning parameters. Also, it
listItem ||| provides constraint-based general graph layout based
listItem ||| on the spring model [14].
listItem ||| Constrained dragging: Chorus3D enables dragging ob-
listItem ||| jects with positioning constraints. For example, it
listItem ||| can constrain a dragged object to be on the surface
listItem ||| of a sphere. Constrained dragging is important for 3D
listItem ||| graphics because it provides a sophisticated way to ac-
page ||| 94
listItem ||| Translation: A translation transformation is characterized
listItem ||| with three variables tx, tr, and tz, and specifies the
listItem ||| translation of vector (tx,tr, tz).
listItem ||| Rotation: A rotation transformation is parameterized with
listItem ||| four variables rx, rr, rz, and rw, and specifies the ro-
listItem ||| tation of angle rw about the axis (rx, rr, rz).
listItem ||| Scale: A scale transformation is represented with three
listItem ||| variables sx, sr, and sz, and specifies the axis-wise
listItem ||| scale (sx, sr, sz) about the origin.
bodyText ||| We can express many practically useful transformations by
bodyText ||| using such elemental ones. In fact, any transformations rep-
bodyText ||| resented with Transform nodes in VRML can be realized by
bodyText ||| combining these kinds of transformations [4].
sectionHeader ||| 3. CONSTRAINT FRAMEWORK
bodyText ||| In this section, we briefly describe our framework for han-
bodyText ||| dling constraints. We base it on the framework for the 2D
bodyText ||| version of the Chorus constraint solver. See [13] for further
bodyText ||| detail.
subsectionHeader ||| 3.1 Problem Formulation
bodyText ||| We first present the mathematical formulation for modeling
bodyText ||| constraints and constraint systems. In the following, we
bodyText ||| write x to represent a variable vector (x1, x2, ... , xn) of
bodyText ||| n variables, and also v to indicate a variable value vector
bodyText ||| (v1, v2, ... , vn) of n real numbers (vi expresses the value of
bodyText ||| xi).
bodyText ||| To support various geometric constraints in a uniform man-
bodyText ||| ner, we adopt error functions as a means of expressing con-
bodyText ||| straints. An error function e(x) is typically associated with
bodyText ||| a single arithmetic constraint, and is defined as a func-
bodyText ||| tion from variable value vectors to errors expressed as non-
bodyText ||| negative real numbers; that is, e(v) gives the error of the
bodyText ||| associated constraint for v. An error function returns a zero
bodyText ||| if and only if the constraint is exactly satisfied. For example,
bodyText ||| e(x) = (xi — xj)2 can be used for the constraint xi = xj.
bodyText ||| We assume that, for each e(x), its gradient is known:
equation ||| De(x) =	�ae(x) ae(x) ae(x) ax1,ax2 ,...,axn )
bodyText ||| In the same way as constraint hierarchies [7], constraint sys-
bodyText ||| tems in our framework can be divided into levels consisting
bodyText ||| of constraints with equal strengths. Constraints with the
bodyText ||| strongest preference are said to be required (or hard), and
bodyText ||| are guaranteed to be always satisfied (if it is impossible,
bodyText ||| there will be no solution). By contrast, constraints with
bodyText ||| weaker preferences are said to be preferential (or soft), and
bodyText ||| may be relaxed if they conflict with stronger constraints.
bodyText ||| Solutions to constraint systems are defined as follows: let
bodyText ||| ei,j(x) be the error function of the j-th constraint (1 < j <
bodyText ||| mi) at strength level i (0 < i < l); then solutions v are
bodyText ||| determined with the optimization problem
bodyText ||| minimize	E(v) subject to e0,j (v) = 0 (1 < j < m0)
none ||| v
bodyText ||| commodate ordinary mouse dragging to 3D spaces.
bodyText ||| Inverse kinematics: Chorus3D is applicable to inverse
bodyText ||| kinematics, which is a problem of finding desired con-
bodyText ||| figurations of “articulated” objects [1, 20]. It allows
bodyText ||| the specification of articulated objects by using coor-
bodyText ||| dinate transformations, and can automatically calcu-
bodyText ||| late the parameters of the transformations that satisfy
bodyText ||| constraints. This method is also applicable to camera
bodyText ||| control by aiming at a possibly moving target object.
bodyText ||| In this paper, we demonstrate the usefulness of Chorus3D
bodyText ||| by presenting sample constraint-based 3D graphical appli-
bodyText ||| cations.
bodyText ||| This paper is organized as follows: We first present our ap-
bodyText ||| proach to the use of constraints for 3D graphics. Second,
bodyText ||| we describe our basic framework of constraints. Next, we
bodyText ||| present a method for processing coordinate transformations
bodyText ||| in our framework. We then provide the implementation of
bodyText ||| Chorus3D, and demonstrate examples of using constraints
bodyText ||| in 3D graphics. After giving related work and discussion, we
bodyText ||| mention the conclusions and future work of this research.
sectionHeader ||| 2. OUR APPROACH
bodyText ||| In this research, we integrate geometric constraints with 3D
bodyText ||| graphics. Basically, we realize this by extending our previ-
bodyText ||| ous 2D geometric constraint solver Chorus [13] to support
bodyText ||| 3D geometry. However, as already mentioned, it is not a
bodyText ||| straightforward task because 3D graphics typically requires
bodyText ||| handling scene graphs with hierarchical structures of coor-
bodyText ||| dinate systems, which is not covered by the 2D version of
bodyText ||| the Chorus constraint solver.
bodyText ||| To support hierarchies of coordinate systems, we introduce
bodyText ||| the following new model of constraints:
listItem ||| Point variables: Each point variable (which consists of
listItem ||| three real-valued constrainable variables) is associated
listItem ||| with one coordinate system, and its value is expressed
listItem ||| as local coordinates.
listItem ||| Geometric constraints: Geometric constraints on point
listItem ||| variables are evaluated by using the world coordinates
listItem ||| of the point variables (they can also refer to 1D vari-
listItem ||| ables for, e.g., distances and angles by using their val-
listItem ||| ues directly). A single constraint can refer to point
listItem ||| variables belonging to different coordinate systems.
listItem ||| Coordinate transformations: Parameters of coordinate
listItem ||| transformations are provided as constrainable vari-
listItem ||| ables, and the solver is allowed to change the param-
listItem ||| eters of transformations to appropriately satisfy given
listItem ||| constraints.
bodyText ||| With this model, we can gain the benefit of the easy mainte-
bodyText ||| nance of geometric relations by using constraints, as well as
bodyText ||| the convenience of modeling geometric objects by employing
bodyText ||| scene graphs.
bodyText ||| In our actual implementation, we provide the following three
bodyText ||| elemental kinds of coordinate transformations:
page ||| 95
bodyText ||| where E is an objective function defined as
equation ||| wiei,j (x)
bodyText ||| in which wi indicates the weight associated with strength i,
bodyText ||| and the relation w1 » w2 » . . . » wl holds. In this formu-
bodyText ||| lation, level 0 corresponds to required constraints, and the
bodyText ||| others to preferential ones. Intuitively, more weighted (or
bodyText ||| stronger) preferential constraints should be more satisfied.
bodyText ||| Our framework simulates constraint hierarchies. Particu-
bodyText ||| larly, if the squares of constraint violations are used to com-
bodyText ||| pute error functions, a system in our framework will obtain
bodyText ||| approximate solutions to the similar hierarchy solved with
bodyText ||| the criterion least-squares-better [3, 17]. The largest differ-
bodyText ||| ence is that a system in our framework slightly considers a
bodyText ||| weak constraint inconsistent with a stronger satisfiable one
bodyText ||| in computing its solutions, while the similar hierarchy would
bodyText ||| discard such a weak one.
bodyText ||| Our actual implementation of the Chorus3D constraint
bodyText ||| solver provides four external strengths required, strong,
bodyText ||| medium, and weak as well as two internal strengths very
bodyText ||| strong (used to approximately handle required nonlinear
bodyText ||| or inequality constraints) and very weak (exploited to make
bodyText ||| new solutions as close to previous ones as possible). It typ-
bodyText ||| ically assigns weights 324, 323, 322, 321, and 1 to strengths
bodyText ||| very strong, strong, medium, weak, and very weak respec-
bodyText ||| tively. These weights were determined according to the pre-
bodyText ||| cision of the actual numerical algorithm (described in the
bodyText ||| next subsection). To know how much these weights affect
bodyText ||| solutions, suppose a system of strong constraint x = 0 and
bodyText ||| medium one x = 100. Then the unique solution will be ob-
bodyText ||| tained as x = 3.0303 . . . (= 100/33). Thus the difference of
bodyText ||| strengths is obvious. According to our actual experience,
bodyText ||| this precision allows us to discriminate constraint strengths
bodyText ||| in most graphical applications.
subsectionHeader ||| 3.2 Algorithm
bodyText ||| To actually find solutions to constraint systems presented
bodyText ||| above, we need to solve their corresponding optimization
bodyText ||| problems. For this purpose, we designed a constraint sat-
bodyText ||| isfaction algorithm by combining a numerical optimization
bodyText ||| technique with a genetic algorithm. It uses numerical op-
bodyText ||| timization to find local solutions, while it adopts a genetic
bodyText ||| algorithm to search for global solutions.
bodyText ||| For numerical optimization, we mainly use the quasi-Newton
bodyText ||| method based on Broyden-Fletcher-Goldfarb-Sahnno updat-
bodyText ||| ing formula [2, 6], which is a fast iterative technique that
bodyText ||| exhibits superlinear convergence. Since it excludes fruit-
bodyText ||| less searches by utilizing its history, it is usually faster than
bodyText ||| straightforward Newton’s method.
bodyText ||| We introduced a genetic algorithm to alleviate the problem
bodyText ||| that some kinds of geometric constraints suffer from local op-
bodyText ||| timal but global non-optimal solutions [11, 16]. Generally,
bodyText ||| a genetic algorithm is a stochastic search method that re-
bodyText ||| peatedly transforms a population of potential solutions into
bodyText ||| another next-generation population [10, 15]. We typically
bodyText ||| necessitate it only for computing initial solutions; in other
bodyText ||| words, we can usually re-solve modified constraint systems
bodyText ||| without the genetic algorithm, only by applying numerical
bodyText ||| optimization to previous solutions.
sectionHeader ||| 4. PROCESSING COORDINATE
sectionHeader ||| TRANSFORMATIONS
bodyText ||| In this section, we propose a method for integrating coordi-
bodyText ||| nate transformations with our constraint framework.
bodyText ||| As already mentioned, we use world coordinates of points
bodyText ||| to evaluate 3D geometric constraints. A naive method for
bodyText ||| this is to duplicate point variables in all ancestor coordinate
bodyText ||| systems, and then to impose required constraints that rep-
bodyText ||| resent coordinate transformations between the point vari-
bodyText ||| ables. However, this method requires an optimization rou-
bodyText ||| tine supporting required nonlinear constraints, which lim-
bodyText ||| its the availability of actual techniques (in fact, we cannot
bodyText ||| use the quasi-Newton method for this purpose). Also, this
bodyText ||| method tends to yield many variables and constraints, and
bodyText ||| therefore requires an extra amount of memory.
bodyText ||| Below we propose a more widely applicable method for han-
bodyText ||| dling coordinate transformations. Its characteristic is to
bodyText ||| hide transformations from optimization routines, which is
bodyText ||| realized by embedding transformations in error functions.
subsectionHeader ||| 4.1 Model
bodyText ||| To begin with, we introduce another variable vector x' =
bodyText ||| (x'1, x'2, ... ,x' n), which is created by replacing variables for
bodyText ||| local coordinates of 3D points in x with the corresponding
bodyText ||| ones for world coordinates (1D variables remain the same).
bodyText ||| We can mathematically model this process as follows: Con-
bodyText ||| sider the sequence of the s transformations
equation ||| t0	t1	s 2	ts 1
equation ||| y0 (= x)� y1 �... t y3-1 —� y3 (= x')
bodyText ||| where y0 and y3 are equal to x and x' respectively, each
bodyText ||| yk (1 < k < s — 1) is an “intermediate” vector, and each tk
bodyText ||| (0 < k < s — 1) is a function that transforms yk into yk+1.
bodyText ||| Intuitively, tk corresponds to a coordinate transformation,
bodyText ||| and transforms related point variables from its source co-
bodyText ||| ordinate system into its destination system. It should be
bodyText ||| noted that, although transformations are, in general, hier-
bodyText ||| archical (or tree-structured), we can always find such a linear
bodyText ||| sequence by “serializing” them in an appropriate order.
bodyText ||| By using such transformations, we can compute x' as fol-
bodyText ||| lows:
equation ||| x' = t3-1(t3-2(...(t1(t0(x))) ... )) = t(x)
bodyText ||| where t is defined as the composition of all the elemental
bodyText ||| transformations. In the following description, we write yk,i
bodyText ||| to denote the i-th element of yk, and also tk,i to represent
bodyText ||| the i-th element of tk; that is,
equation ||| yk+1 = (yk+1,1 , yk+1,2, ... , yk+1,n)
equation ||| = (tk,1(yk),tk,2(yk), ..., tk,n(yk)) = tk(yk).
subsectionHeader ||| 4.2 Method
bodyText ||| Geometric constraints are evaluated by using world coordi-
bodyText ||| nates of points, which means that their error functions are
equation ||| Mi
equation ||| E
equation ||| j=1
equation ||| E(x) =
equation ||| �l
equation ||| i=1
page ||| 96
bodyText ||| defined as e(x'). Using the composed transformations, we	parameter of the coordinate transformation), we have
bodyText ||| can evaluate them as	yk,i = xi, which means that we have atk,j(yk)/axi.
bodyText ||| e(x') = e(t(x)).	Therefore, we can compute ae(x')/axi immediately.
bodyText ||| Importantly, we can efficiently realize this computation by
bodyText ||| applying only necessary transformations to actually used
bodyText ||| variables.
bodyText ||| We also need to compute the gradient of e(t(x)), i.e.,
equation ||| �ae(t(x)) ae(t(x)) ae(t(x))
equation ||| ax1 , ax2 , ..., axn ) .
bodyText ||| Basically, we can decompose each partial derivative
bodyText ||| ae(t(x))/axi into primitive expressions by repeatedly us-
bodyText ||| ing the chain rule. However, we should avoid the simple
bodyText ||| application of the chain rule since it would result in a large
bodyText ||| number of expressions.
bodyText ||| Instead, we perform a controlled way of decomposing such
bodyText ||| partial derivatives; it appropriately arranges the chain rule
bodyText ||| to restrict the computation to only necessary components.
bodyText ||| First, we decompose ae(t(x))/axi as follows:
equation ||| ats-1,j,(ys-1)
equation ||| axi
equation ||| ae(x')	ats-1,j,(ys-1)ats-2,js_1(ys-2)
equation ||| axj,Eays-1,js_1	axi
equation ||| js_1
equation ||| ats-2,js_1(ys-2)
equation ||| axi
equation ||| ae(x') ats-2,js_1(ys-2)
equation ||| ays-1,js_1	axi	.
bodyText ||| Note that each ae(x')/ax'j, is given by the defini-
bodyText ||| tion of the geometric constraint, and also that each
bodyText ||| ats-1,j,(ys-1)/ays-1,js_1 is a partial derivative in the gra-
bodyText ||| dient of a single coordinate transformation ts-1. Thus we
bodyText ||| can obtain each ae(x')/ays-1 ,js_1. Also, by repeating this
bodyText ||| process, we can compute, for each k,
equation ||| atk-1,jk (yk-1)
bodyText ||| and finally achieve
equation ||| ae(t(x))
equation ||| axi
equation ||| where each at0,j1(x)/axi is a component of the gradient of
bodyText ||| t0. Therefore, ae(t(x))/axi is now determined.
bodyText ||| Furthermore, we can considerably reduce the number of the
bodyText ||| computations of ae(x')/ayk,jk in practice. We can make the
bodyText ||| following observations about the above computation:
bodyText ||| 9 For each variable xj,, ae(x')/ax'j, can be non-zero only
bodyText ||| if xj,is actually needed to evaluate the designated con-
bodyText ||| straint.
bodyText ||| 9 If xi is originated in the coordinate system associated
bodyText ||| with tk (that is, xi is either a local coordinate or a
bodyText ||| These observations reveal that we need to transfer a partial
bodyText ||| derivative ae(x')/ayk,j to the next step only when xj rep-
bodyText ||| resents a really necessary coordinate that has not reached
bodyText ||| its local coordinate system. Also, since we can handle each
bodyText ||| necessary point independently, we can implement this pro-
bodyText ||| cess with a linear recursive function that hands over only
bodyText ||| three derivatives ae(x')/ayk,j at each recursive call.
sectionHeader ||| 5. IMPLEMENTATION
bodyText ||| We implemented the proposed method by developing a con-
bodyText ||| straint solver called Chorus3D, which is a 3D extension to
bodyText ||| our previous 2D geometric constraint solver Chorus [13]. We
bodyText ||| constructed Chorus3D as a C++ class library, and also de-
bodyText ||| veloped a native method interface to make it available to
bodyText ||| Java programs.
bodyText ||| Chorus3D allows programmers to add a new kind of arith-
bodyText ||| metic constraints (e.g., Euclidean geometric constraints) by
bodyText ||| constructing a new constraint class with a method that eval-
bodyText ||| uates their error functions. Also, programmers can intro-
bodyText ||| duce a new kind of non-arithmetic (or pseudo) constraints
bodyText ||| (for, e.g., general graph layout) by developing a new evalua-
bodyText ||| tion module which computes an “aggregate” error function
bodyText ||| for a given set of constraints.
bodyText ||| Chorus3D currently provides linear equality, linear inequal-
bodyText ||| ity, edit (update a variable value), stay (fix a variable value),
bodyText ||| Euclidean geometric constraints (for, e.g., parallelism, per-
bodyText ||| pendicularity, and distance equality), and graph layout con-
bodyText ||| straints based on the spring model [14]. Linear equality/
bodyText ||| inequality constraints can refer to only 1D variables (includ-
bodyText ||| ing elements of 3D point variables), while edit and stay con-
bodyText ||| straints can be associated with 1D and 3D point variables.
bodyText ||| Euclidean geometric constraints typically refer to point vari-
bodyText ||| ables although they sometimes require 1D variables for an-
bodyText ||| gles and distances. Each graph layout constraint represents
bodyText ||| a graph edge, and refers to two point variables as its asso-
bodyText ||| ciated graph nodes. As stated earlier, constraints on such
bodyText ||| point variables are evaluated by using world coordinates of
bodyText ||| the points. Also, a single constraint can refer to point vari-
bodyText ||| ables belonging to different coordinate systems.
bodyText ||| The application programming interface of Chorus3D is a
bodyText ||| natural extension to that of Chorus, which provides a certain
bodyText ||| compatibility with a recent linear solver called Cassowary
bodyText ||| [3]; in a similar way to Cassowary and Chorus, Chorus3D
bodyText ||| allows programmers to process constraint systems by cre-
bodyText ||| ating variables and constraints as objects, and by adding/
bodyText ||| removing constraint objects to/from the solver object. In
bodyText ||| addition, Chorus3D handles coordinate transformations as
bodyText ||| objects, and presents an interface for arranging them hier-
bodyText ||| archically.
sectionHeader ||| 6. EXAMPLES
bodyText ||| In this section, we present three examples to demonstrate
bodyText ||| how to incorporate geometric constraints into 3D graphics
bodyText ||| by using the Chorus3D constraint solver. All the examples
bodyText ||| are implemented in Java by using Java 3D as a graphics
equation ||| De(t(x)) =
equation ||| ae(t(x))
equation ||| axi
equation ||| =E
equation ||| j,
equation ||| ae(x')
equation ||| ax'j,
equation ||| =E
equation ||| j,
equation ||| = E
equation ||| js_1
equation ||| = E
equation ||| js_1
equation ||| I
equation ||| ats1,j, (ys-1)
equation ||| ae(x')
equation ||| E
equation ||| ays-1,js_1
equation ||| j,
equation ||| ax'j,
equation ||| I
equation ||| ae(t(x))
equation ||| axi
equation ||| =E	ae(x')
equation ||| jk
equation ||| 	ayk,jk
equation ||| =E	ae(x')
equation ||| j1
equation ||| 	ay1,j1
equation ||| axi
equation ||| at0,j1(x)
equation ||| axi
page ||| 97
figureCaption ||| Figure 1: A 3D geometric layout of a general graph
figureCaption ||| structure.
figureCaption ||| Figure 2: Dragging an object constrained to be on
figureCaption ||| a sphere.
bodyText ||| programming interface as well as the native method interface
bodyText ||| with Chorus3D. We also provide computation times taken
bodyText ||| for constraint satisfaction in these examples.
subsectionHeader ||| 6.1 Graph Layout
bodyText ||| The first example is an application which lays out a set
bodyText ||| of points with a general graph structure in a 3D space as
bodyText ||| shown in Figure 1. This application also allows a user to
bodyText ||| drag graph nodes with a mouse.' The used graph layout
bodyText ||| technique is based on a 3D extension to the spring model
bodyText ||| [14]. This kind of 3D graph layout is practically useful to
bodyText ||| information visualization, and has actually been adopted in
bodyText ||| a certain system [19].
bodyText ||| The constraint system of this graph layout consists of 26
bodyText ||| point variables (i.e., 78 real-valued variables), 31 graph lay-
bodyText ||| out constraints, and three linear equality constraints for fix-
bodyText ||| ing one of the point variables at the origin. When executed
bodyText ||| on an 866 MHz Pentium III processor running Linux 2.2.16,
bodyText ||| Chorus3D obtained an initial solution in 456 milliseconds. It
bodyText ||| performed constraint satisfaction typically within 250 mil-
bodyText ||| liseconds to reflect the user’s dragging a graph node.
subsectionHeader ||| 6.2 Constrained Dragging
bodyText ||| The second example is an application which allows a user
bodyText ||| to drag an object constrained to be on another spherical
bodyText ||| object. Figure 2 depicts this application, where the smaller
bodyText ||| solid spherical object is constrained to be on the surface of
bodyText ||| the larger wireframe one. The application declares a strong
bodyText ||| Euclidean geometric constraint which specifies a constant
bodyText ||| distance between the centers of these objects. When the
bodyText ||| user tries to drag the smaller object with a mouse, the appli-
bodyText ||| cation imposes another medium Euclidean constraint which
bodyText ||| collinearly locates the viewpoint, the 3D position of the
bodyText ||| mouse cursor (which is considered to be on the screen), and
footnote ||| 'Unlike constrained dragging in the next example, this
footnote ||| mouse operation is simply implemented with Java 3D’s
footnote ||| PickMouseBehavior classes.
footnote ||| Sphere
figureCaption ||| Figure 3: Implementation of constrained dragging.
bodyText ||| the center of the dragged object as shown in Figure 3. This
bodyText ||| collinearity constraint reflects the motion of the mouse in
bodyText ||| the position of the dragged object. Since the collinearity
bodyText ||| constraint is weaker than the first Euclidean constraint, the
bodyText ||| user cannot drag the smaller object to the outside of the
bodyText ||| larger sphere.
bodyText ||| The application initially declares one Euclidean geometric
bodyText ||| constraint on two point variables, and solved it in 1 mil-
bodyText ||| lisecond on the same computer as the first example. When
bodyText ||| the user tries to drag the smaller object, it adds another
bodyText ||| Euclidean constraint as well as two edit constraints for the
bodyText ||| viewpoint and mouse position. The solver maintained this
bodyText ||| constraint system usually within 2 milliseconds.
subsectionHeader ||| 6.3 Inverse Kinematics
bodyText ||| The final example applies inverse kinematics to a virtual
bodyText ||| robot arm by using constraints. Unlike the previous ex-
bodyText ||| amples, it takes advantage of coordinate transformations to
bodyText ||| express its constraint system.
figure ||| Mouse cursor which
figure ||| is on the screen
figure ||| Viewpoint
figure ||| Distance
figure ||| constraint
figure ||| Collinearity
figure ||| constraint
figure ||| Object which is on
figure ||| the sphere surface
figure ||| Screen
page ||| 98
figure ||| (a)	(b)	(c)
figureCaption ||| Figure 4: A robot arm application which performs inverse kinematics.
figure ||| (d)	(e)	(f)
bodyText ||| As illustrated in Figure 4(a), the robot arm consists of four
bodyText ||| parts called a base, a shoulder, an upper arm, and a forearm.
bodyText ||| Constraint satisfaction for inverse kinematics is performed
bodyText ||| to position its hand (the end of the forearm) at the target
bodyText ||| object if possible, or otherwise to make it maximally close
bodyText ||| to the target. Figures 4(b)–(f) show the movement of the
bodyText ||| robot arm. In Figures 4(b)–(e), its hand is positioned at
bodyText ||| the exact location of the target by using appropriate angles
bodyText ||| of its joints. By contrast, in Figure 4(f), the hand cannot
bodyText ||| reach the target, and therefore the arm is extended toward
bodyText ||| the target instead.
bodyText ||| Figure 5 describes the constraint program used in the robot
bodyText ||| arm application. After constructing a constraint solver
bodyText ||| s, it creates six coordinate transformations shldrTTfm,
bodyText ||| shldrRTfm, uarmTTfm, uarmRTfm, farmTTfm, and farmRTfm.
bodyText ||| Here the rotation angle parameters of the rotation trans-
bodyText ||| formations shldrRTfm, uarmRTfm, and farmRTfm will actu-
bodyText ||| ally work as variables that can be altered by the solver.
bodyText ||| Next, it generates a point variable handPos to represent
bodyText ||| the position of the hand, and then suggests the target po-
bodyText ||| sition to the hand by using a preferential edit constraint
bodyText ||| editHandPos. Finally, executing the solver, it obtains the
bodyText ||| desired angles shldrAngle, uarmAngle, and farmAngle of
bodyText ||| the rotation transformations. These angles will be passed
bodyText ||| to the Java 3D library to render the properly configured
bodyText ||| robot arm.
bodyText ||| This program generates a constraint system which contains
bodyText ||| three translation and three rotation transformations, one ex-
bodyText ||| plicit point variable as well as six point variables and three
bodyText ||| 1D variables for coordinate transformations, and one edit
bodyText ||| constraint. The solver found an initial solution to this sys-
bodyText ||| tem in 18 milliseconds, and obtained each new solution for
bodyText ||| a frame update typically within 10 milliseconds.
sectionHeader ||| 7. RELATED WORK AND DISCUSSION
bodyText ||| There has been work on integrating constraints or similar
bodyText ||| functions with 3D graphics languages to facilitate the spec-
bodyText ||| ification of graphical objects. For example, we can view the
bodyText ||| event routing mechanism in VRML [4] as a limited form of
bodyText ||| one-way propagation constraints. Also, there is an attempt
bodyText ||| to extend VRML by introducing one-way propagation and
bodyText ||| finite-domain combinatorial constraints [5]. However, they
bodyText ||| cannot handle more powerful simultaneous nonlinear con-
bodyText ||| straints such as Euclidean geometric constraints.
bodyText ||| Although many constraint solvers have been developed in
page ||| 99
figure ||| // constraint solver
figure ||| s = new C3Solver();
figure ||| // translation transformation for the shoulder: fixed to (0, .1, 0)
figure ||| shldrTTfm = new C3TranslateTransform(new C3Domain3D(0, .1, 0));
figure ||| s.add(shldrTTfm); // shldrTTfm is parented by the world coordinate system
figure ||| // rotation transformation for the shoulder: axis fixed to (0, 1, 0); angle ranging over [-10000, 10000]
figure ||| shldrRTfm = new C3RotateTransform(new C3Domain3D(0, 1, 0), new C3Domain(-10000, 10000));
figure ||| s.add(shldrRTfm, shldrTTfm); // shldrRTfm is parented by shldrTTfm
figure ||| // translation transformation for the upper arm: fixed to (0, .1, 0)
figure ||| uarmTTfm = new C3TranslateTransform(new C3Domain3D(0, .1, 0));
figure ||| s.add(uarmTTfm, shldrRTfm); // uarmTTfm is parented by shldrRTfm
figure ||| // rotation transformation for the upper arm: axis fixed to (0, 0, 1); angle ranging over [-1.57,1.57]
figure ||| uarmRTfm = new C3RotateTransform(new C3Domain3D(0, 0, 1), new C3Domain(-1.57, 1.57));
figure ||| s.add(uarmRTfm, uarmTTfm); // uarmRTfm is parented by uarmTTfm
figure ||| // translation transformation for the forearm: fixed to (0, .5, 0)
figure ||| farmTTfm = new C3TranslateTransform(new C3Domain3D(0, .5, 0));
figure ||| s.add(farmTTfm, uarmRTfm); // farmTTfm is parented by uarmRTfm
figure ||| // rotation transformation for the forearm: axis fixed to (0, 0, 1); angle ranging over [-3.14, 0]
figure ||| farmRTfm = new C3RotateTransform(new C3Domain3D(0, 0, 1), new C3Domain(-3.14, 0));
figure ||| s.add(farmRTfm, farmTTfm); // farmRTfm is parented by farmTTfm
figure ||| // variable for the hand’s position, associated with farmRTfm and fixed to (0, .5, 0)
figure ||| handPos = new C3Variable3D(farmRTfm, new C3Domain3D(0, .5, 0));
figure ||| // medium-strength edit constraint for the hand’s position
figure ||| editHandPos = new C3EditConstraint(handPos, C3.MEDIUM);
figure ||| s.add(editHandPos);
figure ||| // suggest the hand being located at the target’s position
figure ||| editHandPos.set(getTargetWorldCoordinates() );
figure ||| // solve the constraint system
figure ||| s.solve();
figure ||| // get solutions
figure ||| double shldrAngle = shldrRTfm.rotationAngle().value() ;
figure ||| double uarmAngle = uarmRTfm.rotationAngle().value();
figure ||| double farmAngle = farmRTfm.rotationAngle().value();
figureCaption ||| Figure 5: Constraint program for the robot arm application.
bodyText ||| the field of graphical user interfaces [3, 7, 11, 12, 13, 17, 18],
bodyText ||| most of them do not provide special treatment for 3D graph-
bodyText ||| ics. In general, the role of nonlinear geometric constraints
bodyText ||| is more important in 3D applications than in 2D interfaces.
bodyText ||| Most importantly, 3D graphics usually requires rotations of
bodyText ||| objects which are rarely used in 2D interfaces. The main
bodyText ||| reason is that we often equally treat all “horizontal” direc-
bodyText ||| tions in a 3D space even if we may clearly distinguish them
bodyText ||| from “vertical” directions. Therefore, nonlinear constraint
bodyText ||| solvers are appropriate for 3D applications. In addition, co-
bodyText ||| ordinate transformations should be supported since they are
bodyText ||| typically used to handle rotations of objects.
bodyText ||| Gleicher proposed the differential approach [8, 9], which sup-
bodyText ||| ports 3D geometric constraints and coordinate transforma-
bodyText ||| tions. In a sense, it shares a motivation with Chorus3D; in
bodyText ||| addition to support for 3D graphics, it allows user-defined
bodyText ||| kinds of geometric constraints. However, it is based on a dif-
bodyText ||| ferent solution method from Chorus3D; it realizes constraint
bodyText ||| satisfaction by running virtual dynamic simulations. This
bodyText ||| difference results in a quite different behavior of solutions as
bodyText ||| well as an interface for controlling solutions. By contrast,
bodyText ||| Chorus3D provides a much more compatible interface with
bodyText ||| recent successful solvers such as Cassowary [3].
bodyText ||| Much research on inverse kinematics has been conducted in
bodyText ||| the fields of computer graphics and robotics [1, 20]. How-
bodyText ||| ever, inverse kinematics is typically implemented as special-
bodyText ||| ized software which only provides limited kinds of geometric
bodyText ||| constraints.
bodyText ||| Chorus3D has two limitations in its algorithm: one is on the
bodyText ||| precision of solutions determined by preferential constraints;
bodyText ||| the other is on the speed of the satisfaction of large con-
bodyText ||| straint systems. These limitations are mainly caused by the
bodyText ||| treatment of multi-level preferences of constraints in addi-
bodyText ||| tion to required constraints (i.e., constraint hierarchies). Al-
bodyText ||| though many numerical optimization techniques have been
bodyText ||| proposed and implemented in the field of mathematical pro-
bodyText ||| gramming [2, 6], most of them do not handle preferential
bodyText ||| constraints. To alleviate the limitations of Chorus3D, we
bodyText ||| are pursuing a more sophisticated method for processing
bodyText ||| multi-level preferential constraints.
bodyText ||| We implemented Chorus3D as a class library which can
bodyText ||| be exploited in C++ and Java programs. However, more
bodyText ||| high-level authoring tools will also be useful for declarative
bodyText ||| approaches to 3D design. One possible direction is to ex-
bodyText ||| tend VRML [4] to support geometric constraints. Standard
bodyText ||| VRML requires scripts in Java or JavaScript to realize com-
bodyText ||| plex layouts and behaviors. By contrast, constraint-enabled
bodyText ||| VRML will cover a wider range of applications without such
bodyText ||| additional scripts.
sectionHeader ||| 8. CONCLUSIONS AND FUTURE WORK
bodyText ||| In this paper, we presented Chorus3D, a geometric con-
bodyText ||| straint library for 3D graphical applications. It enables pro-
bodyText ||| grammers to use geometric constraints for various purposes
page ||| 100
bodyText ||| such as geometric layout, constrained dragging, and inverse
bodyText ||| kinematics. Its novel feature is to handle scene graphs
bodyText ||| by processing coordinate transformations in geometric con-
bodyText ||| straint satisfaction.
bodyText ||| Our future work includes the development of other kinds of
bodyText ||| geometric constraints to further prove the usefulness of our
bodyText ||| approach. In particular, we are planning to implement non-
bodyText ||| overlapping constraints [13] in Chorus3D so that we can use
bodyText ||| it for the collision resolution of graphical objects. Another
bodyText ||| future direction is to improve Chorus3D in the scalability
bodyText ||| and accuracy of constraint satisfaction.
sectionHeader ||| 9. REFERENCES
reference ||| [1] Badler, N. I., Phillips, C. B., and Webber, B. L.
reference ||| Simulating Humans: Computer Graphics, Animation,
reference ||| and Control. Oxford University Press, Oxford, 1993.
reference ||| [2] Bertsekas, D. P. Nonlinear Programming, 2nd ed.
reference ||| Athena Scientific, 1999.
reference ||| [3] Borning, A., Marriott, K., Stuckey, P., and Xiao, Y.
reference ||| Solving linear arithmetic constraints for user interface
reference ||| applications. In Proc. ACM UIST, 1997, 87–96.
reference ||| [4] Carey, R., Bell, G., and Marrin, C. The Virtual
reference ||| Reality Modeling Language (VRML97). ISO/IEC
reference ||| 14772-1:1997, The VRML Consortium Inc., 1997.
reference ||| [5] Diehl, S., and Keller, J. VRML with constraints. In
reference ||| Proc. Web3D-VRML, ACM, 2000, 81–86.
reference ||| [6] Fletcher, R. Practical Methods of Optimization,
reference ||| 2nd ed. John Wiley & Sons, 1987.
reference ||| [7] Freeman-Benson, B. N., Maloney, J., and Borning, A.
reference ||| An incremental constraint solver. Commun. ACM 33,
reference ||| 1 (1990), 54–63.
reference ||| [8] Gleicher, M. A graphical toolkit based on differential
reference ||| constraints. In Proc. ACM UIST, 1993, 109–120.
reference ||| [9] Gleicher, M. A differential approach to graphical
reference ||| manipulation (Ph.D. thesis). Tech. Rep.
reference ||| CMU-CS-94-217, Sch. Comput. Sci. Carnegie Mellon
reference ||| Univ., 1994.
reference ||| [10] Herrera, F., Lozano, M., and Verdegay, J. L. Tackling
reference ||| real-coded genetic algorithms: Operators and tools for
reference ||| behavioural analysis. Artif. Intell. Rev. 12, 4 (1998),
reference ||| 265–319.
reference ||| [11] Heydon, A., and Nelson, G. The Juno-2
reference ||| constraint-based drawing editor. Research Report
reference ||| 131a, Digital Systems Research Center, 1994.
reference ||| [12] Hosobe, H. A scalable linear constraint solver for user
reference ||| interface construction. In Principles and Practice of
reference ||| Constraint Programming—CP2000, vol. 1894 of
reference ||| LNCS, Springer, 2000, 218–232.
reference ||| [13] Hosobe, H. A modular geometric constraint solver for
reference ||| user interface applications. In Proc. ACM UIST, 2001,
reference ||| 91–100.
reference ||| [14] Kamada, T., and Kawai, S. An algorithm for drawing
reference ||| general undirected graphs. Inf. Process. Lett. 31, 1
reference ||| (1989), 7–15.
reference ||| [15] Kitano, H., Ed. Genetic Algorithms. Sangyo-Tosho,
reference ||| 1993. In Japanese.
reference ||| [16] Kramer, G. A. A geometric constraint engine. Artif.
reference ||| Intell. 58, 1–3 (1992), 327–360.
reference ||| [17] Marriott, K., Chok, S. S., and Finlay, A. A tableau
reference ||| based constraint solving toolkit for interactive
reference ||| graphical applications. In Principles and Practice of
reference ||| Constraint Programming—CP98, vol. 1520 of LNCS,
reference ||| Springer, 1998, 340–354.
reference ||| [18] Sannella, M. Skyblue: A multi-way local propagation
reference ||| constraint solver for user interface construction. In
reference ||| Proc. ACM UIST, 1994,137–146.
reference ||| [19] Takahashi, S. Visualizing constraints in visualization
reference ||| rules. In Proc. CP2000 Workshop on Analysis and
reference ||| Visualization of Constraint Programs and Solvers,
reference ||| 2000.
reference ||| [20] Zhao, J., and Badler, N. I. Inverse kinematics
reference ||| positioning using nonlinear programming for highly
reference ||| articulated figures. ACM Trans. Gr. 13, 4 (1994),
reference ||| 313–336.
page ||| 101

title ||| A Machine Learning Based Approach for Table Detection
title ||| on The Web
author ||| Yalin Wang
affiliation ||| Intelligent Systems Laboratory
affiliation ||| Dept. of Electrical Engineering
affiliation ||| Univ. of Washington
address ||| Seattle, WA 98195 US
email ||| ylwang@u.washington.edu
author ||| Jianying Hu
affiliation ||| Avaya Labs Research
address ||| 233, Mount Airy Road
address ||| Basking Ridge, NJ 07920 US
email ||| jianhu@avaya.com
sectionHeader ||| ABSTRACT
bodyText ||| Table is a commonly used presentation scheme, especially
bodyText ||| for describing relational information. However, table under-
bodyText ||| standing remains an open problem. In this paper, we con-
bodyText ||| sider the problem of table detection in web documents. Its
bodyText ||| potential applications include web mining, knowledge man-
bodyText ||| agement, and web content summarization and delivery to
bodyText ||| narrow-bandwidth devices. We describe a machine learning
bodyText ||| based approach to classify each given table entity as either
bodyText ||| genuine or non-genuine. Various features reflecting the lay-
bodyText ||| out as well as content characteristics of tables are studied.
bodyText ||| In order to facilitate the training and evaluation of our
bodyText ||| table classifier, we designed a novel web document table
bodyText ||| ground truthing protocol and used it to build a large ta-
bodyText ||| ble ground truth database. The database consists of 1,393
bodyText ||| HTML files collected from hundreds of different web sites
bodyText ||| and contains 11,477 leaf <TABLE> elements, out of which
bodyText ||| 1,740 are genuine tables. Experiments were conducted us-
bodyText ||| ing the cross validation method and an F-measure of 95.89%
bodyText ||| was achieved.
sectionHeader ||| Categories and Subject Descriptors
category ||| H.4.3 [Information Systems Applications]: Communi-
category ||| cations Applications Information browsers
sectionHeader ||| General Terms
keyword ||| Algorithms
sectionHeader ||| Keywords
keyword ||| Table Detection, Layout Analysis, Machine Learning, Deci-
keyword ||| sion tree, Support Vector Machine, Information Retrieval
sectionHeader ||| 1. INTRODUCTION
bodyText ||| The increasing ubiquity of the Internet has brought about
bodyText ||| a constantly increasing amount of online publications. As
bodyText ||| a compact and efficient way to present relational informa-
bodyText ||| tion, tables are used frequently in web documents. Since
bodyText ||| tables are inherently concise as well as information rich, the
bodyText ||| automatic understanding of tables has many applications in-
bodyText ||| cluding knowledge management, information retrieval, web
copyright ||| Copyright is held by the author/owner(s).
note ||| WWW2002, May 7–11,2002, Honolulu, Hawaii, USA.
note ||| ACM 1-58113-449-5/02/0005.
bodyText ||| mining, summarization, and content delivery to mobile de-
bodyText ||| vices. The processes of table understanding in web doc-
bodyText ||| uments include table detection, functional and structural
bodyText ||| analysis and finally table interpretation [6]. In this paper,
bodyText ||| we concentrate on the problem of table detection. The web
bodyText ||| provides users with great possibilities to use their own style
bodyText ||| of communication and expressions. In particular, people use
bodyText ||| the <TABLE> tag not only for relational information display
bodyText ||| but also to create any type of multiple-column layout to
bodyText ||| facilitate easy viewing, thus the presence of the <TABLE>
bodyText ||| tag does not necessarily indicate the presence of a relational
bodyText ||| table. In this paper, we define genuine tables to be docu-
bodyText ||| ment entities where a two dimensional grid is semantically
bodyText ||| significant in conveying the logical relations among the cells
bodyText ||| [10]. Conversely, Non-genuine tables are document entities
bodyText ||| where <TABLE> tags are used as a mechanism for grouping
bodyText ||| contents into clusters for easy viewing only. Figure 1 gives
bodyText ||| a few examples of genuine and non-genuine tables. While
bodyText ||| genuine tables in web documents could also be created with-
bodyText ||| out the use of <TABLE> tags at all, we do not consider such
bodyText ||| cases in this article as they seem very rare from our ex-
bodyText ||| perience. Thus, in this study, Table detection refers to the
bodyText ||| technique which classifies a document entity enclosed by the
bodyText ||| <TABLE></TABLE> tags as genuine or non-genuine tables.
bodyText ||| Several researchers have reported their work on web table
bodyText ||| detection [2, 10, 6, 14]. In [2], Chen et al. used heuris-
bodyText ||| tic rules and cell similarities to identify tables. They tested
bodyText ||| their table detection algorithm on 918 tables from airline in-
bodyText ||| formation web pages and achieved an F-measure of 86.50%.
bodyText ||| Penn et al. proposed a set of rules for identifying genuinely
bodyText ||| tabular information and news links in HTML documents
bodyText ||| [10]. They tested their algorithm on 75 web site front-pages
bodyText ||| and achieved an F-measure of 88.05%. Yoshida et al. pro-
bodyText ||| posed a method to integrate WWW tables according to the
bodyText ||| category of objects presented in each table [14]. Their data
bodyText ||| set contains 35,232 table tags gathered from the web. They
bodyText ||| estimated their algorithm parameters using all of table data
bodyText ||| and then evaluated algorithm accuracy on 175 of the tables.
bodyText ||| The average F-measure reported in their paper is 82.65%.
bodyText ||| These previous methods all relied on heuristic rules and were
bodyText ||| only tested on a database that is either very small [10], or
bodyText ||| highly domain specific [2]. Hurst mentioned that a Naive
bodyText ||| Bayes classifier algorithm produced adequate results but no
bodyText ||| detailed algorithm and experimental information was pro-
bodyText ||| vided [6].
bodyText ||| We propose a new machine learning based approach for
page ||| 242
figureCaption ||| Figure 1: Examples of genuine and non-genuine tables.
bodyText ||| table detection from generic web documents. In particu-
bodyText ||| lar, we introduce a set of novel features which reflect the
bodyText ||| layout as well as content characteristics of tables. These
bodyText ||| features are used in classifiers trained on thousands of ex-
bodyText ||| amples. To facilitate the training and evaluation of the table
bodyText ||| classifiers, we designed a novel web document table ground
bodyText ||| truthing protocol and used it to build a large table ground
bodyText ||| truth database. The database consists of 1,393 HTML files
bodyText ||| collected from hundreds of different web sites and contains
bodyText ||| 11,477 leaf <TABLE> elements, out of which 1,740 are gen-
bodyText ||| uine tables. Experiments on this database using the cross
bodyText ||| validation method demonstrate significant performance im-
bodyText ||| provements over previous methods.
bodyText ||| The rest of the paper is organized as follows. We describe
bodyText ||| our feature set in Section 2, followed by a brief discussion
bodyText ||| of the classifiers we experimented with in Section 3. In Sec-
bodyText ||| tion 4, we present a novel table ground truthing protocol
bodyText ||| and explain how we built our database. Experimental re-
bodyText ||| sults are then reported in Section 5 and we conclude with
bodyText ||| future directions in Section 6.
sectionHeader ||| 2. FEATURES FOR WEB TABLE
sectionHeader ||| DETECTION
bodyText ||| Feature selection is a crucial step in any machine learning
bodyText ||| based methods. In our case, we need to find a combination
bodyText ||| of features that together provide significant separation be-
bodyText ||| tween genuine and non-genuine tables while at the same time
bodyText ||| constrain the total number of features to avoid the curse of
bodyText ||| dimensionality. Past research has clearly indicated that lay-
bodyText ||| out and content are two important aspects in table under-
bodyText ||| standing [6]. Our features were designed to capture both of
bodyText ||| these aspects. In particular, we developed 16 features which
bodyText ||| can be categorized into three groups: seven layout features,
bodyText ||| eight content type features and one word group feature. In
bodyText ||| the first two groups, we attempt to capture the global com-
bodyText ||| position of tables as well as the consistency within the whole
bodyText ||| table and across rows and columns. The last feature looks at
bodyText ||| words used in tables and is derived directly from the vector
bodyText ||| space model commonly used in Information Retrieval.
bodyText ||| Before feature extraction, each HTML document is first
bodyText ||| parsed into a document hierarchy tree using Java Swing
bodyText ||| XML parser with W3C HTML 3.2 DTD [10]. A <TABLE>
bodyText ||| node is said to be a leaf table if and only if there are no
bodyText ||| <TABLE> nodes among its children [10]. Our experience in-
bodyText ||| dicates that almost all genuine tables are leaf tables. Thus
bodyText ||| in this study only leaf tables are considered candidates for
bodyText ||| genuine tables and are passed on to the feature extraction
bodyText ||| stage. In the following we describe each feature in detail.
subsectionHeader ||| 2.1 Layout Features
bodyText ||| In HTML documents, although tags like <TR> and <TD>
bodyText ||| (or <TH>) may be assumed to delimit table rows and table
bodyText ||| cells, they are not always reliable indicators of the number
bodyText ||| of rows and columns in a table. Variations can be caused
bodyText ||| by spanning cells created using <ROWSPAN> and <COLSPAN>
bodyText ||| tags. Other tags such as <BR> could be used to move con-
bodyText ||| tent into the next row. Therefore to extract layout features
bodyText ||| reliably one can not simply count the number of <TR>'s and
bodyText ||| <TD>'s. For this purpose, we maintain a matrix to record all
page ||| 243
bodyText ||| the cell spanning information and serve as a pseudo render-
bodyText ||| ing of the table. Layout features based on row or column
bodyText ||| numbers are then computed from this matrix.
bodyText ||| Given a table T, assuming its numbers of rows and columns
bodyText ||| are rn and cn respectively, we compute the following layout
bodyText ||| features:
listItem ||| •	Average number of columns, computed as the average
listItem ||| number of cells per row:
bodyText ||| Here LCcl is defined as: LCcl = 0.5 — D, where D =
bodyText ||| min{lcl — mil�mi,1.0}. Intuitively, LCcl measures the
bodyText ||| degree of consistency between cl and the mean cell
bodyText ||| length, with —0.5 indicating extreme inconsistency and
bodyText ||| 0.5 indicating extreme consistency. When most cells
bodyText ||| within Ri are consistent, the cumulative measure CLCi
bodyText ||| is positive, indicating a more or less consistent row.
bodyText ||| 3. Take the average across all rows:
equation ||| ci,
equation ||| c =
equation ||| 1
equation ||| rn
equation ||| Xrn
equation ||| i�1
equation ||| CLCr = 1
equation ||| r
equation ||| Xr CLCi .
equation ||| i�1
bodyText ||| where ci is the number of cells in row i, i = 1, ..., rn,
listItem ||| •	Standard deviation of number of columns:
equation ||| (ci — c) x (ci — c);
listItem ||| •	Average number of rows, computed as the average
listItem ||| number of cells per column:
bodyText ||| where ri is the number of cells in column i, i = 1, ..., cn,
listItem ||| •	Standard deviation of number of rows:
equation ||| (ri — r) x (ri — r).
bodyText ||| Since the majority of tables in web documents contain
bodyText ||| characters, we compute three more layout features based on
bodyText ||| cell length in terms of number of characters:
listItem ||| •	Average overall cell length: cl = en Pin1 cli, where en
listItem ||| is the total number of cells in a given table and cli is
listItem ||| the length of cell i, i = 1, ... , en,
listItem ||| •	Standard deviation of cell length:
equation ||| (cli — cl) x (cli — cl)�
listItem ||| •	Average Cumulative length consistency, CLC.
bodyText ||| The last feature is designed to measure the cell length con-
bodyText ||| sistency along either row or column directions. It is inspired
bodyText ||| by the fact that most genuine tables demonstrate certain
bodyText ||| consistency either along the row or the column direction,
bodyText ||| but usually not both, while non-genuine tables often show
bodyText ||| no consistency in either direction. First, the average cumu-
bodyText ||| lative within-row length consistency, CLCr, is computed as
bodyText ||| follows. Let the set of cell lengths of the cells from row i be
bodyText ||| Ri, i = 1, ... , r (considering only non-spanning cells):
listItem ||| 1. Compute the mean cell length, mi, for row Ri.
listItem ||| 2. Compute cumulative length consistency within each
listItem ||| Ri:
equation ||| CLCi = X LCcl .
equation ||| clERi
bodyText ||| After the within-row length consistency CLCr is com-
bodyText ||| puted, the within-column length consistency CLCc is com-
bodyText ||| puted in a similar manner. Finally, the overall cumulative
bodyText ||| length consistency is computed as CLC = max(CLCr, CLCc).
subsectionHeader ||| 2.2 Content Type Features
bodyText ||| Web documents are inherently multi-media and has more
bodyText ||| types of content than any traditional documents. For ex-
bodyText ||| ample, the content within a <TABLE> element could include
bodyText ||| hyperlinks, images, forms, alphabetical or numerical strings,
bodyText ||| etc. Because of the relational information it needs to convey,
bodyText ||| a genuine table is more likely to contain alpha or numeri-
bodyText ||| cal strings than, say, images. The content type feature was
bodyText ||| designed to reflect such characteristics.
bodyText ||| We define the set of content types T = {Image, Form,
bodyText ||| Hyperlink, Alphabetical, Digit, Empty, Others}. Our content
bodyText ||| type features include:
listItem ||| •	The histogram of content type for a given table. This
listItem ||| contributes 7 features to the feature set,
listItem ||| •	Average content type consistency, CTC.
bodyText ||| The last feature is similar to the cell length consistency fea-
bodyText ||| ture. First, within-row content type consistency CTCr is
bodyText ||| computed as follows. Let the set of cell type of the cells
bodyText ||| from row i as Ti, i = 1,... , r (again, considering only non-
bodyText ||| spanning cells):
listItem ||| 1. Find the dominant type, DTi, for Ti.
listItem ||| 2. Compute the cumulative type consistency with each
listItem ||| row Ri, i = 1,... ,r:
equation ||| CTCi = X D,
equation ||| ctERi
bodyText ||| where D = 1 if ct is equal to DTi and D = —1, other-
bodyText ||| wise.
bodyText ||| 3. Take the average across all rows:
equation ||| CTCr = 1
equation ||| r
bodyText ||| The within-column type consistency is then computed in
bodyText ||| a similar manner. Finally, the overall cumulative type con-
bodyText ||| sistency is computed as: CTC = max(CTCr, CTCc).
equation ||| tiv
equation ||| dC =
equation ||| 1
equation ||| rn
equation ||| Xrn
equation ||| i�1
equation ||| ri,
equation ||| r=
equation ||| 1
equation ||| rn
equation ||| Xcn
equation ||| i�1
equation ||| vt uu
equation ||| dR =
equation ||| 1
equation ||| cn
equation ||| Xcn
equation ||| i�1
equation ||| tuuv
equation ||| dCL =
equation ||| 1
equation ||| en
equation ||| Xen
equation ||| i�1
equation ||| Xr CT Ci
equation ||| i�1
page ||| 244
subsectionHeader ||| 2.3 Word Group Feature
bodyText ||| If we treat each table as a "mini-document" by itself, ta-
bodyText ||| ble classification can be viewed as a document categoriza-
bodyText ||| tion problem with two broad categories: genuine tables and
bodyText ||| non-genuine tables. We designed the word group feature to
bodyText ||| incorporate word content for table classification based on
bodyText ||| techniques developed in information retrieval [7, 13].
bodyText ||| After morphing [11] and removing the infrequent words,
bodyText ||| we obtain the set of words found in the training data, W.
bodyText ||| We then construct weight vectors representing genuine and
bodyText ||| non-genuine tables and compare that against the frequency
bodyText ||| vector from each new incoming table.
bodyText ||| Let 3 represent the non-negative integer set. The follow-
bodyText ||| ing functions are defined on set W.
listItem ||| •	dfG : W —> 3, where dfG (wi) is the number of genuine
listItem ||| tables which include word wi, i = 1, ..., 1W1;
listItem ||| •	t f G : W —> 3, where t f G (wi) is the number of times
listItem ||| word wi, i =1,...,1W1, appears in genuine tables;
listItem ||| •	dfN : W —> 3, where dfN(wi) is the number of non-
listItem ||| genuine tables which include word wi, i =1,...,1W1;
listItem ||| •	t f N : W —> 3, where t f N (wi) is the number of times
listItem ||| word wi, i =1,...,1W1, appears in non-genuine tables.
listItem ||| •	t fT : W —> 3, where t fT (wi) is the number of times
listItem ||| word wi, wi 2 W appears in a new test table.
bodyText ||| To simplify the notations, in the following discussion, we
bodyText ||| will use dfGi, t fGi , df N i and t f Ni to represent dfG (wi), t f G (wi),
bodyText ||| df N (wi) and t f N (wi), respectively.
bodyText ||| Let NG, NN be the number of genuine tables and non-
bodyText ||| genuine tables in the training collection, respectively and let
bodyText ||| C = max(NG, NN). Without loss of generality, we assume
bodyText ||| NG =� 0 and NN =� 0. For each word wi in W, i = 1, ...,1W1,
bodyText ||| two weights, pGi and pNi are computed:
equation ||| N
equation ||| tfGilog(N� fN +1), when df Ni :A 0
equation ||| tfGilog(Ni C+1), when df i = 0
equation ||| tfiNlog(NNN fG
equation ||| G+1), when dfGi00
equation ||| tfNilog(NNC+1),	when dfG=0
bodyText ||| As can be seen from the formulas, the definitions of these
bodyText ||| weights were derived from the traditional t f * idf measures
bodyText ||| used in informational retrieval, with some adjustments made
bodyText ||| for the particular problem at hand.
bodyText ||| Given a new incoming table, let us denote the set includ-
bodyText ||| ing all the words in it as Wn. Since W is constructed using
bodyText ||| thousands of tables, the words that are present in both W
bodyText ||| and Wn are only a small subset of W. Based on the vector
bodyText ||| space model, we define the similarity between weight vec-
bodyText ||| tors representing genuine and non-genuine tables and the
bodyText ||| frequency vector representing the incoming table as the cor-
bodyText ||| responding dot products. Since we only need to consider the
bodyText ||| words that are present in both W and Wn, we first compute
bodyText ||| the effective word set: We = W n Wn. Let the words in
bodyText ||| We be represented as wmk, where mk,k = 1, ..., 1We1, are
bodyText ||| indexes to the words from set W = fw1, w2, ..., wIWI g. we
bodyText ||| define the following vectors:
listItem ||| •	Weight vector representing the genuine table group:
equation ||| i	pGmJ
equation ||| GS=
equation ||| U
bodyText ||| where U is the cosine normalization term:
bodyText ||| where V is the cosine normalization term:
equation ||| NN
equation ||| pmk X pmk .
listItem ||| •	Frequency vector representing the new incoming table:
equation ||| 'i	T T	T
equation ||| I	(tfml,tfmt,... tfT Wel I .
bodyText ||| Finally, the word group feature is defined as the ratio of
bodyText ||| the two dot products:
sectionHeader ||| 3. CLASSIFICATION SCHEMES
bodyText ||| Various classification schemes have been widely used in
bodyText ||| document categorization as well as web information retrieval
bodyText ||| [13, 8]. For the table detection task, the decision tree classi-
bodyText ||| fier is particularly attractive as our features are highly non-
bodyText ||| homogeneous. We also experimented with Support Vector
bodyText ||| Machines (SVM), a relatively new learning approach which
bodyText ||| has achieved one of the best performances in text catego-
bodyText ||| rization [13].
subsectionHeader ||| 3.1 Decision Tree
bodyText ||| Decision tree learning is one of the most widely used and
bodyText ||| practical methods for inductive inference. It is a method
bodyText ||| for approximating discrete-valued functions that is robust
bodyText ||| to noisy data.
bodyText ||| Decision trees classify an instance by sorting it down the
bodyText ||| tree from the root to some leaf node, which provides the clas-
bodyText ||| sification of the instance. Each node in a discrete-valued de-
bodyText ||| cision tree specifies a test of some attribute of the instance,
bodyText ||| and each branch descending from that node corresponds to
bodyText ||| one of the possible values for this attribute. Continuous-
bodyText ||| valued decision attributes can be incorporated by dynami-
bodyText ||| cally defining new discrete-valued attributes that partition
bodyText ||| the continuous attribute value into a discrete set of intervals
bodyText ||| [9].
bodyText ||| An implementation of the continuous-valued decision tree
bodyText ||| described in [4] was used for our experiments. The decision
bodyText ||| tree is constructed using a training set of feature vectors with
bodyText ||| true class labels. At each node, a discriminant threshold
equation ||| tuuv
equation ||| IWeI
equation ||| X
equation ||| k=1
equation ||| U=
equation ||| pGmk X pGmk.
equation ||| �,
equation ||| pmt
equation ||| V
equation ||| ,
equation ||| N
equation ||| pmlWel
equation ||| V
equation ||| iNS= pNm�
equation ||| V
listItem ||| •	Weight vector representing the non-genuine table group:
equation ||| i i
equation ||| ,when IT . NS�= 0
equation ||| i i
equation ||| 	1,	when IT . GS= 0 and
equation ||| i
equation ||| 	10,	when IT .
equation ||| i i
equation ||| IT . NS= 0
equation ||| i
equation ||| NS= 0
equation ||| � �
equation ||| IT� GS
equation ||| � �
equation ||| IT' NS
equation ||| i	i
equation ||| GS�=0and IT .
equation ||| �����
equation ||| ����
equation ||| wg =
equation ||| ��
equation ||| �
equation ||| G
equation ||| pi =
equation ||| I
equation ||| N
equation ||| pi =
equation ||| ,
equation ||| G
equation ||| pmlWel
equation ||| U
equation ||| pmt
equation ||| U
equation ||| �,
equation ||| tuuv
equation ||| V=
equation ||| IWeI
equation ||| X
equation ||| k=1
page ||| 245
bodyText ||| is chosen such that it minimizes an impurity value. The
bodyText ||| learned discriminant function splits the training subset into
bodyText ||| two subsets and generates two child nodes. The process is
bodyText ||| repeated at each newly generated child node until a stopping
bodyText ||| condition is satisfied, and the node is declared as a terminal
bodyText ||| node based on a majority vote. The maximum impurity
bodyText ||| reduction, the maximum depth of the tree, and minimum
bodyText ||| number of samples are used as stopping conditions.
subsectionHeader ||| 3.2 SVM
bodyText ||| Support Vector Machines (SVM) are based on the Struc-
bodyText ||| tural Risk Management principle from computational learn-
bodyText ||| ing theory [12]. The idea of structural risk minimization
bodyText ||| is to find a hypothesis h for which the lowest true error is
bodyText ||| guaranteed. The true error of h is the probability that h
bodyText ||| will make an error on an unseen and randomly selected test
bodyText ||| example.
bodyText ||| The SVM method is defined over a vector space where the
bodyText ||| goal is to find a decision surface that best separates the data
bodyText ||| points in two classes. More precisely, the decision surface by
bodyText ||| SVM for linearly separable space is a hyperplane which can
bodyText ||| be written as
equation ||| w�•x�—b=0
bodyText ||| where x� is an arbitrary data point and the vector w" and
bodyText ||| the constant b are learned from training data. Let D =
bodyText ||| (yz, �xz) denote the training set, and yz E {+1, —1} be the
bodyText ||| classification for �xz, the SVM problem is to find w� and b
bodyText ||| that satisfies the following constraints:
equation ||| w� •�xz—b>+1 for yz=+1
equation ||| w�•�xz—b<—1 for yz=—1
bodyText ||| while minimizing the vector 2-norm of �w.
bodyText ||| The SVM problem in linearly separable cases can be effi-
bodyText ||| ciently solved using quadratic programming techniques, while
bodyText ||| the non-linearly separable cases can be solved by either in-
bodyText ||| troducing soft margin hyperplanes, or by mapping the orig-
bodyText ||| inal data vectors to a higher dimensional space where the
bodyText ||| data points become linearly separable [12, 3].
bodyText ||| One reason why SVMs are very powerful is that they are
bodyText ||| very universal learners. In their basic form, SVMs learn lin-
bodyText ||| ear threshold functions. Nevertheless, by a simple "plug-in"
bodyText ||| of an appropriate kernel function, they can be used to learn
bodyText ||| polynomial classifiers, radial basis function (RBF) networks,
bodyText ||| three-layer sigmoid neural nets, etc. [3].
bodyText ||| For our experiments, we used the SVMlzght system im-
bodyText ||| plemented by Thorsten Joachims.1
sectionHeader ||| 4. DATA COLLECTION AND TRUTHING
bodyText ||| Since there are no publicly available web table ground
bodyText ||| truth database, researchers tested their algorithms in differ-
bodyText ||| ent data sets in the past [2, 10, 14]. However, their data
bodyText ||| sets either had limited manually annotated table data (e.g.,
bodyText ||| 918 table tags in [2], 75 HTML pages in [10], 175 manually
bodyText ||| annotated table tags in [14]), or were collected from some
bodyText ||| specific domains (e.g., a set of tables selected from airline
bodyText ||| information pages were used in [2]). To develop our machine
bodyText ||| learning based table detection algorithm, we needed to build
bodyText ||| a general web table ground truth database of significant size.
footnote ||| 1 http://svmlight.joachims.org
subsectionHeader ||| 4.1 Data Collection
bodyText ||| Instead of working within a specific domain, our goal of
bodyText ||| data collection was to get tables of as many different varieties
bodyText ||| as possible from the web. To accomplish this, we composed
bodyText ||| a set of key words likely to indicate documents containing
bodyText ||| tables and used those key words to retrieve and download
bodyText ||| web pages using the Google search engine. Three directo-
bodyText ||| ries on Google were searched: the business directory and
bodyText ||| news directory using key words: {table, stock, bonds,
bodyText ||| figure, schedule, weather, score, service, results,
bodyText ||| value}, and the science directory using key words {table,
bodyText ||| results, value}. A total of 2,851 web pages were down-
bodyText ||| loaded in this manner and we ground truthed 1,393 HTML
bodyText ||| pages out of these (chosen randomly among all the HTML
bodyText ||| pages). These 1,393 HTML pages from around 200 web sites
bodyText ||| comprise our database.
subsectionHeader ||| 4.2 Ground Truthing
bodyText ||| There has been no previous report on how to systemati-
bodyText ||| cally generate web table ground truth data. To build a large
bodyText ||| web table ground truth database, a simple, flexible and com-
bodyText ||| plete ground truth protocol is required. Figure 4.2(a) shows
bodyText ||| the diagram of our ground truthing procedure. We created
bodyText ||| a new Document Type Definition(DTD) which is a super-
bodyText ||| set of W3C HTML 3.2 DTD. We added three attributes for
bodyText ||| <TABLE> element, which are "tabid", "genuine table" and
bodyText ||| "table title". The possible value of the second attribute is
bodyText ||| yes or no and the value of the first and third attributes is a
bodyText ||| string. We used these three attributes to record the ground
bodyText ||| truth of each leaf <TABLE> node. The benefit of this design
bodyText ||| is that the ground truth data is inside HTML file format.
bodyText ||| We can use exactly the same parser to process the ground
bodyText ||| truth data.
bodyText ||| We developed a graphical user interface for web table
bodyText ||| ground truthing using the Java [1] language. Figure 4.2(b)
bodyText ||| is a snapshot of the interface. There are two windows. Af-
bodyText ||| ter reading an HTML file, the hierarchy of the HTML file is
bodyText ||| shown in the left window. When an item is selected in the
bodyText ||| hierarchy, the HTML source for the selected item is shown
bodyText ||| in the right window. There is a panel below the menu bar.
bodyText ||| The user can use the radio button to select either genuine
bodyText ||| table or non-genuine table. The text window is used to input
bodyText ||| table title.
subsectionHeader ||| 4.3 Database Description
bodyText ||| Our final table ground truth database consists of 1,393
bodyText ||| HTML pages collected from around 200 web sites. There
bodyText ||| are a total of 14,609 <TABLE> nodes, including 11,477 leaf
bodyText ||| <TABLE> nodes. Out of the 11,477 leaf <TABLE> nodes,
bodyText ||| 1,740 are genuine tables and 9,737 are non-genuine tables.
bodyText ||| Not every genuine table has its title and only 1,308 genuine
bodyText ||| tables have table titles. We also found at least 253 HTML
bodyText ||| files have unmatched <TABLE>, </TABLE> pairs or wrong
bodyText ||| hierarchy, which demonstrates the noisy nature of web doc-
bodyText ||| uments.
sectionHeader ||| 5. EXPERIMENTS
bodyText ||| A hold-out method is used to evaluate our table classi-
bodyText ||| fier. We randomly divided the data set into nine parts.
bodyText ||| Each classifier was trained on eight parts and then tested
bodyText ||| on the remaining one part. This procedure was repeated
bodyText ||| nine times, each time with a different choice for the test
page ||| 246
figure ||| HTML File
figure ||| Hierarchy
figure ||| Adding attributes
figure ||| Parser
figure ||| HTML with attributes and unique
figure ||| index to each table(ground truth)
figure ||| Validation
figure ||| (a)	(b)
figureCaption ||| Figure 2: (a) The diagram of ground truthing procedure; (b) A snapshot of the ground truthing software.
figureCaption ||| part. Then the combined nine part results are averaged to
figureCaption ||| arrive at the overall performance measures [4].
figureCaption ||| For the layout and content type features, this procedure
figureCaption ||| is straightforward. However it is more complicated for the
figureCaption ||| word group feature training. To compute wg for training
figureCaption ||| samples, we need to further divide the training set into two
figureCaption ||| groups, a larger one (7 parts) for the computation of the
figureCaption ||| weights pGi and pNi, i =1�...�jWj, and a smaller one (1
none ||| i i i
bodyText ||| part) for the computation of the vectors GS, NS, and IT.
bodyText ||| This partition is again rotated to compute wg for each table
bodyText ||| in the training set.
tableCaption ||| Table 1: Possible true- and detected-state combina-
tableCaption ||| tions for two classes.
table ||| True Class	Assigned Class
table ||| 	genuine table	non-genuine table
table ||| genuine table	Ngg	Ngn
table ||| non-genuine table	Nng	Nnn
table ||| lows:
table ||| Ngg	Ngg	R + P
table ||| R	P 	 F Ngg + Ng'	Ngg + Nng	= 2
bodyText ||| For comparison among different features and learning al-
bodyText ||| gorithms we report the performance measures when the best
bodyText ||| F-measure is achieved. First, the performance of various fea-
bodyText ||| ture groups and their combinations were evaluated using the
bodyText ||| decision tree classifier. The results are given in Table 2.
tableCaption ||| Table 2: Experimental results using various feature
tableCaption ||| groups and the decision tree classifier.
table ||| 	L	T	LT	LTW
table ||| R (%)	87.24	90.80	94.20	94.25
table ||| P (%)	88.15	95.70	97.27	97.50
table ||| F (%)	87.70	93.25	95.73	95.88
table ||| L: Layout only.
table ||| T: Content type only.
table ||| LT: Layout and content type.
table ||| LTW: Layout, content type and word group.
bodyText ||| The output of each classifier is compared with the ground
bodyText ||| truth and a contingency table is computed to indicate the
bodyText ||| number of a particular class label that are identified as mem-
bodyText ||| bers of one of two classes. The rows of the contingency table
bodyText ||| represent the true classes and the columns represent the as-
bodyText ||| signed classes. The cell at row r and column c is the number
bodyText ||| of tables whose true class is r while its assigned class is c.
bodyText ||| The possible true- and detected-state combination is shown
bodyText ||| in Table 1. Three performance measures Recall Rate(R),
bodyText ||| Precision Rate(P) and F-measure(F) are computed as fol-
bodyText ||| As seen from the table, content type features performed
bodyText ||| better than layout features as a single group, achieving an
bodyText ||| F-measure of 93.25%. However, when the two groups were
bodyText ||| combined the F-measure was improved substantially to 95.73%,
bodyText ||| reconfirming the importance of combining layout and con-
bodyText ||| tent features in table detection. The addition of the word
bodyText ||| group feature improved the F-measure slightly more to 95.88%.
bodyText ||| Table 3 compares the performances of different learning
bodyText ||| algorithms using the full feature set. The leaning algorithms
bodyText ||| tested include the decision tree classifier and the SVM al-
page ||| 247
bodyText ||| gorithm with two different kernels — linear and radial basis
bodyText ||| function (RBF).
tableCaption ||| Table 3: Experimental results using different learn-
tableCaption ||| ing algorithms.
table ||| 	Tree	SVM (linear)	SVM (RBF)
table ||| R (%)	94.25	93.91	95.98
table ||| P (%)	97.50	91.39	95.81
table ||| F (%)	95.88	92.65	95.89
bodyText ||| As seen from the table, for this application the SVM with
bodyText ||| radial basis function kernel performed much better than the
bodyText ||| one with linear kernel. It achieved an F measure of 95.89%,
bodyText ||| comparable to the 95.88% achieved by the decision tree clas-
bodyText ||| sifier.
bodyText ||| Figure 3 shows two examples of correctly classified tables,
bodyText ||| where Figure 3(a) is a genuine table and Figure 3(b) is a
bodyText ||| non-genuine table.
bodyText ||| Figure 4 shows a few examples where our algorithm failed.
bodyText ||| Figure 4(a) was misclassified as a non-genuine table, likely
bodyText ||| because its cell lengths are highly inconsistent and it has
bodyText ||| many hyperlinks which is unusual for genuine tables. The
bodyText ||| reason why Figure 4(b) was misclassified as non-genuine is
bodyText ||| more interesting. When we looked at its HTML source code,
bodyText ||| we found it contains only two <TR> tags. All text strings
bodyText ||| in one rectangular box are within one <TD> tag. Its author
bodyText ||| used <p> tags to put them in different rows. This points
bodyText ||| to the need for a more carefully designed pseudo-rendering
bodyText ||| process. Figure 4(c) shows a non-genuine table misclassi-
bodyText ||| fied as genuine. A close examination reveals that it indeed
bodyText ||| has good consistency along the row direction. In fact, one
bodyText ||| could even argue that this is indeed a genuine table, with
bodyText ||| implicit row headers of Title, Name, Company Affiliation
bodyText ||| and Phone Number. This example demonstrates one of the
bodyText ||| most difficult challenges in table understanding, namely the
bodyText ||| ambiguous nature of many table instances (see [5] for a more
bodyText ||| detailed analysis on that). Figure 4(d) was also misclassi-
bodyText ||| fied as a genuine table. This is a case where layout features
bodyText ||| and the kind of shallow content features we used are not
bodyText ||| enough deeper semantic analysis would be needed in or-
bodyText ||| der to identify the lack of logical coherence which makes it
bodyText ||| a non-genuine table.
bodyText ||| For comparison, we tested the previously developed rule-
bodyText ||| based system [10] on the same database. The initial re-
bodyText ||| sults (shown in Table 4 under "Original Rule Based") were
bodyText ||| very poor. After carefully studying the results from the
bodyText ||| initial experiment we realized that most of the errors were
bodyText ||| caused by a rule imposing a hard limit on cell lengths in gen-
bodyText ||| uine tables. After deleting that rule the rule-based system
bodyText ||| achieved much improved results (shown in Table 4 under
bodyText ||| "Modified Rule Based"). However, the proposed machine
bodyText ||| learning based method still performs considerably better in
bodyText ||| comparison. This demonstrates that systems based on hand-
bodyText ||| crafted rules tend to be brittle and do not generalize well.
bodyText ||| In this case, even after careful manual adjustment in a new
bodyText ||| database, it still does not work as well as an automatically
bodyText ||| trained classifier.
figureCaption ||| Figure 3: Examples of correctly classified tables.
figureCaption ||| (a): a genuine table; (b): a non-genuine table.
tableCaption ||| Table 4: Experimental results of a previously devel-
tableCaption ||| oped rule based system.
table ||| 	Original Rule Based	Modified Rule Based
table ||| R (%)	48.16	95.80
table ||| P (%)	75.70	79.46
table ||| F (%)	61.93	87.63
page ||| 248
figure ||| (a)	(b)
figure ||| (c)	(d)
figureCaption ||| Figure 4: Examples of misclassified tables. (a) and (b): Genuine tables misclassified as non-genuine; (c) and
figureCaption ||| (d): Non-genuine tables misclassified as genuine.
bodyText ||| A direct comparison to other previous results [2, 14] is
bodyText ||| not possible currently because of the lack of access to their
bodyText ||| system. However, our test database is clearly more general
bodyText ||| and far larger than the ones used in [2] and [14], while our
bodyText ||| precision and recall rates are both higher.
sectionHeader ||| 6. CONCLUSION AND FUTURE WORK
bodyText ||| Table detection in web documents is an interesting and
bodyText ||| challenging problem with many applications. We present a
bodyText ||| machine learning based table detection algorithm for HTML
bodyText ||| documents. Layout features, content type features and word
bodyText ||| group features were used to construct a novel feature set.
bodyText ||| Decision tree and SVM classifiers were then implemented
bodyText ||| and tested in this feature space. We also designed a novel ta-
bodyText ||| ble ground truthing protocol and used it to construct a large
bodyText ||| web table ground truth database for training and testing.
bodyText ||| Experiments on this large database yielded very promising
bodyText ||| results.
bodyText ||| Our future work includes handling more different HTML
bodyText ||| styles in pseudo-rendering, detecting table titles of the rec-
bodyText ||| ognized genuine tables and developing a machine learning
bodyText ||| based table interpretation algorithm. We would also like to
bodyText ||| investigate ways to incorporate deeper language analysis for
bodyText ||| both table detection and interpretation.
sectionHeader ||| 7. ACKNOWLEDGMENT
bodyText ||| We would like to thank Kathie Shipley for her help in
bodyText ||| collecting the web pages, and Amit Bagga for discussions on
bodyText ||| vector space models.
bodyText ||| 8. REFERENCES
reference ||| [1] M. Campione, K. Walrath, and A. Huml. The
reference ||| java(tm) tutorial: A short course on the basics (the
reference ||| java(tm) series).
reference ||| [2] H.-H. Chen, S.-C. Tsai, and J.-H. Tsai. Mining tables
reference ||| from large scale html texts. In Proc. 18th
reference ||| International Conference on Computational
reference ||| Linguistics, Saabrucken, Germany, July 2000.
reference ||| [3] C. Cortes and V. Vapnik. Support-vector networks.
reference ||| Machine Learning, 20:273{296, August 1995.
reference ||| [4] R. Haralick and L. Shapiro. Computer and Robot
reference ||| Vision, volume 1. Addison Wesley, 1992.
reference ||| [5] J. Hu, R. Kashi, D. Lopresti, G. Nagy, and
reference ||| G. Wilfong. Why table ground-truthing is hard. In
reference ||| Proc. 6th International Conference on Document
reference ||| Analysis and Recognition (ICDAR01), pages 129{133,
reference ||| Seattle, WA, USA, September 2001.
reference ||| [6] M. Hurst. Layout and language: Challenges for table
reference ||| understanding on the web. In Proc. 1st International
reference ||| Workshop on Web Document Analysis, pages 27{30,
reference ||| Seattle, WA, USA, September 2001.
reference ||| [7] T. Joachims. A probabilistic analysis of the rocchio
reference ||| algorithm with tfidf for text categorization. In Proc.
reference ||| 14th International Conference on Machine Learning,
reference ||| pages 143{151, Morgan Kaufmann, 1997.
reference ||| [8] A. McCallum, K. Nigam, J. Rennie, and K. Seymore.
reference ||| Automating the construction of internet portals with
reference ||| machine learning. In Information Retrieval Journal,
reference ||| volume 3, pages 127{163, Kluwer, 2000.
page ||| 249
reference ||| [9] T. M. Mitchell. Machine Learning. McGraw-Hill, 1997.
reference ||| [10] G. Penn, J. Hu, H. Luo, and R. McDonald. Flexible
reference ||| web document analysis for delivery to narrow-
reference ||| bandwidth devices. In Proc. 6th International
reference ||| Conference on Document Analysis and Recognition
reference ||| (ICDAR01), pages 1074{1078, Seattle, WA, USA,
reference ||| September 2001.
reference ||| [11] M. F. Porter. An algorithm for suffix stripping.
reference ||| Program, 14(3):130-137, 1980.
reference ||| [12] V. N. Vapnik. The Nature of Statistical Learning
reference ||| Theory, volume 1. Springer, New York, 1995.
reference ||| [13] Y. Yang and X. Liu. A re-examination of text
reference ||| categorization methods. In Proc. SIGIR'99, pages
reference ||| 42{49, Berkeley, California, USA, August 1999.
reference ||| [14] M. Yoshida, K. Torisawa, and J. Tsujii. A method to
reference ||| integrate tables of the world wide web. In Proc. 1st
reference ||| International Workshop on Web Document Analysis,
reference ||| pages 31{34, Seattle, WA, USA, September 2001.
page ||| 250

title ||| A New Approach to Intranet Search
title ||| Based on Information Extraction
author ||| Hang Li, Yunbo Cao
affiliation ||| Microsoft Research Asia
address ||| 5F Sigma Center
address ||| No.49 Zhichun Road,
address ||| Haidian, Beijing, China, 100080
email ||| {hangli, yucao}@microsoft.com
author ||| Jun Xu*
affiliation ||| College of Software
affiliation ||| Nankai University
address ||| No.94 Weijin Road,
address ||| Tianjin, China, 300071
email ||| nkxj@yahoo.com.cn
author ||| Yunhua Hu*
affiliation ||| Dept. of Computer Science
affiliation ||| Xi’an Jiaotong University
address ||| No 28, West Xianning Road,
address ||| Xi'an, China, 710049
email ||| yunhuahu@mail.xjtu.edu.cn
author ||| Shenjie Li*
affiliation ||| Dept. of Computer Science
affiliation ||| Hong Kong University of Science and Technology
affiliation ||| Kowloon, Hong Kong, China
email ||| lisj@cs.ust.hk
sectionHeader ||| ABSTRACT
bodyText ||| This paper is concerned with ‘intranet search’. By intranet search, we
bodyText ||| mean searching for information on an intranet within an organization.
bodyText ||| We have found that search needs on an intranet can be categorized into
bodyText ||| types, through an analysis of survey results and an analysis of search
bodyText ||| log data. The types include searching for definitions, persons, experts,
bodyText ||| and homepages. Traditional information retrieval only focuses on
bodyText ||| search of relevant documents, but not on search of special types of
bodyText ||| information. We propose a new approach to intranet search in which
bodyText ||| we search for information in each of the special types, in addition to
bodyText ||| the traditional relevance search. Information extraction technologies
bodyText ||| can play key roles in such kind of ‘search by type’ approach, because
bodyText ||| we must first extract from the documents the necessary information in
bodyText ||| each type. We have developed an intranet search system called
bodyText ||| ‘Information Desk’. In the system, we try to address the most
bodyText ||| important types of search first - finding term definitions, homepages of
bodyText ||| groups or topics, employees’ personal information and experts on
bodyText ||| topics. For each type of search, we use information extraction
bodyText ||| technologies to extract, fuse, and summarize information in advance.
bodyText ||| The system is in operation on the intranet of Microsoft and receives
bodyText ||| accesses from about 500 employees per month. Feedbacks from users
bodyText ||| and system logs show that users consider the approach useful and the
bodyText ||| system can really help people to find information. This paper describes
bodyText ||| the architecture, features, component technologies, and evaluation
bodyText ||| results of the system.
sectionHeader ||| Categories and Subject Descriptors
category ||| H.3.3 [Information Storage and Retrieval]: Information Search
category ||| and Retrieval – search process; I.7.m [Document and Text
category ||| Processing]: Miscellaneous
copyright ||| Permission to make digital or hard copies of all or part of this work for
copyright ||| personal or classroom use is granted without fee provided that copies are
copyright ||| not made or distributed for profit or commercial advantage and that
copyright ||| copies bear this notice and the full citation on the first page. To copy
copyright ||| otherwise, or republish, to post on servers or to redistribute to lists,
copyright ||| requires prior specific permission and/or a fee.
note ||| CIKM’05, October 31-November 5, 2005, Bremen, Germany.
note ||| Copyright 2005 ACM 1-59593-140-6/05/0010...$5.00.
author ||| Dmitriy Meyerzon
affiliation ||| Microsoft Corporation
affiliation ||| One Microsoft Way,
address ||| Redmond, WA, USA, 98052
email ||| dmitriym@microsoft.com
sectionHeader ||| General Terms: Algorithms, Experimentation, Human
sectionHeader ||| Factors
sectionHeader ||| Keywords: Intranet search, information extraction, metadata
sectionHeader ||| extraction, expert finding, definition search
sectionHeader ||| 1. INTRODUCTION
bodyText ||| Internet search has made significant progress in recent years. In
bodyText ||| contrast, intranet search does not seem to be so successful. The
bodyText ||| IDC white paper entitled “The high cost of not finding
bodyText ||| information” [13] reports that information workers spend from
bodyText ||| 15% to 35% of their work time on searching for information and
bodyText ||| 40% of information workers complain that they cannot find the
bodyText ||| information they need to do their jobs on their company intranets.
bodyText ||| Many commercial systems [35, 36, 37, 38, 39] have been
bodyText ||| developed for intranet search. However, most of them view
bodyText ||| intranet search as a problem of conventional relevance search. In
bodyText ||| relevance search, when a user types a query, the system returns a
bodyText ||| list of ranked documents with the most relevant documents on the
bodyText ||| top.
bodyText ||| Relevance search can only serve average needs well. It cannot,
bodyText ||| however, help users to find information in a specific type, e.g.,
bodyText ||| definitions of a term and experts on a topic. The characteristic of
bodyText ||| intranet search does not seem to be sufficiently leveraged in the
bodyText ||| commercial systems.
bodyText ||| In this paper, we try to address intranet search in a novel approach.
bodyText ||| We assume that the needs of information access on intranets can
bodyText ||| be categorized into searches for information in different types. An
bodyText ||| analysis on search log data on the intranet of Microsoft and an
bodyText ||| analysis on the results of a survey conducted at Microsoft have
bodyText ||| verified the correctness of the assumption.
bodyText ||| Our proposal then is to take a strategy of ‘divide-and-conquer’.
bodyText ||| We first figure out the most important types of search, e.g.,
bodyText ||| definition search, expert search. For each type, we employ
bodyText ||| information extraction technologies to extract, fuse, and
bodyText ||| summarize search results in advance. Finally, we combine all the
bodyText ||| types of searches together, including the traditional relevance
page ||| 460
bodyText ||| search, in a unified system. In this paper, we refer to the approach
bodyText ||| as ‘search by type’. Search by type can also be viewed as a
bodyText ||| simplified version of Question Answering, adapted to intranet.
bodyText ||| The advantage of the new search approach lies in that it can help
bodyText ||| people find the types of information which relevance search
bodyText ||| cannot easily find. The approach is particularly reasonable on
bodyText ||| intranets, because in such space users are information workers and
bodyText ||| search needs are business oriented.
bodyText ||| We have developed a system based on the approach, which is
bodyText ||| called ‘Information Desk’. Information Desk can help users to
bodyText ||| find term definitions, homepages of groups or topics, employees’
bodyText ||| personal information and experts on topics, on their company
bodyText ||| intranets.
bodyText ||| The system has been put into practical use since November 24th,
bodyText ||| 2004. Each month, about 500 Microsoft employees make access
bodyText ||| to the system. Both the results of an analysis on a survey and the
bodyText ||| results of an analysis on system log show that the features of
bodyText ||| definition search and homepage search are really helpful. The
bodyText ||| results also show that search by type is necessary at enterprise.
sectionHeader ||| 2. RELATED WORK
sectionHeader ||| 2.1 Intranet Search
bodyText ||| The needs on search on intranets are huge. It is estimated that
bodyText ||| intranets at enterprises have tens or even hundreds of times larger
bodyText ||| data collections (both structured and unstructured) than internet.
bodyText ||| As explained above, however, many users are not satisfied with
bodyText ||| the current intranet search systems. How to help people access
bodyText ||| information on intranet is a big challenge in information retrieval.
bodyText ||| Much effort has been made recently on solutions both in industry
bodyText ||| and in academia.
bodyText ||| Many commercial systems [35, 36, 37, 38, 39] dedicated to
bodyText ||| intranet search have been developed. Most of the systems view
bodyText ||| intranet search as a problem of conventional relevance search.
bodyText ||| In the research community, ground designs, fundamental
bodyText ||| approaches, and evaluation methodologies on intranet search have
bodyText ||| been proposed.
bodyText ||| Hawking et al [17] made ten suggestions on how to conduct high
bodyText ||| quality intranet search. Fagin et al [12] made a comparison
bodyText ||| between internet search and intranet search. Recently, Hawking
bodyText ||| [16] conducted a survey on previous work and made an analysis
bodyText ||| on the intranet search problem. Seven open problems on intranet
bodyText ||| search were raised in their paper.
bodyText ||| Chen et al [3] developed a system named ‘Cha-Cha’, which can
bodyText ||| organize intranet search results in a novel way such that the
bodyText ||| underlying structure of the intranet is reflected. Fagin et al [12]
bodyText ||| proposed a new ranking method for intranet search, which
bodyText ||| combine various ranking heuristics. Mattox et al [25] and
bodyText ||| Craswell et al [7] addressed the issue of expert finding on a
bodyText ||| company intranet. They developed methods that can automatically
bodyText ||| identify experts in an area using documents on the intranet.
bodyText ||| Stenmark [30] proposed a method for analyzing and evaluating
bodyText ||| intranet search tools.
subsectionHeader ||| 2.2 Question Answering
bodyText ||| Question Answering (QA) particularly that in TREC
bodyText ||| (http://trec.nist.gov/) is an application in which users type
bodyText ||| questions in natural language and the system returns short and
bodyText ||| usually single answers to the questions.
bodyText ||| When the answer is a personal name, a time expression, or a place
bodyText ||| name, the QA task is called ‘Factoid QA’. Many QA systems have
bodyText ||| been developed, [2, 4, 18, 20, 22, 27]. Factoid QA usually
bodyText ||| consists of the following steps: question type identification,
bodyText ||| question expansion, passage retrieval, answer ranking, and answer
bodyText ||| creation.
bodyText ||| TREC also has a task of ‘Definitional QA’. In the task, “what is
bodyText ||| <term>” and “who is <person>” questions are answered in a
bodyText ||| single combined text [1, 11, 15, 33, 34]. A typical system consists
bodyText ||| of question type identification, document retrieval, key sentence
bodyText ||| matching, kernel fact finding, kernel fact ranking, and answer
bodyText ||| generation.
sectionHeader ||| 3. OUR APPROACH TO INTRANET
sectionHeader ||| SEARCH
bodyText ||| Search is nothing but collecting information based on users’
bodyText ||| information access requests. If we can correctly gather
bodyText ||| information on the basis of users’ requests, then the problem is
bodyText ||| solved. Current intranet search is not designed along this
bodyText ||| direction. Relevance search can help create a list of ranked
bodyText ||| documents that serve only average needs well. The limitation of
bodyText ||| this approach is clear. That is, it cannot help users to find
bodyText ||| information of a specific type, e.g., definitions of a term. On the
bodyText ||| other hand, Question Answering (QA) is an ideal form for
bodyText ||| information access. When a user inputs a natural language
bodyText ||| question or a query (a combination of keywords) as a description
bodyText ||| of his search need, it is ideal to have the machine ‘understand’ the
bodyText ||| input and return only the necessary information based on the
bodyText ||| request. However, there are still lots of research work to do before
bodyText ||| putting QA into practical uses. In short term, we need consider
bodyText ||| adopting a different approach.
bodyText ||| One question arises here: can we take a hybrid approach?
bodyText ||| Specifically, on one hand, we adopt the traditional approach for
bodyText ||| search, and on the other hand, we realize some of the most
bodyText ||| frequently asked types of search with QA. Finally, we integrate
bodyText ||| them in a single system. For the QA part, we can employ
bodyText ||| information extraction technologies to extract, fuse, and
bodyText ||| summarize the results in advance. This is exactly the proposal we
bodyText ||| make to intranet search.
bodyText ||| Can we categorize users’ search needs easily? We have found that
bodyText ||| we can create a hierarchy of search needs for intranet search, as
bodyText ||| will be explained in section 4.
bodyText ||| On intranets, users are information workers and their motivations
bodyText ||| for conducting search are business oriented. We think, therefore,
bodyText ||| that our approach may be relatively easily realized on intranets
bodyText ||| first. (There is no reason why we cannot apply the same approach
bodyText ||| to the internet, however.)
bodyText ||| To verify the correctness of the proposal, we have developed a
bodyText ||| system and made it available internally at Microsoft. The system
bodyText ||| called Information Desk is in operation on the intranet of
bodyText ||| Microsoft and receives accesses from about 500 employees per
bodyText ||| month.
bodyText ||| At Information Desk, we try to solve the most important types of
bodyText ||| search first - find term definitions, homepages of groups or topics,
bodyText ||| experts on topics, and employees’ personal information. We are
page ||| 461
bodyText ||| also trying to increase the number of search types, and integrate
bodyText ||| them with the conventional relevance search. We will explain the
bodyText ||| working of Information Desk in section 5.
sectionHeader ||| 4. ANALYSIS OF SEARCH NEEDS
bodyText ||| In this section, we describe our analyses on intranet search needs
bodyText ||| using search query logs and survey results.
subsectionHeader ||| 4.1 Categorization of Search Needs
bodyText ||| In order to understand the underlying needs of search queries, we
bodyText ||| would need to ask the users about their search intentions.
bodyText ||| Obviously, this is not feasible. We conducted an analysis by using
bodyText ||| query log data. Here query log data means the records on queries
bodyText ||| typed by users, and documents clicked by the users after sending
bodyText ||| the queries.
bodyText ||| Our work was inspirited by those of Rose and Levinson [28]. In
bodyText ||| their work, they categorized the search needs of users on internet
bodyText ||| by analyzing search query logs.
bodyText ||| We tried to understand users’ search needs on intranet by
bodyText ||| identifying and organizing a manageable number of categories of
bodyText ||| the needs. The categories encompass the majority of actual
bodyText ||| requests users may have when conducting search on an intranet.
bodyText ||| We used a sample of queries from the search engine of the
bodyText ||| intranet of Microsoft. First, we brainstormed a number of
bodyText ||| categories, based on our own experiences and previous work.
bodyText ||| Then, we modified the categories, including adding, deleting, and
bodyText ||| merging categories, by assigning queries to the categories.
bodyText ||| Given a query, we used the following information to deduce the
bodyText ||| underlying search need:
listItem ||| •	the query itself
listItem ||| •	the documents returned by the search engine
listItem ||| •	the documents clicked on by the user
bodyText ||| For example, if a user typed a keyword of ‘.net’ and clicked a
bodyText ||| homepage of .net, then we judged that the user was looking for a
bodyText ||| homepage of .net.
bodyText ||| As we repeated the process, we gradually reached the conclusion
bodyText ||| that search needs on intranet can be categorized as a hierarchical
bodyText ||| structure shown in Figure 1. In fact, the top level of the hierarchy
bodyText ||| resembles that in the taxonomy proposed by Rose and Levinson
bodyText ||| for internet [28]. However, the second level differs. On intranet,
bodyText ||| users’ search needs are less diverse than those on internet, because
bodyText ||| the users are information workers and their motivations of
bodyText ||| conducting search are business oriented.
bodyText ||| There is a special need called ‘tell me about’ here. It is similar to
bodyText ||| the traditional relevance search. Many search needs are by nature
bodyText ||| difficult to be categorized, for example, “I want to find documents
bodyText ||| related to both .net and SQL Server”. We can put them into the
bodyText ||| category.
bodyText ||| We think that the search needs are not Microsoft specific; one can
bodyText ||| image that similar needs exist in other companies as well.
figure ||| 	When (time)
figure ||| 	Where
figure ||| 	(place)
figure ||| 	Why (reason)
figure ||| Informational	What is
figure ||| 	(definition) knows
figure ||| 	Who	about (expert)
figure ||| 	Who is
figure ||| 	(person)
figure ||| 	How
figure ||| 	to (manual)
figure ||| 	Tell
figure ||| 	me about (relevance)
figure ||| 	Group
figure ||| 	Person
figure ||| 	Product
figure ||| Navigational
figure ||| 	Technology
figure ||| 	Services
figure ||| Transactional
figureCaption ||| Figure 1. Categories of search needs
subsectionHeader ||| 4.2 Analysis on Search Needs – by Query Log
bodyText ||| We have randomly selected 200 unique queries and tried to assign
bodyText ||| the queries to the categories of search needs described above.
bodyText ||| Table 1 shows the distribution. We have also picked up the top
bodyText ||| 350 frequently submitted queries and assigned them to the
bodyText ||| categories. Table 2 shows the distribution. (There is no result for
bodyText ||| ‘why’, ‘what is’, and ‘who knows about’, because it is nearly
bodyText ||| impossible to guess users’ search intensions by only looking at
bodyText ||| query logs.)
bodyText ||| For random queries, informational needs are dominating. For high
bodyText ||| frequency queries, navigational needs are dominating. The most
bodyText ||| important types for random queries are relevance search, personal
bodyText ||| information search, and manual search. The most important types
bodyText ||| for high frequency queries are home page search and relevance
bodyText ||| search.
subsectionHeader ||| 4.3 Analysis on Search Needs – by Survey
bodyText ||| We can use query log data to analyze users’ search needs, as
bodyText ||| described above. However, there are two shortcomings in the
bodyText ||| approach. First, sometimes it is difficult to guess the search
bodyText ||| intensions of users by only looking at query logs. This is
bodyText ||| especially true for the categories of ‘why’ and ‘what’. Usually it is
bodyText ||| hard to distinguish them from ‘relevance search’. Second, query
bodyText ||| log data cannot reveal users’ potential search needs. For example,
bodyText ||| many employees report that they have needs of searching for
bodyText ||| experts on specific topics. However, it is difficult to find expert
bodyText ||| searches from query log at a conventional search engine, because
bodyText ||| users understand that such search is not supported and they do not
bodyText ||| conduct the search.
bodyText ||| To alleviate the negative effect, we have conducted another
bodyText ||| analysis through a survey. Although a survey also has limitation
bodyText ||| (i.e., it only asks people to answer pre-defined questions and thus
bodyText ||| can be biased), it can help to understand the problem from a
bodyText ||| different perspective.
page ||| 462
tableCaption ||| Table 1. Distribution of search needs for random queries
table ||| Category of Search Needs	Percentage
table ||| When	0.02
table ||| Where	0.02
table ||| Why	NA
table ||| What is	NA
table ||| Who knows about	NA
table ||| Who is	0.23
table ||| How to	0.105
table ||| Tell me about	0.46
table ||| Informational total	0.835
table ||| Groups	0.03
table ||| Persons	0.005
table ||| Products	0.02
table ||| Technologies	0.02
table ||| Services	0.06
table ||| Navigational total	0.135
table ||| Transactional	0.025
table ||| Other	0.005
tableCaption ||| Table 2. Distribution of search needs for high frequency queries
table ||| Category of Search Needs	Relative Prevalence
table ||| When	0.0057
table ||| Where	0.0143
table ||| Why	NA
table ||| What is	NA
table ||| Who knows about	NA
table ||| Who is	0.0314
table ||| How to	0.0429
table ||| Tell me about	0.2143
table ||| Informational total	0.3086
table ||| Groups	0.0571
table ||| Persons	0.0057
table ||| Products	0.26
table ||| Technologies	0.0829
table ||| Services	0.2371
table ||| Navigational total	0.6428
table ||| Transactional	0.0086
table ||| Other	0.04
figureCaption ||| Figure 2. Survey results on search needs
bodyText ||| In the survey, we have asked questions regarding to search needs
bodyText ||| at enterprise. 35 Microsoft employees have taken part in the
bodyText ||| survey. Figure 2 shows the questions and the corresponding
bodyText ||| results.
bodyText ||| We see from the answers that definition search, manual search,
bodyText ||| expert finding, personal information search, and time schedule
bodyText ||| search are requested by the users. Homepage finding on
bodyText ||| technologies and products are important as well. Search for a
bodyText ||| download site is also a common request.
bodyText ||| I have experiences of conducting search at Microsoft intranet in
bodyText ||| order to (multiple choice)
figure ||| •	download a software, a document, or a picture. E.g., "getting
figure ||| MSN logo"
figure ||| 71 %
figure ||| •	make use of a service. E.g., "getting a serial number of
figure ||| Windows"
figure ||| 	53 %
figure ||| •	none of the above
figure ||| 18 %
figure ||| I have experiences of conducting search at Microsoft intranet to
figure ||| look for the web sites (or homepages) of (multiple choice)
figure ||| •	technologies
figure ||| 74 %
figure ||| •	products
figure ||| 	74 %
figure ||| •	services
figure ||| 	68 %
figure ||| •	projects
figure ||| 	68 %
figure ||| •	groups
figure ||| 	60 %
figure ||| •	persons
figure ||| 42 %
figure ||| •	none of the above
figure ||| 11 %
figure ||| I have experiences of conducting search at Microsoft intranet in
figure ||| which the needs can be translated into questions like? (multiple
figure ||| choice)
figure ||| •	‘what is’ - e.g., "what is blaster"
figure ||| 77 %
figure ||| •	‘how to’ - "how to submit expense report"
figure ||| 54 %
figure ||| •	‘where’ - e.g., "where is the company store"
figure ||| 51 %
figure ||| •	‘who knows about’ - e.g., "who knows about data mining"
figure ||| 51 %
figure ||| •	‘who is’ - e.g., "who is Rick Rashid"
figure ||| 45 %
figure ||| •	‘when’ - e.g., "when is TechFest'05 "
figure ||| 42 %
figure ||| •	‘why’ - e.g., "why do Windows NT device drivers contain
figure ||| trusted code"
figure ||| 28 %
figure ||| •	none of the above
figure ||| 14 %
page ||| 463
figure ||| Longhorn	Go
figure ||| What is	Who is	Where is homepage of	Who knows about
figure ||| 	What is	Who isWhere is homepage of	Who knows about
figure ||| 	Definition of Longhorn
figure ||| 	Longhorn is the codename for the next release of the Windows operating system, planned for release in FY 2005. Longhorn will further Microsoft’s long term vision for ...
figure ||| 	http://url1
figure ||| 	Longhorn is a platform that enables incredible user experiences that are unlike anything possible with OS releases to date. This session describes our approach and philosophy that...
figure ||| 	http://url2
figure ||| 	Longhorn is the platform in which significant improvements in the overall manageability of the system by providing the necessary infrastructure to enable standardized configuration/change management, structured eventing and monitoring, and a unified software distribution mechanism will be made. In order to achieve this management with each Longhorn...
figure ||| 	http://url3
figure ||| 	Longhorn is the evolution of the .NET Framework on the client and the biggest investment that Microsoft has made in the Windows client development platform in years. Longhorn is the platform for smart , connected...
figure ||| 	http://url4
figure ||| 	Longhorn is the platform for smart, connected applications, combining the best features of the Web, such as ease of deployment and rich content with the power of the Win32 development platform, enabling developers to build a new breed of applications that take real advantage of the connectivity, storage, and graphical capabilities of the modern personal
figure ||| 	computer .
figure ||| 	http//url5
figure ||| 	Office	Go
figure ||| 	What is	Who is	Where is homepage of	Who knows about
figure ||| 	What is	Who is	Where is homepage of	Who knows about
figure ||| 	Homepages of Office
figure ||| 	Office Portal Site
figure ||| 	This is the internal site for Office
figure ||| 	http://url1
figure ||| 	Office Site (external)
figure ||| 	Microsoft.com site offering information on the various Office products. Links include FAQs, downloads, support, and more.
figure ||| 	http:/url2
figure ||| 	Office
figure ||| 	New Office Site
figure ||| 	http://url3
figure ||| 	Office Office
figure ||| 	http://url4
figure ||| 	Data Mining	Go
figure ||| 	What is	Who is	Where is homepage of	Who knows about
figure ||| 	What is	Who is	Where is homepage of	Who knows about
figure ||| 	People Associated with Data mining
figure ||| 	Jamie MacLennan	DEVELOPMENT LEAD
figure ||| 	US-SQL Data Warehouse +1 (425) XXXXXXX XXXXXX Associated documents(4):
figure ||| 	•	is author of document entitled Data Mining Tutorial
figure ||| 	http://url1
figure ||| 	•	is author of document entitled Solving Business Problems Using Data Mining
figure ||| 	http://url2
figure ||| 	Jim Gray	DISTINGUISHED ENGINEER
figure ||| 	US-WAT MSR San Francisco +XXXXXXXXXXX
figure ||| 	Associated documents(2):
figure ||| 	•	is author of document entitled Mainlining Data Mining
figure ||| 	http://url3
figure ||| 	•	is author of document entitled Data Mining the SDSS SkyServer Database
figure ||| 	http://url4
figure ||| Bill Gates	Go
figure ||| What is	Who is	Where is homepage of	Who knows about
figure ||| What is	Who is	Where is homepage of	Who knows about
figure ||| 	Bill Gates	CHRMN & CHIEF SFTWR ARCHITECT
figure ||| 	US-Executive-Chairman
figure ||| 	+1 (425) XXXXXXX XXXXXX
figure ||| 	Documents of Bill Gates(118)
figure ||| 	•	My advice to students: Education counts
figure ||| 	http://url1
figure ||| 	•	Evento NET Reviewers – Seattle –7/8 Novembro
figure ||| 	http://url2
figure ||| 	•	A Vision for Life Long Learning – Year 2020
figure ||| 	http://url3
figure ||| 	•	Bill Gates answers most frequently asked questions.
figure ||| 	http://url4
figure ||| 	>>more
figure ||| 	Top 10 terms appearing in documents of Bill Gates
figure ||| 	Term 1 (984.4443) Term 2 (816.4247) Term 3 (595.0771) Term 4 (578.5604) Term 5 (565.7299) Term 6 (435.5366) Term 7 (412.4467) Term 8 (385.446) Term 9 (346.5993) Term 10 (345.3285)
figureCaption ||| Figure 3: Information Desk system
sectionHeader ||| 5. INFORMATION DESK
sectionHeader ||| 5.1 Features
bodyText ||| Currently Information Desk provides four types of search. The
bodyText ||| four types are:
listItem ||| 1. ‘what is’ – search of definitions and acronyms. Given a term,
listItem ||| it returns a list of definitions of the term. Given an acronym, it
listItem ||| returns a list of possible expansions of the acronym.
listItem ||| 2. ‘who is’ – search of employees’ personal information. Given
listItem ||| the name of a person, it returns his/her profile information,
listItem ||| authored documents and associated key terms.
listItem ||| 3. ‘where is homepage of’ – search of homepages. Given the
listItem ||| name of a group, a product, or a technology, it returns a list of
listItem ||| its related home pages.
listItem ||| 4. ‘who knows about’ – search of experts. Given a term on a
listItem ||| technology or a product, it returns a list of persons who might
listItem ||| be experts on the technology or the product.
figureCaption ||| Figure 4. Workflow of Information Desk
bodyText ||| There are check boxes on the UI, and each represents one search
bodyText ||| type. In search, users can designate search types by checking the
bodyText ||| corresponding boxes and then submit queries. By default, all the
bodyText ||| boxes are checked.
bodyText ||| For example, when users type ‘longhorn’ with the ‘what is’ box
bodyText ||| checked, they get a list of definitions of ‘Longhorn’ (the first
bodyText ||| snapshot in figure 3). Users can also search for homepages (team
bodyText ||| web sites) related to ‘Office’, using the ‘where is homepage’
bodyText ||| feature (the second snapshot in figure 3). Users can search for
bodyText ||| experts on, for example, ‘data mining’ by asking ‘who knows
bodyText ||| about data mining’ (the third snapshot in figure 3). Users can also
bodyText ||| get a list of documents that are automatically identified as being
bodyText ||| authored by ‘Bill Gates’, for example, with the ‘who is’ feature
bodyText ||| (the last snapshot in figure 3). The top ten key terms found in his
bodyText ||| documents are also given.
bodyText ||| Links to the original documents, from which the information has
bodyText ||| been extracted, are also available on the search result UIs.
subsectionHeader ||| 5.2 Technologies
subsectionHeader ||| 5.2.1 Architecture
bodyText ||| Information Desk makes use of information extraction
bodyText ||| technologies to support the search by type feaatures. The
bodyText ||| technologies include automatically extracting document metadata
bodyText ||| and domain specific knowledge from a web site using information
bodyText ||| extraction technologies. The domain specific knowledge includes
bodyText ||| definition, acronym, and expert. The document metadata includes
bodyText ||| title, author, key term, homepage. Documents are in the form of
bodyText ||| Word, PowerPoint, or HTML. Information Desk stores all the
bodyText ||| data in Microsoft SQL Server and provides search using web
figure ||| homepage
figure ||| term
figure ||| Where is homepage of
figure ||| Crawler &
figure ||| Extractor
figure ||| definition
figure ||| acronym
figure ||| document
figure ||| key term
figure ||| person
figure ||| document
figure ||| what is
figure ||| who is
figure ||| who knows about
figure ||| MS Web
figure ||| Information Desk
figure ||| Web Server
figure ||| term
figure ||| person
figure ||| term
page ||| 464
bodyText ||| services. Figure 4 shows the workflow of Information Desk.
bodyText ||| Currently, there are 4 million documents crawled from the
bodyText ||| Microsoft intranet.
bodyText ||| Below we explain each feature in details. Table 3 shows which
bodyText ||| feature employs what kind of mining technology.
tableCaption ||| Table 3. Information extraction technologies employed
table ||| 	`What is'	`Who is'	`Who knows	`Where is homepage'
table ||| 			about'
table ||| Definition extraction	Yes
table ||| Acronym extraction	Yes
table ||| Homepage				Yes
table ||| finding
table ||| Title		Yes	Yes
table ||| extraction
table ||| Author extraction		Yes	Yes
table ||| Key term extraction		Yes	Yes
table ||| Expert mining			Yes
subsubsectionHeader ||| 5.2.2 `What is'
bodyText ||| There are two parts in the feature: definition finding and acronym
bodyText ||| recognition.
bodyText ||| In definition finding, we extract from the entire collection of
bodyText ||| documents <term, definition, score> triples. They are respectively
bodyText ||| a term, a definitional excerpt of the term, and its score
bodyText ||| representing its likelihood of being a good definition. We assign
bodyText ||| the scores using a statistical model. Both paragraphs and
bodyText ||| sentences can be considered as definition excerpts in our approach.
bodyText ||| Currently, we only consider the use of paragraphs.
bodyText ||| As model, we employ SVM (Support Vector Machines) [31],
bodyText ||| which identifies whether a given paragraph is a definition of the
bodyText ||| first noun phrase (term) in the paragraph. There are positive
bodyText ||| features in the SVM model. For example, if the term appears at
bodyText ||| the beginning of the paragraph or repeatedly occurs in the
bodyText ||| paragraph, then it is likely the paragraph is a (good) definition on
bodyText ||| the term. There are also negative features. If words like `she', `he',
bodyText ||| or `said' occurs in the paragraph, or many adjectives occur in the
bodyText ||| paragraph, then it is likely the paragraph is not a (good) definition.
bodyText ||| In search, given a query term, we retrieve all the triples matched
bodyText ||| against the query term and present the corresponding definitions
bodyText ||| in descending order of the scores.
bodyText ||| The top 1 and top 3 precision of our approach in definition
bodyText ||| ranking are 0.550 and 0.887 respectively. They are much better
bodyText ||| than the baseline method of employing relevance search.
bodyText ||| Methods for extracting definitions from documents have been
bodyText ||| proposed [1, 10, 11, 15, 21, 24, 33]. All of the methods resorted to
bodyText ||| human-defined rules for the extraction and did not consider
bodyText ||| ranking of definitions. In Information Desk, we rank definitions
bodyText ||| according to their likelihoods of being good definitions,
bodyText ||| represented by SVM scores. See [32] for details.
bodyText ||| In acronym recognition, we find candidate acronym and candidate
bodyText ||| expansion pairs from text using pattern matching. There are ten
bodyText ||| types of patterns. For example, one of them is `<expansion>
bodyText ||| (<acronym>)' in which <expansion> denotes a phrase with the
bodyText ||| first letters in the words capitalized and <acronym> denotes a
bodyText ||| sequence of the capitalized letters in the same order. The pattern
bodyText ||| matches sentences such as "Active Directory is implemented
bodyText ||| using the Lightweight Directory Access Protocol (LDAP)". We
bodyText ||| then store all the acronyms, their expansions, and the numbers of
bodyText ||| occurrences of the expansions.
bodyText ||| In search, given an acronym, we retrieve all the expansions
bodyText ||| against the acronym and present the corresponding expansions in
bodyText ||| descending order of their numbers of occurrences.
subsubsectionHeader ||| 5.2.3 `Who is'
bodyText ||| We first harvest all the employees' personal information from a
bodyText ||| database. It includes name, alias, title, and contact information.
bodyText ||| We next automatically extract titles and authors from all the Word
bodyText ||| and PowerPoint documents on the intranet. With the extracted
bodyText ||| titles and authors we bring together all the documents to each
bodyText ||| person, which are thought authored by him/her. Finally, we
bodyText ||| extract key terms from the documents for each person and pick up
bodyText ||| the top ten key terms in terms of TF-IDF. This feature lies mainly
bodyText ||| on document metadata extraction.
bodyText ||| Metadata of documents such as title and author is useful for
bodyText ||| document processing. However, people seldom define document
bodyText ||| metadata by themselves. We collected 6,000 Word and 6,000
bodyText ||| PowerPoint documents and examined how many titles and authors
bodyText ||| in the file properties are correct. We found that the accuracies
bodyText ||| were only 0.265 and 0.126 respectively.
bodyText ||| We take a machine learning approach to automatically extract
bodyText ||| titles and authors from the bodies of Office documents, as shown
bodyText ||| in Figure 5. We annotate titles in sample documents (for Word
bodyText ||| and PowerPoint respectively) and take them as training data, train
bodyText ||| statistical models, and perform title extraction using the trained
bodyText ||| models. In the models, we mainly utilize format information such
bodyText ||| as font size as features. As models, we employ Perceptron with
bodyText ||| Uneven Margins [23].
bodyText ||| Experimental results indicate that our approach works well for
bodyText ||| title extraction from general documents. Our method can
bodyText ||| significantly outperform the baselines: one that always uses the
bodyText ||| first lines as titles and the other that always uses the lines in the
bodyText ||| largest font sizes as titles. Precision and recall for title extraction
bodyText ||| from Word are 0.875 and 0.899 respectively, and precision and
figureCaption ||| Figure 5. Title and author extraction from four example
figure ||| PowerPoint documents
figure ||| Microsoft Project 2002 Project Guide
figure ||| Architecture and Extensibi(ity
figure ||| White Paper
figure ||| DRAFT
page ||| 465
bodyText ||| recall for title extraction from PowerPoint are 0.907 and 0.951
bodyText ||| respectively.
bodyText ||| Metadata extraction has been intensively studied. For instance,
bodyText ||| Han et al [14] proposed a method for metadata extraction from
bodyText ||| research papers. They considered the problem as that of
bodyText ||| classification based on SVM. They mainly used linguistic
bodyText ||| information as features. To the best of our knowledge, no
bodyText ||| previous work has been done on metadata extraction from general
bodyText ||| documents. We report our title extraction work in details in [19].
bodyText ||| The feature of ‘who is’ can help find documents authored by a
bodyText ||| person, but existing in different team web sites. Information
bodyText ||| extraction (specifically metadata extraction) makes the aggregation
bodyText ||| of information possible.
subsubsectionHeader ||| 5.2.4 ‘Who knows about’
bodyText ||| The basic idea for the feature is that if a person has authored many
bodyText ||| documents on an issue (term), then it is very likely that he/she is an
bodyText ||| expert on the issue, or if the person’s name co-occurs in many times
bodyText ||| with the issue, then it is likely that he/she is an expert on the issue.
bodyText ||| As described above, we can extract titles, authors, and key terms
bodyText ||| from all the documents. In this way, we know how many times each
bodyText ||| person is associated with each topic in the extracted titles and in the
bodyText ||| extracted key terms. We also go through all the documents and see
bodyText ||| how many times each person’s name co-occurs with each topic in
bodyText ||| text segments within a pre-determined window size.
bodyText ||| In search, we use the three types of information: topic in title, topic
bodyText ||| in key term, and topic in text segment to rank persons, five persons
bodyText ||| for each type. We rank persons with a heuristic method and return
bodyText ||| the list of ranked persons. A person who has several documents with
bodyText ||| titles containing the topic will be ranked higher than a person whose
bodyText ||| name co-occurs with the topic in many documents.
bodyText ||| It appears that the results of the feature largely depend on the size of
bodyText ||| document collection we crawl. Users’ feedbacks on the results show
bodyText ||| that sometimes the results are very accurate, however, sometimes
bodyText ||| they are not (due to the lack of information).
bodyText ||| Craswell et al. developed a system called ‘P@NOPTIC’, which can
bodyText ||| automatically find experts using documents on an intranet [7]. The
bodyText ||| system took documents as plain texts and did not utilize metadata of
bodyText ||| documents as we do at Information Desk.
subsubsectionHeader ||| 5.2.5 ‘Where is homepage of’
bodyText ||| We identify homepages (team web sites) using several rules. Most of
bodyText ||| the homepages at the intranet of Microsoft are created by
bodyText ||| SharePoint, a product of Microsoft. From SharePoint, we can obtain
bodyText ||| a property of each page called ‘ContentClass’. It tells exactly
bodyText ||| whether a web page corresponds to a homepage or a team site. So
bodyText ||| we know it is a homepage (obviously, this does not apply in
bodyText ||| general). Next we use several patterns to pull out titles from the
bodyText ||| homepages. The precision of home page identification is nearly
bodyText ||| 100%.
bodyText ||| In search, we rank the discovered home pages related to a query
bodyText ||| term using the URL lengths of the home pages. A home page with a
bodyText ||| shorter URL will be ranked higher.
bodyText ||| TREC has a task called ‘home/named page finding’ [8, 9], which is
bodyText ||| to find home pages talking about a topic. Many methods have been
bodyText ||| developed for pursuing the task [5, 6, 26, 29]. Since we can identify
bodyText ||| homepages by using special properties on our domain, we do not
bodyText ||| consider employing a similar method.
sectionHeader ||| 6. EVALUATION
bodyText ||| Usually it is hard to conduct evaluation on a practical system. We
bodyText ||| evaluated the usefulness of Information Desk by conducting a
bodyText ||| survey and by recording system logs.
bodyText ||| We have found from analysis results that the ‘what is’ and ‘where is
bodyText ||| homepage of’ features are very useful. The ‘who is’ feature works
bodyText ||| well, but the ‘who knows about’ feature still needs improvements.
subsectionHeader ||| 6.1 Survey Result Analysis
bodyText ||| The survey described in section 4.3 also includes feedbacks on
bodyText ||| Information Desk.
bodyText ||| Figure 6 shows a question on the usefulness of the features and a
bodyText ||| summary on the answers. We see that the features ‘where is
bodyText ||| homepage of’ and ‘what is’ are regarded useful by the responders in
bodyText ||| the survey.
bodyText ||| Figure 7 shows a question on new features and a summary on the
bodyText ||| answers. We see that the users want to use the features of ‘how to’,
bodyText ||| ‘when’, ‘where’ and ‘why’ in the future. This also justifies the
bodyText ||| correctness of our claim on intranet search made in section 4.
bodyText ||| Figure 8 shows a question on purposes of use and a digest on the
bodyText ||| results. About 50% of the responders really want to use Information
bodyText ||| Desk to search for information.
bodyText ||| There is also an open-ended question asking people to make
bodyText ||| comments freely. Figure 9 gives some typical answers from the
bodyText ||| responders. The first and second answers are very positive, while the
bodyText ||| third and fourth point out the necessity of increasing the coverage of
bodyText ||| the system.
bodyText ||| Figure 6. Users’ evaluation on Information Desk
bodyText ||| Figure 7. New features expected by users
figure ||| Which feature of Information Desk has helped you in finding
figure ||| information?
figure ||| •	‘where is homepage of’ - finding homepages
figure ||| 54 %
figure ||| •	‘what is’ - finding definitions/acronyms
figure ||| 25 %
figure ||| •	‘who is’ - finding information about people
figure ||| 18 %
figure ||| •	‘who knows about’ - finding experts
figure ||| 3 %
figure ||| What kind of new feature do you want to use at Information
figure ||| Desk? (multiple choice)
figure ||| •	‘how to’ - e.g., "how to activate Windows"
figure ||| 57 %
figure ||| •	‘when’ - e.g., "when is Yukon RTM"
figure ||| 57 %
figure ||| •	‘where’ - e.g., "where can I find an ATM"
figure ||| 39 %
figure ||| •	‘why’ - e.g., "why doesn't my printer work"
figure ||| 28 %
figure ||| •	others
figure ||| 9 %
page ||| 466
figure ||| I visited Information Desk today to
figure ||| •	conduct testing on Information Desk
figure ||| 	54 %
figure ||| •	search for information related to my work
figure ||| 	46 %
figureCaption ||| Figure 8. Motivation of using Information Desk
figure ||| Please provide any additional comments, thanks!
figure ||| •	This is a terrific tool! Including ‘how to’ and ‘when’
figure ||| capabilities will put this in the ‘can’t live without it’
figure ||| category.
figure ||| •	Extremely successful searching so far! Very nice product
figure ||| with great potential.
figure ||| •	I would like to see more ‘Microsoftese’ definitions. There is
figure ||| a lot of cultural/tribal knowledge here that is not explained
figure ||| anywhere.
figure ||| •	Typing in my team our website doesn’t come up in the
figure ||| results, is there any way we can provide content for the
figure ||| search tool e.g., out group sharepoint URL?
figure ||| •	...
figureCaption ||| Figure 9. Typical user comments to Information Desk
subsectionHeader ||| 6.2 System Log Analysis
bodyText ||| We have made log during the running of Information Desk. The
bodyText ||| log includes user IP addresses, queries and clicked documents
bodyText ||| (recall that links to the original documents, from which
bodyText ||| information has been extraction, are given in search). The log data
bodyText ||| was collected from 1,303 unique users during the period from
bodyText ||| November 26th, 2004 to February 22nd, 2005. The users were
bodyText ||| Microsoft employees.
bodyText ||| In the log, there are 9,076 query submission records. The records
bodyText ||| include 4,384 unique query terms. About 40% of the queries are
bodyText ||| related to the ‘what is’ feature, 29% related to ‘where is homepage
bodyText ||| of’, 30% related to ‘who knows about’ and 22% related to ‘who
bodyText ||| is’. A query can be related to more than one feature.
bodyText ||| In the log, there are 2,316 clicks on documents after query
bodyText ||| submissions. The numbers of clicks for the ‘what is’, ‘where is
bodyText ||| homepage of’, ‘who knows about’, and ‘who is’ features are 694,
bodyText ||| 1041, 200 and 372, respectively. Note that for ‘what is’, ‘where is
bodyText ||| home page of’, and ‘who knows about’ we conduct ranking on
bodyText ||| retrieved information. The top ranked results are considered to be
bodyText ||| the best. If a user has clicked a top ranked document, then it
bodyText ||| means that he is interested in the document, and thus it is very
bodyText ||| likely he has found the information he looks for. Thus a system
bodyText ||| which has higher average rank of clicks is better than the other
bodyText ||| that does not. We used average rank of clicked documents to
bodyText ||| evaluate the performances of the features. The average ranks of
bodyText ||| clicks for ‘what is’, ‘where is homepage of’ and ‘who knows
bodyText ||| about’ are 2.4, 1.4 and 4.7 respectively. The results indicate that
bodyText ||| for the first two features, users usually can find information they
bodyText ||| look for on the top three answers. Thus it seems safe to say that
bodyText ||| the system have achieved practically acceptable performances for
bodyText ||| the two features. As for ‘who is’, ranking of a person’s documents
bodyText ||| does not seem to be necessary and the performance should be
bodyText ||| evaluated in a different way. (For example, precision and recall of
bodyText ||| metadata extraction as we have already reported in section 5).
sectionHeader ||| 7. CONCLUSION
bodyText ||| In this paper, we have investigated the problem of intranet search
bodyText ||| using information extraction.
bodyText ||| •	Through an analysis of survey results and an analysis of
bodyText ||| search log data, we have found that search needs on intranet
bodyText ||| can be categorized into a hierarchy.
bodyText ||| •	Based on the finding, we propose a new approach to intranet
bodyText ||| search in which we conduct search for each special type of
bodyText ||| information.
bodyText ||| •	We have developed a system called ‘Information Desk’,
bodyText ||| based on the idea. In Information Desk, we provide search on
bodyText ||| four types of information - finding term definitions,
bodyText ||| homepages of groups or topics, employees’ personal
bodyText ||| information and experts on topics. Information Desk has
bodyText ||| been deployed to the intranet of Microsoft and has received
bodyText ||| accesses from about 500 employees per month. Feedbacks
bodyText ||| from users show that the proposed approach is effective and
bodyText ||| the system can really help employees to find information.
bodyText ||| •	For each type of search, information extraction technologies
bodyText ||| have been used to extract, fuse, and summarize information
bodyText ||| in advance. High performance component technologies for
bodyText ||| the mining have been developed.
bodyText ||| As future work, we plan to increase the number of search types
bodyText ||| and combine them with conventional relevance search.
sectionHeader ||| 8. ACKNOWLEDGMENTS
bodyText ||| We thank Jin Jiang, Ming Zhou, Avi Shmueli, Kyle Peltonen,
bodyText ||| Drew DeBruyne, Lauri Ellis, Mark Swenson, and Mark Davies for
bodyText ||| their supports to the project.
sectionHeader ||| 9. REFERENCES
reference ||| [1] S. Blair-Goldensohn, K.R. McKeown, A.H. Schlaikjer. A
reference ||| Hybrid Approach for QA Track Definitional Questions. In
reference ||| Proc. of Twelfth Annual Text Retrieval Conference (TREC-
reference ||| 12), NIST, Nov., 2003.
reference ||| [2] E. Brill, S. Dumais, and M. Banko, An Analysis of the
reference ||| AskMSR Question-Answering System, EMNLP 2002
reference ||| [3] M. Chen, A. Hearst, A. Marti, J. Hong, and J. Lin, Cha-Cha:
reference ||| A System for Organizing Intranet Results. Proceedings of the
reference ||| 2nd USENIX Symposium on Internet Technologies and
reference ||| Systems. Boulder, CO. Oct. 1999.
reference ||| [4] C. L. A. Clarke, G. V. Cormack, T. R. Lynam, C. M. Li, and
reference ||| G. L. McLearn, Web Reinforced Question Answering
reference ||| (MultiText Experiments for TREC 2001). TREC 2001
reference ||| [5] N. Craswell, D. Hawking, and S.E. Robertson. Effective site
reference ||| finding using link anchor information. In Proc. of the 24th
reference ||| annual international ACM SIGIR conference on research
reference ||| and development in information retrieval, pages 250--257,
reference ||| 2001.
reference ||| [6] N. Craswell, D. Hawking, and T. Upstill. TREC12 Web and
reference ||| Interactive Tracks at CSIRO. In TREC12 Proceedings, 2004.
reference ||| [7] N. Craswell, D. Hawking, A. M. Vercoustre, and P. Wilkins.
reference ||| P@noptic expert: Searching for experts not just for
reference ||| documents. Poster Proceedings of AusWeb'01,
page ||| 467
reference ||| 2001b./urlausweb.scu.edu.au/aw01/papers/edited/vercoustre/
reference ||| paper.htm.
reference ||| [8] N. Craswell, D. Hawking, R. Wilkinson, and M. Wu.
reference ||| Overview of the TREC-2003 Web Track. In NIST Special
reference ||| Publication: 500-255, The Twelfth Text REtrieval
reference ||| Conference (TREC 2003), Gaithersburg, MD, 2003.
reference ||| [9] N. Craswell, D. Hawking, R. Wilkinson, and M. Wu. Task
reference ||| Descriptions: Web Track 2003. In TREC12 Proceedings,
reference ||| 2004.
reference ||| [10] H. Cui, M-Y. Kan, and T-S. Chua. Unsupervised Learning of
reference ||| Soft Patterns for Definitional Question Answering,
reference ||| Proceedings of the Thirteenth World Wide Web conference
reference ||| (WWW 2004), New York, May 17-22, 2004.
reference ||| [11] A. Echihabi, U.Hermjakob, E. Hovy, D. Marcu, E. Melz, D.
reference ||| Ravichandran. Multiple-Engine Question Answering in
reference ||| TextMap. In Proc. of Twelfth Annual Text Retrieval
reference ||| Conference (TREC-12), NIST, Nov., 2003.
reference ||| [12] R. Fagin, R. Kumar, K. S. McCurley, J. Novak, D.
reference ||| Sivakumar, J. A. Tomlin, and D. P. Williamson. Searching
reference ||| the workplace web. Proc. 12th World Wide Web Conference,
reference ||| Budapest, 2003.
reference ||| [13] S. Feldman and C. Sherman. The high cost of not finding
reference ||| information. Technical Report #29127, IDC, April 2003.
reference ||| [14] H. Han, C. L. Giles, E. Manavoglu, H. Zha, Z. Zhang, and E.
reference ||| A. Fox. Automatic Document Metadata Extraction using
reference ||| Support Vector Machines. In Proceedings of the third
reference ||| ACM/IEEE-CS joint conference on Digital libraries, 2003
reference ||| [15] S. Harabagiu, D. Moldovan, C. Clark, M. Bowden, J.
reference ||| Williams, J. Bensley. Answer Mining by Combining
reference ||| Extraction Techniques with Abductive Reasoning. In Proc.
reference ||| of Twelfth Annual Text Retrieval Conference (TREC-12),
reference ||| NIST, Nov., 2003.
reference ||| [16] D. Hawking. Challenges in Intranet search. Proceedings of
reference ||| the fifteenth conference on Australasian database. Dunedin,
reference ||| New Zealand, 2004.
reference ||| [17] D. Hawking, N. Craswell, F. Crimmins, and T. Upstill.
reference ||| Intranet search: What works and what doesn't. Proceedings
reference ||| of the Infonortics Search Engines Meeting, San Francisco,
reference ||| April 2002.
reference ||| [18] E. Hovy, L. Gerber, U. Hermjakob, M. Junk, and C. Y. Lin.
reference ||| Question Answering in Webclopedia. TREC 2000
reference ||| [19] Y. Hu, H. Li, Y. Cao, D. Meyerzon, and Q. Zheng.
reference ||| Automatic Extraction of Titles from General Documents
reference ||| using Machine Learning. To appear at Proc. of Joint
reference ||| Conference on Digital Libraries (JCDL), 2005. Denver,
reference ||| Colorado, USA. 2005.
reference ||| [20] A. Ittycheriah and S. Roukos, IBM's Statistical Question
reference ||| Answering System-TREC 11. TREC 2002
reference ||| [21] J. Klavans and S. Muresan. DEFINDER: Rule-Based
reference ||| Methods for the Extraction of Medical Terminology and
reference ||| their Associated Definitions from On-line Text. In
reference ||| Proceedings of AMIA Symposium 2000.
reference ||| [22] C. C. T. Kwok, O. Etzioni, and D. S. Weld, Scaling question
reference ||| answering to the Web. WWW-2001: 150-161
reference ||| [23] Y. Li, H Zaragoza, R Herbrich, J Shawe-Taylor, and J. S.
reference ||| Kandola. The Perceptron Algorithm with Uneven Margins.
reference ||| in Proceedings of ICML'02.
reference ||| [24] B. Liu, C. W. Chin, and H. T. Ng. Mining Topic-Specific
reference ||| Concepts and Definitions on the Web. In Proceedings of the
reference ||| twelfth international World Wide Web conference (WWW-
reference ||| 2003), 20-24 May 2003, Budapest, HUNGARY.
reference ||| [25] D. Mattox, M. Maybury and D. Morey. Enterprise Expert
reference ||| and Knowledge Discovery. Proceedings of the HCI
reference ||| International '99 (the 8th International Conference on
reference ||| Human-Computer Interaction) on Human-Computer
reference ||| Interaction: Communication, Cooperation, and Application
reference ||| Design-Volume 2 - Volume 2. 1999.
reference ||| [26] P. Ogilvie and J. Callan. Combining Structural Information
reference ||| and the Use of Priors in Mixed Named-Page and Homepage
reference ||| Finding. In TREC12 Proceedings, 2004.
reference ||| [27] D. R. Radev, W. Fan, H. Qi, H. Wu, and A. Grewal.
reference ||| Probabilistic question answering on the web. WWW 2002:
reference ||| 408-419
reference ||| [28] D. E. Rose and D. Levinson. Understanding user goals in
reference ||| web search. Proceedings of the 13th international World
reference ||| Wide Web conference on Alternate track papers & posters,
reference ||| 2004 New York, USA.
reference ||| [29] J. Savoy, Y. Rasolofo, and L. Perret, L. Report on the TREC-
reference ||| 2003 Experiment: Genomic and Web Searches. In TREC12
reference ||| Proceedings, 2004.
reference ||| [30] D. Stenmark. A Methodology for Intranet Search Engine
reference ||| Evaluations. Proceedings of IRIS22, Department of CS/IS,
reference ||| University of Jyväskylä, Finland, August 1999.
reference ||| [31 ] V. N. Vapnik. The Nature of Statistical Learning Theory.
reference ||| Springer, 1995.
reference ||| [32] J. Xu, Y. Cao, H. Li, and M. Zhao. Ranking Definitions with
reference ||| Supervised Learning Methods. In Proc. of 14th International
reference ||| World Wide Web Conference (WWW05), Industrial and
reference ||| Practical Experience Track, Chiba, Japan, pp.811-819, 2005.
reference ||| [33] J. Xu, A. Licuanan, R. Weischedel. TREC 2003 QA at BBN:
reference ||| Answering Definitional Questions. In Proc. of 12th Annual
reference ||| Text Retrieval Conference (TREC-12), NIST, Nov., 2003.
reference ||| [34] H. Yang, H. Cui, M. Maslennikov, L. Qiu, M-Y. Kan, and T-
reference ||| S. Chua, QUALIFIER in TREC-12 QA Main Task. TREC
reference ||| 2003: 480-488
reference ||| [35] Intellectual capital management products. Verity,
reference ||| http://www.verity.com/
reference ||| [36] IDOL server. Autonomy,
reference ||| http://www.autonomy.com/content/home/
reference ||| [37] Fast data search. Fast Search & Transfer,
reference ||| http://www.fastsearch.com/
reference ||| [38] Atomz intranet search. Atomz, http://www.atomz.com/
reference ||| [39] Google Search Appliance. Google,
reference ||| http://www.google.com/enterprise/
page ||| 468

title ||| A New Statistical Formula for Chinese Text Segmentation
title ||| Incorporating Contextual Information
author ||| Yubin Dai
author ||| Christopher S.G. Khoo
affiliation ||| Division of Information Studies
affiliation ||| School of Applied Science
affiliation ||| Nanyang Technological University
address ||| Singapore 639798
address ||| (65) 790-4602
email ||| dyb_lte@hotmail.com
email ||| assgkhoo@ntu.edu.sg
sectionHeader ||| ABSTRACT
bodyText ||| A new statistical formula for identifying 2-character words in
bodyText ||| Chinese text, called the contextual information formula, was
bodyText ||| developed empirically by performing stepwise logistic regression
bodyText ||| using a sample of sentences that had been manually segmented.
bodyText ||| Contextual information in the form of the frequency of characters
bodyText ||| that are adjacent to the bigram being processed as well as the
bodyText ||| weighted document frequency of the overlapping bigrams were
bodyText ||| found to be significant factors for predicting the probablity that
bodyText ||| the bigram constitutes a word. Local information (the number of
bodyText ||| times the bigram occurs in the document being segmented) and
bodyText ||| the position of the bigram in the sentence were not found to be
bodyText ||| useful in determining words. The contextual information formula
bodyText ||| was found to be significantly and substantially better than the
bodyText ||| mutual information formula in identifying 2-character words.
bodyText ||| The method can also be used for identifying multi-word terms in
bodyText ||| English text.
sectionHeader ||| Keywords
keyword ||| Chinese text segmentation, word boundary identification, logistic
keyword ||| regression, multi-word terms
sectionHeader ||| 1. INTRODUCTION
bodyText ||| Chinese text is different from English text in that there is no
bodyText ||| explicit word boundary. In English text, words are separated by
bodyText ||| spaces. Chinese text (as well as text of other Oriental languages)
bodyText ||| is made up of ideographic characters, and a word can comprise
bodyText ||| one, two or more such characters, without explicit indication
bodyText ||| where one word ends and another begins.
bodyText ||| This has implications for natural language processing and
bodyText ||| information retrieval with Chinese text. Text processing
bodyText ||| techniques that have been developed for Western languages deal
bodyText ||| with words as meaningful text units and assume that words are
bodyText ||| easy to identify. These techniques may not work well for Chinese
bodyText ||| text without some adjustments. To apply these techniques to
author ||| Teck Ee Loh
address ||| 10 Kent Ridge Crescent
affiliation ||| Data Storage Institute
address ||| Singapore 119260
address ||| (65) 874-8413
email ||| dsilohte@dsi.nus.edu.sg
bodyText ||| Chinese text, automatic methods for identifying word boundaries
bodyText ||| accurately have to be developed. The process of identifying word
bodyText ||| boundaries has been referred to as text segmentation or, more
bodyText ||| accurately, word segmentation.
bodyText ||| Several techniques have been developed for Chinese text
bodyText ||| segmentation. They can be divided into:
listItem ||| 1. statistical methods, based on statistical properties and
listItem ||| frequencies of characters and character strings in a corpus
listItem ||| (e.g. [13] and [16]).
listItem ||| 2. dictionary-based methods, often complemented with
listItem ||| grammar rules. This approach uses a dictionary of words to
listItem ||| identify word boundaries. Grammar rules are often used to
listItem ||| resolve conflicts (choose between alternative segmentations)
listItem ||| and to improve the segmentation (e.g. [4], [8], [19] and [20]).
listItem ||| 3. syntax-based methods, which integrate the word
listItem ||| segmentation process with syntactic parsing or part-of-speech
listItem ||| tagging (e.g. [1]).
listItem ||| 4. conceptual methods, that make use of some kind of semantic
listItem ||| processing to extract information and store it in a knowledge
listItem ||| representation scheme. Domain knowledge is used for
listItem ||| disambiguation (e.g. [9]).
bodyText ||| Many researchers use a combination of methods (e.g. [14]).
bodyText ||| The objective of this study was to empirically develop a
bodyText ||| statistical formula for Chinese text segmentation. Researchers
bodyText ||| have used different statistical methods in segmentation, most of
bodyText ||| which were based on theoretical considerations or adopted from
bodyText ||| other fields. In this study, we developed a statistical formula
bodyText ||| empirically by performing stepwise logistic regression using a
bodyText ||| sample of sentences that had been manually segmented. This
bodyText ||| paper reports the new formula developed for identifying 2-
bodyText ||| character words, and the effectiveness of this formula compared
bodyText ||| with the mutual information formula.
bodyText ||| This study has the following novel aspects:
listItem ||| •	The statistical formula was derived empirically using
listItem ||| regression analysis.
listItem ||| •	The manual segmentation was performed to identify
bodyText ||| meaningful	words rather than simple words.
bodyText ||| Meaningful words include phrasal words and multi-
bodyText ||| word terms.
listItem ||| •	In addition to the relative frequencies of bigrams and
bodyText ||| characters often used in other studies, our study also
bodyText ||| investigated the use of document frequencies and weighted
page ||| 82
bodyText ||| document frequencies. Weighted document frequencies are
bodyText ||| similar to document frequencies but each document is
bodyText ||| weighted by the square of the number of times the character
bodyText ||| or bigram occurs in the document.
listItem ||| •	Contextual information was included in the study. To predict
listItem ||| whether the bigram BC in the character string	A B C D
listItem ||| constitutes a word, we investigated whether the
listItem ||| frequencies for AB, CD, A and D should be included in the
listItem ||| formula.
listItem ||| •	Local frequencies were included in the study. We
listItem ||| investigated character and bigram frequencies within the
listItem ||| document in which the sentence occurs (i.e. the number of
listItem ||| times the character or bigram appears in the document being
listItem ||| segmented).
listItem ||| •	We investigated whether the position of the bigram (at the
listItem ||| beginning of the sentence, before a punctuation mark, or after
listItem ||| a punctuation mark) had a significant effect.
listItem ||| •	We developed a segmentation algorithm to apply the
listItem ||| statistical formula to segment sentences and resolve conflicts.
bodyText ||| In this study, our objective was to segment text into
bodyText ||| meaningful words rather than simple words . A simple
bodyText ||| word is the smallest independent unit of a sentence that has
bodyText ||| meaning on its own. A meaningful word can be a simple word or
bodyText ||| a compound word comprising 2 or more simple words –
bodyText ||| depending on the context. In many cases, the meaning of a
bodyText ||| compound word is more than just a combination of the meanings
bodyText ||| of the constituent simple words, i.e. some meaning is lost when
bodyText ||| the compound word is segmented into simple words.
bodyText ||| Furthermore, some phrases are used so often that native speakers
bodyText ||| perceive them and use them as a unit. Admittedly, there is some
bodyText ||| subjectivity in the manual segmentation of text. But the fact that
bodyText ||| statistical models can be developed to predict the manually
bodyText ||| segmented words substantially better than chance indicates some
bodyText ||| level of consistency in the manual segmentation.
bodyText ||| The problem of identifying meaningful words is not limited to
bodyText ||| Chinese and oriental languages. Identifying multi-word terms is
bodyText ||| also a problem in text processing with English and other Western
bodyText ||| languages, and researchers have used the mutual information
bodyText ||| formula and other statistical approaches for identifying such
bodyText ||| terms (e.g. [3], [6] and [7]).
sectionHeader ||| 2. PREVIOUS STUDIES
bodyText ||| There are few studies using a purely statistical approach to
bodyText ||| Chinese text segmentation. One statistical formula that has been
bodyText ||| used by other researchers (e.g. [11] and [16]) is the mutual
bodyText ||| information formula. Given a character string A B C D
bodyText ||| , the mutual information for the bigram BC is given by the
bodyText ||| formula:
equation ||| freq(BC)
equation ||| log2 freq(B) * freq(C)
equation ||| = log2 freq(BC) – log2 freq(B) – log2 freq(C)
bodyText ||| where freq refers to the relative frequency of the character or
bodyText ||| bigram in the corpus (i.e. the number of times the character or
bodyText ||| bigram occurs in the corpus divided by the number of characters
bodyText ||| in the corpus).
bodyText ||| Mutual information is a measure of how strongly the two
bodyText ||| characters are associated, and can be used as a measure of how
bodyText ||| likely the pair of characters constitutes a word. Sproat & Shih
bodyText ||| [16] obtained recall and precision values of 94% using mutual
bodyText ||| information to identify words. This study probably segmented
bodyText ||| text into simple words rather than meaningful words. In our
bodyText ||| study, text was segmented into meaningful words and we
bodyText ||| obtained much poorer results for the mutual information
bodyText ||| formula.
bodyText ||| Lua [12] and Lua & Gan [13] applied information theory to the
bodyText ||| problem of Chinese text segmentation. They calculated the
bodyText ||| information content of characters and words using the
bodyText ||| information entropy formula I = - log2 P, where P is the
bodyText ||| probability of occurrence of the character or word. If the
bodyText ||| information content of a character string is less than the sum of
bodyText ||| the information content of the constituent characters, then the
bodyText ||| character string is likely to constitute a word. The formula for
bodyText ||| calculating this loss of information content when a word is
bodyText ||| formed is identical to the mutual information formula. Lua &
bodyText ||| Gan [13] obtained an accuracy of 99% (measured in terms of the
bodyText ||| number of errors per 100 characters).
bodyText ||| Tung & Lee [18] also used information entropy to identify
bodyText ||| unknown words in a corpus. However, instead of calculating the
bodyText ||| entropy value for the character string that is hypothesized to be a
bodyText ||| word (i.e. the candidate word), they identified all the characters
bodyText ||| that occurred to the left of the candidate word in the corpus. For
bodyText ||| each left character, they calculated the probability and entropy
bodyText ||| value for that character given that it occurs to the left of the
bodyText ||| candidate word. The same is done for the characters to the right
bodyText ||| of the candidate word. If the sum of the entropy values for the
bodyText ||| left characters and the sum of the entropy values for the right
bodyText ||| characters are both high, than the candidate word is considered
bodyText ||| likely to be a word. In other words, a character string is likely to
bodyText ||| be a word if it has several different characters to the left and to
bodyText ||| the right of it in the corpus, and none of the left and right
bodyText ||| characters predominate (i.e. not strongly associated with the
bodyText ||| character string).
bodyText ||| Ogawa & Matsuda [15] developed a statistical method to
bodyText ||| segment Japanese text. Instead of attempting to identify words
bodyText ||| directly, they developed a formula to estimate the probability that
bodyText ||| a bigram straddles a word boundary. They referred to this as the
bodyText ||| segmentation probability. This was complemented with some
bodyText ||| syntactic information about which class of characters could be
bodyText ||| combined with which other class.
bodyText ||| All the above mathematical formulas used for identifying words
bodyText ||| and word boundaries were developed based on theoretical
bodyText ||| considerations and not derived empirically.
bodyText ||| Other researchers have developed statistical methods to find the
bodyText ||| best segmentation for the whole sentence rather than focusing on
bodyText ||| identifying individual words. Sproat et al. [17] developed a
bodyText ||| stochastic finite state model for segmenting text. In their model,
bodyText ||| a word dictionary is represented as a weighted finite state
bodyText ||| transducer. Each weight represents the estimated cost of the
bodyText ||| word (calculated using the negative log probability). Basically,
bodyText ||| the system selects the sentence segmentation that has the
bodyText ||| smallest total cost. Chang & Chen [1] developed a method for
bodyText ||| word segmentation and part-of-speech tagging based on a first-
bodyText ||| order hidden Markov model.
equation ||| MI(BC) =
page ||| 83
sectionHeader ||| 3. RESEARCH METHOD
bodyText ||| The purpose of this study was to empirically develop a statistical
bodyText ||| formula for identifying 2-character words as well as to
bodyText ||| investigate the usefulness of various factors for identifying the
bodyText ||| words. A sample of 400 sentences was randomly selected from 2
bodyText ||| months (August and September 1995) of news articles from the
bodyText ||| Xin Hua News Agency, comprising around 2.3 million characters.
bodyText ||| The sample sentences were manually segmented. The
bodyText ||| segmentation rules described in [10] were followed fairly closely.
bodyText ||| More details of the manual segmentation process, especially with
bodyText ||| regard to identifying meaningful words will be given in [5].
bodyText ||| 300 sentences were used for model building, i.e. using regression
bodyText ||| analysis to develop a statistical formula. 100 sentences were set
bodyText ||| aside for model validation to evaluate the formula developed in
bodyText ||| the regression analysis. The sample sentences were broken up
bodyText ||| into overlapping bigrams. In the regression analysis, the
bodyText ||| dependent variable was whether a bigram was a two-character
bodyText ||| word according to the manual segmentation. The independent
bodyText ||| variables were various corpus statistics derived from the corpus
bodyText ||| (2 months of news articles).
bodyText ||| The types of frequency information investigated were:
listItem ||| 1. Relative frequency of individual characters and bigrams
listItem ||| (character pairs) in the corpus, i.e. the number of times the
listItem ||| character or bigram occurs in the corpus divided by the total
listItem ||| number of characters in the corpus.
listItem ||| 2. Document frequency of characters and bigrams, i.e. the
listItem ||| number of documents in the corpus containing the character
listItem ||| or bigram divided by the total number of documents in the
listItem ||| corpus.
listItem ||| 3. Weighted document frequency of characters and bigrams. To
listItem ||| calculate the weighted document frequency of a character
listItem ||| string, each document containing the character string is
listItem ||| assigned a score equal to the square of the number of times
listItem ||| the character string occurs in the document. The scores for all
listItem ||| the documents containing the character string are then
listItem ||| summed and divided by the total number of documents in the
listItem ||| corpus to obtain the weighted document frequency for the
listItem ||| character string. The rationale is that if a character string
listItem ||| occurs several times within the same document, this is
listItem ||| stronger evidence that the character string constitutes a word,
listItem ||| than if the character string occurs once in several documents.
listItem ||| Two or more characters can occur together by chance in
listItem ||| several different documents. It is less likely for two
listItem ||| characters to occur together several times within the same
listItem ||| document by chance.
listItem ||| 4. Local frequency in the form of within-document frequency of
listItem ||| characters and bigrams, i.e. the number of times the character
listItem ||| or bigram occurs in the document being segmented.
listItem ||| 5. Contextual information. Frequency information of characters
listItem ||| adjacent to a bigram is used to help determine whether the
listItem ||| bigram is a word. For the character string	A B C D
listItem ||| , to determine whether the bigram BC is a word,
listItem ||| frequency information for the adjacent characters A and D, as
listItem ||| well as the overlapping bigrams AB and BC were considered.
listItem ||| 6. Positional information. We studied whether the position of a
listItem ||| character string (at the beginning, middle or end of a
listItem ||| sentence) gave some indication of whether the character
listItem ||| string was a word.
bodyText ||| The statistical model was developed using forward stepwise
bodyText ||| logistic regression, using the Proc Logistic function in the SAS
bodyText ||| v.6.12 statistical package for Windows. Logistic regression is an
bodyText ||| appropriate regression technique when the dependent variable is
bodyText ||| binary valued (takes the value 0 or 1). The formula developed
bodyText ||| using logistic regression predicts the probability (more
bodyText ||| accurately, the log of the odds) that a bigram is a meaningful
bodyText ||| word.
bodyText ||| In the stepwise regression, the threshold for a variable to enter
bodyText ||| the model was set at the 0.001 significance level and the
bodyText ||| threshold for retaining a variable in the model was set at 0.01. In
bodyText ||| addition, preference was given to relative frequencies and local
bodyText ||| frequencies because they are easier to calculate than document
bodyText ||| frequencies and weighted document frequencies. Also, relative
bodyText ||| frequencies are commonly used in previous studies.
bodyText ||| Furthermore, a variable was entered in a model only if it gave a
bodyText ||| noticeable improvement to the effectiveness of the model. During
bodyText ||| regression analysis, the effectiveness of the model was estimated
bodyText ||| using the measure of concordance that was automatically output
bodyText ||| by the SAS statistical program. A variable was accepted into the
bodyText ||| model only if the measure of concordance improved by at least
bodyText ||| 2% when the variable was entered into the model.
bodyText ||| We evaluated the accuracy of the segmentation using measures of
bodyText ||| recall and precision. Recall and precision in this context are
bodyText ||| defined as follows:
equation ||| Recall = No. of 2-character words identified in the automatic
equation ||| segmentation that are correct
equation ||| No. of 2-character words identified in the manual
equation ||| segmentation
equation ||| Precision = No. of 2-character words identified in the automatic
equation ||| segmentation that are correct
equation ||| No. of 2-character words identified in the automatic
equation ||| segmentation
sectionHeader ||| 4. STATISTICAL FORMULAS
sectionHeader ||| DEVELOPED
subsectionHeader ||| 4.1 The Contextual Information Formula
bodyText ||| The formula that was developed for 2-character words is as
bodyText ||| follows. Given a character string A B C D , the
bodyText ||| association strength for bigram BC is:
equation ||| Assoc(BC) = 0.35 * log2 freq(BC) + 0.37 * log2 freq(A) +
equation ||| 0.32 log2 freq(D) – 0.36 * log2 docfreqwt(AB) –
equation ||| 0.29 * log2 docfreqwt(CD) + 5.91
bodyText ||| where freq refers to the relative frequency in the corpus and
bodyText ||| docfreqwt refers to the weighted document frequency. We refer to
bodyText ||| this formula as the contextual information formula. More details
bodyText ||| of the regression model are given in Table 1.
bodyText ||| The formula indicates that contextual information is helpful in
bodyText ||| identifying word boundaries. A in the formula refers to the
bodyText ||| character preceding the bigram that is being processed, whereas
bodyText ||| D is the character following the bigram. The formula indicates
bodyText ||| that if the character preceding and the character following the
bodyText ||| bigram have high relative frequencies, then the bigram is more
bodyText ||| likely to be a word.
page ||| 84
table ||| 		Parameter	Standard	Wald		Pr >	Standardized
table ||| Variable	DF	Estimate	Error	Chi-Square		Chi-Square	Estimate
table ||| INTERCPT	1	5.9144	0.1719	1184.0532	0.0001	.
table ||| Log freq(BC)	1	0.3502	0.0106	1088.7291	0.0001	0.638740
table ||| Log freq(A)	1	0.3730	0.0113	1092.1382	0.0001	0.709621
table ||| Log freq(D)	1	0.3171	0.0107	886.4446	0.0001	0.607326
table ||| Log docfreqwt(AB)	1	-0.3580	0.0111	1034.0948	0.0001	-0.800520
table ||| Log docfreqwt(CD)	1	-0.2867	0.0104	754.2276	0.0001	-0.635704
table ||| Note: freq refers to the relative frequency, and docfreqwt refers to the
table ||| weighted document frequency.
table ||| Association of Predicted Probabilities and Observed Responses
table ||| Somers' D = 0.803
table ||| Gamma	= 0.803
table ||| Tau-a	= 0.295
table ||| (23875432 pairs)	c	= 0.901
table ||| Concordant	=	90.1%
table ||| Discordant	=	9.8%
table ||| Tied	=	0.1%
tableCaption ||| Table 1. Final regression model for 2-character words
bodyText ||| Contextual information involving the weighted document
bodyText ||| frequency was also found to be significant. The formula indicates
bodyText ||| that if the overlapping bigrams AB and CD have high weighted
bodyText ||| document frequencies, then the bigram BC is less likely to be a
bodyText ||| word. We tried replacing the weighted document frequencies
bodyText ||| with the unweighted document frequencies as well as the relative
bodyText ||| frequencies. These were found to give a lower concordance score.
bodyText ||| Even with docfreq (AB) and docfreq (CD) in the model, docfreqwt
bodyText ||| (AB) and docfreqwt (CD) were found to improve the model
bodyText ||| significantly. However, local frequencies were surprisingly not
bodyText ||| found to be useful in predicting 2-character words.
bodyText ||| We investigated whether the position of the bigram in the
bodyText ||| sentence was a significant factor. We included a variable to
bodyText ||| indicate whether the bigram occurred just after a punctuation
bodyText ||| mark or at the beginning of the sentence, and another variable to
bodyText ||| indicate whether the bigram occurred just before a punctuation
bodyText ||| mark or at the end of a sentence. The interaction between each of
bodyText ||| the position variables and the various relative frequencies
bodyText ||| were not significant. However, it was found that whether or not
bodyText ||| the bigram was at the end of a sentence or just before a
bodyText ||| punctuation mark was a significant factor. Bigrams at the end of
bodyText ||| a sentence or just before a punctuation mark tend to be words.
bodyText ||| However, since this factor did not improve the concordance score
bodyText ||| by 2%, the effect was deemed too small to be included in the
bodyText ||| model.
bodyText ||| It should be noted that the contextual information used in the
bodyText ||| study already incorporates some positional information. The
bodyText ||| frequency of character A (the character preceding the bigram)
bodyText ||| was given the value 0 if the bigram was preceded by a
bodyText ||| punctuation mark or was at the beginning of a sentence.
bodyText ||| Similarly, the frequency of character D (the character following
bodyText ||| the bigram) was given the value 0 if the bigram preceded a
bodyText ||| punctuation mark.
bodyText ||| We also investigated whether the model would be different for
bodyText ||| high and low frequency words. We included in the regression
bodyText ||| analysis the interaction between the relative frequency of the
bodyText ||| bigram and the other relative frequencies. The interaction terms
bodyText ||| were not found to be significant. Finally, it is noted that the
bodyText ||| coefficients for the various factors are nearly the same, hovering
bodyText ||| around 0.34.
subsectionHeader ||| 4.2 Improved Mutual Information Formula
bodyText ||| In this study, the contextual information formula (CIF) was
bodyText ||| evaluated by comparing it with the mutual information formula
bodyText ||| (MIF). We wanted to find out whether the segmentation results
bodyText ||| using the CIF was better than the segmentation results using the
bodyText ||| MIF.
bodyText ||| In the CIF model, the coefficients of the variables were
bodyText ||| determined using regression analysis. If CIF was found to give
bodyText ||| better results than MIF, it could be because the coefficients for
bodyText ||| the variables in CIF had been determined empirically – and not
bodyText ||| because of the types of variables in the formula. To reject this
bodyText ||| explanation, regression analysis was used to determine the
bodyText ||| coefficients for the factors in the mutual information formula.
bodyText ||| We refer to this new version of the formula as the improved
bodyText ||| mutual information formula.
bodyText ||| Given a character string	A B C D	, the improved
bodyText ||| mutual information formula is:
equation ||| Improved MI(BC) = 0.39 * log2 freq(BC) - 0.28 * log2 freq(B) -
equation ||| 0.23 log2 freq(C) - 0.32
bodyText ||| The coefficients are all close to 0.3. The formula is thus quite
bodyText ||| similar to the mutual information formula, except for a
bodyText ||| multiplier of 0.3.
sectionHeader ||| 5. SEGMENTATION ALGORITHMS
bodyText ||| The automatic segmentation process has the following steps:
listItem ||| 1. The statistical formula is used to calculate a score for each
listItem ||| bigram to indicate its association strength (or how likely the
listItem ||| bigram is a word).
listItem ||| 2. A threshold value is then set and used to decide which
listItem ||| bigram is a word. If a bigram obtains a score above the
listItem ||| threshold value, then it is selected as a word. Different
listItem ||| threshold values can be used, depending on whether the user
listItem ||| prefers high recall or high precision.
listItem ||| 3. A segmentation algorithm is used to resolve conflict. If two
listItem ||| overlapping bigrams both have association scores above the
page ||| 85
table ||| 	Precision
table ||| Recall	Comparative Forward Match	Forward Match	Improvement
table ||| Mutual Information		-	-
table ||| 90%	51%
table ||| 80%	52%	47%	5%
table ||| 70%	53%	51%	2%
table ||| 60%	54%	52%	2%
table ||| Improved Mutual Information
table ||| 90%	51%		-	-
table ||| 80%	53%	46%	7%
table ||| 70%	54%	52%	2%
table ||| 60%	55%	54%	1%
table ||| Contextual Information Formula
table ||| 90%	55%	54%	1%
table ||| 80%	62%	62%	0%
table ||| 70%	65%	65%	0%
table ||| 60%	68%	68%	0%
tableCaption ||| Table 2. Recall and precision values for the comparative
tableCaption ||| forward match segmentation algorithm vs. forward match
bodyText ||| threshold value, then there is conflict or ambiguity. The
bodyText ||| frequency of such conflicts will rise as the threshold value is
bodyText ||| lowered. The segmentation algorithm resolves the conflict
bodyText ||| and selects one of the bigrams as a word.
bodyText ||| One simple segmentation algorithm is the forward match
bodyText ||| algorithm. Consider the sentence A B C D E . The
bodyText ||| segmentation process proceeds from the beginning of the
bodyText ||| sentence to the end. First the bigram AB is considered. If the
bodyText ||| association score is above the threshold, then AB is taken as a
bodyText ||| word, and the bigram CD is next considered. If the association
bodyText ||| score of AB is below the threshold, the character A is taken as a
bodyText ||| 1-character word. And the bigram BC is next considered. In
bodyText ||| effect, if the association score of both AB and BC are above
bodyText ||| threshold, the forward match algorithm selects AB as a word and
bodyText ||| not BC.
bodyText ||| The forward match method for resolving ambiguity is somewhat
bodyText ||| arbitrary and not satisfactory. When overlapping bigrams exceed
bodyText ||| the threshold value, it simply decides in favour of the earlier
bodyText ||| bigram. Another segmentation algorithm was developed in this
bodyText ||| study which we refer to as the comparative forward match
bodyText ||| algorithm. This has an additional step:
bodyText ||| If 2 overlapping bigrams AB and BC both have scores above
bodyText ||| the threshold value then their scores are compared. If AB has a
bodyText ||| higher value, then it is selected as a word, and the program
bodyText ||| next considers the bigrams CD and DE. On the other hand, if
bodyText ||| AB has a lower value, then character A is selected as a 1-
bodyText ||| character word, and the program next considers bigrams BC
bodyText ||| and CD.
bodyText ||| The comparative forward match method (CFM) was compared
bodyText ||| with the forward match method (FM) by applying them to the 3
bodyText ||| statistical formulas (the contextual information formula, the
bodyText ||| mutual information formula and the improved mutual
bodyText ||| information formula). One way to compare the effectiveness of
bodyText ||| the 2 segmentation algorithms is by comparing their precision
bodyText ||| figures at the same recall levels. The precision figures for
table ||| Precision
table ||| Recall	Mutual	Improved Mutual Contextual
table ||| Information	Information	Information
table ||| 90%	57%	(0.0)	57%	(-2.5)	61%	(-1.5)
table ||| 80%	59%	(3.7)	59%	(-1.5)	66%	(-0.8)
table ||| 70%	59%	(4.7)	60%	(-1.0)	70%	(-0.3)
table ||| 60%	60%	(5.6)	62%	(-0.7)	74%	(0.0)
table ||| * Threshold values are given in parenthesis.
tableCaption ||| Table 3. Recall and precision for three statistical formulas
bodyText ||| selected recall levels are given in Table 2. The results are based
bodyText ||| on the sample of 300 sentences.
bodyText ||| The comparative forward match algorithm gave better results for
bodyText ||| the mutual information and improved mutual information
bodyText ||| formulas – especially at low threshold values when a large
bodyText ||| number of conflicts are likely. Furthermore, for the forward
bodyText ||| match method, the recall didn t go substantially higher than
bodyText ||| 80% even at low threshold values.
bodyText ||| For the contextual information formula, the comparative forward
bodyText ||| match method did not perform better than forward match, except
bodyText ||| at very low threshold values when the recall was above 90%.
bodyText ||| This was expected because the contextual information formula
bodyText ||| already incorporates information about neighboring characters
bodyText ||| within the formula. The formula gave very few conflicting
bodyText ||| segmentations. There were very few cases of overlapping
bodyText ||| bigrams both having association scores above the threshold –
bodyText ||| except when threshold values were below –1.5.
sectionHeader ||| 6. EVALUATION
subsectionHeader ||| 6.1 Comparing the Contextual Information
subsectionHeader ||| Formula with the Mutual Information
subsectionHeader ||| Formula
bodyText ||| In this section we compare the effectiveness of the contextual
bodyText ||| information formula with the mutual information formula and
bodyText ||| the improved mutual information formula using the 100
bodyText ||| sentences that had been set aside for evaluation purposes. For the
bodyText ||| contextual information formula, the forward match segmentation
bodyText ||| algorithm was used. The comparative forward match algorithm
bodyText ||| was used for the mutual information and the improved mutual
bodyText ||| information formulas.
bodyText ||| The three statistical formulas were compared by comparing their
bodyText ||| precision figures at 4 recall levels – at 60%, 70%, 80% and 90%.
bodyText ||| For each of the three statistical formulas, we identified the
bodyText ||| threshold values that would give a recall of 60%, 70%, 80% and
bodyText ||| 90%. We then determined the precision values at these threshold
bodyText ||| values to find out whether the contextual information formula
bodyText ||| gave better precision than the other two formulas at 60%, 70%,
bodyText ||| 80% and 90% recall. These recall levels were selected because a
bodyText ||| recall of 50% or less is probably unacceptable for most
bodyText ||| applications.
bodyText ||| The precision figures for the 4 recall levels are given in Table 3.
bodyText ||| The recall-precision graphs for the 3 formulas are given in Fig. 1.
bodyText ||| The contextual information formula substantially outperforms
bodyText ||| the mutual information and the improved mutual information
bodyText ||| formulas. At the 90% recall level, the contextual information
page ||| 86
table ||| Avg Precision
table ||| Avg	Mutual	Improved Mutual Contextual
table ||| Recall Information	Information	Information
table ||| 90%	57%	(1.0)	58%	(-2.3)	61%	(-1.5)
table ||| 80%	60%	(3.8)	60%	(-1.4)	67%	(-0.7)
table ||| 70%	59%	(4.8)	60%	(-1.0)	70%	(-0.3)
table ||| 60%	60%	(5.6)	63%	(-0.6)	73%	(0.0)
table ||| * Threshold values are given in parenthesis.
tableCaption ||| Table 4. Average recall and average precision for the three
tableCaption ||| statistical formulas
figure ||| 60	65	70	75	80	85	90	95
figure ||| Recall(%)
figureCaption ||| Fig. 1. Recall-precision graph for the three statistical
bodyText ||| formula was better by about 4%. At the 60% recall level, it
bodyText ||| outperformed the mutual information formula by 14% (giving a
bodyText ||| relative improvement of 23%). The results also indicate that the
bodyText ||| improved mutual information formula does not perform better
bodyText ||| than the mutual information formula.
subsectionHeader ||| 6.2 Statistical Test of Significance
bodyText ||| In order to perform a statistical test, recall and precision figures
bodyText ||| were calculated for each of the 100 sentences used in the
bodyText ||| evaluation. The average recall and the average precision across
bodyText ||| the 100 sentences were then calculated for the three statistical
bodyText ||| formulas. In the previous section, recall and precision were
bodyText ||| calculated for all the 100 sentences combined. Here, recall and
bodyText ||| precision were obtained for individual sentences and then the
bodyText ||| average across the 100 sentences was calculated. The average
bodyText ||| precision for 60%, 70%, 80% and 90% average recall are given
bodyText ||| in Table 4.
bodyText ||| For each recall level, an analysis of variance with repeated
bodyText ||| measures was carried out to find out whether the differences in
bodyText ||| precision were significant. Pairwise comparisons using Tukey s
bodyText ||| HSD test was also carried out. The contextual information
bodyText ||| formula was significantly better (a=0.001) than the mutual
bodyText ||| information and the improved mutual information formulas at all
bodyText ||| 4 recall levels. The improved mutual information formula was
bodyText ||| not found to be significantly better than mutual information.
table ||| Association Score>1.0 (definite errors)
table ||| (	)	university (agricultural
table ||| university)
table ||| (	)	geology (geologic age)
table ||| (	)	plant (upland plant)
table ||| (	)	sovereignty (sovereign state)
table ||| Association Score Between –1.0 and 1.0
table ||| (borderline errors)
table ||| (	)	statistics (statistical data)
table ||| (	)	calamity (natural calamity)
table ||| (	)	resources (manpower resources)
table ||| (	)	professor (associate professor)
table ||| (	)	poor (pauperization)
table ||| (	)	fourteen (the 14th day)
table ||| (	)	twenty (twenty pieces)
tableCaption ||| Table 5. Simple words that are part of a longer
tableCaption ||| meaningful word
table ||| Association Score >1.0 (definite errors)
table ||| will through
table ||| telegraph [on the] day [31 July]
table ||| Association Score Between –1.0 and 1.0
table ||| (borderline errors)
table ||| still	to
table ||| will be
table ||| people etc.
table ||| I want
table ||| Person's name
table ||| (	)	Wan Wen Ju
table ||| Place name
table ||| (	)	a village name in China
table ||| (	)	Canada
table ||| Name of an organization/institution
table ||| (	)	Xin Hua Agency
table ||| (	)	The State Department
tableCaption ||| Table 6. Bigrams incorrectly identified as words
sectionHeader ||| 7. ANALYSIS OF ERRORS
bodyText ||| The errors that arose from using the contextual information
bodyText ||| formula were analyzed to gain insights into the weaknesses of
bodyText ||| the model and how the model can be improved. There are two
bodyText ||| types of errors: errors of commission and errors of omission.
bodyText ||| Errors of commission are bigrams that are identified by the
bodyText ||| automatic segmentation to be words when in fact they are not
bodyText ||| (according to the manual segmentation). Errors of omission are
bodyText ||| bigrams that are not identified by the automatic segmentation to
bodyText ||| be words but in fact they are.
bodyText ||| The errors depend of course on the threshold values used. A high
bodyText ||| threshold (e.g. 1.0) emphasizes precision and a low threshold
bodyText ||| (e.g. –1.0) emphasizes recall. 50 sentences were selected from
bodyText ||| the 100 sample sentences to find the distribution of errors at
bodyText ||| different regions of threshold values.
figure ||| Contextual information
figure ||| Mutual information
figure ||| Improved mutual
figure ||| information
figure ||| 	75 70 65 60 55
page ||| 87
table ||| Association Score between -1.0 and -2.0
table ||| the northern section of a construction project
table ||| fragments of ancient books
table ||| Association Score < -2.0
table ||| September
table ||| 3rd day
table ||| (name of a district in China )
table ||| (name of an institution)
table ||| the Book of Changes
tableCaption ||| Table 7. 2-character words with association score
tableCaption ||| below -1.0
bodyText ||| We divide the errors of commission (bigrams that are incorrectly
bodyText ||| identified as words by the automatic segmentation) into 2 groups:
listItem ||| 1. Definite errors: bigrams with association scores above 1.0 but
listItem ||| are not words
listItem ||| 2. Borderline errors: bigrams with association scores between –
listItem ||| 1.0 and 1.0 and are not words
bodyText ||| We also divide the errors of omission (bigrams that are words
bodyText ||| but are not identified by the automatic segmentation) into 2
bodyText ||| groups:
listItem ||| 1. Definite errors: bigrams with association scores below –1.0
listItem ||| but are words
listItem ||| 2. Borderline errors: bigrams with association scores between –
listItem ||| 1.0 and 1.0 and are words.
subsectionHeader ||| 7.1 Errors of Commission
bodyText ||| Errors of commission can be divided into 2 types:
listItem ||| 1. The bigram is a simple word that is part of a longer
listItem ||| meaningful word.
listItem ||| 2. The bigram is not a word (neither simple word nor
listItem ||| meaningful word).
bodyText ||| Errors of the first type are illustrated in Table 5. The words
bodyText ||| within parenthesis are actually meaningful words but segmented
bodyText ||| as simple words (words on the left). The words lose part of the
bodyText ||| meaning when segmented as simple words. These errors
bodyText ||| occurred mostly with 3 or 4-character meaningful words.
bodyText ||| Errors of the second type are illustrated in Table 6. Many of the
bodyText ||| errors are caused by incorrectly linking a character with a
bodyText ||| function word or pronoun. Some of the errors can easily be
bodyText ||| removed by using a list of function words and pronouns to
bodyText ||| identify these characters.
subsectionHeader ||| 7.2 Errors of Omission
bodyText ||| Examples of definite errors of omission (bigrams with
bodyText ||| association scores below –1.0 but are words) are given in Table
bodyText ||| 7. Most of the errors are rare words and time words. Some are
bodyText ||| ancient names, rare and unknown place names, as well as
bodyText ||| technical terms. Since our corpus comprises general news
bodyText ||| articles, these types of words are not frequent in the corpus. Time
bodyText ||| words like dates usually have low association values because
bodyText ||| they change everyday! These errors can be reduced by
bodyText ||| incorporating a separate algorithm for recognizing them.
bodyText ||| The proportion of errors of the various types are given in Table 8.
sectionHeader ||| 8. CONCLUSION
bodyText ||| A new statistical formula for identifying 2-character words in
bodyText ||| Chinese text, called the contextual information formula, was
bodyText ||| developed empirically using regression analysis. The focus was
bodyText ||| on identifying meaningful words (including multi-word terms
bodyText ||| and idioms) rather than simple words. The formula was found to
bodyText ||| give significantly and substantially better results than the mutual
bodyText ||| information formula.
bodyText ||| Contextual information in the form of the frequency of characters
bodyText ||| that are adjacent to the bigram being processed as well as the
bodyText ||| weighted document frequency of the overlapping bigrams were
bodyText ||| found to be significant factors for predicting the probablity that
bodyText ||| the bigram constitutes a word. Local information (e.g. the
bodyText ||| number of times the bigram occurs in the document being
bodyText ||| segmented) and the position of the bigram in the sentence were
bodyText ||| not found to be useful in determining words.
bodyText ||| Of the bigrams that the formula erroneously identified as words,
bodyText ||| about 80% of them were actually simple words. Of the rest,
bodyText ||| many involved incorrect linking with a function words. Of the
bodyText ||| words that the formula failed to identify as words, more than a
bodyText ||| third of them were rare words or time words. The proportion of
bodyText ||| rare words increased as the threshold value used was lowered.
bodyText ||| These rare words cannot be identified using statistical
bodyText ||| techniques.
bodyText ||| This study investigated a purely statistical approach to text
table ||| Errors of Commission	Borderline Cases	Errors of Omission
table ||| Association score > 1.0	Association score: –1.0 to1.0	Association score < –1.0
table ||| (No. of errors=34)	(No. of cases: 210)
table ||| Simple words	Not words	Simple words	Not words	Meaning- ful words	Association score:	Association score
table ||| 82.3%	17.7%	55.2%	20.5%	24.3%	–1.0 to –2.0	< –2.0
table ||| 					(No. of errors=43)	(No. of errors=22)
table ||| 					Rare words	Others	Rare words	Others
table ||| 					& time	76.8%	& time	36.4%
table ||| 					words		words
table ||| 					23.2%		63.6%
tableCaption ||| Table 8. Proportion of errors of different types
page ||| 88
bodyText ||| segmentation. The advantage of the statistical approach is that it
bodyText ||| can be applied to any domain, provided that the document
bodyText ||| collection is sufficiently large to provide frequency information.
bodyText ||| A domain-specific dictionary of words is not required. In fact, the
bodyText ||| statistical formula can be used to generate a shortlist of candidate
bodyText ||| words for such a dictionary. On the other hand, the statistical
bodyText ||| method cannot identify rare words and proper names. It is also
bodyText ||| fooled by combinations of function words that occur frequently
bodyText ||| and by function words that co-occur with other words.
bodyText ||| It is well-known that a combination of methods is needed to give
bodyText ||| the best segmentation results. The segmentation quality in this
bodyText ||| study can be improved by using a list of function words and
bodyText ||| segmenting the function words as single character words. A
bodyText ||| dictionary of common and well-known names (including names
bodyText ||| of persons, places, institutions, government bodies and classic
bodyText ||| books) could be used by the system to identify proper names that
bodyText ||| occur infrequently in the corpus. Chang et al. [2] developed a
bodyText ||| method for recognizing proper nouns using a dictionary of family
bodyText ||| names in combination with a statistical method for identifying
bodyText ||| the end of the name. An algorithm for identifying time and dates
bodyText ||| would also be helpful. It is not clear whether syntactic processing
bodyText ||| can be used to improve the segmentation results substantially.
bodyText ||| Our current work includes developing statistical formulas for
bodyText ||| identifying 3 and 4-character words, as well as investigating
bodyText ||| whether the statistical formula developed here can be used with
bodyText ||| other corpora. The approach adopted in this study can also be
bodyText ||| used to develop statistical models for identifying multi-word
bodyText ||| terms in English text. It would be interesting to see whether the
bodyText ||| regression model developed for English text is similar to the one
bodyText ||| developed in this study for Chinese text. Frantzi, Ananiadou &
bodyText ||| Tsujii [7], using a different statistical approach, found that
bodyText ||| contextual information could be used to improve the
bodyText ||| identification of multi-word terms in English text.
sectionHeader ||| 9. REFERENCES
reference ||| [1] Chang, C.-H., and Chen, C.-D. A study of integrating
reference ||| Chinese word segmentation and part-of-speech tagging.
reference ||| Communications of COLIPS, 3, 1 (1993), 69-77.
reference ||| [2] Chang, J.-S., Chen, S.-D., Ker, S.-J., Chen, Y., and Liu, J.S.
reference ||| A multiple-corpus approach to recognition of proper names
reference ||| in Chinese texts. Computer Processing of Chinese and
reference ||| Oriental Languages, 8, 1 (June 1994), 75-85.
reference ||| [3] Church, K.W., and Hanks, P. Word association norms,
reference ||| mutual information and lexicography. In Proceedings of the
reference ||| 27th Annual Meeting of the Association for Computational
reference ||| Linguistics (Vancouver, June 1989), 76-83.
reference ||| [4] Dai, J.C., and Lee, H.J. A generalized unification-based LR
reference ||| parser for Chinese. Computer Processing of Chinese and
reference ||| Oriental Languages, 8, 1 (1994), 1-18.
reference ||| [5] Dai, Y. Developing a new statistical method for Chinese
reference ||| text segmentation. (Master s thesis in preparation)
reference ||| [6] Damerau, F.J. Generating and evaluating domain-oriented
reference ||| multi-word terms from texts. Information Processing &
reference ||| Management, 29, 4 (1993), 433-447.
reference ||| [7] Frantzi, K.T., Ananiadou, S., and Tsujii, J. The C-
reference ||| value/NC-value method of automatic recognition for multi-
reference ||| word terms. In C. Nikolaou and C. Stephanidis (eds.),
reference ||| Research and Advanced Technology for Digital Libraries,
reference ||| 2nd European Conference, ECDL 98 (Heraklion, Crete,
reference ||| September 1998), Springer-Verlag, 585-604.
reference ||| [8] Liang, N.Y. The knowledge of Chinese words segmentation
reference ||| [in Chinese]. Journal of Chinese Information Processing, 4,
reference ||| 2 (1990), 42-49.
reference ||| [9] Liu, I.M. Descriptive-unit analysis of sentences: Toward a
reference ||| model natural language processing. Computer Processing of
reference ||| Chinese & Oriental Languages, 4, 4 (1990), 314-355.
reference ||| [10] Liu, Y., Tan, Q., and Shen, X.K. Xin xi chu li yong xian dai
reference ||| han yu fen ci gui fan ji zi dong fen ci fang fa [ Modern
reference ||| Chinese Word Segmentation Rules and Automatic Word
reference ||| Segmentation Methods for Information Processing ]. Qing
reference ||| Hua University Press, Beijing, 1994.
reference ||| [11] Lua, K.T. Experiments on the use of bigram mutual
reference ||| information in Chinese natural language processing.
reference ||| Presented at the 1995 International Conference on Computer
reference ||| Processing of Oriental Languages (ICCPOL) (Hawaii,
reference ||| November 1995). Available: http://137.132.89.143/luakt/
reference ||| publication.html
reference ||| [12] Lua, K.T. From character to word - An application of
reference ||| information theory. Computer Processing of Chinese &
reference ||| Oriental Languages, 4, 4 (1990), 304-312.
reference ||| [13] Lua, K.T., and Gan, G.W. An application of information
reference ||| theory in Chinese word segmentation. Computer Processing
reference ||| of Chinese & Oriental Languages, 8, 1 (1994), 115-124.
reference ||| [14] Nie, J.Y., Hannan, M.L., and Jin, W.Y. Unknown word
reference ||| detection and segmentation of Chinese using statistical and
reference ||| heuristic knowledge. Communications of COLIPS, 5, 1&2
reference ||| (1995), 47-57.
reference ||| [15] Ogawa, Y., and Matsuda, T. Overlapping statistical word
reference ||| indexing: A new indexing method for Japanese text. In
reference ||| Proceedings of the 20th Annual International ACM SIGIR
reference ||| Conference on Research and Development in Information
reference ||| Retrieval (Philadelphia, July 1997), ACM, 226-234.
reference ||| [16] Sproat, R., and Shih, C.L. A statistical method for finding
reference ||| word boundaries in Chinese text. Computer Processing of
reference ||| Chinese & Oriental Languages, 4, 4 (1990), 336-351.
reference ||| [17] Sproat, R., Shih, C., Gale, W., and Chang, N. A stochastic
reference ||| finite-state word-segmentation algorithm for Chinese.
reference ||| Computational Lingustics, 22, 3 (1996), 377-404.
reference ||| [18] Tung, C.-H., and Lee, H.-J. Identification of unknown words
reference ||| from a corpus. Computer Processing of Chinese and
reference ||| Oriental Languages, 8 (Supplement, Dec. 1994), 131-145.
reference ||| [19] Wu, Z., and Tseng, G. ACTS: An automatic Chinese text
reference ||| segmentation system for full text retrieval. Journal of the
reference ||| American Society for Information Science, 46, 2 (1995), 83-
reference ||| 96.
reference ||| [20] Yeh, C.L., and Lee, H.J. Rule-based word identification for
reference ||| mandarin Chinese sentences: A unification approach.
reference ||| Computer Processing of Chinese and Oriental Languages, 5,
reference ||| 2 (1991), 97-118.
page ||| 89

title ||| A Pseudo Random Coordinated Scheduling Algorithm for
title ||| Bluetooth Scatternets
author ||| Andr´as R´acz, Gy¨orgy Mikl´os, Ferenc Kubinszky, Andr´as Valk´o
affiliation ||| Traffic Analysis and Network Performance Lab., Ericsson Research
address ||| Laborc 1, 1037 Budapest, Hungary
address ||| Ph: +36-1-4377621, Fax: +36-1-4377767
email ||| Andras.Racz@eth.ericsson.se
sectionHeader ||| ABSTRACT
bodyText ||| The emergence of Bluetooth as a default radio interface allows
bodyText ||| handheld devices to be rapidly interconnected into ad hoc networks.
bodyText ||| Bluetooth allows large numbers of piconets to form a scatternet us-
bodyText ||| ing designated nodes that participate in multiple piconets. A unit
bodyText ||| that participates in multiple piconets can serve as a bridge and for-
bodyText ||| wards traffic between neighbouring piconets. Since a Bluetooth
bodyText ||| unit can transmit or receive in only one piconet at a time, a bridging
bodyText ||| unit has to share its time among the different piconets. To sched-
bodyText ||| ule communication with bridging nodes one must take into account
bodyText ||| their availability in the different piconets, which represents a dif-
bodyText ||| ficult, scatternet wide coordination problem and can be an impor-
bodyText ||| tant performance bottleneck in building scatternets. In this paper
bodyText ||| we propose the Pseudo-Random Coordinated Scatternet Schedul-
bodyText ||| ing (PCSS) algorithm to perform the scheduling of both intra and
bodyText ||| inter-piconet communication. In this algorithm Bluetooth nodes
bodyText ||| assign meeting points with their peers such that the sequence of
bodyText ||| meeting points follows a pseudo random process that is different
bodyText ||| for each pair of nodes. The uniqueness of the pseudo random se-
bodyText ||| quence guarantees that the meeting points with different peers of
bodyText ||| the node will collide only occasionally. This removes the need
bodyText ||| for explicit information exchange between peer devices, which is
bodyText ||| a major advantage of the algorithm. The lack of explicit signaling
bodyText ||| between Bluetooth nodes makes it easy to deploy the PCSS algo-
bodyText ||| rithm in Bluetooth devices, while conformance to the current Blue-
bodyText ||| tooth specification is also maintained. To assess the performance of
bodyText ||| the algorithm we define two reference case schedulers and perform
bodyText ||| simulations in a number of scenarios where we compare the perfor-
bodyText ||| mance of PCSS to the performance of the reference schedulers.
sectionHeader ||| Keywords
keyword ||| Bluetooth, scheduling, inter-piconet communication, scatternet
sectionHeader ||| 1. INTRODUCTION
bodyText ||| Short range radio technologies enable users to rapidly interconnect
bodyText ||| handheld electronic devices such as cellular phones, palm devices
bodyText ||| or notebook computers. The emergence of Bluetooth [1] as de-
copyright ||| Permission to make digital or hard copies of part or all of this work or
copyright ||| personal or classroom use is granted without fee provided that copies are
copyright ||| not made or distributed for profit or commercial advantage and that copies
copyright ||| bear this notice and the full citation on the first page. To copy otherwise, to
copyright ||| republish, to post on servers, or to redistribute to lists, requires prior
copyright ||| specific permission and/or a fee.
note ||| MobiHOC 2001, Long Beach, CA, USA
copyright ||| © ACM 2001 1-58113-390-1/01/10...$5.00
bodyText ||| fault radio interface in these devices provides an opportunity to turn
bodyText ||| them from stand-alone tools into networked equipment. Building
bodyText ||| Bluetooth ad hoc networks also represents, however, a number of
bodyText ||| new challenges, partly stemming from the fact that Bluetooth was
bodyText ||| originally developed for single hop wireless connections. In this
bodyText ||| paper we study the scheduling problems of inter-piconet commu-
bodyText ||| nication and propose a lightweight scheduling algorithm that Blue-
bodyText ||| tooth nodes can employ to perform the scheduling of both intra and
bodyText ||| inter-piconet communication.
bodyText ||| Bluetooth is a short range radio technology operating in the unli-
bodyText ||| censed ISM (Industrial-Scientific-Medical) band using a frequency
bodyText ||| hopping scheme. Bluetooth (BT) units are organized into piconets.
bodyText ||| There is one Bluetooth device in each piconet that acts as the mas-
bodyText ||| ter, which can have any number of slaves out of which up to seven
bodyText ||| can be active simultaneously. The communication within a piconet
bodyText ||| is organized by the master which polls each slave according to some
bodyText ||| polling scheme. A slave is only allowed to transmit in a slave-
bodyText ||| to-master slot if it has been polled by the master in the previous
bodyText ||| master-to-slave slot. In Section 3 we present a brief overview of
bodyText ||| the Bluetooth technology.
bodyText ||| A Bluetooth unit can participate in more than one piconet at any
bodyText ||| time but it can be a master in only one piconet. A unit that par-
bodyText ||| ticipates in multiple piconets can serve as a bridge thus allowing
bodyText ||| the piconets to form a larger network. We define bridging degree
bodyText ||| as the number of piconets a bridging node is member of. A set
bodyText ||| of piconets that are all interconnected by such bridging units is re-
bodyText ||| ferred to as a scatternet network (Figure 1). Since a Bluetooth unit
bodyText ||| can transmit or receive in only one piconet at a time, bridging units
bodyText ||| must switch between piconets on a time division basis. Due to the
bodyText ||| fact that different piconets are not synchronized in time a bridging
bodyText ||| unit necessarily loses some time while switching from one piconet
bodyText ||| to the other. Furthermore, the temporal unavailability of bridging
bodyText ||| nodes in the different piconets makes it difficult to coordinate the
bodyText ||| communication with them, which impacts throughput and can be
bodyText ||| an important performance constraint in building scatternets.
bodyText ||| There are two important phenomena that can reduce the efficiency
bodyText ||| of the polling based communication in Bluetooth scatternets:
listItem ||| •	slaves that have no data to transmit may be unnecessarily
listItem ||| polled, while other slaves with data to transmit may have to
listItem ||| wait to be polled; and
listItem ||| •	at the time of an expected poll one of the nodes of a master-
listItem ||| slave node pair may not be present in the piconet (the slave
figureCaption ||| Figure 1: Example scatternet
bodyText ||| that is being polled is not listening or the master that is ex-
bodyText ||| pected to poll is not polling).
bodyText ||| The first problem applies to polling based schemes in general, while
bodyText ||| the second one is specific to the Bluetooth environment. In or-
bodyText ||| der to improve the efficiency of inter-piconet communication the
bodyText ||| scheduling algorithm has to coordinate the presence of bridging
bodyText ||| nodes in the different piconets such that the effect of the second
bodyText ||| phenomenon be minimized.
bodyText ||| However, the scheduling of inter-piconet communication expands
bodyText ||| to a scatternet wide coordination problem. Each node that has more
bodyText ||| than one Bluetooth links have to schedule the order in which it com-
bodyText ||| municates with its respective neighbours. A node with multiple
bodyText ||| Bluetooth links can be either a piconet master or a bridging node or
bodyText ||| both. The scheduling order of two nodes will mutually depend on
bodyText ||| each other if they have a direct Bluetooth link in which case they
bodyText ||| have to schedule the communication on their common link for the
bodyText ||| same time slots. This necessitates some coordination between the
bodyText ||| respective schedulers. For instance in Figure 1 the scheduling order
bodyText ||| of node A and the scheduling order of its bridging neighbours, B,
bodyText ||| C, D and E mutually depend on each other, while nodes D and E
bodyText ||| further effects nodes F, G and H as well. Furthermore, the possi-
bodyText ||| ble loops in a scatternet (e.g., A-E-G-H-F-D) makes it even more
bodyText ||| complicated to resolve scheduling conflicts.
bodyText ||| In case of bursty traffic in the scatternet the scheduling problem
bodyText ||| is further augmented by the need to adjust scheduling order in re-
bodyText ||| sponse to dynamic variation of traffic intensity. In a bursty traffic
bodyText ||| environment it is desirable that a node spends most of its time on
bodyText ||| those links that have a backlogged burst of data.
bodyText ||| One way to address the coordination problem of inter-piconet
bodyText ||| scheduling is to explicitly allocate, in advance, time slots for com-
bodyText ||| munication in each pair of nodes. Such a hard coordination ap-
bodyText ||| proach eliminates ambiguity with regards to a node’s presence in
bodyText ||| piconets, but it implies a complex, scatternet wide coordination
bodyText ||| problem and requires explicit signaling between nodes of a scat-
bodyText ||| ternet. In the case of bursty traffic, hard coordination schemes
bodyText ||| generate a significant computation and signaling overhead as the
bodyText ||| communication slots have to be reallocated in response to changes
bodyText ||| in traffic intensity and each time when a new connection is estab-
bodyText ||| lished or released.
bodyText ||| In this paper we propose the Pseudo-Random Coordinated Scatter-
bodyText ||| net Scheduling algorithm which falls in the category of soft coor-
bodyText ||| dination schemes. In soft coordination schemes nodes decide their
bodyText ||| presence in piconets based on local information. By nature, soft co-
bodyText ||| ordination schemes cannot guarantee conflict-free participation of
bodyText ||| bridging nodes in the different piconets, however, they have a sig-
bodyText ||| nificantly reduced complexity. In the PCSS algorithm coordination
bodyText ||| is achieved by implicit rules in the communication without the need
bodyText ||| of exchanging explicit control information. The low complexity of
bodyText ||| the algorithm and its conformance to the current Bluetooth specifi-
bodyText ||| cation allow easy implementation and deployment.
bodyText ||| The first key component of the algorithm is the notion of check-
bodyText ||| points which are defined in relation to each pair of nodes that
bodyText ||| are connected by a Bluetooth link and which represent predictable
bodyText ||| points in time when packet transmission can be initiated on the par-
bodyText ||| ticular link. In other words, checkpoints serve as regular meeting
bodyText ||| points for neighboring nodes when they can exchange packets. In
bodyText ||| order to avoid systematic collision of checkpoints on different links
bodyText ||| of a node the position of checkpoints follows a pseudo random se-
bodyText ||| quence that is specific to the particular link the checkpoints belong
bodyText ||| to.
bodyText ||| The second key component of the algorithm is the dynamic adjust-
bodyText ||| ment of checking intensity, which is necessary in order to effec-
bodyText ||| tively support bursty data traffic. Bandwidth can be allocated and
bodyText ||| deallocated to a particular link by increasing and decreasing check-
bodyText ||| point intensity, respectively.
bodyText ||| To assess the performance of the algorithm we define two reference
bodyText ||| schedulers and relate the performance of the PCSS scheme to these
bodyText ||| reference algorithms in a number of simulation scenarios.
bodyText ||| The remainder of the paper is structured as follows. In Section 2 we
bodyText ||| give an overview of related work focusing on Bluetooth scheduling
bodyText ||| related studies available in the literature. Section 3 gives a brief
bodyText ||| overview of the Bluetooth technology. In Section 4 and 5 we intro-
bodyText ||| duce the proposed algorithm. In Section 6 we define the reference
bodyText ||| schedulers. Finally, in Section 7 we present simulation results.
sectionHeader ||| 2. RELATED WORK
bodyText ||| A number of researchers have addressed the issue of scheduling in
bodyText ||| Bluetooth. Most of these studies have been restricted, however, to
bodyText ||| the single piconet environment, where the fundamental question is
bodyText ||| the polling discipline used by the piconet master to poll its slaves.
bodyText ||| These algorithms are often referred to as intra-piconet scheduling
bodyText ||| schemes. In [7] the authors assume a simple round robin polling
bodyText ||| scheme and investigate queueing delays in master and slave units
bodyText ||| depending on the length of the Bluetooth packets used. In [5] Jo-
bodyText ||| hansson et al. analyze and compare the behavior of three differ-
bodyText ||| ent polling algorithms. They conclude that the simple round robin
bodyText ||| scheme may perform poorly in Bluetooth systems and they propose
bodyText ||| a scheme called Fair Exhaustive Polling. The authors demonstrate
bodyText ||| the strength of this scheme and argue in favor of using multi-slot
bodyText ||| packets. Similar conclusions are drawn by Kalia et al. who argue
bodyText ||| that the traditional round robin scheme may result in waste and un-
bodyText ||| fairness [8]. The authors propose two new scheduling disciplines
bodyText ||| that utilize information about the status of master and slave queues.
bodyText ||| In [9, 10] the authors concentrate on scheduling policies designed
bodyText ||| with the aim of low power consumption. A number of schedul-
bodyText ||| ing policies are proposed which exploit either the park or sniff low
bodyText ||| power modes of Bluetooth.
figure ||| B
figure ||| E
figure ||| A
figure ||| G
figure ||| C
figure ||| D
figure ||| H
figure ||| F
figure ||| master
figure ||| slave
figure ||| slave in two piconets
figure ||| slave in one piconet and master in another
bodyText ||| Although the above studies have revealed a number of important
bodyText ||| performance aspects of scheduling in Bluetooth piconets, the algo-
bodyText ||| rithms developed therein are not applicable for inter-piconet com-
bodyText ||| munication. In [6] the authors have shown that constructing an op-
bodyText ||| timal link schedule that maximizes total throughput in a Bluetooth
bodyText ||| scatternet is an NP hard problem even if scheduling is performed
bodyText ||| by a central entity. The authors also propose a scheduling algo-
bodyText ||| rithm referred to as Distributed Scatternet Scheduling Algorithm
bodyText ||| (DSSA), which falls in the category of distributed, hard coordina-
bodyText ||| tion schemes. Although the DSSA algorithm provides a solution
bodyText ||| for scheduling communication in a scatternet, some of its idealized
bodyText ||| properties (e.g., nodes are aware of the traffic requirements of their
bodyText ||| neighbours) and its relatively high complexity make it difficult to
bodyText ||| apply it in a real life environment.
bodyText ||| There is an ongoing work in the Personal Area Networking (PAN)
bodyText ||| working group of the Bluetooth Special Interest Group (SIG) [2] to
bodyText ||| define an appropriate scheduling algorithm for Bluetooth scatter-
bodyText ||| nets.
sectionHeader ||| 3. BLUETOOTH BACKGROUND
bodyText ||| Bluetooth is a short range radio technology that uses frequency
bodyText ||| hopping scheme, where hopping is performed on 79 RF channels
bodyText ||| spaced 1 MHz apart. Communication in Bluetooth is always be-
bodyText ||| tween master and slave nodes. Being a master or a slave is only
bodyText ||| a logical state: any Bluetooth unit can be a master or a slave.
bodyText ||| The Bluetooth system provides full-duplex transmission based on
bodyText ||| slotted Time Division Duplex (TDD) scheme, where each slot is
bodyText ||| 0.625 ms long. Master-to-slave transmission always starts in an
bodyText ||| even-numbered time slot, while slave-to-master transmission al-
bodyText ||| ways starts in an odd-numbered time slot. A pair of master-to-slave
bodyText ||| and slave-to-master slots are often referred to as a frame. The com-
bodyText ||| munication within a piconet is organized by the master which polls
bodyText ||| each slave according to some polling scheme. A slave is only al-
bodyText ||| lowed to transmit in a slave-to-master slot if it has been polled by
bodyText ||| the master in the previous master-to-slave slot. The master may
bodyText ||| or may not include data in the packet used to poll a slave. Blue-
bodyText ||| tooth packets can carry synchronous data (e.g., real-time traffic) on
bodyText ||| Synchronous Connection Oriented (SCO) links or asynchronous
bodyText ||| data (e.g., elastic data traffic, which is the case in our study) on
bodyText ||| Asynchronous Connectionless (ACL) links. Bluetooth packets on
bodyText ||| an ACL link can be 1, 3 or 5 slot long and they can carry differ-
bodyText ||| ent amount of user data depending on whether the payload is FEC
bodyText ||| coded or not. Accordingly, the Bluetooth packet types DH 1, DH3
bodyText ||| and DH5 denote 1, 3 and 5 slot packets, respectively, where the
bodyText ||| payload is not FEC encoded, while in case of packet types DM1,
bodyText ||| DM3 and DM5 the payload is protected with FEC encoding. There
bodyText ||| are two other types of packets, the POLL and NULL packets that do
bodyText ||| not carry user data. The POLL packet is used by the master when
bodyText ||| it has no user data to the slave but it still wants to poll it. Similarly,
bodyText ||| the NULL packet is used by the slave to respond to the master if it
bodyText ||| has no user data. For further information regarding the Bluetooth
bodyText ||| technology the reader is referred to [1, 3].
sectionHeader ||| 4. OVERVIEW OF THE PCSS ALGO-
sectionHeader ||| RITHM
bodyText ||| Coordination in the PCSS algorithm is achieved by the unique
bodyText ||| pseudo random sequence of checkpoints that is specific to each
bodyText ||| master-slave node pair and by implicit information exchange be-
bodyText ||| tween peer devices. A checkpoint is a designated Bluetooth frame.
bodyText ||| The activity of being present at a checkpoint is referred to as to
bodyText ||| check. A master node actively checks its slave by sending a packet
bodyText ||| to the slave at the corresponding checkpoint and waiting for a re-
bodyText ||| sponse from the slave. The slave node passively checks its master
bodyText ||| by listening to the master at the checkpoint and sending a response
bodyText ||| packet in case of being addressed.
bodyText ||| The expected behaviour of nodes is that they show up at each
bodyText ||| checkpoint on all of their links and check their peers for available
bodyText ||| user data. The exchange of user data packets started at a check-
bodyText ||| point can be continued in the slots following the checkpoint. A
bodyText ||| node remains active on the current link until there is user data in
bodyText ||| either the master-to-slave or slave-to-master directions or until it
bodyText ||| has to leave for a next checkpoint on one of its other links. In
bodyText ||| the PCSS scheme we exploit the concept of randomness in assign-
bodyText ||| ing the position of checkpoints, which excludes the possibility that
bodyText ||| checkpoints on different links of a node will collide systematically,
bodyText ||| thus giving the node an equal chance to visit all of its checkpoints.
bodyText ||| The pseudo random procedure is similar to the one used to derive
bodyText ||| the pseudo random frequency hopping sequence. In particular, the
bodyText ||| PCSS scheme assigns the positions of checkpoints on a given link
bodyText ||| following a pseudo random sequence that is generated based on the
bodyText ||| Bluetooth clock of the master and the MAC address of the slave.
bodyText ||| This scheme guarantees that the same pseudo random sequence
bodyText ||| will be generated by both nodes of a master-slave pair, while the se-
bodyText ||| quences belonging to different node pairs will be different. Figure
bodyText ||| 2 shows an example for the pseudo random arrangement of check-
bodyText ||| points in case of a node pair A and B. The length of the current base
bodyText ||| checking interval is denoted by T(h k and the current checking in-
bodyText ||| tensity is defined accordingly as e9 . There is one checkpoint
bodyText ||| T(i) heck
bodyText ||| within each base checking interval and the position of the check-
bodyText ||| point within this window is changing from one time window to the
bodyText ||| other in a pseudo random manner.
figureCaption ||| Figure 2: Pseudo-random positioning of checkpoints
bodyText ||| Since the pseudo random sequence is different from one link to an-
bodyText ||| other, checkpoints on different links of a node will collide only oc-
bodyText ||| casionally. In case of collision the node can attend only one of the
bodyText ||| colliding checkpoints, which implies that the corresponding neigh-
bodyText ||| bours have to be prepared for a non-present peer. That is, the mas-
bodyText ||| ter might not poll and the slave might not listen at a checkpoint.
bodyText ||| We note that a collision occurs either if there are more than one
bodyText ||| checkpoints scheduled for the same time slot or if the checkpoints
bodyText ||| are so close to each other that a packet transmission started at the
bodyText ||| first checkpoint necessarily overlaps the second one. Furthermore,
bodyText ||| if the colliding checkpoints belong to links in different piconets,
bodyText ||| the necessary time to perform the switch must be also taken into
bodyText ||| account.
bodyText ||| During the communication there is the possibility to increase or
bodyText ||| decrease the intensity of checkpoints depending on the amount of
bodyText ||| user data to be transmitted and on the available capacity of the
bodyText ||| node. According to the PCSS algorithm a node performs certain
bodyText ||| traffic measurements at the checkpoints and increases or decreases
bodyText ||| the current checking intensity based on these measurements. Since
figure ||| T(Z)
figure ||| check
figure ||| 1 frame
figure ||| checkpoints of A toward B	checkpoints of B toward A
bodyText ||| nodes decide independently about the current checking intensity
bodyText ||| without explicit coordination, two nodes on a given link may select
bodyText ||| different base checking periods. In order to ensure that two nodes
bodyText ||| with different checking intensities on the same link can still com-
bodyText ||| municate we require the pseudo random generation of checkpoints
bodyText ||| to be such that the set of checkpoint positions at a lower checking
bodyText ||| intensity is a subset of checkpoint positions at any higher checking
bodyText ||| intensities. In the Appendix we are going to present a pseudo ran-
bodyText ||| dom scheme for generating the position of checkpoints, which has
bodyText ||| the desired properties.
sectionHeader ||| 5. OPERATION OF PCSS
bodyText ||| In what follows, we describe the procedures of the PCSS algorithm.
bodyText ||| We start by the initialization process which ensures that two nodes
bodyText ||| can start communication as soon as a new link has been established
bodyText ||| or the connection has been reset. Next, we describe the rules that
bodyText ||| define how nodes calculate their checkpoints, decide upon their
bodyText ||| presence at checkpoints and exchange packets. Finally, we present
bodyText ||| the way neighboring nodes can dynamically increase and decrease
bodyText ||| of checkpoint intensity.
subsectionHeader ||| 5.1 Initialization
bodyText ||| In the PCSS algorithm there is no need for a separate initialization
bodyText ||| procedure to start communication, since the pseudo random gener-
bodyText ||| ation of checkpoints is defined such that once a master slave node
bodyText ||| pair share the same master’s clock and slave’s MAC address infor-
bodyText ||| mation, it is guaranteed that the same pseudo random sequence will
bodyText ||| be produced at each node. That is, it is guaranteed that two nodes
bodyText ||| starting checkpoint generation at different time instants with differ-
bodyText ||| ent checking intensities will be able to communicate. It is the own
bodyText ||| decision of the nodes to select an appropriate initial checking in-
bodyText ||| tensity, which may depend for example on the free capacities of the
bodyText ||| node or on the amount of data to transmit. Once the communication
bodyText ||| is established the increase and decrease procedures will adjust the
bodyText ||| possibly different initial checking intensities to a common value.
subsectionHeader ||| 5.2 Communication
bodyText ||| A pair of nodes can start exchanging user data packets at a check-
bodyText ||| point, which can expand through the slots following the checkpoint.
bodyText ||| The nodes remain active on the current link following a check-
bodyText ||| point until there is user data to be transmitted or one of them has to
bodyText ||| leave in order to attend a checkpoint on one of its other links. Af-
bodyText ||| ter a POLL/NULL packet pair has been exchanged indicating that
bodyText ||| there is no more user data left the nodes switch off their transmit-
bodyText ||| ters/receivers and remain idle until a next checkpoint comes on one
bodyText ||| of their links. However, during the communication any of the nodes
bodyText ||| can leave in order to attend a coming checkpoint on one of its other
bodyText ||| links. After one of the nodes has left the remaining peer will realize
bodyText ||| the absence of the node and will go idle until the time of its next
bodyText ||| checkpoint. If the master has left earlier the slave will realize the
bodyText ||| absence of the master at the next master-to-slave slot by not receiv-
bodyText ||| ing the expected poll. In the worst case the master has left before
bodyText ||| receiving the last packet response from the slave, which can be a 5
bodyText ||| slot packet in which case the slave wastes 5+1 slots before realiz-
bodyText ||| ing the absence of the master. Similarly, if the master does not get
bodyText ||| a response from the slave it assumes that the slave has already left
bodyText ||| the checkpoint and goes idle until its next checkpoint. Note that the
bodyText ||| master may also waste 5+1 slots in the worst case before realizing
bodyText ||| the absence of the slave.
bodyText ||| A node stores the current length of the base checking interval and
bodyText ||| the time of the next checkpoint for each of its Bluetooth links sep-
bodyText ||| arately. For its ith link a node maintains the variable Tcheck to
bodyText ||| store the length of the current base checking period in number of
bodyText ||| frames and the variable t(i)
bodyText ||| check, which stores the Bluetooth clock
bodyText ||| of the master at the next checkpoint. After passing a checkpoint
bodyText ||| the variable thheck is updated to the next checkpoint by running
bodyText ||| the pseudo random generator (PseudoChkGen) with the current
bodyText ||| value of the master’s clock t(i) and the length of the base checking
bodyText ||| period Tcheck and with the MAC address of the slave A(i)
bodyText ||| slave as in-
bodyText ||| put parameters; tcizeck = PseudoChkGen(Tcheck, A(i)slave, t(i)).
bodyText ||| The procedure PseudoChkGen is described in the Appendix.
bodyText ||| There is a maximum and minimum checking interval Tmax =
bodyText ||| 2fmax and Tmin = 2fmin, respectively. The length of the check-
bodyText ||| ing period must be a power of 2 number of frames and it must take
bodyText ||| a value from the interval [2fmin, 2fmax].
subsectionHeader ||| 5.3 Increasing and Decreasing Checking In-
subsectionHeader ||| tensity
bodyText ||| The increase and decrease procedures are used to adjust the check-
bodyText ||| ing intensity of a node according to the traffic intensity and to the
bodyText ||| availability of the peer device. Each node decides independently
bodyText ||| about the current checking intensity based on traffic measurements
bodyText ||| at checkpoints.
bodyText ||| Since the time spent by a node on a link is proportional to the ratio
bodyText ||| of the number of checkpoints on that link and the number of check-
bodyText ||| points on all links of the node, the bandwidth allocated to a link can
bodyText ||| be controlled by the intensity of checkpoints on that link. This can
bodyText ||| be shown by the following simple calculation.
bodyText ||| Let us assume that the node has L number of links and assume
bodyText ||| further that for the base checking periods on all links of the node
bodyText ||| it holds that Tmin :5 T(i)
bodyText ||| check < Tmax, Vi = 1, ... , L. Then the
bodyText ||| average number of checkpoints within an interval of length Tmaxis
equation ||| L
equation ||| N = 1 T ,)ax  , and the average time between two consecutive
equation ||| Tcheck
equation ||| checkpoints is
equation ||| t=	Tmax	=		1
equation ||| 	N
equation ||| 					,
equation ||| 			L	1  Th
equation ||| 				check
equation ||| 			i=1
bodyText ||| provided that the pseudo random generator produces a uniformly
bodyText ||| distributed sequence of checkpoints. Then, the share of link j from
bodyText ||| the total capacity of the node is
bodyText ||| A node has to measure the utilization of checkpoints on each of
bodyText ||| its links separately in order to provide input to the checking inten-
bodyText ||| sity increase and decrease procedures. According to the algorithm
bodyText ||| a given checkpoint is considered to be utilized if both nodes have
bodyText ||| shown up at the checkpoint and at least one Bluetooth packet carry-
bodyText ||| ing user data has been transmitted or received. If there has not been
bodyText ||| a successful poll at the checkpoint due to the unavailability of any
bodyText ||| of the nodes or if there has been only a POLL/NULL packet pair
bodyText ||| exchange but no user data has been transmitted, the checkpoint is
bodyText ||| considered to be unutilized. We note that due to packet losses the
bodyText ||| utilization of a given checkpoint might be interpreted differently by
bodyText ||| the nodes. However, this does not impact correct operation of the
bodyText ||| algorithm.
equation ||| .
equation ||| rj =
equation ||| 1/T(j) check
equation ||| L
equation ||| 1
equation ||| T(i)
equation ||| i=1 check
bodyText ||| To measure the utilization of checkpoints p(i) on the ith link of the
bodyText ||| node we employ the moving average method as follows. The uti-
bodyText ||| lization of a checkpoint equals to 1 if it has been utilized, otherwise
bodyText ||| it equals to 0. If the checkpoint has been utilized the variable p(i)
bodyText ||| is updated as,
equation ||| p(i) = quti • p(i) + (1 — quti) • 1;
bodyText ||| if the checkpoint has not been utilized it is updated as,
bodyText ||| p(i) = quti • p(i) + (1 — quti) • 0,
bodyText ||| where 0 < quti < 1 is the time scale parameter of the moving
bodyText ||| average method. A further parameter of the utilization measure-
bodyText ||| ment is the minimum number of samples that have to be observed
bodyText ||| before the measured utilization value is considered to be confident
bodyText ||| and can be used as input to decide about increase and decrease of
bodyText ||| checking intensity. This minimum number of samples is a denoted
bodyText ||| by Nsample,min.
bodyText ||| Finally, a node also has to measure its total utilization, which is
bodyText ||| defined as the fraction of time slots where the node has been active
bodyText ||| (transmitted or received) over the total number of time slots. To
bodyText ||| measure the total utilization of a node we employ the moving aver-
bodyText ||| age method again. Each node measures its own utilization p(node)
bodyText ||| and updates the p(node) variable after each Nuti,win number of
bodyText ||| slots as follows:
equation ||| (node) _ (node) (node) (node)
equation ||| p —quti•p +(1—
equation ||| quti )•p (win ),
bodyText ||| where p(win) is the fraction of time slots in the past time window
bodyText ||| of length Nuti,win where the node has been active over the total
bodyText ||| number of time slots Nuti,win.
bodyText ||| If the utilization of checkpoints on link i falls below the lower
bodyText ||| threshold plower, the current base checking period T(i)
bodyText ||| check will be
bodyText ||| doubled. Having a low checkpoint utilization can be either because
bodyText ||| one or both of the nodes have not shown up at all of the checkpoints
bodyText ||| or because there is not enough user data to be transmitted. In either
bodyText ||| cases the intensity of checkpoints has to be decreased. Whenever a
bodyText ||| decrease or increase is performed on link i the measured utilization
bodyText ||| p(i) must be reset.
bodyText ||| Since the parameter T (i)k is one of the inputs to the pseudo ran-
bodyText ||| chec
bodyText ||| dom checkpoint generation process, PseudoChkGen the check-
bodyText ||| points after the decrease will be generated according to the new
bodyText ||| period. Furthermore, due to the special characteristic of the check-
bodyText ||| point generation scheme the remaining checkpoints after the de-
bodyText ||| crease will be a subset of the original checkpoints, which guaran-
bodyText ||| tees that the two nodes can sustain communication independent of
bodyText ||| local changes in checking intensities.
bodyText ||| An example for the checking intensity decrease in case of a node
bodyText ||| pair A and B is shown in Figure 3. First, node A decreases check-
bodyText ||| ing intensity by doubling its current base checking period in re-
bodyText ||| sponse to the measured low utilization. As a consequence node B
bodyText ||| will find node A on average only at every second checkpoint and
bodyText ||| its measured utilization will decrease rapidly. When the measured
bodyText ||| utilization at node B falls below the threshold plower, B realizes
bodyText ||| that its peer has a lower checking intensity and follows the de-
bodyText ||| crease by doubling its current base checking period. Although we
bodyText ||| have not explicitly indicated in the Figure, it is assumed that there
bodyText ||| has been user data exchanged at each checkpoint where both nodes
bodyText ||| were present.
figure ||| checkpoints of A toward B
figure ||| node A reduces the checking
figure ||| intensity, by doubling its base period	checkpoints of B toward A
figure ||| ρ=0.35<ρlower	ρ=0.2	ρ=0.35	ρ=0.5	ρ=0.65 ρ=0.7
figure ||| node B realizes the decrease and
figure ||| doubles its base period
figureCaption ||| Figure 3: Checking intensity decrease
bodyText ||| Recall from the utilization measurement procedure that there is a
bodyText ||| minimum number of checkpoints Nsample,min that has to be sam-
bodyText ||| pled before the measured utilization is considered to be confident
bodyText ||| and can be used to decide about checking intensity decrease. The
bodyText ||| parameter Nsample,min together with the parameter of the mov-
bodyText ||| ing average method quti determine the time scale over which the
bodyText ||| utilization of checkpoints has to be above the threshold plower,
bodyText ||| otherwise the node decreases checking intensity. It might be also
bodyText ||| reasonable to allow that the parameter Nsample,min and the mov-
bodyText ||| ing average parameter quti can be changed after each decrease or
bodyText ||| increase taking into account for example the current checking in-
bodyText ||| tensity, the available resources of the node or the amount of user
bodyText ||| data to be transmitted, etc. However, in the current implementation
bodyText ||| we apply fixed parameter values.
bodyText ||| After a checkpoint where user data has been exchanged (not only a
bodyText ||| POLL/NULL packet pair) checking intensity can be increased pro-
bodyText ||| vided that the measured utilization of checkpoints exceeds the up-
bodyText ||| per threshold pupper and the node has available capacity. Formally
bodyText ||| a checking intensity increase is performed on link i if the following
bodyText ||| two conditions are satisfied: p(i) > pupper and p(node) < piinn T),
bodyText ||| where pupil r is the upper threshold of the total utilization of the
bodyText ||| node. This last condition ensures that the intensity of checkpoints
bodyText ||| will not increase unbounded. The intensity of checkpoints is dou-
bodyText ||| bled at each increase by dividing the current length of the base
bodyText ||| checking period T(n,eck by 2. For typical values of pupper we rec-
bodyText ||| ommend 0.8 < pupper < 0.9 in which case the respective plower
bodyText ||| value should be plower < 0.4 in order to avoid oscillation of in-
bodyText ||| creases and decreases.
bodyText ||| Figure 4 shows an example where node A and B communicate and
bodyText ||| after exchanging user data at the second checkpoint both nodes
bodyText ||| double the checking intensity. In the Figure we have explicitly in-
bodyText ||| dicated whether there has been user data exchanged at a checkpoint
bodyText ||| or not.
figureCaption ||| Figure 4: Checking intensity increase
figure ||| ρ=0.6ρ=0.5 ρ=0.58ρ=0.48ρ=0.56 ρ=0.46ρ=0.36<ρlower ρ=0.2	ρ=0.35 ρ=0.5
figure ||| ρ=0.7	ρ=0.8>ρupper ρ=0.2 ρ=0.4	ρ=0.3 ρ=0.55
figure ||| checking intensity
figure ||| ρ=0.3
figure ||| ρ=0.55
figure ||| ρ=0.8>ρupper
figure ||| ρ=0.2 ρ=0.4
figure ||| checkpoints of A toward B
figure ||| checkpoints of B toward A
figure ||| ρ=0.7
figure ||| user data
figure ||| both node A and B double
figure ||| user data
figure ||| user data	user data
sectionHeader ||| 6. REFERENCE ALGORITHMS
bodyText ||| In this section we define the Ideal Coordinated Scatternet Sched-
bodyText ||| uler (ICSS) and the Uncoordinated Greedy Scatternet Scheduler
bodyText ||| (UGSS) reference algorithms. The ICSS algorithm represents
bodyText ||| the “ideal” case where nodes exploit all extra information when
bodyText ||| scheduling packet transmissions, which would not be available in a
bodyText ||| realistic scenario. The UGSS algorithm represents the greedy case
bodyText ||| where nodes continuously switch among their Bluetooth links in a
bodyText ||| random order.
subsectionHeader ||| 6.1 The ICSS Algorithm
bodyText ||| The ICSS algorithm is a hypothetical, ideal scheduling algorithm
bodyText ||| that we use as a reference case in the evaluation of the PCSS
bodyText ||| scheme. In the ICSS algorithm a node has the following extra
bodyText ||| information about its neighbours, which represents the idealized
bodyText ||| property of the algorithm:
listItem ||| •	a node is aware of the already pre-scheduled transmissions
listItem ||| of its neighbours; and
listItem ||| •	a node is aware of the content of the transmission buffers of
listItem ||| its neighbours.
bodyText ||| According to the ICSS algorithm each node maintains a scheduling
bodyText ||| list, which contains the already pre-scheduled tasks of the node. A
bodyText ||| task always corresponds to one packet pair exchange with a given
bodyText ||| peer of the node. Knowing the scheduling list of the neighbours
bodyText ||| allows the node to schedule communication with its neighbours
bodyText ||| without overlapping their other communication, such that the ca-
bodyText ||| pacity of the nodes is utilized as much as possible. Furthermore
bodyText ||| being aware of the content of the transmission buffers of neigh-
bodyText ||| bours eliminates the inefficiencies of the polling based scheme,
bodyText ||| since there will be no unnecessary polls and the system will be
bodyText ||| work-conserving.
bodyText ||| In the scheduling list of a node there is at most one packet pair
bodyText ||| exchange scheduled in relation to each of its peers, provided that
bodyText ||| there is a Bluetooth packet carrying user data either in the trans-
bodyText ||| mission buffer of the node or in the transmission buffer of the peer
bodyText ||| or in both. After completing a packet exchange on a given link the
bodyText ||| two nodes schedule the next packet exchange, provided that there
bodyText ||| is user data to be transmitted in at least one of the directions. If
bodyText ||| there is user data in only one of the directions, a POLL or NULL
bodyText ||| packet is assumed for the reverse direction depending on whether
bodyText ||| it is the master-to-slave or slave-to-master direction, respectively.
bodyText ||| The new task is fitted into the scheduling lists of the nodes using
bodyText ||| a first fit strategy. According to this strategy the task is fitted into
bodyText ||| the first time interval that is available in both of the scheduling lists
bodyText ||| and that is long enough to accommodate the new task. Note that the
bodyText ||| algorithm strives for maximal utilization of node capacity by trying
bodyText ||| to fill in the unused gaps in the scheduling lists.
bodyText ||| If there is no more user data to be transmitted on a previously busy
bodyText ||| link, the link goes to idle in which case no tasks corresponding to
bodyText ||| the given link will be scheduled until there is user data again in at
bodyText ||| least one of the directions.
bodyText ||| An example for the scheduling lists of a node pair A and B is shown
bodyText ||| in Figure 5. The tasks are labeled with the name of the correspond-
bodyText ||| ing peers the different tasks belong to. Each node has as many
bodyText ||| pre-scheduled tasks in its scheduling list as the number of its ac-
bodyText ||| tive Bluetooth links. A link is considered to be active if there is
bodyText ||| current time
bodyText ||| schedule the next packet pair
bodyText ||| exchange for node A and B
figureCaption ||| Figure 5: Example for the scheduling lists of a node pair in case
figureCaption ||| of the ICSS algorithm
bodyText ||| user data packet in at least one of the directions. Node A has active
bodyText ||| peers B and C, while node B has active peers A, D and E. After
bodyText ||| node A and B have finished the transmission of a packet pair they
bodyText ||| schedule the next task for the nearest time slots that are available
bodyText ||| in both of their scheduling lists and the number of consecutive free
bodyText ||| time slots is greater than or equal to the length of the task.
subsectionHeader ||| 6.2 The UGSS Algorithm
bodyText ||| In the UGSS algorithm Bluetooth nodes do not attempt to coordi-
bodyText ||| nate their meeting points, instead each node visits its neighbours
bodyText ||| in a random order. Nodes switch continuously among their Blue-
bodyText ||| tooth links in a greedy manner. If the node has n number of links it
bodyText ||| chooses each of them with a probability of 1/n. The greedy nature
bodyText ||| of the algorithm results in high power consumption of Bluetooth
bodyText ||| devices.
bodyText ||| If the node is the master on the visited link it polls the slave by
bodyText ||| sending a packet on the given link. The type of Bluetooth packet
bodyText ||| sent can be a 1, 3 or 5 slot packet carrying useful data or an empty
bodyText ||| POLL packet depending on whether there is user data to be trans-
bodyText ||| mitted or not. After the packet has been sent the master remains
bodyText ||| active on the link in order to receive any response from the slave.
bodyText ||| If the slave has not been active on the given link at the time when
bodyText ||| the master has sent the packet it could not have received the packet
bodyText ||| and consequently it will not send a response to the master. After
bodyText ||| the master has received the response of the slave or if it has sensed
bodyText ||| the link to be idle indicating that no response from the salve can be
bodyText ||| expected, it selects the next link to visit randomly.
bodyText ||| Similar procedure is followed when the node is the slave on the
bodyText ||| visited link. The slave tunes its receiver to the master and listens
bodyText ||| for a packet transmission from the master in the current master-
bodyText ||| to-slave slot. If the slave has not been addressed by the master
bodyText ||| in the actual master-to-slave slot it immediately goes to the next
bodyText ||| link. However, if the slave has been addressed it remains active on
bodyText ||| the current link and receives the packet. After having received the
bodyText ||| packet of the master the slave responds with its own packet in the
bodyText ||| following slave-to-master slot. After the slave has sent its response
bodyText ||| it selects the next link to visit randomly.
sectionHeader ||| 7. SIMULATION RESULTS
bodyText ||| First, we evaluate the algorithm in a realistic usage scenario, which
bodyText ||| is the Network Access Point (NAP) scenario. Next we investigate
bodyText ||| theoretical configurations and obtain asymptotical results that re-
bodyText ||| veals the scaling properties of the algorithm. For instance we in-
bodyText ||| vestigate the carried traffic in function of the number of forwarding
figure ||| peer B
figure ||| Dee, C	pear C
figure ||| t
figure ||| peer A
figure ||| ✑peer E	peer E
figure ||| t
figure ||| scheduling list of
figure ||| node A
figure ||| Deer B
figure ||| scheduling list of
figure ||| node B
figure ||| Deer A p
figure ||| eer D
bodyText ||| hops along the path and in function of bridging degree. Both in the
bodyText ||| realistic and theoretical configurations we relate the performance of
bodyText ||| the PCSS scheme to the performance of the ICSS and UGSS ref-
bodyText ||| erence algorithms. Before presenting the scenarios and simulation
bodyText ||| results we shortly describe the simulation environment and define
bodyText ||| the performance metrics that are going to be measured during the
bodyText ||| simulations.
subsectionHeader ||| 7.1 Simulation Environment
bodyText ||| We have developed a Bluetooth packet level simulator, which is
bodyText ||| based on the Plasma simulation environment [4]. The simulator
bodyText ||| has a detailed model of all the packet transmission, reception pro-
bodyText ||| cedures in the Bluetooth Baseband including packet buffering, up-
bodyText ||| per layer packet segmentation/reassemble, the ARQ mechanism,
bodyText ||| etc. The simulator supports all Bluetooth packet types and follows
bodyText ||| the same master-slave slot structure as in Bluetooth. For the physi-
bodyText ||| cal layer we employ a simplified analytical model that captures the
bodyText ||| frequency collision effect of interfering piconets.
bodyText ||| In the current simulations the connection establishment procedures,
bodyText ||| e.g., the inquiry and page procedures are not simulated in detail and
bodyText ||| we do not consider dynamic scatternet formation either. Instead we
bodyText ||| perform simulations in static scatternet configurations where the
bodyText ||| scatternet topology is kept constant during one particular run of
bodyText ||| simulation.
bodyText ||| In the current simulations we run IP directly on top of the Blue-
bodyText ||| tooth link layer and we apply AODV as the routing protocol in the
bodyText ||| IP layer. The simulator also includes various implementations of
bodyText ||| the TCP protocol (we employed RenoPlus) and supports different
bodyText ||| TCP/IP applications, from which we used TCP bulk data transfer
bodyText ||| in the current simulations.
bodyText ||| One of the most important user perceived performance measures is
bodyText ||| the achieved throughput. We are going to investigate the throughput
bodyText ||| in case of bulk TCP data transfer and in case of Constant Bit Rate
bodyText ||| (CBR) sources.
bodyText ||| In order to take into account the power consumption of nodes we
bodyText ||| define activity ratio of a node, ract as the fraction of time when
bodyText ||| the node has been active over the total elapsed time; and power
bodyText ||| efficiency, pep p as the fraction of the number of user bytes success-
bodyText ||| fully communicated (transmitted and received) over the total time
bodyText ||| the node has been active. The power efficiency shows the num-
bodyText ||| ber of user bytes that can be communicated by the node during an
bodyText ||| active period of length 1 sec. Power efficiency can be measured
bodyText ||| in [kbit/sec], or assuming that being active for 1 sec consumes 1
bodyText ||| unit of energy we can get a more straightforward dimension of
bodyText ||| [kbit/energy unit], which is interpreted as the number of bits that
bodyText ||| can be transmitted while consuming one unit of energy.
subsectionHeader ||| 7.2 Network Access Point Scenario
bodyText ||| In this scenario we have a NAP that is assumed to be connected to
bodyText ||| a wired network infrastructure and it provides network access via
bodyText ||| its Bluetooth radio interface. The NAP acts as a master and up to 7
bodyText ||| laptops, all acting as slaves, can connect to the NAP. Furthermore
bodyText ||| we assume that each laptop has a Bluetooth enabled mouse and
bodyText ||| each laptop connects to its mouse by forming a new piconet as it is
bodyText ||| shown in Figure 6.
bodyText ||| We simulate a bulk TCP data transfer from the NAP towards each
bodyText ||| laptop separately. Regarding the traffic generated by the mouse we
bodyText ||| assume that the mouse produces a 16 byte long packet each 50 ms,
figureCaption ||| Figure 6: Network Access Point Scenario
bodyText ||| periodically. In the NAP-laptop communication we are interested
bodyText ||| in the achieved throughput while in the laptop-mouse communi-
bodyText ||| cation we are concerned with the delay perceived by the mouse.
bodyText ||| In the current scenario we switched off the dynamic checkperiod
bodyText ||| adjustment capability of the PCSS algorithm and we set the base
bodyText ||| checking period to 32 frames (40 ms), which is in accordance with
bodyText ||| the delay requirement of a mouse. Note that this same base check-
bodyText ||| ing period is applied also on the NAP-laptop links, although, there
bodyText ||| is no delay requirement for the TCP traffic. However, the current
bodyText ||| implementation in the simulator does not yet support the setting of
bodyText ||| the base checking periods for each link separately. The dynamic
bodyText ||| checking period adjustment would definitely improve the through-
bodyText ||| put of NAP-laptop communication as we are going to see later in
bodyText ||| case of other configurations.
bodyText ||| The simulation results are shown in Figure 7. In plot (a) the aver-
bodyText ||| aged throughput of NAP-laptop communications are shown in the
bodyText ||| function of number of laptops for the different algorithms, respec-
bodyText ||| tively. Graph (b) plots the sum of the throughputs between the
bodyText ||| NAP and all laptops. As we expect, the individual laptop through-
bodyText ||| put decreases as the number of laptops increases. However, it is
bodyText ||| important to notice that the sum of laptop throughputs do not de-
bodyText ||| crease with increasing number of laptops in case of the PCSS and
bodyText ||| ICSS algorithms. As the number of laptops increases the efficient
bodyText ||| coordination becomes more important and the total carried traffic
bodyText ||| will decrease with the uncoordinated UGSS scheme. The increase
bodyText ||| of the total throughput in case of the PCSS algorithm is the conse-
bodyText ||| quence of the fixed checking intensities, which allocates one half
bodyText ||| of a laptop capacity to the mouse and the other half to the NAP. In
bodyText ||| case of small number of laptops this prevents the laptops to fully
bodyText ||| utilize the NAP capacity, which improves as the number of laptops
bodyText ||| increases.
bodyText ||| The 99% percentile of the delay seen by mouse packets is shown in
bodyText ||| plot (c). The delay that can be provided with the PCSS algorithm
bodyText ||| is determined by the base checking period that we use. Recall, that
bodyText ||| in the current setup the base checking period of the PCSS scheme
bodyText ||| was set to 32 frames, which implies that the delay has to be in the
bodyText ||| order of 32 frames, as shown in the figure. The low delay with the
bodyText ||| UGSS algorithm is due to the continuous switching among the links
bodyText ||| of a node, which ensures high polling intensity within a piconet
bodyText ||| and frequent switching between piconets. The UGSS algorithm
bodyText ||| provides an unnecessarily low delay, which is less than the delay
bodyText ||| requirement at the expense of higher power consumption.
bodyText ||| Plots (d) and (e) show the averaged activity ratio over all lap-
bodyText ||| tops and mice, respectively. The considerably higher throughput
bodyText ||| achieved for small number of laptops by the ICSS scheme explains
bodyText ||| its higher activity ratio. On graph (f) the averaged power efficiency
bodyText ||| of laptops is shown, which relates the number of bytes transmit-
bodyText ||| ted to the total time of activity. The power efficiency of the PCSS
figure ||| mouse
figure ||| mouse
figure ||| NAP
figure ||| laptop	max 7	laptop
bodyText ||| scheme decreases with increasing number of laptops, which is a
bodyText ||| consequence of the fixed checking intensities. Since the NAP has
bodyText ||| to share its capacity among the laptops, with an increasing number
bodyText ||| of laptops there will be an increasing number of checkpoints where
bodyText ||| the NAP cannot show up. In such cases the dynamic checking in-
bodyText ||| tensity adjustment procedure could help by decreasing checking
bodyText ||| intensity on the NAP-laptop links. Recall that in the current sce-
bodyText ||| nario we employed fixed checking intensities in order to satisfy the
bodyText ||| mouse delay requirement. It is also important to notice that with the
bodyText ||| uncoordinated UGSS scheme the activity ratio of a mouse is rela-
bodyText ||| tively high, which is an important drawback considering the low
bodyText ||| power capabilities of such devices.
subsectionHeader ||| 7.3 Impact of Number of Forwarding Hops
bodyText ||| In what follows, we investigate the performance impact of the num-
bodyText ||| ber of forwarding hops along the communication path in the scat-
bodyText ||| ternet configuration shown in Figure 8. The configuration consists
bodyText ||| of a chain of S/M forwarding nodes (Fi) and a certain number of
bodyText ||| additional node pairs connected to each forwarding node in order to
bodyText ||| generate background traffic. The number of S/M forwarding nodes
bodyText ||| is denoted by NF. There are NB number of background node pairs
bodyText ||| connected to each forwarding node as masters. The background
bodyText ||| traffic flows from each source node Bz) to its destination pair
bodyText ||| B(P) through the corresponding forwarding node Fi. The traffic
bodyText ||| that we are interested in is a bulk TCP data transfer between node
bodyText ||| S and D. The background traffic is a CBR source, which generates
bodyText ||| 512 byte long IP packets with a period of length 0.05 sec.
none ||| D
bodyText ||| During the simulations we vary the number of forwarding hops NF
bodyText ||| and the number of background node pairs NB connected to each
bodyText ||| forwarding node. As one would expect, with increasing number of
bodyText ||| forwarding hops and background node pairs the coordinated algo-
bodyText ||| rithms will perform significantly better than the one without any
bodyText ||| coordination (UGSS).
bodyText ||| The throughput of the S-D traffic as a function of the number of
bodyText ||| forwarding nodes (NF) without background traffic (NB = 0) and
bodyText ||| with two pairs of background nodes (NB = 2) are shown in Fig-
bodyText ||| ure 9 (a) and (b), respectively. The throughput in case of no cross
bodyText ||| traffic drops roughly by half when we introduce the first forward-
bodyText ||| ing node. Adding additional forwarding hops continuously reduces
bodyText ||| the throughput, however, the decrease at each step is less drasti-
bodyText ||| cal. We note that in case of the ICSS scheme one would expect
bodyText ||| that for NF > 1 the throughput should not decrease by adding
bodyText ||| additional forwarding hops. However, there are a number of other
bodyText ||| effects besides the number of forwarding hops that decrease the
bodyText ||| throughput. For instance, with an increasing number of forward-
bodyText ||| ing hops the number of piconets in the same area increases, which,
bodyText ||| in turn, causes an increasing number of lost packets over the radio
bodyText ||| interface due to frequency collisions. Furthermore with increasing
bodyText ||| number of hops the end-to-end delay suffered by the TCP flow in-
bodyText ||| creases, which makes the TCP connection less reactive to recover
bodyText ||| from packet losses.
bodyText ||| In the no background traffic case the PCSS scheme performs close
bodyText ||| to the UGSS algorithm in terms of throughput. However, as we
bodyText ||| introduce two pairs of background nodes the UGSS algorithm fails
bodyText ||| completely, while the PCSS scheme still achieves approximately 20
bodyText ||| kbit/sec throughput. Furthermore, the power efficiency of the PCSS
bodyText ||| scheme is an order of magnitude higher than that of the UGSS algo-
bodyText ||| rithm in both cases, which indicates that the PCSS algorithm con-
bodyText ||| sumes significantly less power to transmit the same amount of data
bodyText ||| than the UGSS scheme.
subsectionHeader ||| 7.4 Impact of Bridging Degree
bodyText ||| Next we investigate the performance of scheduling algorithms as
bodyText ||| the number of piconets that a bridging node participates in is in-
bodyText ||| creased. The scatternet setup that we consider is shown in Figure
bodyText ||| 10, where we are interested in the performance of the bridging node
bodyText ||| C. Node C is an all slave bridging node and it is connected to mas-
bodyText ||| ter nodes Pi, where the number of these master nodes is denoted
bodyText ||| by NP. To each master node Pi we connect NL number of leaf
bodyText ||| nodes as slaves in order to generate additional background load in
bodyText ||| the piconets. We introduce bulk TCP data transfer from node C
bodyText ||| towards each of its master node Pi and CBR background traffic
bodyText ||| on each Lij — Pi link. The packet generation interval for back-
bodyText ||| ground sources was set to 0.25 sec, which corresponds to a 16
bodyText ||| kbit/sec stream. During the simulation we vary the number of pi-
bodyText ||| conets NP participated by node C and investigate the performance
bodyText ||| of the PCSS algorithm with and without dynamic checkpoint inten-
bodyText ||| sity changes. The number of background nodes NL connected to
bodyText ||| each master node Pi was set to NL = 3 and it was kept constant in
bodyText ||| the simulations.
none ||| LmNL
bodyText ||| The throughputs of TCP flows between node C and each Pi are av-
bodyText ||| eraged and it is shown in Figure 10 (a). The sum of TCP through-
bodyText ||| puts are plotted in graph (b) and the power efficiency of the central
bodyText ||| node is shown in graph (c). The PCSS algorithm has been tested
bodyText ||| both with fixed base checking periods equal to 32 frames (“PCSS-
bodyText ||| 32”) and with dynamic checking intensity changes as well (“PCSS-
bodyText ||| dyn”). The parameter settings of the dynamic case is shown in Ta-
bodyText ||| ble 1.
table ||| quti = 0.7	Nsample,min = 4
table ||| Plower = 0.3	Pupper = 0.7
table ||| quiode)=0.7	Nuti,win = 10	maxe) = 0.8
table ||| Tmin = 8	Tmax = 256
tableCaption ||| Table 1: Parameter setting of the dynamic PCSS scheme
figure ||| Lmi
figure ||| LNPm
figure ||| Pm
figure ||| LNPNL
figure ||| PNP
figure ||| C
figureCaption ||| Figure 10: Impact of number of participated piconets
figure ||| 	B(D)	B(D)	B(D).
figure ||| 	1i	2i	NF�
figureCaption ||| Figure 8: Impact of number of forwarding nodes
figure ||| B(S)
figure ||| B(S)
figure ||| F1	F2	FNF
figure ||| S
figure ||| B(S)
figure ||| N.
figure ||| F�
figure ||| (d)	(e)	(f)
figureCaption ||| Figure 7: Throughput, delay and power measures in the function of number of laptops connected to the NAP
figure ||| Activity Ratio of laptops
figure ||| Activity Ratio of mice
figure ||| Power efficiency of laptops
figure ||| TCP throughput per laptop
figure ||| Sum TCP throughput of laptops
figure ||| 0.99 percentile of mouse dealy
figure ||| 1	2	3	4	5	6	7
figure ||| Number of laptops
figure ||| 1	2	3	4	5	6	7
figure ||| Number of laptops
figure ||| 1	2	3	4	5	6	7
figure ||| Number of laptops
figure ||| (a)	(b)	(c)
figure ||| PCSS
figure ||| UGSS
figure ||| ICSS
figure ||| PCSS
figure ||| UGSS
figure ||| ICSS
figure ||| 500
figure ||| 450
figure ||| 400
figure ||| 350
figure ||| 300
figure ||| 250
figure ||| 200
figure ||| 150
figure ||| 100
figure ||| 50
figure ||| 0
figure ||| 0.06
figure ||| 0.05
figure ||| 0.04
figure ||| 0.03
figure ||| 0.02
figure ||| 0.01
figure ||| 0
figure ||| 500
figure ||| 450
figure ||| 400
figure ||| 350
figure ||| 300
figure ||| 250
figure ||| 200
figure ||| 150
figure ||| 100
figure ||| 50
figure ||| 0
figure ||| PCSS
figure ||| UGSS
figure ||| ICSS
figure ||| 1	2	3	4	5	6	7
figure ||| Number of laptops
figure ||| 1	2	3	4	5	6	7
figure ||| Number of laptops
figure ||| 1	2	3	4	5	6	7
figure ||| Number of laptops
figure ||| 600
figure ||| 0.9
figure ||| 0.8
figure ||| 0.7
figure ||| 0.6
figure ||| 0.5
figure ||| 0.4
figure ||| 0.3
figure ||| 0.2
figure ||| 0.1
figure ||| 500
figure ||| PCSS
figure ||| UGSS
figure ||| ICSS
figure ||| 0.9
figure ||| 0.8
figure ||| 0.7
figure ||| 0.6
figure ||| 0.5
figure ||| 0.4
figure ||| 0.3
figure ||| 0.2
figure ||| 0.1
figure ||| 400
figure ||| 300
figure ||| 200
figure ||| 100
figure ||| 0
figure ||| 0
figure ||| 0
figure ||| PCSS
figure ||| UGSS
figure ||| ICSS
figure ||| PCSS
figure ||| UGSS
figure ||| ICSS
figure ||| TCP throughput without background nodes (N_B=0)
figure ||| PCSS
figure ||| UGSS
figure ||| ICSS
figure ||| 0	1	2	3	4	5	6	7	8
figure ||| Number of forwarding nodes (N_F)
figure ||| 500
figure ||| 450
figure ||| 400
figure ||| 350
figure ||| 300
figure ||| 250
figure ||| 200
figure ||| 150
figure ||| 100
figure ||| 50
figure ||| 0
figure ||| TCP throughput with 2 pairs of background nodes (N_B=2)
figure ||| Power efficiency of forwarding nodes (N_B=2)
figure ||| 0	1	2	3	4	5	6	7	8
figure ||| Number of forwarding nodes (N_F)
figure ||| 0	1	2	3	4	5	6	7	8
figure ||| Number of forwarding nodes (N_F)
figure ||| 0
figure ||| 300
figure ||| 200
figure ||| 100
figure ||| 500
figure ||| 450
figure ||| 400
figure ||| PCSS
figure ||| UGSS
figure ||| ICSS
figure ||| 350
figure ||| 300
figure ||| 250
figure ||| 200
figure ||| 150
figure ||| 100
figure ||| 50
figure ||| 0
figure ||| 600
figure ||| 500
figure ||| 400
figure ||| PCSS
figure ||| UGSS
figure ||| ICSS
figure ||| (a)	(b)	(c)
figureCaption ||| Figure 9: Throughput and power efficiency in function of number of forwarding hops
bodyText ||| It is important to notice that the per flow TCP throughputs in case
bodyText ||| of the dynamic PCSS scheme matches quite closely the through-
bodyText ||| put achieved by the ICSS algorithm and it significantly exceeds the
bodyText ||| throughput that has been achieved by the fixed PCSS. This large
bodyText ||| difference is due to the relatively low background traffic in the
bodyText ||| neighbouring piconets of node C, in which case the dynamic PCSS
bodyText ||| automatically reduces checkpoint intensity on the lightly loaded
bodyText ||| links and allocates more bandwidth to the highly loaded ones by
bodyText ||| increasing checking intensity.
sectionHeader ||| 8. CONCLUSIONS
bodyText ||| We have presented Pseudo Random Coordinated Scatternet
bodyText ||| Scheduling, an algorithm that can efficiently control communica-
bodyText ||| tion in Bluetooth scatternets without exchange of control informa-
bodyText ||| tion between Bluetooth devices. The algorithm relies on two key
bodyText ||| components, namely the use of pseudo random sequences of meet-
bodyText ||| ing points, that eliminate systematic collisions, and a set of rules
bodyText ||| that govern the increase and decrease of meeting point intensity
bodyText ||| without explicit coordination.
bodyText ||| We have evaluated the performance of PCSS in a number of sim-
bodyText ||| ulation scenarios, where we have compared throughput and power
bodyText ||| measures achieved by PCSS to those achieved by two reference
bodyText ||| schedulers. The first reference scheduler is an uncoordinated
bodyText ||| greedy algorithm, while the other is a hypothetical “ideal” sched-
bodyText ||| uler.
bodyText ||| In all the scenarios investigated we have found that PCSS achieves
bodyText ||| higher throughput than the uncoordinated reference algorithm.
bodyText ||| Moreover, with the traffic dependent meeting point intensity adjust-
bodyText ||| ments the throughput and power measures of PCSS quite closely
bodyText ||| match the results of the “ideal” reference algorithm. At the same
bodyText ||| time PCSS consumes approximately the same amount of power as
bodyText ||| the ideal scheduler to achieve the same throughput, which is sig-
bodyText ||| nificantly less than the power consumption of the uncoordinated
bodyText ||| reference scheduler.
sectionHeader ||| 9. REFERENCES
reference ||| [1] Bluetooth Special Interest Group. Bluetooth Baseband
reference ||| Specification Version 1.0 B. http://www.bluetooth.com/.
figureCaption ||| Figure 11: Throughput and power efficiency in function of the bridging degree of node C
figure ||| Averaged TCP throughput between central node and master nodes
figure ||| Sum of TCP throughputs at the central node
figure ||| Effective power of central node
figure ||| 1	2	3	4	5	6
figure ||| Number of piconets participated by the central node (N_P)
figure ||| 1	2	3	4	5	6
figure ||| Number of piconets participated by the central node (N_P)
figure ||| 1	2	3	4	5	6
figure ||| Number of piconets participated by the central node (N_P)
figure ||| (a)	(b)	(c)
figure ||| PCSS-3y2
figure ||| PCSUGSS
figure ||| ICSS
figure ||| PCSS-32
figure ||| PCSS-dyn
figure ||| UGSS
figure ||| ICSS
figure ||| 450
figure ||| 400
figure ||| 350
figure ||| 300
figure ||| 250
figure ||| 200
figure ||| 150
figure ||| 100
figure ||| 50
figure ||| 0
figure ||| 450
figure ||| 400
figure ||| 350
figure ||| 300
figure ||| 250
figure ||| 200
figure ||| 150
figure ||| 100
figure ||| 50
figure ||| 0
figure ||| 600
figure ||| 500
figure ||| 400
figure ||| 300
figure ||| 200
figure ||| 100
figure ||| 0
figure ||| PCSS-32
figure ||| P	y UGG
figure ||| ICSS
reference ||| [2] Bluetooth Special Interest Group.
reference ||| http://www.bluetooth.com/.
reference ||| [3] J. Haartsen. BLUETOOTH- the universal radio interface for
reference ||| ad-hoc, wireless connectivity. Ericsson Review, (3), 1998.
reference ||| [4] Z. Haraszti, I. Dahlquist, A. Farag´o, and T. Henk. Plasma -
reference ||| an integrated tool for ATM network operation. In Proc.
reference ||| International Switching Symposium, 1995.
reference ||| [5] N. Johansson, U. K¨orner, and P. Johansson. Performance
reference ||| evaluation of scheduling algorithms for Bluetooth. In IFIP
reference ||| TC6 WG6.2 Fifth International Conference on Broadband
reference ||| Communications (BC’99), Hong Kong, November 1999.
reference ||| [6] N. Johansson, U. K¨orner, and L. Tassiulas. A distributed
reference ||| scheduling algorithm for a Bluetooth scatternet. In Proc. of
reference ||| The Seventeenth International Teletraffic Congress, ITC’17,
reference ||| Salvador da Bahia, Brazil, September 2001.
reference ||| [7] P. Johansson, N. Johansson, U. K¨orner, J. Elgg, and
reference ||| G. Svennarp. Short range radio based ad hoc networking:
reference ||| Performance and properties. In Proc. ofICC’99, Vancouver,
reference ||| 1999.
reference ||| [8] M. Kalia, D. Bansal, and R. Shorey. MAC scheduling and
reference ||| SAR policies for Bluetooth: A master driven TDD
reference ||| pico-cellular wireless system. In IEEE Mobile Multimedia
reference ||| Communications Conference MOMUC’99, San Diego,
reference ||| November 1999.
reference ||| [9] M. Kalia, D. Bansal, and R. Shorey. MAC scheduling
reference ||| policies for power optimization in Bluetooth: A master
reference ||| driven TDD wireless system. In IEEE Vehicular Technology
reference ||| Conference 2000, Tokyo, 2000.
reference ||| [10] M. Kalia, S. Garg, and R. Shorey. Efficient policies for
reference ||| increasing capacity in Bluetooth: An indoor pico-cellular
reference ||| wireless system. In IEEE Vehicular Technology Conference
reference ||| 2000, Tokyo, 2000.
sectionHeader ||| APPENDIX
bodyText ||| Here, we present the procedure for generating the pseudo ran-
bodyText ||| dom sequence of checkpoints, where we reuse the elements of
bodyText ||| the pseudo random frequency hop generation procedure available
bodyText ||| in Bluetooth. The inputs to the checkpoint generation procedure
bodyText ||| PseudoChkGen are the current checking period T(h ck, the Blue-
bodyText ||| tooth MAC address of the slave As`ave and the current value of the
bodyText ||| master’s clock t(i). A node can perform checkpoint generation us-
bodyText ||| ing the PseudoChkGen procedure at any point in time, it is al-
bodyText ||| ways guaranteed that the position of checkpoint generated by the
bodyText ||| two nodes will be the same, as it has been pointed out in Section
bodyText ||| 5.1. Nevertheless the typical case will be that whenever a node ar-
bodyText ||| rives to a checkpoint it generates the position of the next checkpoint
bodyText ||| on the given link. The variable t(i)cysstores the master’s
bodyText ||| chek
bodyText ||| clock at the next checkpoint, thus it needs to be updated every time
bodyText ||| a checkpoint is passed. Here we note that the Bluetooth clock of a
bodyText ||| device is a 28 bit counter, where the LSB changes at every half slot.
bodyText ||| Let us assume that the base period of checkpoints on the it h link of
bodyText ||| the node is Tcheck = 2j-2, j > 2 number of frames, which means
bodyText ||| that there is one pseudo randomly positioned checkpoint in each
bodyText ||| consecutive time interval of length T(h ck and the jth bit of the
bodyText ||| Bluetooth clock changes at every Tcheck. Upon arrival to a check-
bodyText ||| point the variable t(i)
bodyText ||| check equals to the current value of the master’s
bodyText ||| clock on that link. After the checkpoint generation procedure has
bodyText ||| been executed the variable tcheck will store the master’s clock at
bodyText ||| the time of the next checkpoint on that link.
bodyText ||| Before starting the procedure the variable tch)eck is set to the cur-
bodyText ||| rent value of the master’s clock t(i) in order to cover the general
bodyText ||| case when at the time of generating the next checkpoint the value
bodyText ||| of t(i)
bodyText ||| check does not necessarily equals to the current value of the
bodyText ||| master’s clock t(i). The position of the next checkpoint is ob-
bodyText ||| tained such that the node first adds the current value of Tcheck
bodyText ||| to the variable tclzeck, clears the bits [j — 1, ... , 0] of tch)eck and
bodyText ||| then generates the bits [j — 1, ... , 2] one by one using the pro-
bodyText ||| cedure PseudoBitGen(X, WctT`). When generating the kth bit
bodyText ||| (j-1 < k < 2) the clock bits X = tcheck [k+1, ... , k+5] are fed
bodyText ||| as inputs to the PseudoBitGen procedure, while the control word
bodyText ||| WctT` is derived from tcheck including the bits already generated
bodyText ||| and from the MAC address of the slave As`ave. The schematic view
bodyText ||| of generating the clock bits of the next checkpoint is illustrated in
bodyText ||| Figure 12.
figureCaption ||| Figure 12: Generating the clock bits of the next checkpoint
figure ||| 28.
figure ||| 27.
figure ||| Wctrl
figure ||| k+5.
figure ||| PseudoBitGen
figure ||| X
figure ||| k+1.
figure ||| k.
figure ||| 2.
figure ||| 1.
figure ||| 0.
bodyText ||| The PseudoBitGen procedure is based on the pseudo random
bodyText ||| scheme used for frequency hop selection in Bluetooth. How-
bodyText ||| ever, before presenting the PseudoBitGen procedure we give the
bodyText ||| pseudo-code of the PseudoChkGen procedure.
bodyText ||| PseudoChkGen procedure:
bodyText ||| t(i): the current value of the master’s clock;
bodyText ||| Tcheck = 2j-2, j > 2: current length of the base checkperiod
bodyText ||| in terms of number of frames.
equation ||| (i)	(i)
equation ||| tcheck = t
equation ||| (i)tcheck [j — 1, . . . , 0] = 0;
equation ||| t(i)= t(i)	+T(i)
equation ||| check	check	check;
equation ||| k=j—1;
equation ||| while (k > 2)
equation ||| X[0, ... , 4] = t(i)
equation ||| check [k + 1,... , k + 5];
equation ||| tcheck[k] =PseudoBitGen(X,WctTd);
equation ||| k=k-1;
equation ||| end
bodyText ||| Finally, we discuss the PseudoBitGen procedure, which is illus-
bodyText ||| trated in Figure 13.
figure ||| Z[0]
figureCaption ||| Figure 13: The PseudoBitGen procedure
figure ||| P[13,12] P[11,10] P[9,8]	P[7,6]	P[5,4]	P[3,2] P[1,0]
figure ||| B
figure ||| A
figure ||| D
figure ||| 5
figure ||| C
figure ||| 5
figure ||| 5
figure ||| 9
figure ||| Add
figure ||| mod 32
figure ||| 5
figure ||| Y
figure ||| PERM5
figure ||| bit selector
figure ||| V[k mod 5]
figure ||| X
figure ||| O
figure ||| R
figure ||| Z
figure ||| X  5
figure ||| 5
figure ||| 5
figure ||| V
figure ||| 1
figure ||| O
figureCaption ||| Figure 14: Butterfly permutation
bodyText ||| The control words of the PseudoBitGen procedure
bodyText ||| WctTd = {A, B, C, D} are the same as the control words of
bodyText ||| the frequency hop selection scheme in Bluetooth and they are
bodyText ||| shown in Table 2. However, the input X and the additional
bodyText ||| bit selection operator at the end are different. As it has been
bodyText ||| discussed above the input X is changing depending on which
bodyText ||| bit of the checkpoint is going to be generated. When gener-
bodyText ||| ating the kth clock bit of the next checkpoint the clock bits
bodyText ||| X = tcheck [k + 1,... , k + 5] are fed as inputs and the bit
bodyText ||| selection operator at the end selects the (k mod 5)th bit of the 5
bodyText ||| bits long output V.
table ||| A	Asdave [27 — 23] ® tcheck [25 — 21]
table ||| B	B[0 — 3] = Asdave[22 — 19], B[4] =		0
table ||| C	Asdave [8, 6, 4, 2, 0] ® t(i)	— 16]
table ||| 	check [20
table ||| D	Asdave[18 — 10] ® t(i)	— 7]
table ||| 	check [15
tableCaption ||| Table 2: Control words
bodyText ||| The operation PERM5 is a butterfly permutation, which is the
bodyText ||| same as in the frequency hop selection scheme of Bluetooth and
bodyText ||| it is described in Figure 14. Each bit of the control word P is
bodyText ||| associated with a given bit exchange in the input word. If the
bodyText ||| given bit of the control word equals to 1 the corresponding bit ex-
bodyText ||| change is performed otherwise skipped. The control word P is
bodyText ||| obtained from C and D, such that P[i] = D[i], i = 0... 8 and
bodyText ||| P[j + 9] = C[j], j = 0 ... 4.

title ||| A Resilient Packet-Forwarding Scheme against Maliciously
title ||| Packet-Dropping Nodes in Sensor Networks
author ||| Suk-Bok Lee and Yoon-Hwa Choi
affiliation ||| Department of Computer Engineering
affiliation ||| Hongik University
address ||| 121-791 Seoul, Korea
email ||| {sblee, yhchoi}@cs.hongik.ac.kr
sectionHeader ||| ABSTRACT
bodyText ||| This paper focuses on defending against compromised nodes’
bodyText ||| dropping of legitimate reports and investigates the misbe-
bodyText ||| havior of a maliciously packet-dropping node in sensor net-
bodyText ||| works. We present a resilient packet-forwarding scheme us-
bodyText ||| ing Neighbor Watch System (NWS), specifically designed
bodyText ||| for hop-by-hop reliable delivery in face of malicious nodes
bodyText ||| that drop relaying packets, as well as faulty nodes that
bodyText ||| fail to relay packets. Unlike previous work with multipath
bodyText ||| data forwarding, our scheme basically employs single-path
bodyText ||| data forwarding, which consumes less power than multipath
bodyText ||| schemes. As the packet is forwarded along the single-path
bodyText ||| toward the base station, our scheme, however, converts into
bodyText ||| multipath data forwarding at the location where NWS de-
bodyText ||| tects relaying nodes’ misbehavior. Simulation experiments
bodyText ||| show that, with the help of NWS, our forwarding scheme
bodyText ||| achieves a high success ratio in face of a large number of
bodyText ||| packet-dropping nodes, and effectively adjusts its forwarding
bodyText ||| style, depending on the number of packet-dropping nodes
bodyText ||| en-route to the base station.
sectionHeader ||| Categories and Subject Descriptors
category ||| C.2.0 [Computer-Communication Networks]: General—
category ||| Security and protection
sectionHeader ||| General Terms
keyword ||| Security, Algorithm, Reliability
sectionHeader ||| Keywords
keyword ||| Sensor Network Security, Reliable Delivery, Packet-dropping
keyword ||| Attacks, Secure Routing
sectionHeader ||| 1. INTRODUCTION
bodyText ||| Wireless sensor networks consist of hundreds or even thou-
bodyText ||| sands of small devices each with sensing, processing, and
copyright ||| Permission to make digital or hard copies of all or part of this work for
copyright ||| personal or classroom use is granted without fee provided that copies are
copyright ||| not made or distributed for profit or commercial advantage and that copies
copyright ||| bear this notice and the full citation on the first page. To copy otherwise, to
copyright ||| republish, to post on servers or to redistribute to lists, requires prior specific
copyright ||| permission and/or a fee.
note ||| SASN’06, October 30, 2006, Alexandria, Virginia, USA.
copyright ||| Copyright 2006 ACM 1-59593-554-1/06/0010 ...$5.00.
bodyText ||| communicating capabilities to monitor the real-world envi-
bodyText ||| ronment. They are envisioned to play an important role
bodyText ||| in a wide variety of areas ranging from critical military-
bodyText ||| surveillance applications to forest fire monitoring and the
bodyText ||| building security monitoring in the near future. In such a
bodyText ||| network, a large number of sensor nodes are distributed to
bodyText ||| monitor a vast field where the operational conditions are
bodyText ||| harsh or even hostile. To operate in such environments, se-
bodyText ||| curity is an important aspect for sensor networks and secu-
bodyText ||| rity mechanisms should be provided against various attacks
bodyText ||| such as node capture, physical tampering, eavesdropping,
bodyText ||| denial of service, etc [23, 33, 38].
bodyText ||| Previous research efforts against outsider attacks in key-
bodyText ||| management schemes [4, 13, 32] and secure node-to-node
bodyText ||| communication mechanisms [24, 32] in sensor networks are
bodyText ||| well-defined. Those security protections, however, break
bodyText ||| down when even a single legitimate node is compromised.
bodyText ||| It turns out to be relatively easy to compromise a legiti-
bodyText ||| mate node [14], which is to extract all the security infor-
bodyText ||| mation from the captured node and to make malicious code
bodyText ||| running for the attacker’s purpose.
bodyText ||| Even a small number of compromised nodes can pose
bodyText ||| severe security threats on the entire part of the network,
bodyText ||| launching several attacks such as dropping legitimate re-
bodyText ||| ports, injecting bogus sensing reports, advertising inconsis-
bodyText ||| tent routing information, eavesdropping in-network commu-
bodyText ||| nication using exposed keys, etc. Such disruption by the
bodyText ||| insider attacks can be devastating unless proper security
bodyText ||| countermeasures against each type of attacks are provided.
bodyText ||| In reality, detecting all of the compromised nodes in the
bodyText ||| network is not always possible, so we should pursue grace-
bodyText ||| ful degradation [35], with a small number of compromised
bodyText ||| nodes. The fundamental principle for defense against the
bodyText ||| insider attacks is to restrict the security impact of a node
bodyText ||| compromise as close to the vicinity of the compromised node
bodyText ||| as possible.
bodyText ||| When the attacker compromises a legitimate node, it may
bodyText ||| first try to replicate the captured node indefinitely with the
bodyText ||| same ID and spread them over the network. Against such
bodyText ||| attacks, a distributed detection mechanism (based on emer-
bodyText ||| gent properties [11]) has been proposed by Parno et al. [31].
bodyText ||| In addition, Newsome et al. [30] have presented the tech-
bodyText ||| niques that prevent the adversary from arbitrarily creating
bodyText ||| new IDs for nodes.
bodyText ||| Using cryptographic information obtained from a cap-
bodyText ||| tured node, attackers can establish pairwise keys with any
bodyText ||| legitimate nodes in order to eavesdrop communication any-
page ||| 59
bodyText ||| where in the network. Localized key-establishment scheme
bodyText ||| by Zhu et al. [46] is a good solution against such an in-
bodyText ||| sider attack. Since the scheme does not allow a cloned node
bodyText ||| (by inside-attackers) to establish pairwise keys with any le-
bodyText ||| gitimate nodes except the neighbors of the compromised
bodyText ||| nodes, the cryptographic keys extracted from the compro-
bodyText ||| mised node are of no use for attackers.
bodyText ||| Compromised nodes can also inject false sensing reports
bodyText ||| to the network (i.e. report fabrication attacks [39]), which
bodyText ||| causes false alarms at the base station or the aggregation
bodyText ||| result to far deviate from the true measurement. Proposed
bodyText ||| en-route filtering mechanisms [8, 39, 41, 44, 47] that de-
bodyText ||| tect and drop such false reports effectively limit the impact
bodyText ||| of this type of attacks. Also, proposed secure aggregation
bodyText ||| protocols [34, 40] have addressed the problem of false data
bodyText ||| injection, and they ensure that the aggregated result is a
bodyText ||| good approximation to the true value in the presence of a
bodyText ||| small number of compromised nodes.
bodyText ||| Advertising inconsistent routing information by compro-
bodyText ||| mised nodes can disrupt the whole network topology. Hu et
bodyText ||| al. [19, 20] have proposed SEAD, a secure ad-hoc network
bodyText ||| routing protocol that uses efficient one-way hash functions
bodyText ||| to prevent any inside attackers from injecting inconsistent
bodyText ||| route updates. A few secure routing protocols [6, 27] in sen-
bodyText ||| sor networks have been proposed to detect and exclude the
bodyText ||| compromised nodes injecting inconsistent route updates.
bodyText ||| Compromised nodes also can silently drop legitimate re-
bodyText ||| ports (i.e. selective forwarding attacks [23]), instead of for-
bodyText ||| warding them to the next-hop toward the base station. Since
bodyText ||| data reports are delivered over multihop wireless paths to
bodyText ||| the base station, even a small number of strategically-placed
bodyText ||| packet-dropping nodes can deteriorate the network through-
bodyText ||| put significantly. In order to bypass such nodes, most work
bodyText ||| on secure routing and reliable delivery in sensor networks re-
bodyText ||| lies on multipath forwarding scheme [5, 6, 7, 10], or interleaved-
bodyText ||| mesh forwarding scheme [26, 29, 39, 42].
bodyText ||| Among the insider attacks described above, this paper fo-
bodyText ||| cuses on defense against compromised nodes’ dropping of le-
bodyText ||| gitimate reports and we present a resilient packet-forwarding
bodyText ||| scheme using Neighbor Watch System (NWS) against ma-
bodyText ||| liciously packet-dropping nodes in sensor networks. We in-
bodyText ||| vestigate the misbehavior of a maliciously packet-dropping
bodyText ||| node and show that an acknowledgement (ACK) that its
bodyText ||| packets were correctly received at the next-hop node does
bodyText ||| not guarantee reliable delivery from the security perspective.
bodyText ||| NWS is specifically designed for hop-by-hop reliable de-
bodyText ||| livery in face of malicious nodes that drop relaying packets,
bodyText ||| as well as faulty nodes that fail to relay packets. Unlike pre-
bodyText ||| vious work [10, 29, 42] with multipath data forwarding, our
bodyText ||| scheme basically employs single-path data forwarding, which
bodyText ||| consumes less power than multipath schemes. As the packet
bodyText ||| is forwarded along the single-path toward the base station,
bodyText ||| our scheme, however, converts into multipath data forward-
bodyText ||| ing at the location where NWS detects relaying nodes’ mis-
bodyText ||| behavior.
bodyText ||| NWS exploits the dense deployment of large-scale static
bodyText ||| sensor networks and the broadcast nature of communication
bodyText ||| pattern to overhear neighbors’ communication for free.
bodyText ||| The contribution of this paper is two-fold. First, we in-
bodyText ||| vestigate the misbehavior of a maliciously packet-dropping
bodyText ||| node and propose a resilient packet-forwarding scheme, which
bodyText ||| basically employs single-path data forwarding, in face of
bodyText ||| such nodes, as well as faulty nodes. Second, our scheme
bodyText ||| can work with any existing routing protocols. Since it is
bodyText ||| designed not for securing specific protocols but for universal
bodyText ||| protocols, it can be applied to any existing routing protocols
bodyText ||| as a security complement.
bodyText ||| The rest of paper is organized as follows. Background is
bodyText ||| given in Section 2. We present our resilient packet-forwarding
bodyText ||| scheme in Section 3. An evaluation of the scheme is given
bodyText ||| and discussed in Section 4. We present conclusions and fu-
bodyText ||| ture work in Section 5.
sectionHeader ||| 2. BACKGROUND
sectionHeader ||| 2.1 Network Model
bodyText ||| Sensor networks typically comprise one or multiple base
bodyText ||| stations and hundreds or thousands of inexpensive, small,
bodyText ||| static, and resource-constrained nodes scattered over a wide
bodyText ||| area. An inexpensive sensor node cannot afford tamper-
bodyText ||| resistant packaging. We assume that a large number of sen-
bodyText ||| sor nodes are deployed in high density over a vast field, such
bodyText ||| that the expected degree of a node is high; each sensor has
bodyText ||| multiple neighbors within its communication range. Sensing
bodyText ||| data or aggregated data are sent along the multihop route
bodyText ||| to the base station. We assume that each sensor node has
bodyText ||| a constant transmission range, and communication links are
bodyText ||| bidirectional.
bodyText ||| Our sensor network model employs a key-establishment
bodyText ||| scheme that extends the one in LEAP [46] where the im-
bodyText ||| pact of a node compromise is localized in the immediate
bodyText ||| neighborhood of the compromised node, and our scheme is
bodyText ||| based on it. To evolve from LEAP, we will describe it briefly
bodyText ||| in Section 2.4.
subsectionHeader ||| 2.2 Threat Model
bodyText ||| The attacks launched from outsiders hardly cause much
bodyText ||| damage to the network, since the rouge node, which does not
bodyText ||| possesses the legitimate credentials (e.g. the predistributed
bodyText ||| key ring from the key pool [13]), fails to participate in the
bodyText ||| network. On the other hand, there may be multiple attacks
bodyText ||| from insiders (e.g. dropping legitimate reports, injecting
bodyText ||| false sensing reports, advertising inconsistent route infor-
bodyText ||| mation, and eavesdropping in-network communication us-
bodyText ||| ing exposed keys, etc), and the combination of such attacks
bodyText ||| can lead to disruption of the whole network. Thus, proper
bodyText ||| security countermeasures (specifically designed to protect
bodyText ||| against each type of the attacks) should be provided.
bodyText ||| Among them, in this paper, we focus on defending against
bodyText ||| compromised nodes’ dropping of legitimate reports; Other
bodyText ||| attacks mentioned above are effectively dealt with by several
bodyText ||| proposed schemes as described in the previous section.
bodyText ||| We consider a packet-dropping node as not merely a faulty
bodyText ||| node, but also an arbitrarily malicious node. Some previous
bodyText ||| work [3, 29, 36] on reliable delivery uses an acknowledge-
bodyText ||| ment (ACK) that its packets were correctly received at the
bodyText ||| next-hop node, in order to find out unreliable links. How-
bodyText ||| ever, in the presence of maliciously packet-dropping nodes,
bodyText ||| simply receiving ACK from a next-hop node does not guar-
bodyText ||| antee that the packet will be really forwarded by the next-
bodyText ||| hop node. For example, node u forwards a packet to com-
bodyText ||| promised node v, and node u waits for ACK from node v.
bodyText ||| Node v sends back ACK to node u, and then node v silently
bodyText ||| drops the packet. This simple example shows that receiving
bodyText ||| ACK is not enough for reliable delivery in face of maliciously
bodyText ||| packet-dropping nodes.
page ||| 60
bodyText ||| For more reliability, we should check whether the next-
bodyText ||| hop node really forwards the relaying packet to its proper
bodyText ||| next-hop node. Fortunately, due to the broadcast nature of
bodyText ||| communication pattern in sensor networks, we can overhear
bodyText ||| neighbors’ communication for free (for now per-link encryp-
bodyText ||| tion is ignored). After forwarding a packet to next-hop node
bodyText ||| v and buffering recently-sent packets, by listening in on node
bodyText ||| v’s traffic, we can tell whether node v really transmits the
bodyText ||| packet. Watchdog [28] mechanism (extension to DSR [22]),
bodyText ||| implicit ACK in M2 RC [29], and local monitoring in DI-
bodyText ||| CAS [25] detect misbehaving nodes in this way. However,
bodyText ||| this kind of simple overhearing schemes does not guarantee
bodyText ||| reliable delivery, either.
bodyText ||| With arbitrarily malicious nodes, we should be assured
bodyText ||| that the node, to which the next-hop node forwards the
bodyText ||| relaying packet, is really a neighbor of the next-hop node.
bodyText ||| For example, node u forwards a packet to compromised node
bodyText ||| v, and node u listens in on node v’s traffic to compare each
bodyText ||| overheard packet with the packet in the buffer. Node v
bodyText ||| transmits the relaying packet whose intended next-hop id
bodyText ||| marked with any id in the network such as x that is not a
bodyText ||| neighbor of v. Then node u overhears this packet from node
bodyText ||| v, and considers it forwarded correctly despite the fact that
bodyText ||| none actually receives the packet. The packet is eventually
bodyText ||| dropped without being detected. We refer to this attack as
bodyText ||| blind letter attack.
bodyText ||| We consider packet-dropping attacks to be addressed in
bodyText ||| this paper as ones ranging from the naive case (e.g. a faulty
bodyText ||| node) to the most malicious one (e.g. a node launching
bodyText ||| blind letter attack). We focus on developing a solution to
bodyText ||| such attacks.
subsectionHeader ||| 2.3 Notation
bodyText ||| We use the following notation throughout the paper:
listItem ||| •	u, v are principals, such as communicating nodes.
listItem ||| •	R.. is a random number generated by u.
listItem ||| •	fK is a family of pseudo-random function [12].
listItem ||| •MAC(K, M1 |M2) denotes the message authentication
listItem ||| code (MAC) of message - concatenation of M1 and M2,
listItem ||| with MAC key K.
subsectionHeader ||| 2.4 Key-Establishment Scheme in LEAP
bodyText ||| LEAP supports the establishment of four types of keys for
bodyText ||| each sensor node - an individual key shared with the base
bodyText ||| station, a pairwise key shared with its neighbor, a cluster
bodyText ||| key shared with its surrounding neighbors, and a group key
bodyText ||| shared by all the nodes in the networks.
bodyText ||| It assumes that the time interval Test for a newly deployed
bodyText ||| sensor node to complete the neighbor discovery phase (e.g.
bodyText ||| tens of seconds) is smaller than the time interval T.i. that is
bodyText ||| necessary for the attacker to compromise a legitimate node
bodyText ||| (i.e. T�i. > Test). Some existing work [1, 39] has made
bodyText ||| similar assumptions, which are believed to be reasonable.
bodyText ||| The four steps for a newly added node u to establish a
bodyText ||| pairwise key with each of its neighbors are as follows:
listItem ||| 1. KEY PRE-dIStRIbUtIOn. Each node u is loaded with
listItem ||| a common initial key KI, and derives its master key
listItem ||| K.. = fKI (u).
listItem ||| 2. NEIghbOR DISCOVERY. Once deployed, node u sets
listItem ||| up a timer to fire after time T�i., broadcasts its id,
listItem ||| and waits for each neighbor v’s ACK. The ACK from
listItem ||| v is authenticated using the master key K, of node v.
listItem ||| Since node u knows KI, it can derive K, = fKI (v).
listItem ||| u−→∗: u,R...
listItem ||| v−→u: v, MAC(K,, R.. |v).
listItem ||| 3. PAIRWISE KEY EStAblIShmEnt. Node u computes its
listItem ||| pairwise key with v, K..,, as K.., = fKv (u). Node v
listItem ||| also computes K.., in the same way. K.., serves as
listItem ||| their pairwise key.
listItem ||| 4. KEY ERASURE. When its timer expires, node u erases
listItem ||| KI and all the master keys of its neighbors. Every
listItem ||| node, however, keeps its own master key, in order to
listItem ||| establish pairwise keys with later-deployed nodes.
bodyText ||| Once erasing KI, a node will not be able to establish a
bodyText ||| pairwise key with any other nodes that have also erased KI.
bodyText ||| Without KI, a cloned node (by an attacker compromising a
bodyText ||| legitimate node after T.i.) fails to establish pairwise keys
bodyText ||| with any nodes except the neighbors of the compromised
bodyText ||| node. In such a way, LEAP localizes the security impact of
bodyText ||| a node compromise.
sectionHeader ||| 3. A RESILIENT PACKET-FORWARDING
sectionHeader ||| SCHEME USING NEIGHBOR WATCH SYS-
sectionHeader ||| TEM
bodyText ||| In this section, we present our resilient packet-forwarding
bodyText ||| scheme using Neighbor Watch System (NWS). NWS works
bodyText ||| with the information provided by Neighbor List Verification
bodyText ||| (NLV) to be described in Section 3.2.
subsectionHeader ||| 3.1 Neighbor Watch System
bodyText ||| Our scheme seeks to achieve hop-by-hop reliable delivery
bodyText ||| in face of maliciously packet-dropping nodes, basically em-
bodyText ||| ploying single-path forwarding. To the best of our knowl-
bodyText ||| edge, proposed works so far rely on multipath forwarding
bodyText ||| or diffusion-based forwarding, exploiting a large number of
bodyText ||| nodes in order to deliver a single packet. ACK-based tech-
bodyText ||| nique is not a proper solution at all as explained in the
bodyText ||| previous section.
bodyText ||| With NWS, we can check whether the next-hop node re-
bodyText ||| ally forwards the relaying packet to the actual neighbor of
bodyText ||| the next-hop node. The basic idea of our scheme is as fol-
bodyText ||| lows:
listItem ||| 1. Neighbor List Verification. After deployment, dur-
listItem ||| ing neighbor discovery phase, every node u gets to
listItem ||| know of not only its immediate neighbors, but also the
listItem ||| neighbors’ respective neighbor lists (i.e. u’s neighbors’
listItem ||| neighbor lists). The lists are verified using Neighbor
listItem ||| List Verification to be described in Section 3.2. Every
listItem ||| node stores its neighbors’ neighbor lists in the neighbor
listItem ||| table.
listItem ||| 2. Packet Forwarding to Next-hop. If node u has
listItem ||| a packet to be relayed, it buffers the packet and for-
listItem ||| wards the packet (encrypted with cluster key of node
listItem ||| u so that neighbors of node u can overhear it) to its
listItem ||| next-hop node v. As in LEAP, a cluster key is a key
listItem ||| shared by a node and all its neighbors, for passive par-
listItem ||| ticipation.
page ||| 61
figureCaption ||| Figure 1: Neighbor Watch System. Sub-watch
figureCaption ||| nodes w and y, as well as primary-watch node u lis-
figureCaption ||| ten in on v’s traffic.
listItem ||| 3. Designation of Watch Nodes. Overhearing the
listItem ||| packet from node u to node v, among neighbors of
listItem ||| node u, the nodes that are also neighbors of node v (in
listItem ||| Figure 1, nodes w and y) are designated as sub-watch
listItem ||| nodes and store the packet in the buffer. Other nodes
listItem ||| (that are not neighbors of node v) discard the packet.
listItem ||| Node u itself is a primary-watch node. A primary-
listItem ||| watch node knows which nodes are sub-watch nodes,
listItem ||| since every node has the knowledge of not only its
listItem ||| neighbors but also their respective neighbor lists.
listItem ||| 4. Neighbor Watch by Sub-Watch Node. Sub-watch
listItem ||| nodes w and y listen in on node v’s traffic to compare
listItem ||| each overheard packet with the packet in the buffer.
listItem ||| To defend against blind letter attack, each of them
listItem ||| also checks whether the packet’s intended next-hop is
listItem ||| a verified neighbor of node v, by looking up the neigh-
listItem ||| bor table. If all correct, the packet in the buffer is
listItem ||| removed and the role of the sub-watch node is over.
listItem ||| If the packet has remained in the buffer for longer
listItem ||| than a certain timeout, sub-watch nodes w and y for-
listItem ||| ward the packet (encrypted with their respective clus-
listItem ||| ter keys) to their respective next-hop nodes other than
listItem ||| node v. Then the role of a sub-watch node is over (each
listItem ||| of them is now designated as a primary-watch node for
listItem ||| the packet it has forwarded).
listItem ||| 5. Neighbor Watch by Primary-Watch Node. Primary-
listItem ||| watch node u does the same job as sub-watch nodes.
bodyText ||| The only difference, however, is that it listens in on
bodyText ||| not only node v’s traffic, but also sub-watch nodes w’s
bodyText ||| and y’s. If the packet is correctly forwarded on by at
bodyText ||| least one of them (nodes v, w, or y), primary-watch
bodyText ||| node u removes the packet in the buffer and the role
bodyText ||| of the primary-watch node is over.
bodyText ||| Otherwise, after a certain timeout, primary-watch node
bodyText ||| u forwards the packet (encrypted with its cluster key)
bodyText ||| to its next-hop other than node v.
bodyText ||| As the packet is forwarded on, this procedure (except for
bodyText ||| Neighbor List Verification) of NWS is performed at each
bodyText ||| hop so that hop-by-hop reliable delivery can be achieved
bodyText ||| with mainly depending on single-path forwarding. On the
bodyText ||| other hand, in the previous approaches [29, 39, 42], when
bodyText ||| forwarding a packet, a node broadcasts the packet with no
bodyText ||| designated next-hop, and all neighbors with smaller costs'
bodyText ||| 'The cost at a node is the minimum energy overhead to
figureCaption ||| Figure 2: An example of our packet-forwarding
figureCaption ||| scheme. Only the nodes that relay the packet are
figureCaption ||| presented. With the help of sub-watch nodes (grey
figureCaption ||| ones), our scheme bypasses two packet-dropping
figureCaption ||| nodes en-route to the base station.
bodyText ||| or within a specific geographic region continue forwarding
bodyText ||| the packet anyway. For example, in Figure 1, if nodes v,
bodyText ||| w, and y have smaller costs than node u in the previous
bodyText ||| approaches, they all forward2 the packet from node u. In
bodyText ||| our scheme, however, sub-watch nodes w and y are just on
bodyText ||| watch in designated next-hop node v, instead of uncondi-
bodyText ||| tionally forwarding the packet. If no packet-dropping occurs
bodyText ||| en-route to the base station, the packet may be forwarded
bodyText ||| along single-path all the way through.
bodyText ||| However, a packet-dropping triggers the multipath for-
bodyText ||| warding for the dropped packet. If the designated next-hop
bodyText ||| node v in Figure 1 has not forwarded the relaying packet to
bodyText ||| its certified neighbor by a certain timeout, sub-watch nodes
bodyText ||| w and y forward the packet to their respective next-hop.
bodyText ||| At the point, the packet is sent over multiple paths. Since
bodyText ||| the location where the packet-dropping occurs is likely in
bodyText ||| an unreliable region, this prompt reaction of the conver-
bodyText ||| sion to multipath forwarding augments the robustness in our
bodyText ||| scheme. The degree of multipath depends on the number of
bodyText ||| the sub-watch nodes. Figure 2 shows an example of our
bodyText ||| packet-forwarding scheme, bypassing two packet-dropping
bodyText ||| nodes en-route to the base station. If a node utilizes a cache
bodyText ||| [16, 21] for recently-received packets, it can suppress the
bodyText ||| same copy of previously-received one within a certain time-
bodyText ||| out, as nodes u and v in Figure 2.
bodyText ||| Our scheme requires that a relaying packet should be en-
bodyText ||| crypted with a cluster key of a forwarding node, in order
bodyText ||| that all its neighbors can decrypt and overhear it. In fact,
bodyText ||| per-link encryption provides better robustness to a node
bodyText ||| compromise, since a compromised node can decrypt only
bodyText ||| the packets addressed to it. Thus, there exists a tradeoff
bodyText ||| between resiliency against packet-dropping and robustness
bodyText ||| to a node compromise. However, encryption with a cluster
bodyText ||| key provides an intermediate level of robustness to a node
bodyText ||| compromise [24] (a compromised node can overhear only
bodyText ||| its immediate neighborhood), and also supports local broad-
bodyText ||| cast (i.e. resiliency against packet-dropping), so that we can
bodyText ||| achieve graceful degradation in face of compromised nodes.
bodyText ||| forward a packet from this node to the base station.
footnote ||| 2It is the broadcast transmission with no designated next-
footnote ||| hop, and, if needed, the packet should be encrypted with a
footnote ||| cluster key in order for all neighbors to overhear it.
figure ||| u
figure ||| y
figure ||| v
figure ||| w
figure ||| Base
figure ||| Station
figure ||| v
figure ||| u
page ||| 62
bodyText ||| To make our scheme work (against blind letter attack), we
bodyText ||| must address the problem of how a node proves that it re-
bodyText ||| ally has the claimed neighbors. It is the identical problem of
bodyText ||| how a node verifies the existence of its neighbors’ neighbors.
bodyText ||| Apparently, a node has the knowledge of its direct neigh-
bodyText ||| bors by neighbor discovery and pairwise key establishment
bodyText ||| phases. However, in the case of two-hop away neighbors,
bodyText ||| as in Figure 1, malicious node v can inform its neighbor u
bodyText ||| that it also has neighbor node x (any possible id in the net-
bodyText ||| work) which in fact is not a neighbor of node v. Node u has
bodyText ||| to believe it, since node x is not a direct neighbor of node
bodyText ||| u, and only the node v itself knows its actual surrounding
bodyText ||| neighbors. Then, how do we verify the neighbors’ neigh-
bodyText ||| bors? The answer to this critical question is described in
bodyText ||| the next subsection.
subsectionHeader ||| 3.2 Neighbor List Verification
bodyText ||| To verify neighbors’ neighbors, we present Neighbor List
bodyText ||| Verification (NLV) which extends the pairwise key estab-
bodyText ||| lishment in LEAP. During neighbor discovery in LEAP, two
bodyText ||| messages are exchanged between neighbors to identify each
bodyText ||| other. On the other hand, NLV adopts three-way handshak-
bodyText ||| ing neighbor discovery, in order to identify not only com-
bodyText ||| municating parties but also their respective neighbors.
bodyText ||| NLV has two cases of neighbor discovery. One is that
bodyText ||| neighbor discovery between two nodes that are both still
bodyText ||| within the initial Tmin3 (referred as pure nodes). The other
bodyText ||| is that neighbor discovery between a newly-deployed node
bodyText ||| within the initial Tmin and an existing node over the initial
bodyText ||| Tmin (referred as an adult node).
bodyText ||| Neighbor Discovery between Pure Nodes. Neighbor
bodyText ||| list verification process between pure nodes is quite simple.
bodyText ||| If a pure node broadcasts its neighbor list before the elapse of
bodyText ||| its initial Tmin, we can accept the list as verifiable. Thus, the
bodyText ||| key point here is to keep track of each other’s Tmin, and to
bodyText ||| make sure that both broadcast their respective neighbor lists
bodyText ||| before their respective Tmin. The following shows the three-
bodyText ||| way handshaking neighbor discovery between pure node u
bodyText ||| and v:
figure ||| u----+*: u,Ru.
figure ||| v ----+u : �v, Tv, �Rv ,  MAC(Kv, Ru J Ku JMv).
figure ||| M„
figure ||| u----+v: u,Tu , MAC(Kuv, RvJMu).
figure ||| M.
bodyText ||| where Tv and Tu are the amount of time remaining until
bodyText ||| Tmin of v and Tmin of u, respectively. Once deployed, node
bodyText ||| u sets up a timer to fire after time Tmin. Then, it broadcasts
bodyText ||| its id, and waits for each neighbor v’s ACK. The ACK from
bodyText ||| every neighbor v is authenticated using the master key Kv of
bodyText ||| node v. Since node u knows KI4, it can derive Kv = fKI (v).
bodyText ||| The ACK from node v contains Tv, the amount of time
bodyText ||| remaining until Tmin of node v. If Tv is a non-zero value,
bodyText ||| node v claims to be a pure node. Ku in MAC proves node
bodyText ||| v to be a pure node, since pure node v should know KI
bodyText ||| and derive Ku = fKI (u). Node u records ˇTv (Tv added
footnote ||| 3Tmin is the time interval, necessary for the attacker to com-
footnote ||| promise a legitimate node as in LEAP [46].
footnote ||| 4Each node u is loaded with a common initial key KI, and
footnote ||| derives its master key Ku = fKI (u). After time Tmin, node
footnote ||| u erases KI and all the master keys of its neighbors.
figureCaption ||| Figure 3: Neighbor Discovery between Pure node x
figureCaption ||| and Adult node u. Grey and white nodes represent
figureCaption ||| adult and pure nodes, respectively.
bodyText ||| to the current time of node u) in the entry for node v in
bodyText ||| the neighbor table. Node u computes its pairwise key with
bodyText ||| v, Kuv = fK„ (u).5 Node u also generates MAC(Kv, v Ju)
bodyText ||| (which means that v certifies u as an immediate neighbor),
bodyText ||| and stores it as a certificate.
bodyText ||| The ACK from node u also contains Tu, the amount of
bodyText ||| time remaining until Tmin of u. This ACK is authenticated
bodyText ||| using their pairwise key Kuv, which proves node u a pure
bodyText ||| node and u’s identity. Node v then records ˇTu (Tu added
bodyText ||| to the current time of v) in the entry for u in the neighbor
bodyText ||| table. It also generates MAC(Ku, uJv) and stores it as a
bodyText ||| certificate. Then, the three-way handshaking is done.
bodyText ||| Every pure node u broadcasts its neighbor list just prior
bodyText ||| to Tmin of u. Each receiving neighbor v checks whether the
bodyText ||| receiving time at v is prior to ˇTu in the neighbor table. If
bodyText ||| yes, the neighbor list of u is now certified by each neighbor v.
bodyText ||| Neighbor Discovery between A Pure Node and An
bodyText ||| Adult node. After most nodes have completed bootstrap-
bodyText ||| ping phase, new nodes can be added in the network. Con-
bodyText ||| sider Figure 3. The issue here is how adult node u can as-
bodyText ||| sure its existing neighbors (v and w) of the existence of its
bodyText ||| newly-added neighbor x. This is a different situation from
bodyText ||| the above neighbor list verification case between two pure
bodyText ||| nodes. Thus, the messages exchanged during the three-way
bodyText ||| handshaking are somewhat different in this case. The fol-
bodyText ||| lowing shows the three-way handshaking neighbor discovery
bodyText ||| between pure node x and adult node u:
equation ||| x----+ * :	x, Rx.
equation ||| , MAC(Kxu, Ru JMx).
bodyText ||| Newly-added node x sets up a timer to fire after time Tmin.
bodyText ||| Then, it broadcasts its id, and waits for each neighbor u’s
footnote ||| 5Node v also computes Kuv in the same way. Kuv serves as
footnote ||| their pairwise key.
equation ||| r
equation ||| t
equation ||| z
equation ||| v
equation ||| w
equation ||| u
equation ||| x
equation ||| q
equation ||| certificate ��	�
equation ||| certificate ��	�
equation ||| u----+ x : u, Tu, Ru, v,	MAC(Kv, vJu), w, MAC(Kw, wJu)
equation ||| 	�	��	�
equation ||| M.
equation ||| , MAC(Ku, Rx JMu).
equation ||| x----+u:	certificate ��	�	one—time cert. �	one—time cert.
equation ||| 			^ �
equation ||| MAC(Kx, xJu), v, MAC(Kv, xJu), w, MAC(Kw, xJu)
equation ||| �	��	�
equation ||| Ms
equation ||| x, Tx,
page ||| 63
bodyText ||| ACK. The ACK from every neighbor u is authenticated us-
bodyText ||| ing the master key Ku of node u. Since node x knows KI,
bodyText ||| it can derive Ku = fKI (u). The ACK from node u contains
bodyText ||| Tu, the amount of time remaining until Tmin of u. If Tu is
bodyText ||| zero, node u is an adult node that may already have mul-
bodyText ||| tiple neighbors as in Figure 3. Node u reports its certified
bodyText ||| neighbor list (v and w) to x by including their respective
bodyText ||| certificates in the ACK. Node x verifies u’s neighbor list by
bodyText ||| examining each certificate, since x can generate any certifi-
bodyText ||| cate with KI. If all correct, x computes its pairwise key with
bodyText ||| u, Kxu = fKu (x). Node x also generates MAC(Ku, ujx) and
bodyText ||| stores it as a certificate.
bodyText ||| The ACK from x also contains Tx, the amount of time
bodyText ||| remaining until Tmin of x. This ACK is authenticated using
bodyText ||| their pairwise key Kxu, which proves node x a pure node
bodyText ||| and x’s identity. Node u then records ˇTx (Tx added to the
bodyText ||| current time of u) in the entry for x in the neighbor table.
bodyText ||| Since adult node u cannot generate MAC(Kx, xju) by itself,
bodyText ||| pure node x provides the certificate for u in the ACK. Node
bodyText ||| x also provides one-time certificates6 for each of u’s certified
bodyText ||| neighbors (v and w). Then, the three-way handshaking is
bodyText ||| done.
bodyText ||| After that, adult node u broadcasts one-time certificates
bodyText ||| (from newly-discovered pure node x), in order to assure u’s
bodyText ||| existing neighbors (v and w) of the discovery of new neighbor
bodyText ||| x. The packet containing one-time certificates is as follows:
equation ||| Mu
equation ||| , MAC(Kcu, Mu).
bodyText ||| where x is a new neighbor of u, KAu is a local broadcast au-
bodyText ||| thentication key in u’s one-way key chain, Kcu is the cluster
bodyText ||| key of u. Each receiving neighbor v of u verifies u’s new
bodyText ||| neighbor x by examining the one-time certificate designated
bodyText ||| for v, MAC(Kv, xju)6. If ok, node x is now certified by each
bodyText ||| neighbor v of u. Then, one-time certificates can be erased,
bodyText ||| since they are of no use any more.
bodyText ||| Broadcast authentication only with symmetric keys such
bodyText ||| as cluster key Kcu fails to prevent an impersonation attack,
bodyText ||| since every neighbor of u shares the cluster key of u. Thus,
bodyText ||| we employ the reverse disclosure of one-way key chain KAu
bodyText ||| as in LEAP.
bodyText ||| Just prior to Tmin of x, pure node x broadcasts its neigh-
bodyText ||| bor list. Each receiving neighbor u of x checks whether the
bodyText ||| receiving time at u is prior to ˇTx in the neighbor table. If
bodyText ||| yes, the neighbor list of x is now certified by each neighbor u.
bodyText ||| In summary, through the proposed three-way handshak-
bodyText ||| ing neighbor discovery process, pure node u identifies each
bodyText ||| immediate neighbor v and v’s certified neighbor list (if v is
bodyText ||| an adult node), and keeps track of Tmin of v. Just prior
bodyText ||| to Tmin of u, node u broadcasts its direct neighbor list so
bodyText ||| that every neighbor of u accepts the list as verifiable. Then,
bodyText ||| node u becomes an adult node. After that, if newly-added
bodyText ||| node x initiates neighbor discovery with adult node u, node
bodyText ||| u identifies pure node x, keeps track of Tmin of x, provides
bodyText ||| u’s certified neighbor list to x, and, in return, takes one-time
bodyText ||| certificates from x. Node u then broadcasts these one-time
footnote ||| 6One-time certificate, for instance MAC(Kv, xju), assures
bodyText ||| v that x is an immediate neighbor of u. It is generated by
bodyText ||| pure node x with master key of v.
tableCaption ||| Table 1: An example of the Neighbor Table of u.
table ||| Neighbor ID	Certificate	Verified Neighbor List
table ||| v	MAC(Kv, v ju)	u, w, t
table ||| w	MAC(Kw, wju)	u, v, z
table ||| x	MAC(Kx, xju)	u, r, q
bodyText ||| certificates, in order to assure u’s existing neighbors of the
bodyText ||| discovery of new neighbor x. Thus, every time adult node u
bodyText ||| discovers newly-added node x through three-way handshak-
bodyText ||| ing, node u informs (by broadcasting) its existing neighbors
bodyText ||| of the discovery of new neighbor x. Also, whenever receiv-
bodyText ||| ing neighbor list information from pure neighbor x, node u
bodyText ||| checks whether the receiving time at u is prior to ˇTx in the
bodyText ||| neighbor table. If yes, u now accepts the neighbor list of x
bodyText ||| as verifiable.
bodyText ||| Through the above neighbor list verification in the boot-
bodyText ||| strapping phase, every node gets the knowledge of its neigh-
bodyText ||| bors’ certified neighbors. Our Neighbor Watch System makes
bodyText ||| use of this information to prevent blind letter attack. With
bodyText ||| this knowledge, watch nodes are able to check whether the
bodyText ||| relaying packet’s intended next-hop is a verified neighbor of
bodyText ||| the forwarding node.
subsectionHeader ||| 3.3 Neighbor Table Maintenance
bodyText ||| The information obtained through neighbor list verifica-
bodyText ||| tion (e.g. its direct neighbors, corresponding certificates,
bodyText ||| neighbors’ neighbor lists, etc) is stored in the neighbor table
bodyText ||| of each node. Table 1 shows an example of the neighbor
bodyText ||| table of node u. In densely-deployed sensor networks, the
bodyText ||| expected degree of a node is high. However, in this example,
bodyText ||| for simplicity, node u has only three neighbors v, w, and x
bodyText ||| as in Figure 3.
bodyText ||| The entries in the neighbor table are accessed and main-
bodyText ||| tained with immediate neighbor IDs. For example, if node
bodyText ||| u overhears the packet sent from w to v, node u begins to
bodyText ||| listen in on v’s traffic as a sub-watch node (since the neigh-
bodyText ||| bor table of u has both v’s and w’s entries in it). Unless v
bodyText ||| forwards the packet to a node of the Verified Neighbor List
bodyText ||| in v’s entry by a certain timeout, sub-watch node u will for-
bodyText ||| ward the packet to its next-hop other than v; many existing
bodyText ||| routing protocols [5, 18, 21, 27, 37, 43] enable each node to
bodyText ||| maintain multiple potential next-hop. Once forwarding the
bodyText ||| packet, sub-watch node u becomes a primary-watch node
bodyText ||| and begins to listen in on its next-hop’s traffic as described
bodyText ||| above.
bodyText ||| If newly-added node y initiates the three-way handshaking
bodyText ||| with u, node u provides its neighbor list to y by sending
bodyText ||| certificates in the neighbor table. Node u, in return from
bodyText ||| node y, takes the certificate for y and one-time certificates
bodyText ||| for u’s existing neighbors. Then, node u stores the certificate
bodyText ||| in the new entry for y. However, node u does not store the
bodyText ||| one-time certificates but broadcasts them to its neighbors.
bodyText ||| If new neighbor y broadcasts its neighbor list within Tmin,
bodyText ||| node u stores the list in the entry for y.
bodyText ||| If node u is compromised, not only cryptographic key
bodyText ||| information but also certificates in the neighbor table are
bodyText ||| exposed. However, the attacker cannot misuse these cer-
bodyText ||| tificates for other purposes. Since a certificate only attests
bodyText ||| neighborship between two specific nodes, it cannot be ap-
bodyText ||| plied to any other nodes. In fact, it can be made even public.
bodyText ||| However, colluding nodes can deceive a pure node anyway,
bodyText ||| one—time cert.	one—time cert.
equation ||| � �	�
equation ||| MAC(Kv, xju), w, MAC(Kw, xju), KAu
equation ||| �	��	�
equation ||| u____+ * :	u, x, v,
equation ||| �
page ||| 64
bodyText ||| by fabricating a bogus certificate. We will describe this lim-
bodyText ||| itation in Section 4.4.
sectionHeader ||| 4. EVALUATION
bodyText ||| In this section, we evaluate the communication and stor-
bodyText ||| age cost, and analyze the security of our resilient forwarding
bodyText ||| scheme (Neighbor Watch System) as well as Neighbor List
bodyText ||| Verification. We then present the simulation results of our
bodyText ||| forwarding scheme.
subsectionHeader ||| 4.1 Communication Cost
bodyText ||| Unlike the previously proposed diffusion-based reliable-
bodyText ||| forwarding schemes [21, 29, 39, 42] that exploit a large num-
bodyText ||| ber of nodes to deliver a single packet, our scheme requires
bodyText ||| only the designated next-hop node to relay the packet, un-
bodyText ||| der the supervision of watch nodes. We note that, like over-
bodyText ||| hearing by watch nodes in our scheme, those diffusion-based
bodyText ||| schemes require each node to listen to all its neighbors, since
bodyText ||| they forward a packet by broadcasting with no designated
bodyText ||| next-hop. With a smaller number of relaying nodes, our
bodyText ||| scheme makes a report successfully reach the base station.
bodyText ||| Thus, the average communication cost of our forwarding
bodyText ||| scheme for delivery of a single packet is smaller than those
bodyText ||| of the previous schemes.
bodyText ||| Our neighbor list verification during the bootstrapping
bodyText ||| phase requires the three-way handshaking neighbor discov-
bodyText ||| ery. Unlike the neighbor discovery between two pure nodes,
bodyText ||| the size of the messages exchanged between a pure and an
bodyText ||| adult node varies with the degree of the adult node. A large
bodyText ||| number of certificates caused by the high degree can be over-
bodyText ||| burdensome to a single TinyOS packet which provides 29
bodyText ||| bytes for data. Considering 8-byte certificates and a 4-byte7
bodyText ||| message authentication code (MAC), the adult node is able
bodyText ||| to include at most two neighbors’ information in a single
bodyText ||| TinyOS packet. Thus, when the entire neighbor list cannot
bodyText ||| be accommodated within a single packet, the node should
bodyText ||| allot the list to several packets and send them serially. In a
bodyText ||| network of size N with the expected degree d of each node,
bodyText ||| the average number of packets invoked by a newly-added
bodyText ||| node per each node is nearly (d — 1)2/2(N — 1).
bodyText ||| Therefore, as node density d grows, the total number
bodyText ||| of packets transmitted from adult nodes to a newly-added
bodyText ||| node increases. However, neighbor discovery between a pure
bodyText ||| and an adult node occurs much less than between two pure
bodyText ||| nodes, since most neighbor discoveries throughout the net-
bodyText ||| work are between two pure nodes in the early stage of the
bodyText ||| network. Neighbor discovery between a pure and an adult
bodyText ||| node occurs generally when a new node is added to the net-
bodyText ||| work.
subsectionHeader ||| 4.2 Storage Overhead
bodyText ||| In LEAP, each node keeps four types of keys and a man-
bodyText ||| ageable length of hash chain, which is found to be scalable.
bodyText ||| In our scheme, each node needs to additionally store its di-
bodyText ||| rect neighbors’ certificates and their respective neighbor lists
bodyText ||| as in Table 1. Thus, for a network of the expected degree
bodyText ||| d and the byte size l of node ID, the additional storage re-
bodyText ||| quirement for each node is d • (8 + ld) bytes.
bodyText ||| Although our storage requirement for these neighbor lists
bodyText ||| is O(d 2), for a reasonable degree d, memory overhead does
footnote ||| 74-byte MAC is found to be not detrimental in sensor net-
footnote ||| works as in TinySec [24] which employs 4-byte MAC.
figureCaption ||| Figure 4: Examples of critical area C1 and C2.
bodyText ||| not exceed 1 KB (a Berkeley MICA2 Mote with 128 KB
bodyText ||| flash memory and 4 KB SRAM). For example, when d = 20
bodyText ||| and l = 2, a node needs 960 bytes of memory to store such
bodyText ||| information.
bodyText ||| If node density of a network is so high that the required
bodyText ||| space for those neighbor lists significantly increases and the
bodyText ||| storage utilization becomes an issue, we can employ a storage-
bodyText ||| reduction technique such as Bloom filter [2]. For example,
bodyText ||| when d = 30 and l = 2, a node requires 2,040 bytes of addi-
bodyText ||| tional space mainly for the neighbor lists. Instead of storing
bodyText ||| neighbors’ neighbor lists, applying each of the neighbor lists
bodyText ||| (480 bits) to a Bloom filter (of 5 hash functions mapping to
bodyText ||| a 256 bit vector), a node needs the reduced space of 1,200
bodyText ||| bytes for such information (with the false positive probabil-
bodyText ||| ity = 0.02).
subsectionHeader ||| 4.3 Resilience to Packet-Dropping Attacks
bodyText ||| In face of maliciously packet-dropping nodes, the higher
bodyText ||| degree of multipath we provide, the more resiliency our
bodyText ||| scheme achieves against such attacks. The average degree
bodyText ||| of multipath depends on the number of sub-watch nodes
bodyText ||| around a packet-dropping node. Sub-watch nodes should
bodyText ||| be located in the region within the communication range of
bodyText ||| both forwarding node u and designated next-hop v. We re-
bodyText ||| fer to such a region as critical area. As in Figure 4, if nodes
bodyText ||| u and v are located farther away, the size of critical area C2
bodyText ||| gets smaller than that of C1, and the probability (p.) that
bodyText ||| at least one sub-watch node exists in the critical area goes
bodyText ||| down. The probability (p.) is
equation ||| p. = 1 — (1 — c)d-1,
bodyText ||| where c is the ratio of the critical area size to the node’s com-
bodyText ||| munication range, and the expected degree d of the node.
bodyText ||| To determine the appropriate degree d, we set the smallest
bodyText ||| critical area C2 in Figure 4 as a lower bound case (c = 0.4).
bodyText ||| Figure 5 shows that, even in the lower bound critical area,
bodyText ||| with d = 6 and d = 10, probability p. is above 0.9 and above
bodyText ||| 0.99, respectively.
bodyText ||| Since, in a network of degree d, the probability that there
bodyText ||| exist m sub-watch nodes in the critical area of the ratio c is
equation ||| p(m) = �d — m J 1) cm(1 — c)d-m-1
bodyText ||| the expected number of sub-watch nodes, m, in the critical
bodyText ||| area is given by
equation ||| E[m] = (d — 1)c.
bodyText ||| Thus, in the lower bound (c = 0.4) critical area, when d =
bodyText ||| 10, 15, 20, the number of sub-watch nodes (i.e. the degree
bodyText ||| of multipath) is 3.6, 5.6, 7.6 on average, respectively. This
figure ||| u	v	?	u	v	?
figure ||| C1	C2
figure ||| ,
page ||| 65
figureCaption ||| Figure 5: Probability (p.) that at least one sub-
figureCaption ||| watch node exists in the lower bound (c = 0.4) criti-
figureCaption ||| cal area.
bodyText ||| shows that the higher degree of each node has, our scheme
bodyText ||| has the higher degree of multipath and resiliency against
bodyText ||| packet-dropping nodes.
subsectionHeader ||| 4.4 The Security of Neighbor List Verification
bodyText ||| Our Neighbor List Verification(NLV) keeps the nice prop-
bodyText ||| erties of LEAP. Adult nodes fail to establish pairwise keys
bodyText ||| with any adult nodes in arbitrary locations, so that the im-
bodyText ||| pact of a node compromise is localized. NLV performs the
bodyText ||| three-way handshaking neighbor discovery, instead of two-
bodyText ||| message exchange in LEAP. The three-way handshaking en-
bodyText ||| ables each node to verify not only its direct neighbors but
bodyText ||| also their respective neighbor lists.
bodyText ||| Moreover, this this three-way handshaking can be a po-
bodyText ||| tential solution to deal with irregularity of radio range [15,
bodyText ||| 37, 45]. In reality, due to the noise and some environmen-
bodyText ||| tal factors, radio range of each node is not exactly circu-
bodyText ||| lar. So, communication links among nodes are asymmetric;
bodyText ||| node u can hear node v which is unable to hear u. With
bodyText ||| two-message exchange, only the node initiating the neigh-
bodyText ||| bor discovery is assured of the link’s bidirectionality. By the
bodyText ||| three-way handshaking, both of neighbors can be assured of
bodyText ||| their symmetric connectivity.
bodyText ||| With NLV, only the verified lists are stored and utilized
bodyText ||| for our packet-forwarding scheme. NLV verifies the neighbor
bodyText ||| list of an adult node with certificates. These certificates
bodyText ||| merely attest neighborship between two specific nodes. Even
bodyText ||| if a node is compromised, the attacker fails to abuse the
bodyText ||| certificates of the captured node for other purpose.
bodyText ||| However, collusion among compromised nodes can fab-
bodyText ||| ricate bogus certificates in order to deceive a newly-added
bodyText ||| node. For example, consider two colluding nodes u and v at
bodyText ||| the different locations. When compromised node u discovers
bodyText ||| newly-added node x, node u provides x with u’s neighbor
bodyText ||| list (maliciously including v in it). Even though node v is
bodyText ||| not an actual neighbor of u, colluding node v can generate
bodyText ||| the bogus certificate for u, MAC(K,, v1u). Then, x falsely
bodyText ||| believes that v is a direct neighbor of u. This attack, how-
bodyText ||| ever, affects only the one newly-added node x. Thus, when
bodyText ||| compromised node u tries to launch the blind letter attack 8,
footnote ||| 8Compromised node u transmits the relaying packet with its
bodyText ||| other surrounding adult neighbors of u can still detect it
bodyText ||| anyway.
bodyText ||| The more serious case is that colluding nodes exploit a
bodyText ||| newly-added node to generate bogus one-time certificates.
bodyText ||| For example, consider two colluding nodes u and v that
bodyText ||| share all their secret information as well as all their certifi-
bodyText ||| cates. When newly-added node x initiates the three-way
bodyText ||| handshaking with u, compromised node u pretends to be
bodyText ||| v and provides x with v’ neighbor list. Then, x in return
bodyText ||| provides u with one-time certificates for each neighbor of
bodyText ||| v; these one-time certificates falsely attest that v has new
bodyText ||| neighbor x. Node u sends this information to v over the
bodyText ||| covert channel. Then, v broadcasts these one-time certifi-
bodyText ||| cates, and neighbors of v falsely believe that x is a direct
bodyText ||| neighbor of v.
bodyText ||| Unfortunately, we do not provide a proper countermea-
bodyText ||| sure to defend against this type of man-in-the-middle at-
bodyText ||| tacks. However, we point out that this type of attacks has
bodyText ||| to be launched in the passive manner. The adversary has
bodyText ||| to get the chance of discovery of a newly-added node. In
bodyText ||| other words, compromised nodes wait for the initiation of
bodyText ||| the three-way handshaking from a newly-added node. Since
bodyText ||| the attacker does not know where the new nodes will be
bodyText ||| added, it has to compromise a sufficient number of legiti-
bodyText ||| mate nodes in order to increase the probability of discovery
bodyText ||| of newly-added nodes.
bodyText ||| As an active defense against such man-in-the-middle at-
bodyText ||| tacks, we can apply a node replication detection mechanism
bodyText ||| such as Randomized or Line-Selected Multicast [31], which
bodyText ||| revokes the same ID node at the different location claims.
bodyText ||| To successfully launch such man-in-the-middle attacks, two
bodyText ||| colluding nodes should pretend to be each other so that each
bodyText ||| of them claims to be at two different locations with the same
bodyText ||| ID. Location-binding key-assignment scheme by Yang et al.
bodyText ||| [39] with a little modification also can be a good solution
bodyText ||| to such attacks. Since it binds secret keys with nodes’ geo-
bodyText ||| graphic locations, the key bound to the particular location
bodyText ||| cannot be used at any arbitrary locations. Adopting this,
bodyText ||| NLV can check whether the claimed neighbors are really lo-
bodyText ||| cated within geographically two hops away.
subsectionHeader ||| 4.5 Simulations
bodyText ||| To further evaluate the performance of our resilient for-
bodyText ||| warding scheme, we run simulations of our scheme in the
bodyText ||| presence of packet-dropping nodes on a network simulator,
bodyText ||| ns-2 [9].
subsubsectionHeader ||| 4.5.1 Simulation Model
bodyText ||| In our simulations, we deploy N sensor nodes uniformly at
bodyText ||| random within 500 x 500m2 target field, with N = 300 and
bodyText ||| 600. Each sensor node has a constant transmission range of
bodyText ||| 30m, so that the degree of each node is approximately 10
bodyText ||| (N = 300) and 20 (N = 600) on average. We position a base
bodyText ||| station and a source node in opposite corners of the field, at
bodyText ||| a fixed point (50, 50) and (450, 450), respectively. They are
bodyText ||| located approximately 18 hops away from each other.
bodyText ||| We distribute compromised nodes over an inner square
bodyText ||| area with 200m each side (from 150m to 350m of each side
bodyText ||| of the 500 x 500m2 target area). Thus, compromised nodes
bodyText ||| are strategically-placed in between the base station and the
bodyText ||| source node. In the simulations, those compromised nodes
bodyText ||| drop all the relaying packets.
bodyText ||| next-hop id as v, so that x considers it forwarded correctly.
figure ||| 1
figure ||| 0.9
figure ||| 0.8
figure ||| 0.7
figure ||| 0.6
figure ||| 0.5
figure ||| 0.4
figure ||| 0.3
figure ||| 0.2
figure ||| 0.1
figure ||| 0
figure ||| 1	5	10	15	20
figure ||| Degree of a node
figure ||| 66
figureCaption ||| Figure 6: Simulation Results (averaged over 100 runs).
figure ||| 0	5	10	15	20	25	30	35	40	45	50
figure ||| Number of Packet-dropping Nodes
figure ||| (a) Success ratio (N = 300, x = 0 — 50)
figure ||| 0	10	20	30	40	50	60	70	80	90	100
figure ||| Number of Packet-dropping Nodes
figure ||| (b) Success ratio (N = 600, x = 0 — 100)
figure ||| 100
figure ||| 100
figure ||| 10
figure ||| 10
figure ||| 0
figure ||| 0
figure ||| 90
figure ||| 90
figure ||| ( 300 nodes )
figure ||| 80
figure ||| 70
figure ||| 60
figure ||| 50
figure ||| 40
figure ||| 30
figure ||| 20
figure ||| 80
figure ||| 70
figure ||| 60
figure ||| 50
figure ||| 40
figure ||| 30
figure ||| 20
figure ||| ( 600 nodes )
figure ||| 0	5	10	15	20	25	30	35	40	45	50
figure ||| Number of Packet-Dropping Nodes
figure ||| 0	10	20	30	40	50	60	70	80	90	100
figure ||| Number of Packet-dropping Nodes
figure ||| (c) The number of relaying nodes with N = 300
figure ||| (d) The number of relaying nodes with N = 600
figure ||| ( 300 nodes )
figure ||| 0.6
figure ||| 0.5
figure ||| 0.4
figure ||| 1
figure ||| 0.9
figure ||| 0.8
figure ||| 0.7
figure ||| 0.3
figure ||| 0.2
figure ||| 0.1
figure ||| 0
figure ||| 1
figure ||| 0.9
figure ||| 0.8
figure ||| 0.7
figure ||| 0.6
figure ||| 0.5
figure ||| 0.4
figure ||| 0.3
figure ||| 0.2
figure ||| 0.1
figure ||| 0
figure ||| ( 600 nodes )
figure ||| Single Path Forwarding	with NWS
figure ||| Single Path Forwarding	with NWS
figure ||| Single Path Forwarding	with NWS
figure ||| Single Path Forwarding	with NWS
bodyText ||| We use the typical TinyOS beaconing [17] with a little
bodyText ||| modification as a base routing protocol in our simulations.
bodyText ||| We add a hop count value in a beacon message9. To have
bodyText ||| multiple potential next-hops, when receiving a beacon with
bodyText ||| the same or better hop count than the parent node’s, each
bodyText ||| node marks the node sending the beacon as a potential next-
bodyText ||| hop.
bodyText ||| Each simulation experiment is conducted using 100 differ-
bodyText ||| ent network topologies, and each result is averaged over 100
bodyText ||| runs of different network topologies.
subsubsectionHeader ||| 4.5.2 Simulation Results
bodyText ||| In the presence of compromised node dropping all the re-
bodyText ||| laying packets, we measure the success ratio (i.e. the per-
bodyText ||| centage of the packets that successfully reach the base sta-
bodyText ||| tion from the source) and the number of relaying nodes by
bodyText ||| the primitive single-path forwarding and with NWS in a
bodyText ||| network of size N, with N = 300 and 600.
footnote ||| 9The base station initiates the beacon-broadcasting, which
footnote ||| floods through the network, in order to set up a routing tree.
bodyText ||| Figure 6(a) shows the success ratio in face of x packet-
bodyText ||| dropping nodes (varying x=0 to 50) in a 300-sensor-node
bodyText ||| network with the approximate degree d = 10. Although
bodyText ||| the success ratio gently decreases with x, it keeps up above
bodyText ||| 0.8 even with x = 30, with the help of NWS. This ten-
bodyText ||| dency of decreasing success ratio can be attributed to the
bodyText ||| degree d = 10 (3.6 sub-watch nodes on average) as well as
bodyText ||| an increasing number of packet-dropping nodes. Due to the
bodyText ||| strategically-placement of compromised nodes in our sim-
bodyText ||| ulations, as x increases on, it is likely that a forwarding
bodyText ||| node’s all potential sub-watch nodes themselves are packet-
bodyText ||| dropping nodes. Figure 6(c) shows the number of nodes
bodyText ||| that relay the packet from the source to the base station
bodyText ||| in the same experiments. Since the source is located about
bodyText ||| 18 hops away from the base station, the number of relaying
bodyText ||| nodes only with the single-path forwarding remains at 18.
bodyText ||| With NWS, the number of relaying nodes increases with x,
bodyText ||| in order to bypass an increasing number of packet-dropping
bodyText ||| nodes. In face of such nodes, our scheme converts single-
bodyText ||| path forwarding into multipath data forwarding, with the
page ||| 67
bodyText ||| help of sub-watch nodes around such packet-dropping nodes.
bodyText ||| Utilizing a cache for recently-received packets can suppress
bodyText ||| the same copy within a certain timeout, which reduces the
bodyText ||| number of relaying nodes.
bodyText ||| Figure 6(b) shows the success ratio in a 600-sensor-node
bodyText ||| network with the approximate degree d = 20 with x packet-
bodyText ||| dropping nodes (varying x=0 to 100). Unlike that with N =
bodyText ||| 300, the success ratio stays constantly at around 0.99 even
bodyText ||| with x = 100, with the help of NWS. This tendency of high
bodyText ||| success ratio can be mainly attributed to the degree d = 20
bodyText ||| (7.6 sub-watch nodes on average in the lower bound case),
bodyText ||| which is found to be high enough to bypass a large number
bodyText ||| of packet-dropping nodes. Figure 6(d) shows the number
bodyText ||| of relaying nodes from the source to the base station in the
bodyText ||| same experiments. With NWS, the increase in the number
bodyText ||| of relaying nodes with x is more conspicuous than that with
bodyText ||| N = 300, since more than twice as many as sub-watch nodes
bodyText ||| help forward the packets so that it can bypass a large number
bodyText ||| of packet-dropping nodes anyway.
bodyText ||| In the simulation results, we note that our forwarding
bodyText ||| scheme dynamically adjusts its forwarding style, depending
bodyText ||| on the number of packet-dropping nodes en-route to the base
bodyText ||| station. As in Figures 6(c) and 6(d), while there exist none
bodyText ||| or a small number of packet-dropping nodes on the way, our
bodyText ||| scheme works almost like the single-path forwarding with
bodyText ||| the help of a few additional relaying nodes. On the other
bodyText ||| hand, when confronting a large number of packet-dropping
bodyText ||| nodes, our scheme makes full use of the help from additional
bodyText ||| relaying nodes, in order to successfully deliver the packet to
bodyText ||| the base station at any cost to the best efforts.
sectionHeader ||| 5. CONCLUSIONS AND FUTURE WORK
bodyText ||| In this paper we focus on defending against compromised
bodyText ||| nodes’ dropping of legitimate reports. We have presented
bodyText ||| a resilient packet-forwarding scheme using Neighbor Watch
bodyText ||| System (NWS) against maliciously packet-dropping nodes in
bodyText ||| sensor networks. In face of such nodes, NWS is specifically
bodyText ||| designed for hop-by-hop reliable delivery, and the prompt
bodyText ||| reaction of the conversion from single-path to multipath for-
bodyText ||| warding augments the robustness in our scheme so that the
bodyText ||| packet successfully reach the base station.
bodyText ||| In future work, we plan on further improving NLV to de-
bodyText ||| fend against the man-in-the-middle attacks, collusion among
bodyText ||| compromised nodes. Such attacks can be prevented by using
bodyText ||| a master key derived with not only a node ID but also its
bodyText ||| geographic information. We will also seek to address O(d 2)
bodyText ||| storage requirement for the neighbors’ neighbor lists. Fi-
bodyText ||| nally, we would like to perform an intensive experimental
bodyText ||| evaluation to compare our scheme with other reliable deliv-
bodyText ||| ery protocols [10, 29, 42].
sectionHeader ||| 6. ACKNOWLEDGMENTS
bodyText ||| This work was supported by grant No.R01-2006-000-10073-
bodyText ||| 0 from the Basic Research Program of the Korea Science and
bodyText ||| Engineering Foundation.
sectionHeader ||| 7. REFERENCES
reference ||| [1] R. Anderson, H. Chan, and A. Perrig, Key Infection:
reference ||| Smart Trust for Smart Dust, IEEE ICNP 2004
reference ||| [2] Burton H. Bloom, Space/Time Trade-offs in Hash
reference ||| Coding with Allowable Errors, Communication of the
reference ||| ACM, vol. 13, 422-426, 1970
reference ||| [3] B. Carbunar, I. Ioannidis, and C. Nita-Rotaru,
reference ||| JANUS: Towards Robust and Malicious Resilient
reference ||| Routing in Hybrid Wireless Networks, ACM workshop
reference ||| on Wireless security (WiSe’04), Oct. 2004
reference ||| [4] H. Chan, A. Perrig, and D. Song, Random Key
reference ||| Predistribution Schemes for Sensor Networks, IEEE
reference ||| Symposium on Security and Privacy, pp. 197-213, May
reference ||| 2003.
reference ||| [5] B. Deb, S. Bhatnagar, and B. Nath, ReInForM:
reference ||| Reliable Information Forwarding Using Multiple Paths
reference ||| in Sensor Networks, IEEE Local Computer Networks
reference ||| (LCN 2003), pp. 406-415, Oct. 2003.
reference ||| [6] J. Deng, R. Han, and S. Mishra, A Performance
reference ||| Evaluation of Intrusion- Tolerant Routing in Wireless
reference ||| Sensor Networks, 2nd International Workshop on
reference ||| Information Processing in Sensor Networks (IPSN 03),
reference ||| pp. 349-364, Apr. 2003.
reference ||| [7] J. Deng, R. Han, and S. Mishra, Intrusion Tolerance
reference ||| and Anti-Traffic Analysis Strategies for Wireless
reference ||| Sensor Networks, IEEE International Conference on
reference ||| Dependable Systems and Networks (DSN), pp.
reference ||| 594-603, 2004.
reference ||| [8] J. Deng, R. Han, and S. Mishra, Defending against
reference ||| Path-based DoS Attacks in Wireless Sensor Networks,
reference ||| ACM Workshop on Security of Ad-Hoc and Sensor
reference ||| Networks (SASN’05) , Nov, 2005.
reference ||| [9] K. Fall and K. Varadhan (editors), NS notes and
reference ||| documentation, The VINT project, LBL, Feb 2000,
reference ||| http://www.isi.edu/nsnam/ns/
reference ||| [10] D. Ganesan, R. Govindan, S. Shenker, and D. Estrin,
reference ||| Highly Resilient, Energy-Efficient Multipath Routing
reference ||| in Wireless Sensor Networks, Computing and
reference ||| Communications Review (MC2R) Vol 1., pp. 11-25,
reference ||| 2002.
reference ||| [11] V. D. Gligor, Security of Emergent Properties in
reference ||| Ad-Hoc Networks, International Workshop on Security
reference ||| Protocols, Apr. 2004.
reference ||| [12] O. Goldreich, S. Goldwasser, and S. Micali, How to
reference ||| Construct Random Functions, Journal of the ACM,
reference ||| Vol. 33, No. 4, 210-217, 1986
reference ||| [13] L. Eschenauer and V. D. Gligor, A Key-Management
reference ||| Scheme for Distributed Sensor Networks, 9th ACM
reference ||| Conference on Computer and Communication
reference ||| Security (CCS), pp. 41-47, Nov. 2002.
reference ||| [14] C. Hartung, J. Balasalle, and R. Han, Node
reference ||| Compromise in Sensor Networks: The Need for Secure
reference ||| Systems, Technical Report CU-CS-990-05,
reference ||| Department of Computer Science University of
reference ||| Colorado at Boulder, Jan. 2005
reference ||| [15] T. He, S. Krishnamurthy, J. A. Stankovic, T. F.
reference ||| Abdelzaher, L. Luo, R. Stoleru, T. Yan, L. Gu, J. Hui,
reference ||| and B. Krogh, An Energy-Efficient Surveillance
reference ||| System Using Wireless Sensor Networks, ACM
reference ||| MobiSys’04, June, 2004
reference ||| [16] W.R. Heinzelman, J. Kulik, H. Balakrishnan, Adaptive
reference ||| Protocols for Information Dissemination in Wireless
reference ||| Sensor Networks, ACM MobiCom99, pp. 174.185,
reference ||| 1999.
reference ||| [17] J. Hill, R. Szewczyk, A. Woo, S. Hollar, D. Culler, and
reference ||| K. Pister, System Architecture Directions for
reference ||| Networked Sensors, ACU ASPLOS IX, November
reference ||| 2000.
page ||| 68
reference ||| [18] X. Hong, M. Gerla, W. Hanbiao, and L. Clare, Load
reference ||| Balanced, Energy-Aware Communications for Mars
reference ||| Sensor Networks, IEEE Aerospace Conference, vol.3,
reference ||| 1109-1115, 2002.
reference ||| [19] Y.-C. Hu, D. B. Johnson, and A. Perrig, SEAD:
reference ||| Secure Efficient Distance Vector Routing for Mobile
reference ||| Wireless Ad Hoc Networks, IEEE Workshop on Mobile
reference ||| Computing Systems and Applications, pp. 3-13, Jun.
reference ||| 2002.
reference ||| [20] Y.-C. Hu, A. Perrig, and D. B. Johnson, Efficient
reference ||| Security Mechanisms for Routing Protocols, NDSS
reference ||| 2003, pp. 57-73, Feb. 2003.
reference ||| [21] C. Intanagonwiwat, R. Govindan and D. Estrin,
reference ||| Directed Diffusion: A Scalable and Robust
reference ||| Communication Paradigm for Sensor Networks,
reference ||| MobiCom’00, Aug. 2000.
reference ||| [22] D. Johnson, D.A. Maltz, and J. Broch, The Dynamic
reference ||| Source Routing Protocol for Mobile Ad Hoc Networks
reference ||| (Internet-Draft), Mobile Ad-hoc Network (MANET)
reference ||| Working Group, IETF, Oct. 1999.
reference ||| [23] C. Karlof and D. Wagner, Secure Routing in Wireless
reference ||| Sensor Networks: Attacks and Countermeasures, The
reference ||| First IEEE International Workshop on Sensor Network
reference ||| Protocols and Applications, pp. 113-127, May 2003
reference ||| [24] C. Karlof, N. Sastry, and D. Wagner, TinySec: A Link
reference ||| Layer Security Architecture for Wireless Sensor
reference ||| Networks, ACM SensSys’04, pp. 162-175, Nov. 2004.
reference ||| [25] I. Khalil, S. Bagchi, and C. Nina-Rotaru, DICAS:
reference ||| Detection, Diagnosis and Isolation of Control Attacks
reference ||| in Sensor Networks, IEEE SecureComm 2005, pp. 89 -
reference ||| 100, Sep. 2005
reference ||| [26] Y. Liu and W. K.G. Seah, A Priority-Based
reference ||| Multi-Path Routing Protocol for Sensor Networks,
reference ||| 15th IEEE International Symposium on Volume 1, 216
reference ||| -220, 2004
reference ||| [27] S.-B. Lee and Y.-H. Choi, A Secure Alternate Path
reference ||| Routing in Sensor Networks, Computer
reference ||| Communications (2006),
reference ||| doi:10.1016 /j . comcom.2006.08.006.
reference ||| [28] S. Marti, T.J. Giuli, K. Lai, and M. Baker, Mitigating
reference ||| Routing Misbehavior in Mobile Ad Hoc Networks,
reference ||| ACM/IEEE International Conference on Mobile
reference ||| Computing and Networking, pp. 255-265, 2000
reference ||| [29] H. Morcos, I. Matta, and A. Bestavros, M2 RC:
reference ||| Multiplicative-Increase/Additive-Decrease Multipath
reference ||| Routing Control for Wireless Sensor Networks, ACM
reference ||| SIGBED Review, Vol. 2, Jan 2005.
reference ||| [30] J. Newsome, E. Shi, D. Song, and A. Perrig, The Sybil
reference ||| Attack in Sensor Networks: Analysis and Defenses,
reference ||| IEEE IPSN’04, pp. 259-268, Apr. 2004.
reference ||| [31] B. Parno, A. Perrig, and V. D. Gligor, Distributed
reference ||| Detection of Node Replication Attacks in Sensor
reference ||| Networks, the 2005 IEEE Symposium on Security and
reference ||| Privacy, pp. 49-63, May 2005.
reference ||| [32] A. Perrig, R. Szewczyk, V. Wen, D. Culler, and
reference ||| J. Tygar, SPINS: Security Protocols for Sensor
reference ||| Networks, ACM MobiCom’01, pp. 189-199, 2001.
reference ||| [33] A. Perrig, J. Stankovic, and D. Wagner, Security in
reference ||| Wireless Sensor Networks, Communications of the
reference ||| ACM, 47(6), Special Issue on Wireless sensor
reference ||| networks, pp.53- 57, Jun. 2004
reference ||| [34] B. Przydatek, D. Song, and A. Perrig, SIA: Secure
reference ||| Information Aggregation in Sensor Networks, 1st
reference ||| International Conference on Embedded Networked
reference ||| Sensor Systems, 255-256, 2003
reference ||| [35] E. Shi and A. Perrig, Designing Secure Sensor
reference ||| Networks, Wireless Communications, IEEE Volume
reference ||| 11, Issue 6, pp. 38-43, Dec. 2004.
reference ||| [36] D. Tian and N.D. Georganas, Energy Efficient
reference ||| Routing with Guaranteed Delivery in Wireless Sensor
reference ||| Networks, IEEE Wireless Communications and
reference ||| Networking (WCNC 2003), IEEE Volume 3, 1923 -
reference ||| 1929, March 2003
reference ||| [37] A. Woo, T. Tong, and D. Culler, Taming the
reference ||| Underlying Challenges of Reliable Multhop Routing in
reference ||| Sensor Networks, ACM SenSys03, Nov, 2003
reference ||| [38] A. Wood and J. Stankovic, Denial of Service in Sensor
reference ||| Networks, IEEE Computer, Vol.35, 54-62, Oct. 2002
reference ||| [39] H.Yang, F. Ye, Y. Yuan, S. Lu and W. Arbough,
reference ||| Toward Resilient Security in Wireless Sensor
reference ||| Networks, ACM MobiHoc’05, 34-45, May 2005
reference ||| [40] Y. Yang, X. Wang, S. Zhu, and G. Cao SDAP: A
reference ||| Secure Hop-by-Hop Data Aggregation Protocol for
reference ||| Sensor Networks, ACM MobiHoc’06 May 2006
reference ||| [41] F. Ye, H. Luo, S. Lu and L. Zhang, Statictial En-route
reference ||| Filtering of Injected False Data in Sensor Networks,
reference ||| IEEE INFOCOM, 2004
reference ||| [42] F. Ye, G. Zhong, S. Lu and L. Zhang, GRAdient
reference ||| Broadcast: A Robust Data Delivery Protocol for Large
reference ||| Scale Sensor Networks, ACM Wireless Networks
reference ||| (WINET), March 2005
reference ||| [43] Y. Yu, R. Govindan, and D. Estrin, Geographical and
reference ||| Energy Aware Routing: a recursive data dissemination
reference ||| protocol for wireless sensor networks, UCLA
reference ||| Computer Science Department Technical Report
reference ||| UCLA/CSD-TR-01-0023, May 2001.
reference ||| [44] W. Zhang and G. Cao, Group Rekeying for Filtering
reference ||| False Data in Sensor Networks: A Predistribution and
reference ||| Local Collaboration-Based Approach, IEEE
reference ||| INFOCOM’05. Vol. 1, 503-514, March 2005
reference ||| [45] G. Zhou, T. He, S. Krishnamurthy, and J. A.
reference ||| Stankovic, Impact of radio irregularity on wireless
reference ||| sensor networks, the 2nd International Conference on
reference ||| Mobile Systems, Applications, and Services
reference ||| (MobiSys04), June, 2004
reference ||| [46] S. Zhu, S. Setia, and S. Jajodia, LEAP: Efficient
reference ||| Security Mechanisms for Large-Scale Distributed
reference ||| Sensor Networks, The 10th ACM Conference on
reference ||| Computer and Communications Security (CCS ’03),
reference ||| 62-72, 2003
reference ||| [47] S.Zhu, S. Setia, S. Jajodia, and P. Ning, An
reference ||| Interleaved Hop-by-Hop Authentication Scheme for
reference ||| Filtering False Data in Sensor Networks, IEEE
reference ||| Symposium on Security and Privacy, 2004
page ||| 69

title ||| A Similarity Measure for Motion Stream
title ||| Segmentation and Recognition*
author ||| Chuanjun Li	B. Prabhakaran
affiliation ||| Department of Computer Science
affiliation ||| The University of Texas at Dallas, Richardson, TX 75083
email ||| {chuanjun, praba}@utdallas.edu
sectionHeader ||| ABSTRACT
bodyText ||| Recognition of motion streams such as data streams gener-
bodyText ||| ated by different sign languages or various captured human
bodyText ||| body motions requires a high performance similarity mea-
bodyText ||| sure. The motion streams have multiple attributes, and mo-
bodyText ||| tion patterns in the streams can have different lengths from
bodyText ||| those of isolated motion patterns and different attributes
bodyText ||| can have different temporal shifts and variations. To ad-
bodyText ||| dress these issues, this paper proposes a similarity measure
bodyText ||| based on singular value decomposition (SVD) of motion ma-
bodyText ||| trices. Eigenvector differences weighed by the corresponding
bodyText ||| eigenvalues are considered for the proposed similarity mea-
bodyText ||| sure. Experiments with general hand gestures and human
bodyText ||| motion streams show that the proposed similarity measure
bodyText ||| gives good performance for recognizing motion patterns in
bodyText ||| the motion streams in real time.
sectionHeader ||| Categories and Subject Descriptors: H.2.8 [Database
sectionHeader ||| Management]: Database Applications – Data Mining
sectionHeader ||| General Terms: Algorithm
sectionHeader ||| Keywords: Pattern recognition, gesture, data streams, seg-
sectionHeader ||| mentation, singular value decomposition.
sectionHeader ||| 1. INTRODUCTION
bodyText ||| Motion streams can be generated by continuously per-
bodyText ||| formed sign language words [14] or captured human body
bodyText ||| motions such as various dances. Captured human motions
bodyText ||| can be applied to the movie and computer game industries
bodyText ||| by reconstructing various motions from video sequences [10]
bodyText ||| or images [15] or from motions captured by motion capture
bodyText ||| systems [4]. Recognizing motion patterns in the streams
bodyText ||| with unsupervised methods requires no training process, and
bodyText ||| is very convenient when new motions are expected to be
bodyText ||| added to the known pattern pools. A similarity measure
bodyText ||| with good performance is thus necessary for segmenting and
bodyText ||| recognizing the motion streams. Such a similarity measure
bodyText ||| needs to address some new challenges posed by real world
footnote ||| *Work supported partially by the National Science Founda-
footnote ||| tion under Grant No. 0237954 for the project CAREER:
footnote ||| Animation Databases.
copyright ||| Permission to make digital or hard copies of all or part of this work for
copyright ||| personal or classroom use is granted without fee provided that copies are
copyright ||| not made or distributed for profit or commercial advantage and that copies
copyright ||| bear this notice and the full citation on the first page. To copy otherwise, to
copyright ||| republish, to post on servers or to redistribute to lists, requires prior specific
copyright ||| permission and/or a fee.
copyright ||| Copyright 200X ACM X-XXXXX-XX-X/XX/XX ...$5.00.
bodyText ||| motion streams: first, the motion patterns have dozens of at-
bodyText ||| tributes, and similar patterns can have different lengths due
bodyText ||| to different motion durations; second, different attributes of
bodyText ||| similar motions have different variations and different tem-
bodyText ||| poral shifts due to motion variations; and finally, motion
bodyText ||| streams are continuous, and there are no obvious ”pauses”
bodyText ||| between neighboring motions in a stream. A good similarity
bodyText ||| measure not only needs to capture the similarity of complete
bodyText ||| motion patterns, but also needs to capture the differences
bodyText ||| between complete motion patterns and incomplete motion
bodyText ||| patterns or sub-patterns in order to segment a stream for
bodyText ||| motion recognition.
bodyText ||| As the main contribution of this paper, we propose a sim-
bodyText ||| ilarity measure to address the above issues. The proposed
bodyText ||| similarity measure is defined based on singular value decom-
bodyText ||| position of the motion matrices. The first few eigenvectors
bodyText ||| are compared for capturing the similarity of two matrices,
bodyText ||| and the inner products of the eigenvectors are given differ-
bodyText ||| ent weights for their different contributions. We propose to
bodyText ||| use only the eigenvalues corresponding to the involved eigen-
bodyText ||| vectors of the two motion matrices as weights. This simple
bodyText ||| and intuitive weighing strategy gives the same importance to
bodyText ||| eigenvalues of the two matrices. We also show that the 95%
bodyText ||| variance rule for choosing the number of eigenvectors [13] is
bodyText ||| not sufficient for recognizing both isolated patterns and mo-
bodyText ||| tion streams. Our experiments demonstrate that at least the
bodyText ||| first 6 eigenvectors need to be considered for motion streams
bodyText ||| of either 22 attribute or 54 attributes, and the first 6 eigen-
bodyText ||| values accounts for more than 99.5% of the total variance in
bodyText ||| the motion matrices.
sectionHeader ||| 2. RELATED WORK
bodyText ||| Multi-attribute pattern similarity search, especially in con-
bodyText ||| tinuous motion streams, has been widely studied for sign
bodyText ||| language recognition and for motion synthesis in computer
bodyText ||| animation. The recognition methods usually include tem-
bodyText ||| plate matching by distance measures and hidden Markov
bodyText ||| models (HMM).
bodyText ||| Template matching by using similarity/distance measures
bodyText ||| has been employed for multi-attribute pattern recognition.
bodyText ||| Joint angles are extracted in [11] as features to represent dif-
bodyText ||| ferent human body static poses for the Mahalanobis distance
bodyText ||| measure of two joint angle features. Similarly, momentum,
bodyText ||| kinetic energy and force are constructed in [2,5] as activ-
bodyText ||| ity measure and prediction of gesture boundaries for various
bodyText ||| segments of the human body, and the Mahalanobis distance
bodyText ||| function of two composite features are solved by dynamic
bodyText ||| programming.
page ||| 89
bodyText ||| Similarity measures are defined for multi-attribute data
bodyText ||| in [6,12,16] based on principal component analysis (PCA).
bodyText ||| Inner products or angular differences of principal compo-
bodyText ||| nents (PCs) are considered for similarity measure defini-
bodyText ||| tions, with different weighted strategies for different PCs.
bodyText ||| Equal weights are considered for different combinations of
bodyText ||| PCs in [6], giving different PCs equal contributions to the
bodyText ||| similarity measure. The similarity measure in [12] takes the
bodyText ||| minimum of two weighted sums of PC inner products, and
bodyText ||| the two sums are respectively weighted by different weights.
bodyText ||| A global weight vector is obtained by taking into account all
bodyText ||| available isolated motion patterns in [16], and this weight
bodyText ||| vector is used for specifying different contributions from dif-
bodyText ||| ferent PC inner products to the similarity measure Eros.
bodyText ||| The dominating first PC and a normalized eigenvalue vector
bodyText ||| are considered in [7,8] for pattern recognition. In contrast,
bodyText ||| this paper propose to consider the first few PCs, and the
bodyText ||| angular differences or inner products of different PCs are
bodyText ||| weighted by different weights which depends on the data
bodyText ||| variances along the corresponding PCs.
bodyText ||| The HMM technique has been widely used for sign lan-
bodyText ||| guage recognition, and different recognition rates have been
bodyText ||| reported for different sign languages and different feature se-
bodyText ||| lection approaches. Starner et al. [14] achieved 92% and 98%
bodyText ||| word accuracy respectively for two systems, the first of the
bodyText ||| systems used a camera mounted on a desk and the second
bodyText ||| one used a camera in a user’s cap for extracting features
bodyText ||| as the input of HMM. Similarly Liang and Ouhyoung [9]
bodyText ||| used HMM for postures, orientations and motion primitives
bodyText ||| as features extracted from continuous Taiwan sign language
bodyText ||| streams and an average 80.4% recognition rate was achieved.
bodyText ||| In contrast, the approach proposed in this paper is an un-
bodyText ||| supervised approach, and no training as required for HMM
bodyText ||| recognizers is needed.
sectionHeader ||| 3. SIMILARITY MEASURE FOR MOTION
sectionHeader ||| STREAM RECOGNITION
bodyText ||| The joint positional coordinates or joint angular values of
bodyText ||| a subject in motion can be represented by a matrix: the
bodyText ||| columns or attributes of the matrix are for different joints,
bodyText ||| and the rows or frames of the matrix are for different time
bodyText ||| instants. Similarity of two motions is the similarity of the
bodyText ||| resulting motion matrices, which have the same number of
bodyText ||| attributes or columns, and yet can have different number
bodyText ||| of rows due to different motion durations. To capture the
bodyText ||| similarity of two matrices of different lengths, we propose
bodyText ||| to apply singular value decomposition (SVD) to the motion
bodyText ||| matrices in order to capture the similarity of the matrix
bodyText ||| geometric structures. Hence we briefly present SVD and its
bodyText ||| associated properties below before proposing the similarity
bodyText ||| measure based on SVD in this section.
subsectionHeader ||| 3.1 Singular Value Decomposition
bodyText ||| The geometric structure of a matrix can be revealed by
bodyText ||| the SVD of the matrix. As shown in [3], any real m x n
bodyText ||| matrix A can be decomposed into A = UEVT , where U =
bodyText ||| [u1, u2, ... , um] E Rm×m and V = [v1, v2, ... , vn] E RnXn
bodyText ||| are two orthogonal matrices, and E is a diagonal matrix with
bodyText ||| diagonal entries being the singular values of A: v1 > v2 >
bodyText ||| . . . > Qmin(m,n) > 0. Column vectors ui and vi are the ith
bodyText ||| left and right singular vectors of A, respectively.
bodyText ||| It can be shown that the right singular vectors of the sym-
bodyText ||| metric n x n matrix M = AT A are identical to the corre-
bodyText ||| sponding right singular vectors of A, referred to as eigenvec-
bodyText ||| tors of M. The singular values of M, or eigenvalues of M,
bodyText ||| are squares of the corresponding singular values of A. The
bodyText ||| eigenvector with the largest eigenvalue gives the first prin-
bodyText ||| cipal component. The eigenvector with the second largest
bodyText ||| eigenvalue is the second principal component and so on.
subsectionHeader ||| 3.2 Similarity Measure
bodyText ||| Since SVD exposes the geometric structure of a matrix, it
bodyText ||| can be used for capturing the similarity of two matrices. We
bodyText ||| can compute the SVD of M = AT A instead of computing
bodyText ||| the SVD of A to save computational time. The reasons are
bodyText ||| that the eigenvectors of M are identical to the corresponding
bodyText ||| right singular vectors of A, the eigenvalues of M are the
bodyText ||| squares of the corresponding singular values of A, and SVD
bodyText ||| takes O(n 3) time for the n x n M and takes O(mn2) time
bodyText ||| with a large constant for the m x n A, and usually m > n.
bodyText ||| Ideally, if two motions are similar, their corresponding
bodyText ||| eigenvectors should be parallel to each other, and their cor-
bodyText ||| responding eigenvalues should also be proportional to each
bodyText ||| other. This is because the eigenvectors are the correspond-
bodyText ||| ing principal components, and the eigenvalues reflect the
bodyText ||| variances of the matrix data along the corresponding prin-
bodyText ||| cipal components. But due to motion variations, all corre-
bodyText ||| sponding eigenvectors cannot be parallel as shown in Fig-
bodyText ||| ure 1. The parallelness or angular differences of two eigen-
bodyText ||| vectors u and v can be described by the absolute value of
bodyText ||| their inner products: l cosOl = lu • vl/(lullvl) = lu • vl, where
bodyText ||| lul = lvl = 1. We consider the absolute value of the in-
bodyText ||| ner products because eigenvectors can have different signs
bodyText ||| as shown in [8].
bodyText ||| Since eigenvalues are numerically related to the variances
bodyText ||| of the matrix data along the associated eigenvectors, the im-
bodyText ||| portance of the eigenvector parallelness can be described by
bodyText ||| the corresponding eigenvalues. Hence, eigenvalues are to be
bodyText ||| used to give different weights to different eigenvector pairs.
bodyText ||| Figure 2 shows that the first eigenvalues are the dominat-
bodyText ||| ing components of all the eigenvalues, and other eigenval-
bodyText ||| ues become smaller and smaller and approach zero. As the
bodyText ||| eigenvalues are close to zero, their corresponding eigenvec-
bodyText ||| tors can be very different even if two matrices are similar.
bodyText ||| Hence not all the eigenvectors need to be incorporated into
bodyText ||| the similarity measure.
bodyText ||| Since two matrices have two eigenvalues for the corre-
bodyText ||| sponding eigenvector pair, these two eigenvalues should have
bodyText ||| equal contributions or weights to the eigenvector parallel-
bodyText ||| ness. In addition, the similarity measure of two matrices
bodyText ||| should be independent to other matrices, hence only eigen-
bodyText ||| vectors and eigenvalues of the two matrices should be con-
bodyText ||| sidered.
bodyText ||| Based on the above discussions, we propose the following
bodyText ||| similarity measure for two matrices Q and P:
equation ||| k
equation ||| 1
equation |||   (Q, P) =
equation ||| 2 i=1
bodyText ||| where vi and Ai are the ith eigenvalues corresponding to the
bodyText ||| ith eigenvectors ui and vi of square matrices of Q and P,
bodyText ||| respectively, and 1 < k < n. Integer k determines how many
bodyText ||| eigenvectors are considered and it depends on the number
bodyText ||| of attributes n of motion matrices. Experiments with hand
bodyText ||| gesture motions (n = 22) and human body motions (n =
equation ||| n
equation ||| ((�i/
equation ||| i=1
equation ||| n
equation ||| Qi+Ai/
equation ||| i=1
equation ||| Ai)lui •vil)
page ||| 90
figureCaption ||| Figure 1: Eigenvectors of similar patterns. The first
figureCaption ||| eigenvectors are similar to each other, while other
figureCaption ||| eigenvectors, such as the second vectors shown in
figureCaption ||| the bottom, can be quite different.
bodyText ||| 54) in Section 4 show that k = 6 is large enough without
bodyText ||| loss of pattern recognition accuracy in streams. We refer to
bodyText ||| this non-metric similarity measure as k Weighted Angular
bodyText ||| Similarity (kWAS) , which captures the angular similarities
bodyText ||| of the first k corresponding eigenvector pairs weighted by
bodyText ||| the corresponding eigenvalues.
bodyText ||| It can be easily verified that the value of kWAS ranges over
bodyText ||| [0,1]. When all corresponding eigenvectors are normal to
bodyText ||| each other, the similarity measure will be zero, and when two
bodyText ||| matrices are identical, the similarity measure approaches the
bodyText ||| maximum value one if k approaches n.
subsectionHeader ||| 3.3 Stream Segmentation Algorithm
bodyText ||| In order to recognize motion streams, we assume one mo-
bodyText ||| tion in a stream has a minimum length l and a maximum
bodyText ||| length L. The following steps can be applied to incremen-
bodyText ||| tally segment a stream for motion recognition:
listItem ||| 1. SVD is applied to all isolated motion patterns P to
listItem ||| obtain their eigenvectors and eigenvalues. Let S be
listItem ||| the incremented stream length for segmentation, and
listItem ||| let L be the location for segmentation. Initially L = l.
listItem ||| 2. Starting from the beginning of the stream or the end of
listItem ||| the previously recognized motion, segment the stream
listItem ||| at location L. Compute the eigenvectors and eigenval-
listItem ||| ues of the motion segment Q.
listItem ||| 3. Compute kWAS between Q and all motion patterns
bodyText ||| P. Update T... to be the highest similarity after the
bodyText ||| previous motion’s recognition.
listItem ||| 4. If L+S < L, update L = L+S and go to step 2. Other-
bodyText ||| wise, the segment corresponding to T,r,.. is recognized
bodyText ||| to be the motion pattern which gives the highest simi-
bodyText ||| larity T..., update L = l starting from the end of the
bodyText ||| last recognized motion pattern and go to step 2.
figure ||| 100
figure ||| 99
figure ||| 95
figure ||| 93
figure ||| 91
figure ||| 89
figure ||| 87
figure ||| 1	2	3	4	5	6	7	8
figure ||| Number of Eigenvalues
figureCaption ||| Figure 2: Accumulated eigenvalue percentages in
figureCaption ||| total eigenvalues for CyberGlove data and captured
figureCaption ||| human body motion data. There are 22 eigenvalues
figureCaption ||| for the CyberGlove data and 54 eigenvalues for the
figureCaption ||| captured motion data. The sum of the first 2 eigen-
figureCaption ||| values is more than 95% of the corresponding total
figureCaption ||| eigenvalues, and the sum of the first 6 eigenvalues is
figureCaption ||| almost 100% of the total eigenvalues.
sectionHeader ||| 4. PERFORMANCE EVALUATION
bodyText ||| This section evaluates experimentally the performances
bodyText ||| of the similarity measure kWAS proposed in this paper. It
bodyText ||| has been shown in [16] that Eros [16] outperforms other
bodyText ||| similarity measures mentioned in Section 2 except MAS [8].
bodyText ||| Hence in this section, we compare the performances of the
bodyText ||| proposed kWAS with Eros and MAS for recognizing similar
bodyText ||| isolated motion patterns and for segmenting and recognizing
bodyText ||| motion streams from hand gesture capturing CyberGlove
bodyText ||| and human body motion capture system.
subsectionHeader ||| 4.1 Data Generation
bodyText ||| A similarity measure should be able to be used not only
bodyText ||| for recognizing isolated patterns with high accuracy, but also
bodyText ||| for recognizing patterns in continuous motions or motion
bodyText ||| streams. Recognizing motion streams is more challenging
bodyText ||| than recognizing isolated patterns. This is because many
bodyText ||| very similar motion segments or sub-patterns needs to be
bodyText ||| compared in order to find appropriate segmentation loca-
bodyText ||| tions, and a similarity measure should capture the difference
bodyText ||| between a complete motion or pattern and its sub-patterns.
bodyText ||| Hence, both isolated motion patterns and motion streams
bodyText ||| were generated for evaluating the performance of kWAS.
bodyText ||| Two data sources are considered for data generation: a Cy-
bodyText ||| berGlove for capturing hand gestures and a Vicon motion
bodyText ||| capture system for capturing human body motions.
subsubsectionHeader ||| 4.1.1 CyberGlove Data
bodyText ||| A CyberGlove is a fully instrumented data glove that pro-
bodyText ||| vides 22 sensors for measuring hand joint angular values to
bodyText ||| capture motions of a hand, such as American Sign Language
bodyText ||| (ASL) words for hearing impaired. The data for a hand ges-
bodyText ||| ture contain 22 angular values for each time instant/frame,
bodyText ||| one value for a joint of one degree of freedom. The mo-
bodyText ||| tion data are extracted at around 120 frames per second.
bodyText ||| Data matrices thus have 22 attributes for the CyberGlove
bodyText ||| motions.
bodyText ||| One hundred and ten different isolated motions were gen-
bodyText ||| erated as motion patterns, and each motion was repeated
bodyText ||| for three times, resulting in 330 isolated hand gesture mo-
bodyText ||| tions. Some motions have semantic meanings. For example,
figure ||| 2	4	6	8	10	12	14	16	18	20	22
figure ||| Motion341
figure ||| Motion342
figure ||| Motion341
figure ||| Motion342
figure ||| 2	4	6	8	10	12	14	16	18	20	22
figure ||| Component of Second Eigenvector
figure ||| 	0.6 0.4 0.2 0 −0.2 −0.4
figure ||| 0.2
figure ||| 0.1
figure ||| 0
figure ||| −0.1
figure ||| −0.2
figure ||| −0.3
figure ||| −0.4
figure ||| −0.5
figure ||| −0.6
figure ||| −0.7
figure ||| Component of First Eigenvector
figure ||| 97
figure ||| 85
figure ||| CyberGlove Data
figure ||| MoCap Data
page ||| 91
bodyText ||| the motion for BUS as shown in Table 1 is for the ASL sign
bodyText ||| ”bus”. Yet for segmentation and recognition, we only re-
bodyText ||| quire that each individual motion be different from others,
bodyText ||| and thus some motions are general motions, and do not have
bodyText ||| any particular semantic meanings, such as the THUMBUP
bodyText ||| motion in Table 1.
bodyText ||| The following 18 motions shown in Table 1 were used to
bodyText ||| generate continuous motions or streams. Twenty four dif-
bodyText ||| ferent motion streams were generated for segmentation and
bodyText ||| recognition purpose. There are 5 to 10 motions in a stream
bodyText ||| and 150 motions in total in 24 streams, with 6.25 motions in
bodyText ||| a stream on average. It should be noted that variable-length
bodyText ||| transitional noises occur between successive motions in the
bodyText ||| generated streams.
tableCaption ||| Table 1: Individual motions used for streams
table ||| 35 60 70 80 90 BUS GOODBYE
table ||| HALF IDIOM JAR JUICE KENNEL KNEE
table ||| MILK TV SCISSOR SPREAD THUMBUP
subsubsectionHeader ||| 4.1.2 Motion Capture Data
bodyText ||| The motion capture data come from various motions cap-
bodyText ||| tured collectively by using 16 Vicon cameras and the Vicon
bodyText ||| iQ Workstation software. A dancer wears a suit of non-
bodyText ||| reflective material and 44 markers are attached to the body
bodyText ||| suit. After system calibration and subject calibration, global
bodyText ||| coordinates and rotation angles of 19 joints/segments can
bodyText ||| be obtained at about 120 frames per second for any mo-
bodyText ||| tion. Similarity of patterns with global 3D positional data
bodyText ||| can be disguised by different locations, orientations or differ-
bodyText ||| ent paths of motion execution as illustrated in Figure 3(a).
bodyText ||| Since two patterns are similar to each other because of sim-
bodyText ||| ilar relative positions of corresponding body segments at
bodyText ||| corresponding time, and the relative positions of different
bodyText ||| segments are independent of locations or orientations of the
bodyText ||| body, we can transform the global position data into local
bodyText ||| position data as follows.
bodyText ||| Let Xp, Yp, Zp be the global coordinates of one point on
bodyText ||| pelvis, the selected origin of the ”moving” local coordinate
bodyText ||| system, and a,,3, -y be the rotation angles of the pelvis seg-
bodyText ||| ment relative to the global coordinate system axes, respec-
bodyText ||| tively. The translation matrix is T as follows:
equation ||| 1	0	0	0
equation ||| 0	1	0	0
equation ||| 0	0	1	0
equation ||| —Xp	—Yp	—Zp	1
equation ||| The rotation matrix R = R. x Ry x Rz, where
equation ||| 1	0	0	0
equation ||| 0 cos a — sin a 0
equation ||| 0 sin a cos a 0
equation ||| 0 0 0 1
equation ||| cos,3 0 sin,3 0
equation ||| 0	1	0	0
equation ||| —sin,3 0 cos,3 0
equation ||| 0	0	0	1
figure ||| Motion Capture Frames	Motion Capture Frames
figure ||| (a)	(b)
figureCaption ||| Figure 3: 3D motion capture data for similar motions
figureCaption ||| executed at different locations and in different orien-
figureCaption ||| tations: (a) before transformation; (b) after transfor-
figureCaption ||| mation.
equation ||| cos-y —sin -y 0 0
equation ||| sin -y cos -y 0 0
equation ||| 0 0 1 0
equation ||| 0 0 0 1
bodyText ||| Let X, Y, Z be the global coordinates of one point on any
bodyText ||| segments, and x, y, z be the corresponding transformed local
bodyText ||| coordinates. x, y and z can be computed as follows:
equation ||| [x y z 1]=[X Y Z 1] x T x R
bodyText ||| The transformed data are positions of different segments
bodyText ||| relative to a moving coordinate system with the origin at
bodyText ||| some fixed point of the body, for example the pelvis. The
bodyText ||| moving coordinate system is not necessarily aligned with
bodyText ||| the global system, and it can rotate with the body. So data
bodyText ||| transformation includes both translation and rotation, and
bodyText ||| the transformed data would be translation and rotation in-
bodyText ||| variant as shown in Figure 3(b). The coordinates of the
bodyText ||| origin pelvis are not included, thus the transformed matri-
bodyText ||| ces have 54 columns.
bodyText ||| Sixty two isolated motions including Taiqi, Indian dances,
bodyText ||| and western dances were performed for generating motion
bodyText ||| capture data, and each motion was repeated 5 times, yield-
bodyText ||| ing 310 isolated human motions. Every repeated motion has
bodyText ||| a different location and different durations, and can face
bodyText ||| different orientations. Twenty three motion streams were
bodyText ||| generated for segmentation. There are 3 to 5 motions in
bodyText ||| a stream, and 93 motions in total in 23 streams, with 4.0
bodyText ||| motions in a stream on average.
subsectionHeader ||| 4.2 Performance of kWAS for Capturing Sim-
subsectionHeader ||| ilarities and Segmenting Streams
bodyText ||| We first apply kWAS to isolated motion patterns to show
bodyText ||| that the proposed similarity measure kWAS can capture the
bodyText ||| similarities of isolated motion patterns. Then kWAS is ap-
bodyText ||| plied to motion streams for segmenting streams and recog-
bodyText ||| nizing motion patterns in the streams. We experimented
bodyText ||| with different k values in order to find out the smallest k
bodyText ||| without loss of good performance.
bodyText ||| Figure 2 shows the accumulated eigenvalue percentages
bodyText ||| averaged on 330 hand gestures and 310 human motions, re-
bodyText ||| spectively. Although the first two eigenvalues account for
figure ||| 1500
figure ||| 1000
figure ||| 500
figure ||| 0
figure ||| −500
figure ||| −1000
figure ||| −1500
figure ||| 0	50	100	150	200	250	300	350	400	450
figure ||| −1000
figure ||| 0	50	100	150	200	250	300	350	400	450
figure ||| 1000
figure ||| 500
figure ||| 0
figure ||| −500
figure ||| 2000
figure ||| 1500
figure ||| 1000
figure ||| 500
figure ||| 0
figure ||| 0	50	100	150	200	250	300	350	400	450
figure ||| −1000
figure ||| 0	50	100	150	200	250	300	350	400	450
figure ||| 1000
figure ||| 500
figure ||| 0
figure ||| −500
figure ||| T=
figure ||| R, =
figure ||| Ry =
figure ||| Rz =
figure ||| 92
figure ||| Number of Nearest Neghbors (Most Simlar Patterns)
figureCaption ||| Figure 4: Recognition rate of similar CyberGlove
figureCaption ||| motion patterns. When k is 3, kWAS can find the
figureCaption ||| most similar motions for about 99.7% of 330 mo-
figureCaption ||| tions, and can find the second most similar motions
figureCaption ||| for 97.5% of the them.
figure ||| Number of Nearest Neighbors (Most aimilar Patterns1
figureCaption ||| Figure 5: Recognition rate of similar captured mo-
figureCaption ||| tion patterns. When k is 5, by using kWAS, the most
figureCaption ||| similar motions of all 310 motions can be found, and
figureCaption ||| the second most similar motions of 99.8% of the 310
figureCaption ||| motions can also be found.
bodyText ||| more than 95% of the respective sums of all eigenvalues,
bodyText ||| considering only the first two eigenvectors for kWAS is not
bodyText ||| sufficient as shown in Figure 4 and Figure 5. For Cyber-
bodyText ||| Glove data with 22 attributes, kWAS with k = 3 gives the
bodyText ||| same performance as kWAS with k = 22, and for motion
bodyText ||| capture data with 54 attributes, kWAS with k = 5 gives the
bodyText ||| same performance as kWAS with k = 54. Figure 4 and Fig-
bodyText ||| ure 5 illustrate that kWAS can be used for finding similar
bodyText ||| motion patterns and outperforms MAS and Eros for both
bodyText ||| hand gesture and human body motion data.
bodyText ||| The steps in Section 3.3 are used for segmenting streams
bodyText ||| and recognizing motions in streams. The recognition accu-
bodyText ||| racy as defined in [14] is used for motion stream recognition.
bodyText ||| The motion recognition accuracies are shown in Table 2. For
bodyText ||| both CyberGlove motion and captured motion data, k = 6
bodyText ||| is used for kWAS, which gives the same accuracy as k = 22
bodyText ||| for CyberGlove data and k = 54 for motion capture data,
bodyText ||| respectively.
bodyText ||| Figure 6 shows the time taken for updating the candi-
bodyText ||| date segment, including updating the matrix, computing the
bodyText ||| SVD of the updated matrix, and computing the similarities
bodyText ||| of the segment and all motion patterns. The code imple-
bodyText ||| mented in C++ was run on one 2.70 GHz Intel processor
bodyText ||| of a GenuineIntel Linux box. There are 22 attributes for
bodyText ||| the CyberGlove streams, and 54 attributes for the captured
figureCaption ||| Figure 6: Computation time for stream segment up-
figureCaption ||| date and similarity computation.
tableCaption ||| Table 2: Stream Pattern Recognition Accuracy (%)
table ||| Similarity Measures	CyberGlove	Motion Capture
table ||| 	Streams	Streams
table ||| Eros	68.7	78.5
table ||| MAS	93.3	78.5
table ||| kWAS (k=6)	94.0	94.6
bodyText ||| motion streams. Hence updating captured motion segments
bodyText ||| takes longer than updating CyberGlove motion segments as
bodyText ||| shown in Figure 6. The time required by kWAS is close to
bodyText ||| the time required by MAS, and is less than half of the time
bodyText ||| taken by using Eros.
subsectionHeader ||| 4.3 Discussions
bodyText ||| kWAS captures the similarity of square matrices of two
bodyText ||| matrices P and Q, yet the temporal order of pattern execu-
bodyText ||| tion is not revealed in the square matrices. As shown in [7],
bodyText ||| two matrices with the identical row vectors in different or-
bodyText ||| ders have identical eigenvectors and identical eigenvalues. If
bodyText ||| different temporal orders of pattern execution yield patterns
bodyText ||| with different semantic meanings, we need to further con-
bodyText ||| sider the temporal execution order, which is not reflected in
bodyText ||| the eigenvectors and eigenvalues and has not been consid-
bodyText ||| ered previously in [6,12,16].
bodyText ||| Since the first eigenvectors are close or parallel for similar
bodyText ||| patterns, we can project pattern A onto its first eigenvector
bodyText ||| ul by Aul. Then similar patterns would have similar projec-
bodyText ||| tions (called projection vectors hereafter), showing similar
bodyText ||| temporal execution orders while the projection variations
bodyText ||| for each pattern can be maximized. The pattern projection
bodyText ||| vectors can be compared by computing their dynamic time
bodyText ||| warping (DTW) distances, for DTW can align sequences
bodyText ||| of different lengths and can be solved easily by dynamic
bodyText ||| programming [1]. Incorporating temporal order information
bodyText ||| into the similarity measure can be done as for MAS in [7]
bodyText ||| if motion temporal execution orders cause motion pattern
bodyText ||| ambiguity to kWAS.
sectionHeader ||| 5. CONCLUSIONS
bodyText ||| This paper has proposed a similarity measure kWAS for
bodyText ||| motion stream segmentation and motion pattern recogni-
bodyText ||| tion. kWAS considers the first few k eigenvectors and com-
bodyText ||| putes their angular similarities/differences, and weighs con-
bodyText ||| tributions of different eigenvector pairs by their correspond-
figure ||| 100
figure ||| 99
figure ||| 98
figure ||| 97
figure ||| 96
figure ||| 95
figure ||| 94
figure ||| 93
figure ||| 92
figure ||| 91
figure ||| 90
figure ||| 1	2
figure ||| kWAS (k = 22)
figure ||| kWAS (k = 5)
figure ||| kWAS (k = 3)
figure ||| kWAS (k = 2)
figure ||| MAS
figure ||| EROS
figure ||| 99.5
figure ||| 98.5
figure ||| 97.5
figure ||| 96.5
figure ||| 95.5
figure ||| 100
figure ||| 99
figure ||| 98
figure ||| 97
figure ||| 96
figure ||| 95
figure ||| 123	4
figure ||| kWna (k = 541
figure ||| kWna (k = 51
figure ||| kWna (k = 41
figure ||| kWna (k = 31
figure ||| Mna
figure ||| EROa
figure ||| 20
figure ||| 18
figure ||| 16
figure ||| 14
figure ||| 12
figure ||| 10
figure ||| 8
figure ||| 6
figure ||| 4
figure ||| 2
figure ||| 0
figure ||| CyberGlove Streams	Motion Capture Streams
figure ||| MAS
figure ||| kWAS (k = 6)
figure ||| EROS
page ||| 93
bodyText ||| ing eigenvalues. Eigenvalues from two motion matrices are
bodyText ||| given equal importance to the weights. Experiments with
bodyText ||| CyberGlove hand gesture streams and captured human body
bodyText ||| motions such as Taiqi and dances show that kWAS can rec-
bodyText ||| ognize 100% most similar isolated patterns and can recog-
bodyText ||| nize 94% motion patterns in continuous motion streams.
sectionHeader ||| 6. REFERENCES
reference ||| [1] D. Berndt and J. Clifford. Using dynamic time
reference ||| warping to find patterns in time series. In AAAI-94
reference ||| Workshop on Knowledge Discovery in Databases,
reference ||| pages 229–248, 1994.
reference ||| [2] V. M. Dyaberi, H. Sundaram, J. James, and G. Qian.
reference ||| Phrase structure detection in dance. In Proceedings of
reference ||| the ACM Multimedia Conference 2004, pages 332–335,
reference ||| Oct. 2004.
reference ||| [3] G. H. Golub and C. F. V. Loan. Matrix Computations.
reference ||| The Johns Hopkins University Press,
reference ||| Baltimore,Maryland, 1996.
reference ||| [4] L. Ikemoto and D. A. Forsyth. Enriching a motion
reference ||| collection by transplanting limbs. In Proceedings of the
reference ||| 2004 ACM SIGGRAPH/Eurographics symposium on
reference ||| Computer animation, pages 99 – 108, 2004.
reference ||| [5] K. Kahol, P. Tripathi, S. Panchanathan, and
reference ||| T. Rikakis. Gesture segmentation in complex motion
reference ||| sequences. In Proceedings of IEEE International
reference ||| Conference on Image Processing, pages II – 105–108,
reference ||| Sept. 2003.
reference ||| [6] W. Krzanowski. Between-groups comparison of
reference ||| principal components. J. Amer. Stat. Assoc.,
reference ||| 74(367):703–707, 1979.
reference ||| [7] C. Li, B. Prabhakaran, and S. Zheng. Similarity
reference ||| measure for multi-attribute data. In Proceedings of the
reference ||| 2005 IEEE International Conference on Acoustics,
reference ||| Speach, and Signal Processing (ICASSP), Mar. 2005.
reference ||| [8] C. Li, P. Zhai, S.-Q. Zheng, and B. Prabhakaran.
reference ||| Segmentation and recognition of multi-attribute
reference ||| motion sequences. In Proceedings of the ACM
reference ||| Multimedia Conference 2004, pages 836–843, Oct.
reference ||| 2004.
reference ||| [9] R. H. Liang and M. Ouhyoung. A real-time continuous
reference ||| gesture recognition system for sign language. In
reference ||| Proceedings of the 3rd. International Conference on
reference ||| Face and Gesture Recognition, pages 558–565, 1998.
reference ||| [10] K. Pullen and C. Bregler. Motion capture assisted
reference ||| animation: texturing and synthesis. In SIGGRAPH,
reference ||| pages 501–508, 2002.
reference ||| [11] G. Qian, F. Guo, T. Ingalls, L. Olson, J. James, and
reference ||| T. Rikakis. A gesture-driven multimodal interactive
reference ||| dance system. In Proceedings of IEEE International
reference ||| Conference on Multimedia and Expo, June 2004.
reference ||| [12] C. Shahabi and D. Yan. Real-time pattern isolation
reference ||| and recognition over immersive sensor data streams.
reference ||| In Proceedings of the 9th International Conference on
reference ||| Multi-Media Modeling, pages 93–113, Jan 2003.
reference ||| [13] A. Singhal and D. E. Seborg. Clustering of
reference ||| multivariate time-series data. In Proceedings of the
reference ||| American Control Conference, pages 3931–3936, 2002.
reference ||| [14] T. Starner, J. Weaver, and A. Pentland. Real-time
reference ||| american sign language recognition using desk and
reference ||| wearable computer based video. IEEE Transactions
reference ||| on Pattern Analysis and Machine Intelligence,
reference ||| 20(12):1371–1375, 1998.
reference ||| [15] C. J. Taylor. Reconstruction of articulated objects
reference ||| from point correspondences in a single image.
reference ||| Computer Vision and Image Understanding,
reference ||| 80(3):349–363, 2000.
reference ||| [16] K. Yang and C. Shahabi. A PCA-based similarity
reference ||| measure for multivariate time series. In Proceedings of
reference ||| the Second ACM International Workshop on
reference ||| Multimedia Databases, pages 65–74, Nov. 2004.
page ||| 94

title ||| A Taxonomy of Ambient Information Systems:
title ||| Four Patterns of Design
author ||| Zachary Pousman
affiliation ||| College of Computing/GVU Center
affiliation ||| Georgia Institute of Technology
address ||| Atlanta, GA 30332
address ||| +1 (404) 385-2447
email ||| zach@cc.gatech.edu
author ||| John Stasko
affiliation ||| College of Computing/GVU Center
affiliation ||| Georgia Institute of Technology
address ||| Atlanta, GA 30332
address ||| + 1 (404) 894 5617
email ||| stasko@cc.gatech.edu
sectionHeader ||| ABSTRACT
bodyText ||| Researchers have explored the design of ambient information
bodyText ||| systems across a wide range of physical and screen-based media.
bodyText ||| This work has yielded rich examples of design approaches to the
bodyText ||| problem of presenting information about a user’s world in a way
bodyText ||| that is not distracting, but is aesthetically pleasing, and tangible to
bodyText ||| varying degrees. Despite these successes, accumulating theoretical
bodyText ||| and craft knowledge has been stymied by the lack of a unified
bodyText ||| vocabulary to describe these systems and a consequent lack of a
bodyText ||| framework for understanding their design attributes. We argue that
bodyText ||| this area would significantly benefit from consensus about the
bodyText ||| design space of ambient information systems and the design
bodyText ||| attributes that define and distinguish existing approaches. We
bodyText ||| present a definition of ambient information systems and a
bodyText ||| taxonomy across four design dimensions: Information Capacity,
bodyText ||| Notification Level, Representational Fidelity, and Aesthetic
bodyText ||| Emphasis. Our analysis has uncovered four patterns of system
bodyText ||| design and points to unexplored regions of the design space,
bodyText ||| which may motivate future work in the field.
sectionHeader ||| Categories and Subject Descriptors
category ||| Visual Interface Design, Tangible Interfaces
sectionHeader ||| Keywords
keyword ||| Ubiquitous Computing, Ambient Display, Peripheral Display,
keyword ||| Notification System, Taxonomy, Design Guidelines
sectionHeader ||| 1. INTRODUCTION
bodyText ||| From the very first formulation of Ubiquitous Computing, the
bodyText ||| idea of a calmer and more environmentally integrated way of
bodyText ||| displaying information has held intuitive appeal. Weiser called this
bodyText ||| “calm computing” [35] and described the area through an elegant
bodyText ||| example: a small, tangible representation of information in the
bodyText ||| world, a dangling string that would wiggle based on network
bodyText ||| traffic. When information can be conveyed via calm changes in
bodyText ||| the environment, users are more able to focus on their primary
bodyText ||| work tasks while staying aware of non-critical information that
copyright ||| Permission to make digital or hard copies of all or part of this work for
copyright ||| personal or classroom use is granted without fee provided that copies are
copyright ||| not made or distributed for profit or commercial advantage and that
copyright ||| copies bear this notice and the full citation on the first page. To copy
copyright ||| otherwise, or republish, to post on servers or to redistribute to lists,
copyright ||| requires prior specific permission and/or a fee.
note ||| AVI '06, May 23-26, 2006, Venezia, Italy.
copyright ||| Copyright 2006 ACM 1-59593-353-0/06/0005. $5.00.
bodyText ||| affects them. Research in this sub-domain goes by various names
bodyText ||| including “ambient displays”, “peripheral displays”, and
bodyText ||| “notification systems”. The breadth of the systems in these broad
bodyText ||| categories is quite large. We seek to disentangle the terminology
bodyText ||| used to describe and categorize the wide array of systems in order
bodyText ||| to provide a common language for discussing research therein.
bodyText ||| An ambient display can represent many types of data, from
bodyText ||| stock prices, to weather forecasts, to the presence or absence of
bodyText ||| colleagues. Maintaining awareness of co-located and distant work
bodyText ||| and social groups has been a long-term research thread in the area
bodyText ||| of Computer Supported Cooperative Work (CSCW) [5, 8]. The
bodyText ||| Tangible Media Group at the MIT Media Lab, directed by Ishii,
bodyText ||| also helped shape the field of ambient computation. They coined
bodyText ||| the term “tangible media,” citing inspiration from Weiser’s vision
bodyText ||| [35] and from Pederson and Sokoler’s AROMA system [29] and
bodyText ||| developed AmbientROOM [17] and Ambient Fixtures [6, 18].
bodyText ||| These systems use ambient displays to make people aware of both
bodyText ||| group activity and other information such as network traffic.
bodyText ||| Recent work in Ambient Intelligence has brought techniques from
bodyText ||| Artificial Intelligence to ambient systems, spearheaded by the
bodyText ||| Disappearing Computer initiative of the European Union [31].
bodyText ||| This research thrust seeks to imbue ambient systems with
bodyText ||| contextual knowledge about the environment. The Roomware
bodyText ||| project has resulted in smart architectural spaces that support
bodyText ||| information conveyance (and group collaboration) [33].
bodyText ||| Researchers have developed systems that use a multitude of
bodyText ||| everyday objects to display information. Examples include lights
bodyText ||| of various sorts [2, 17], sounds [25], shadows [8], artificial flowers
bodyText ||| [18], mobiles [24], and office-décor water fountains [12, 16].
bodyText ||| Further research has sought to use framed photographs [26] and
bodyText ||| larger artistic pictures to represent information from the world in
bodyText ||| an art-like manner [14, 30, 32]. There are also peripheral display
bodyText ||| “modes” of a user’s main desktop, including screensavers like
bodyText ||| What’s Happening [36], information bars and menus such as those
bodyText ||| leveraged in Sideshow and Irwin [6, 22], and alternate panes, like
bodyText ||| Apple’s Dashboard [3]. As one can see, the design space is large.
bodyText ||| All these systems provide a rich history of system design
bodyText ||| principles, approaches, and decisions, but accumulating theoretical
bodyText ||| and craft knowledge has been stymied by the lack of a unified
bodyText ||| vocabulary to define and describe these systems. In this paper we
bodyText ||| propose a set of design choices that developers of ambient
bodyText ||| information systems must confront to build successful and
bodyText ||| compelling systems. First we set out a definition of an ambient
bodyText ||| information system that is a synthesis of the varied definitions
bodyText ||| given in published research. We hone the intuitive set of
page ||| 67
bodyText ||| characteristics that distinguish ambient systems from other
bodyText ||| ubiquitous computing research systems. Next, we propose a set of
bodyText ||| design dimensions for ambient information systems. The four
bodyText ||| dimensions of system design elucidate the main decisions one
bodyText ||| confronts when designing an effective ambient system. Finally, we
bodyText ||| explore the clusters across dimensions to uncover four coherent
bodyText ||| combinations of system designs, which work as design patterns for
bodyText ||| the field. The results also identify new ways of combining the
bodyText ||| design attributes to explore new possibilities for ambient
bodyText ||| information systems.
sectionHeader ||| 2. AMBIENT INFORMATION SYSTEMS
bodyText ||| Many different terms have been used to describe the types of
bodyText ||| systems we discuss in this paper. Three of the most commonly
bodyText ||| used terms are “ambient display,” “peripheral display,” and
bodyText ||| “notification system.” But how does one differentiate these
bodyText ||| terms? Based on general understandings, we claim that:
listItem ||| - all ambient displays are peripheral displays,
listItem ||| - some notification systems are peripheral displays
bodyText ||| (some notification systems are not peripheral but are
bodyText ||| instead the object of focused work and attention)
bodyText ||| The words of researchers themselves likely best explain their
bodyText ||| conceptions of the systems that they have built. Below, we present
bodyText ||| germane definitional quotes.
listItem ||| •	Ishii et al: “[In Ambient Displays] information is moved off
listItem ||| the screen into the physical environment, manifesting itself as
listItem ||| subtle changes in form, movement, sound, color, smell,
listItem ||| temperature, or light. Ambient displays are well suited as a
listItem ||| means to keep users aware of people or general states of large
listItem ||| systems, like network traffic and weather.” [17]
listItem ||| •	Matthews et al: Peripheral displays, then, are displays that
bodyText ||| show information that a person is aware of, but not focused on.
bodyText ||| [24]
listItem ||| •	Matthews et al: “Ambient displays might be defined as those
bodyText ||| that are "minimally attended" (e.g. just salient enough for
bodyText ||| conscious perception) while alerting displays are "maximally
bodyText ||| divided" (e.g. slightly less salient than focal tasks). [24]
listItem ||| •	Stasko et al: Ambient displays typically communicate just one,
bodyText ||| or perhaps a few at the most, pieces of information and the
bodyText ||| aesthetics and visual appeal of the display is often paramount.
bodyText ||| Peripheral displays refer to systems that are out of a person’s
bodyText ||| primary focus of attention and may communicate one or more
bodyText ||| pieces of information.” [32]
listItem ||| •	Mankoff et al: “Ambient displays are abstract and aesthetic
bodyText ||| peripheral displays portraying non-critical information on the
bodyText ||| periphery of a user’s attention... They generally support
bodyText ||| monitoring of non-critical information.” “Ambient displays
bodyText ||| have the ambitious goal of presenting information without
bodyText ||| distracting or burdening the user.” [20]
listItem ||| •	Rounding and Greenberg: “The [notification collage] is
bodyText ||| designed to present info[rmation] as lightweight and peripheral
bodyText ||| objects. It does not demand the full attention of its users: rather
bodyText ||| it can be attended to in passing, where people collaborate should
bodyText ||| the need or desire arise.” [14]
listItem ||| •	McCrickard et al: “Often implemented as ubiquitous systems or
bodyText ||| within a small portion of the traditional desktop, notification
bodyText ||| systems typically deliver information of interest in a parallel,
bodyText ||| multitasking approach, extraneous or supplemental to a user’s
bodyText ||| attention priority.” [21 ]
listItem ||| •	McCrickard et al: Notification systems are defined as
bodyText ||| interfaces that are typically used in a divided-attention,
bodyText ||| multitasking situation, attempting to deliver current, valued
bodyText ||| information through a variety of platforms and modes in an
bodyText ||| efficient and effective manner [21 ].
bodyText ||| The easiest way to explain the differences between systems is
bodyText ||| to look at the design motivations that informed them. Ambient
bodyText ||| displays are those that have pointed aesthetic goals and present a
bodyText ||| very small number of information elements. These systems are a
bodyText ||| proper subset of peripheral displays, which can appear either in the
bodyText ||| environment or on secondary or even primary computer displays.
bodyText ||| Notification systems’ design motivation results from divided
bodyText ||| attention situations. As such, they can be equal to a primary work
bodyText ||| task in their attentional needs or be secondary. When notification
bodyText ||| systems are designed to be secondary to a primary task, the
bodyText ||| systems are appropriately defined as peripheral.
bodyText ||| In this paper, we propose the term ambient information system
bodyText ||| as the unit of study and define the behavioral characteristics of
bodyText ||| such as systems as follows:
listItem ||| •	Display information that is important but not critical.
listItem ||| •	Can move from the periphery to the focus of attention and
listItem ||| back again.
listItem ||| •	Focus on the tangible; representations in the environment.
listItem ||| •	Provide subtle changes to reflect updates in information
listItem ||| (should not be distracting).
listItem ||| •	Are aesthetically pleasing and environmentally appropriate.
listItem ||| 3. PREVIOUS TAXONOMIES
bodyText ||| A small number of research papers that describe ambient
bodyText ||| information systems also include extended discussions of the
bodyText ||| design dimensions that motivate and contextualize their work. The
bodyText ||| authors provide dimensions to compare and contrast their systems
bodyText ||| to others in order to explain their design rationales.
bodyText ||| Matthews et al use the dimensions notification level,
bodyText ||| transition, and abstraction to characterize systems in this space
bodyText ||| [24]. They developed the Peripheral Display Toolkit [23] that
bodyText ||| helps people to develop ambient information displays more easily.
bodyText ||| Their concept of notification level means the relative importance
bodyText ||| of a particular data stream. Transitions are the programmatic
bodyText ||| changes to the display, based on the data. Transitions include
bodyText ||| fading, scrolling, or animation effects. They define abstraction as
bodyText ||| the mapping that takes a piece of numerical or ordinal data and
bodyText ||| turns it into something that the ambient display can use, something
bodyText ||| “more easily interpreted with less [user] attention.”
bodyText ||| Matthews et al segregate notification level into five levels:
bodyText ||| Ignore, Change Blind, Make Aware, Interrupt, and Demand
bodyText ||| Attention. The gradations run from low, a system ignoring the
bodyText ||| change in the data, to high, a system demanding attention in a way
bodyText ||| that must also be explicitly dismissed. They propose categories of
bodyText ||| transition: interrupt, make aware, and change blind. Finally, they
bodyText ||| bifurcate abstraction into feature abstraction or degradation.
bodyText ||| McCrickard et al introduce a different set of three dimensions
bodyText ||| to classify notification systems: interruption, reaction, and
bodyText ||| comprehension [21]. Interruption is defined psychologically,
bodyText ||| similar to Matthews’ notion, “as an event prompting transition and
bodyText ||| reallocation of attention focus from a [primary] task to the
bodyText ||| notification.” Reaction is defined as the rapid response to a given
bodyText ||| stimulus, while comprehension is the long-term notion of
bodyText ||| remembering and sense-making.
page ||| 68
bodyText ||| McCrickard et al then plot the design space as a 3-tuple of
bodyText ||| interaction, reaction, and comprehension (IRC). Each dimension is
bodyText ||| assigned a rating of high (1) or low (0), creating models like 0-1-0.
bodyText ||| They label these models with meaningful names like “Ambient
bodyText ||| Media, 0-0-1” “Indicator, 0-1-0” and “Critical Activity Monitor,
bodyText ||| 1-1-1.” Eight models serve as the corners of a design space. The
bodyText ||| resulting space, it should be noted, is larger than the design space
bodyText ||| of ambient information systems as we discuss in this paper
bodyText ||| because it contains games, secondary displays, and critical activity
bodyText ||| monitors (which by our definition, are notification systems that are
bodyText ||| not also peripheral systems). McCrickard also classifies a set of 14
bodyText ||| extant systems in the design space on the three dimensions.
bodyText ||| Both of these taxonomies deal thoroughly with interruption
bodyText ||| and detail some of the criteria for categorizing systems along this
bodyText ||| design dimension. We extend this analysis to other dimensions of
bodyText ||| data representation, flexibility, and aesthetics. This more holistic
bodyText ||| view points out design trade-offs between aesthetic emphasis and
bodyText ||| and flexibility, and between a system’s information display style
bodyText ||| and display capacity.
bodyText ||| Mankoff et al proposed a set of heuristics for evaluating
bodyText ||| ambient systems [20], which may also assist system builders. The
bodyText ||| heuristics attempt to give guidance for the formative evaluation of
bodyText ||| ambient systems, but they also can be viewed as high-level design
bodyText ||| guidelines, such as “The display should be designed to give ‘just
bodyText ||| enough’ information. Too much information cramps the display,
bodyText ||| and too little makes the display less useful.”
sectionHeader ||| 4. DESIGN DIMENSIONS OF AMBIENT
sectionHeader ||| SYSTEMS
bodyText ||| Designers of ambient information systems make decisions
bodyText ||| about how much information to display, what specific aspects to
bodyText ||| depict, and how exactly to display it, transparently or abstractly,
bodyText ||| on a monitor or via a decorative sculpture. We present four design
bodyText ||| dimensions that capture the space of ambient information systems.
bodyText ||| The dimensions can be thought of as design choices or design
bodyText ||| questions that system builders must answer. The dimensions are:
listItem ||| •	information capacity
listItem ||| •	notification level
listItem ||| •	representational fidelity
listItem ||| •	aesthetic emphasis
bodyText ||| We rank 19 research systems and three consumer ambient
bodyText ||| information systems on each of the four axes. Each axis is divided
bodyText ||| into 5 bands, from low to high. We place systems into groups
bodyText ||| based on information from published conference and journal
bodyText ||| proceedings, including images and videos of systems in use if
bodyText ||| available. The 19 systems we chose are not intended to be an
bodyText ||| exhaustive list of all ambient information systems in the research
bodyText ||| literature. The 19 systems are representative of the breadth of the
bodyText ||| field and we feel that attempting an exhaustive list, while
bodyText ||| amplifying completeness, would not significantly alter the design
bodyText ||| dimensions.
bodyText ||| Research systems that we analyzed include: Bus Mobile [24],
bodyText ||| Dangling String [35], Digital Family Portrait [26], InfoCanvas
bodyText ||| [33], Informative Art [30], Information Percolator [16], Irwin [22],
bodyText ||| Kandinsky [11], Kiumra [19], Lumitouch [5], Notification Collage
bodyText ||| [14], Scope [34], Sideshow [7], Table Fountain [12], Water Lamp
bodyText ||| [8], and What’s Happening [36]. We include three consumer
bodyText ||| systems that fit our definition of ambient information systems,
bodyText ||| Ambient Devices Ambient Orb [2], the My Yahoo! web portal
bodyText ||| [27] and Apple’s Dashboard [3].
bodyText ||| Figure 1 shows the four dimensions for our analysis, and
bodyText ||| each of the 19 systems placed into a group along each. Thin
bodyText ||| colored lines trace the rankings of systems on each axis, similar to
bodyText ||| a parallel coordinates plot. Each axis has values that range from
bodyText ||| low to high through five grades. The dimensions of notification
bodyText ||| level and representational fidelity have more descriptive axis
bodyText ||| labels that will be explained in detail below.
subsectionHeader ||| 4.1 Information Capacity
bodyText ||| Ambient information systems are created to convey
bodyText ||| information to users—information that typically is important to a
bodyText ||| user’s sense of wellbeing and general awareness, but not critical to
bodyText ||| their work or personal life. Information capacity represents the
bodyText ||| number of discrete information sources that a system can
bodyText ||| represent. Some systems are capable of displaying a single piece
bodyText ||| of data such as the current price of a stock index. Others can
bodyText ||| display the value of 20 (or more) different information elements
bodyText ||| on one screen. We rank systems from “Low” to “High” on this
bodyText ||| design dimension.
bodyText ||| Information elements are discrete information “nuggets”. For
bodyText ||| example, if a system monitors campus shuttle buses, each bus is a
bodyText ||| single nugget. If the system can represent both the time to a
bodyText ||| location and a direction of travel, then there are two nuggets of
bodyText ||| information for each bus that is monitored.
bodyText ||| Information capacity makes visible the design trade-off
bodyText ||| between space and time. A designer can increase the information
bodyText ||| capacity of a display by increasing the space for information to be
bodyText ||| presented or by creating a display that transitions through a set of
bodyText ||| views over time. If a system is designed with multiple views or
bodyText ||| uses scrolling, we rank it in the top tier, since the number of pieces
bodyText ||| of information that it could display is arbitrarily large.
bodyText ||| A further caveat about information capacity is necessary.
bodyText ||| Some of the analyzed systems such as InfoCanvas, Sideshow, and
bodyText ||| Dashboard are user-configured and user-customizable. This means
bodyText ||| that these and other systems could potentially be made to display
bodyText ||| hundreds of elements. Instead of attempting to calculate a
bodyText ||| theoretical maximum throughput for the display in these cases, we
bodyText ||| use the system designer’s naturalistic portrayal in their published
bodyText ||| work to determine the “everyday maximum.” Each of these
bodyText ||| systems is also in the top tier of information capacity.
bodyText ||| The design dimension of information capacity has a barbell
bodyText ||| distribution. Five of the 19 systems display a single information
bodyText ||| element and are ranked “Low”. Conversely, there are eight
bodyText ||| systems that display from ten to 20 information elements, with
bodyText ||| some systems having the potential to display more and these are
bodyText ||| ranked “High.” Only a few systems take a middle-ground
bodyText ||| approach, attempting to display a small number (from two to ten)
bodyText ||| of information elements.
bodyText ||| The systems with low ratings on the attribute of information
bodyText ||| conveyance are those that are physical displays. Fountains,
bodyText ||| glowing lights, and office-decoration sculptures afford designers
bodyText ||| only so much flexibility for changes.
page ||| 69
figureCaption ||| Figure 1: Parallel Coordinate plot of 19 existing ambient information systems across four design dimensions. Colored lines trace
figureCaption ||| each system’s ranking along the design dimensions. Different colors are used to denote groups of systems which are similar as
figureCaption ||| explained more fully in Section 5.
figureCaption ||| Since the number of changes possible is small, the total number
figureCaption ||| of information nuggets that can be represented is
figureCaption ||| correspondingly small. The systems with high information
figureCaption ||| conveyance are those that are presented on LCD screens. The
figureCaption ||| systems that run at full screen (instead of as a small section of a
figureCaption ||| focused main monitor) are ranked the highest.
subsectionHeader ||| 4.2 Notification Level
bodyText ||| Notification level is the degree to which system alerts are
bodyText ||| meant to interrupt a user. Notification level is a design attribute
bodyText ||| that is present in the two taxonomies of ambient and peripheral
bodyText ||| information systems we reviewed earlier. Matthews et al
bodyText ||| subdivides notification level into five categories: ignore, change
bodyText ||| blind, make aware, interrupt, and demand attention. For our
bodyText ||| analysis we adopt those categories but replace the lowest level
bodyText ||| of system alert function, ignore (a degenerate case) with user
bodyText ||| poll. Systems such as Apple Dashboard and My Yahoo! do not
bodyText ||| always appear in a user’s environment and must be explicitly
bodyText ||| called to the fore.
bodyText ||| Notification level can be thought of as the “ambience” of
bodyText ||| the systems in question. Some systems in the ambient space are
bodyText ||| quiet, and afford opportunistic glances to the information, while
bodyText ||| others provide more strident alerts by blinking, flashing,
bodyText ||| beeping, or even opening dialog windows. Systems that provide
bodyText ||| unobtrusive change blind or make aware notifications to the user
bodyText ||| are at the core of the ambient information system design space.
bodyText ||| Systems that interrupt users with alarms or that demand
bodyText ||| attention (by launching system dialog windows) are not subtle,
bodyText ||| so are further from the core concept of ambient information
bodyText ||| systems, though, as Matthews et al argues, the smooth transition
bodyText ||| from more subtle to more jarring is an interesting design
bodyText ||| direction for ambient system designers.
bodyText ||| Notification level is the designer-intended level of alert.
bodyText ||| We do not take pains to distinguish between systems that are
bodyText ||| proven to be “change blind” through user experimentation
bodyText ||| versus those that merely claim change blindness. We remain
bodyText ||| agnostic here about the techniques used for ensuring subtlety
bodyText ||| including slow animation, scrolling, and fading (these
bodyText ||| implementation details are at a lower level of design rationale).
bodyText ||| Once the decision has been made to produce a system with
bodyText ||| change blind transitions, the designer must then produce system
bodyText ||| transitions that meet the goal in the specifics of the system. Our
bodyText ||| analysis focuses on the high level decision on the part of the
bodyText ||| designer or design team.
bodyText ||| The distribution of systems here shows a good fit to our
bodyText ||| definition of ambient information systems. It is apparent that
bodyText ||| most ambient information systems adhere to the central notion
bodyText ||| of subtle visual or representational changes. The vast majority of
bodyText ||| ambient information systems fall into the change blind and make
bodyText ||| aware transition categories (somewhat low and medium). Few
bodyText ||| systems are designed to interrupt users or demand attention.
page ||| 70
bodyText ||| Two that do however are Scope and Sideshow. Note that most
bodyText ||| systems that are physical displays do not have make-aware or
bodyText ||| interruption-level alerts, much less demand attention alerts. The
bodyText ||| Bus Mobile does enable make-aware transitions, when, for
bodyText ||| example, the last bus of the day approaches.
subsectionHeader ||| 4.3 Representational Fidelity
bodyText ||| Representational fidelity describes a system’s display
bodyText ||| components and how the data from the world is encoded into
bodyText ||| patterns, pictures, words, or sounds. Some systems reproduce
bodyText ||| the information being monitored in a very direct way, while
bodyText ||| others are much more abstract in their representation. Matthews
bodyText ||| et al’s taxonomy characterizes this design choice as abstraction,
bodyText ||| but only distinguishes two sub-types, feature degradation and
bodyText ||| feature abstraction. We consider this design dimension to be rich
bodyText ||| and complex, so we will try to tease apart the many different
bodyText ||| types of abstraction that appear in ambient information systems.
bodyText ||| Representational fidelity can be described in the language
bodyText ||| of Semiotics, the branch of Philosophy that deals with signs, sign
bodyText ||| systems (such as natural languages) and their meanings. As such
bodyText ||| it has an accepted vocabulary for the elements of a symbolic
bodyText ||| representation. Semiotics can help analyze the way that
bodyText ||| particular signifiers—words, pictures, sounds, and other
bodyText ||| things—stand for the things they represent.
bodyText ||| A semiotic sign is made up of three parts [28]. The object
bodyText ||| is called the signified; it is the physical thing or idea that the
bodyText ||| sign stands for. The signifier is the representation of the object,
bodyText ||| which could be a word, a picture, or a a sound. The sense is the
bodyText ||| understanding that an observer gets from seeing or experiencing
bodyText ||| either the signified or its signifier. The signifier and the signified
bodyText ||| need not have any direct relationship. However, both the
bodyText ||| signified and the signifier create the same sense in the head of an
bodyText ||| observer; seeing a log aflame and seeing the word “fire” create
bodyText ||| the same meaning for a person.
bodyText ||| Ambient information systems, in the vocabulary of
bodyText ||| semiotics, contain one or more signs. Each sign has its object,
bodyText ||| information in the world, and its representation, the lights,
bodyText ||| pictures, or sounds used to signify that information. Many
bodyText ||| ambient information systems contain multiple signs—each
bodyText ||| picture element standing for a different piece of information.
bodyText ||| The theory of Semiotics also helps to explain the notion
bodyText ||| that some signs are transparent, easily understood, while others
bodyText ||| are metaphorical and still others are abstract. Signs can be
bodyText ||| symbolic, iconic, or indexical. Symbolic signs are those that are
bodyText ||| completely arbitrary. For example languages are arbitrary, for
bodyText ||| the word “bachelor” has no more natural relation to an
bodyText ||| unmarried man than does the word “foobar. ” Symbolic signs
bodyText ||| are those signs for which a code, or rule-following convention,
bodyText ||| is required to understand. Language characters and numbers are
bodyText ||| all symbolic, as are abstract visual representations (the color red
bodyText ||| standing for “danger”). Iconic signs are those signs that have an
bodyText ||| intermediate degree of transparency to the signified object.
bodyText ||| Iconic signs include metaphors as well as doodles, drawings,
bodyText ||| and caricatures. Icons represent their objects by having some
bodyText ||| similarity or resemblance to the object or to an essential aspects
bodyText ||| of the object. Indexical signs are those that are directly
bodyText ||| connected to the signified. Examples include measuring
bodyText ||| instruments, maps, and photographs.
bodyText ||| We have subdivided the three main categories of
bodyText ||| representational fidelity to distinguish between ambient
bodyText ||| information systems. We propose five groups, ranked from
bodyText ||| indexical (high) to symbolic (low):
listItem ||| •	INDEXICAL: measuring instruments, maps,
listItem ||| photographs
listItem ||| •	ICONIC: drawings, doodles, caricatures
listItem ||| •	ICONIC: Metaphors
listItem ||| ■ SYMBOLIC: language symbols (letters and numbers)
listItem ||| ■ SYMBOLIC: abstract symbols
bodyText ||| Some ambient information systems have displays that do
bodyText ||| not afford representational flexibility, because of the constraints
bodyText ||| of the display. For example, the LiveWire system and the
bodyText ||| Ambient Orb cannot represent language symbols, nor can they
bodyText ||| convey indexical forms like photographs. However, some
bodyText ||| flexibility is present. The systems might map information in an
bodyText ||| arbitrary way, remaining fully abstract (representing stock
bodyText ||| increases with the color green and losses with the color red), or
bodyText ||| it could map information more metaphorically, as would be the
bodyText ||| case if LiveWire were connected to information from a
bodyText ||| seismograph or ocean tides. As one can see, the question
bodyText ||| concerning representational flexibility requires one to consider
bodyText ||| both the display and the information that is displayed.
bodyText ||| The InfoCanvas is a very flexible system when considering
bodyText ||| representational fidelity. The InfoCanvas uses all five types of
bodyText ||| representational fidelity. It uses abstract symbols, such as the
bodyText ||| color red standing for traffic being stopped, metaphors, like a
bodyText ||| cartoon drawing of a cloud representing cloudy conditions, and
bodyText ||| also photographs and words of news stories, which are fully
bodyText ||| indexical. We show this ability for a system to straddle multiple
bodyText ||| representational forms by duplicating the system in each
bodyText ||| category and noting them with an asterisk (see Figure 1).
bodyText ||| Systems which are designed to represent information at multiple
bodyText ||| levels of fidelity are: Apple’s Dashboard, InfoCanvas,
bodyText ||| Informative Art, Notification Collage, Sideshow, and What’s
bodyText ||| Happening. In these cases, we draw the parallel coordinate plot
bodyText ||| to the top-most tier of representational fidelity for each system.
bodyText ||| The majority of systems however, only afford a single level
bodyText ||| of representational fidelity. Many of the sculptural displays only
bodyText ||| afford symbolic, that is abstract, representations, while a smaller
bodyText ||| number afford text and photographic representations.
subsectionHeader ||| 4.4 Aesthetic Emphasis
bodyText ||| The final dimension concerns the relative importance of the
bodyText ||| aesthetics of the display. Some system designers seek to build
bodyText ||| displays and artifacts with sculptural or artistic conventions. For
bodyText ||| these systems, being visually pleasing is a primary objective.
bodyText ||| Others however place relatively little focus on aesthetics and
bodyText ||| typically focus more on information communication ability.
bodyText ||| Since aesthetic judgment is at its core a subjective phenomenon,
bodyText ||| we do not judge systems on their relative artistic merits. Instead
bodyText ||| we attempt to rank ambient information systems by our
bodyText ||| perception of the importance given to aesthetics. There is often a
bodyText ||| tradeoff made between communication capacity,
bodyText ||| representational fidelity, and aesthetics, a relationship that we
bodyText ||| explore in this section.
bodyText ||| Ambient information systems are intended to be visible;
bodyText ||| positioned on a shelf, hung on the wall, or placed as a small
bodyText ||| sculpture on a desk, the systems are seen not just by a user, but
bodyText ||| also by co-workers, colleagues, or family members. There are a
page ||| 71
bodyText ||| multitude of approaches when it comes to building aesthetically
bodyText ||| pleasing devices. One approach is to build systems that mirror
bodyText ||| existing artworks by a particular artist, as is the case in
bodyText ||| Kandinsky and Informative Art. A second approach is to design
bodyText ||| a display that is representative of a particular style or art
bodyText ||| movement. InfoCanvas, through its use of themes, allows the
bodyText ||| display to take on characteristics of Asian water-color paintings,
bodyText ||| for example.
bodyText ||| We rank systems on the design dimension of aesthetic
bodyText ||| emphasis as low, somewhat low, medium, somewhat high and
bodyText ||| high. Note again that we are not assessing the degree to which
bodyText ||| the systems are successful as art. We are providing a subjective
bodyText ||| measure of how much the system designers focused on
bodyText ||| aesthetics and how much they emphasized aesthetic
bodyText ||| considerations in their research and design decisions.
bodyText ||| Most systems that we analyzed had medium or somewhat
bodyText ||| high degrees of aesthetic emphasis (12 of 19). The decisions of
bodyText ||| designers to strive for visually pleasing displays is most clear in
bodyText ||| the cases where the display is intended to leverage the work of
bodyText ||| existing artists. The physical ambient information displays are
bodyText ||| often sculptural in their design decisions. They attempt to set
bodyText ||| themselves off from the rest of the environment, often on
bodyText ||| pedestals or stands. Their capability to display much information
bodyText ||| (information capacity) is often limited by their design clarity and
bodyText ||| austerity. We consider this design trade-off in the next section.
bodyText ||| Systems that we ranked at the middle of the spectrum of
bodyText ||| aesthetic emphasis are those which are not intended by their
bodyText ||| designers to be art worthy of contemplation as art objects. But
bodyText ||| they are explicitly intended to be viewed as calm pleasing
bodyText ||| objects and displays. Apple’s Dashboard widgets have a clean
bodyText ||| design sense about them, as does Kimura, What’s Happening
bodyText ||| and the Information Percolator. The systems that are ranked low
bodyText ||| on aesthetic emphasis are Scope, Sideshow, Bus Mobile, Elvin,
bodyText ||| and My Yahoo!. These systems put information conveyance at a
bodyText ||| higher priority than being aesthetically pleasing. They are still
bodyText ||| calm and environmentally appropriate, but their designers did
bodyText ||| not emphasize their aesthetic qualities. Cleary, some systems
bodyText ||| that are early-stage prototypes like Bus Mobile, may not have
bodyText ||| the aesthetic polish of more finished systems.
sectionHeader ||| 5. FOUR DESIGN PATTERNS
bodyText ||| In this section, we introduce four design patterns for
bodyText ||| ambient information systems, after Alexander’s pattern language
bodyText ||| for architectural studies [1]. The design patterns illustrate four
bodyText ||| coherent combinations of the four design dimensions previously
bodyText ||| presented. We have already pointed out trends and clusters that
bodyText ||| are present in each particular design dimension. However, there
bodyText ||| are fruitful conclusions for system designers as we consider the
bodyText ||| interaction between the design dimensions to form design
bodyText ||| patterns.
bodyText ||| Considering the clusters of systems in each dimension and
bodyText ||| the correspondences that are visible in the parallel coordinate
bodyText ||| plot, we find four main archetypes in existing ambient
bodyText ||| information system design: Symbolic Sculptural Display,
bodyText ||| Multiple-Information Consolidators, Information Monitor
bodyText ||| Display, and High Throughput Textual Display. Figure 2
bodyText ||| shows the pattern of each archetype across the dimensions.
figureCaption ||| Figure 2: a-d System design archetypes shown in the context
bodyText ||| of the design space. Heavy boxes indicate core design
bodyText ||| decisions, while light boxes show alternate choices.
bodyText ||| Symbolic Sculptural Displays are ambient information systems
bodyText ||| that display very few pieces of information, usually a single
bodyText ||| element. They represent information in an abstract sculptural
bodyText ||| way with light, water, or moving objects. They are intended to
bodyText ||| be decorative objects for a home or office setting and as such are
bodyText ||| highly aesthetic in their design (see Figure 2a). This design
bodyText ||| pattern is a core of ambient system design, and accounts for six
bodyText ||| of our analyzed systems: Ambient Orb, Dangling String, Digital
bodyText ||| Family Portrait, Information Percolator, Lumitouch, Table
bodyText ||| Fountain, and Water Lamp. The Digital Family Portrait
bodyText ||| combines multiple information sources and so truly represents
bodyText ||| more information than the other members of this type.
page ||| 72
bodyText ||| Multiple Information Consolidators are ambient systems that
bodyText ||| display many individual pieces of information in a consolidated
bodyText ||| manner. They are typically screen-based in order to convey
bodyText ||| much information and make users aware of changes to that
bodyText ||| information (usually by blinking the visual representation of a
bodyText ||| certain element). They are reasonably aesthetically motivated,
bodyText ||| but all clearly demonstrate the trade-off between aesthetics and
bodyText ||| customization and information capacity (see Figure 2b). Systems
bodyText ||| which illustrate this design pattern are: Kandinsky, Kimura,
bodyText ||| InfoCanvas, Notification Collage, and What’s Happening.
bodyText ||| Kandinsky departs from the other systems in that it is explicitly
bodyText ||| modeled on the fine art of Kandinsky, and as such is highly
bodyText ||| stylized and design-focused. It does so at the expense of
bodyText ||| flexibility, since it can only display photographs in its slots.
bodyText ||| Information Monitor Displays are displays that are a
bodyText ||| peripheral part of a user’s computer desktop. As such, they
bodyText ||| afford different interactions and design choices. They display
bodyText ||| multiple sources of information, and do so usually by visual
bodyText ||| metaphors. They are capable of notifying users in multiple ways
bodyText ||| about changes in the source data, including subtle awareness,
bodyText ||| interrupting, and even demanding user attention when necessary
bodyText ||| (i.e., requiring the user to switch focus to dismiss a notification).
bodyText ||| The systems achieve aesthetics, but their primary purpose is not
bodyText ||| good looks (see Figure 2c). Examples of this design archetype
bodyText ||| include: Scope, and Sideshow.
bodyText ||| High Throughput Textual Display systems are those that use
bodyText ||| text and very simple graphics (icons) to denote information.
bodyText ||| They are capable of representing voluminous information, but
bodyText ||| do not draw attention with interruption-level notifications. These
bodyText ||| systems are not primarily as concerned with aesthetics as they
bodyText ||| are with information conveyance (see Figure 2d). These systems
bodyText ||| are simple but efficient for certain types of tasks. Examples of
bodyText ||| this design archetype are: Elvin, and My Yahoo!.
bodyText ||| The four design archetypes cover nearly all of the analyzed
bodyText ||| systems, but do not cleanly categorize three systems. Apple’s
bodyText ||| Dashboard system is most similar to a Multiple Information
bodyText ||| Consolidator. It fails being a pure example of this archetype
bodyText ||| because of its inability to alert users to changes in information –
bodyText ||| it requires users poll the system by calling up the transparent
bodyText ||| pane via a hot key. The Bus Mobile is an early stage prototype,
bodyText ||| and as such is not concerned with aesthetics to a large degree.
bodyText ||| With a higher degree of aesthetic emphasis, it might be closer to
bodyText ||| a Information Monitor Display (albeit a physical instead of
bodyText ||| screen-based system). Informative Art is quite unlike the four
bodyText ||| design archetypes. Informative Art has high aesthetic emphasis,
bodyText ||| but low information capacity (e.g. 5 or 6 city’s weather forecast
bodyText ||| information). It is metaphorical and abstract in its information
bodyText ||| mapping fidelity.
sectionHeader ||| 6. EXTENDING THE PATTERNS
bodyText ||| The four patterns for system design can help designers to
bodyText ||| make appropriate choices as they develop new ambient
bodyText ||| information systems. The design patterns can be used as models
bodyText ||| so a designer can decide to build “an information monitor
bodyText ||| display for a home health awareness application”, or “a set of
bodyText ||| symbolic sculptural displays for work-group collaboration”.
bodyText ||| Further, the designer may be depart from the pattern, by building
bodyText ||| up a system’s range of possible notification levels, or by
bodyText ||| choosing to trade aesthetics for increased information capacity.
bodyText ||| However, our analysis also points at what has not yet been
bodyText ||| explored. The four design patterns show four coherent
bodyText ||| combinations, but they are not the only possibilities for building
bodyText ||| useful ambient systems. Combined with longer-term trends in
bodyText ||| the fields of Ambient Intelligence and Ubiquitous Computing,
bodyText ||| new archetypes for system design are emerging. We note
bodyText ||| possibilities here, which change both the dimensions and the
bodyText ||| four design patterns.
bodyText ||| We do not expect the information capacity for ambient
bodyText ||| systems to increase by dramatically. Though scrolling or time-
bodyText ||| divided ambient systems (What’s Happening, Elvin) can already
bodyText ||| display data elements numbering in the hundreds, simultaneous
bodyText ||| visual displays are usually limited to 25 or 30 elements by
bodyText ||| readability and user learnability. Ambient information systems
bodyText ||| will not turn into information visualization systems showing
bodyText ||| thousands of data points. However, contextual sets of
bodyText ||| information may be useful for ambient systems in specialized
bodyText ||| environments. Systems which display contextual sets of
bodyText ||| information like that of the Bus Mobile (all of the buses on a
bodyText ||| college campus) or Scope (email and calendar data) would
bodyText ||| increase the number of systems in the middle portion of this
bodyText ||| design dimension.
bodyText ||| We also expect to see changes to the design dimension of
bodyText ||| representational flexibility. Designers have begun to explore the
bodyText ||| affordances of abstract and symbolic mappings between
bodyText ||| information sources and their representations. We see this
bodyText ||| continuing, with new systems focusing on personally relevant
bodyText ||| symbolic representations, and utilizing metaphors from the
bodyText ||| natural and built worlds. Another shift that we foresee is the
bodyText ||| designers creating systems where multiple information sources
bodyText ||| and aspects interact to affect a single part of the representation.
bodyText ||| This is apparent already in Digital Family Portrait where the size
bodyText ||| of the butterflies represents “activity,” even though activity is
bodyText ||| not the reading from a single sensor, but it instead a reading
bodyText ||| from multiple sensors in a home. Informative Art also has
bodyText ||| aspects of this approach, changing both the color and
bodyText ||| dimensions of squares based on two different aspects of weather.
bodyText ||| As regards aesthetic emphasis, we foresee a more radical
bodyText ||| change. We predict further exploration of the space of truly
bodyText ||| artistically motivated ambient information systems. These
bodyText ||| generative artworks use information from the world to drive
bodyText ||| their behavior and ask (and answer) art questions as well as
bodyText ||| technology questions. Though most of these works are outside
bodyText ||| the academy (they are shown in galleries instead of computer
bodyText ||| science conferences), Bolen and Mateas’ Office Plant #1 [4] is a
bodyText ||| sculpture that characterizes the mood of a user’s email stream
bodyText ||| and conveys it via transformations of a robotic plant. These
bodyText ||| systems are going to create a new design space above the top tier
bodyText ||| that we depict in this work.
sectionHeader ||| 7. CONCLUSIONS
bodyText ||| In this work we synthesize a definition that distinguishes
bodyText ||| research in ambient information systems from that of
bodyText ||| notification systems and peripheral displays. We propose four
bodyText ||| design dimensions, rank systems to show clusters, and uncover
bodyText ||| four design patterns on which system developers may model
bodyText ||| their system designs. Future work will expand the four
bodyText ||| dimensions to include aspects of the social interaction and
bodyText ||| impact that system have on the behavior of individuals and
bodyText ||| groups.
bodyText ||| In this work we point toward open areas in the design
bodyText ||| space, and we point to new design directions that may fill these
bodyText ||| gaps. Future work may also turn this taxonomy into an
bodyText ||| evaluation framework for ambient information systems.
page ||| 73
sectionHeader ||| 8. REFERENCES
reference ||| 1. Alexander, C., A Pattern Language: Towns, Buildings,
reference ||| Construction. Oxford University Press, 1977.
reference ||| 2. Ambient Orb. http://www.ambientdevices.com/
reference ||| 3. Apple Mac OS X Dashboard. http://www.apple.com/
reference ||| macosx/features/dashboard/index.htm
reference ||| 4. Bohlen, M., and Mateas, M. Office Plant #1. Leonardo 31:5. pp.
reference ||| 345-349.
reference ||| 5. Chang, A., Resner, B., Koerner B., Wang, X and Ishii, H.,
reference ||| Lumitouch: An emotional communication device. Extended
reference ||| Abstracts of CHI 2001, pp. 371-372.
reference ||| 6. Cadiz, J., Fussell, S., Kraut, R., Lerch, J., and Scherlis, W. The
reference ||| Awareness Monitor: A Coordination Tool for
reference ||| Asynchronous, Distributed Work Teams. Unpublished
reference ||| manuscript. Demonstrated at CSCW 1998.
reference ||| 7. Cadiz, J., Venolia, G., Janke, G., ans Gupta, A. Designing
reference ||| and deploying an information awareness interface.
reference ||| Proceedings of CSCW 2002, pp. 314 - 323.
reference ||| 8. Dahley, A., Wisneski, C., and Ishii, H. Water lamp and
reference ||| pinwheels: Ambient projection of digital information into
reference ||| architectural space. CHI Conference Summary 1998, pp.
reference ||| 269–270.
reference ||| 9. Espinosa, A., Cadiz, J., Rico-Gutierrez L., Kraut, R., Sherlis,
reference ||| W., and Lautenbacher, G. Coming to the Wrong Decision
reference ||| Quickly: Why Awareness Tools Must be Matched with
reference ||| Appropriate Tasks. Proceedings of CHI 2000, pp. 392-399.
reference ||| 10. Fitzpatrick, G., Kaplan, S., Arnold, D., Phelps, T., and
reference ||| Segall, B. Augmenting the Workaday World with Elvin.
reference ||| Proceedings of ECSCW 1999, pp. 431-450.
reference ||| 11. Fogarty, J., Forlizzi, J., and Hudson, S. Aesthetic
reference ||| Information Collages: Generating Decorative Displays that
reference ||| Contain Information. Proceedings of the UIST 2001,
reference ||| pp. 141-150.
reference ||| 12. Gellersen, H.-W., Schmidt, A. and Beigl. M. Ambient Media
reference ||| for Peripheral Information Display. Personal Technologies
reference ||| 3, 4 : 199-208. 1999.
reference ||| 13. Greenberg, S., and Fitchett, C. Phidgets: Easy development
reference ||| of physical interfaces through physical widgets. Proceedings
reference ||| of UIST 2001. pp 209-218.
reference ||| 14. Greenberg, S., and Rounding, M. The Notification Collage:
reference ||| Posting Information to Public and Personal Displays.
reference ||| Proceedings of CHI 2001, pp. 515-521.
reference ||| 15. De Guzman, E., Yau M, Park, A., and Gagliano, A.
reference ||| Exploring the Design and Use of Peripheral Displays of
reference ||| Awareness Information. Extended Abstracts of CHI 2004,
reference ||| pp. 1247-1250.
reference ||| 16. Heiner, J. M., Hudson, S., and Kenichiro, T. The
reference ||| Information Percolator: Ambient information display in a
reference ||| decorative object. In Proc. of UIST 1999, pp. 141-148.
reference ||| 17. Ishii, H.,Wisenski, C., Brave, S., Dahley, A., Gorbet, M.,
reference ||| Ullmer, B., and Yarin, P. AmbientROOM: Integrating
reference ||| Ambient Media with Architectural Space. Summary of CHI
reference ||| 1998, pp. 173-174.
reference ||| 18. Ishii, H., Ren, S., and Frei, P. Pinwheels: visualizing
reference ||| information flow in an architectural space. Extended
reference ||| Abstracts of CHI 2001, pp. 111-112.
reference ||| 19. MacIntyre, B., Mynatt, E., Voida, S., Hansen, K., Tullio, J.,
reference ||| and Corso, G. Support For Multitasking and Background
reference ||| Awareness Using Interactive Peripheral Displays.
reference ||| Proceedings of UIST 2001, pp. 41-50.
reference ||| 20. Mankoff, J., Dey, A., Heish, G., Kientz, J., Lederer, S., and
reference ||| Ames, M. Heuristic evaluation of ambient displays.
reference ||| Proceedings of CHI 2003, pp. 169-176.
reference ||| 21. McCrickard, D. S., Chewar, C., Somervell, J., and
reference ||| Ndiwalana, A. A Model for Notification Systems
reference ||| Evaluation—Assessing User Goals for Multitasking
reference ||| Activity. ACM Transactions on CHI 10,4 : 312 – 338. 2002
reference ||| 22. McCrickard, D.S., Catrambone, R., and Stasko, J. Evaluating
reference ||| animation in the periphery as a mechanism for maintaining
reference ||| awareness. Proceedings of INTERACT 2001, pp. 148-156.
reference ||| 23. Matthews, T., Dey, A.., Mankoff, J., Carter S., and
reference ||| Rattenbury, T. A Toolkit for Managing User Attention in
reference ||| Peripheral Displays. Proceedings of UIST 2004, pp. 247-
reference ||| 256.
reference ||| 24. Matthews ,T., Rattenbury, T., Carter, S., Dey, A., and
reference ||| Mankoff, J. A Peripheral Display Toolkit. Tech Report IRB-
reference ||| TR-03-018. Intel Research Berkeley. 2002.
reference ||| 25. Mynatt, E.D., Back, M., Want, R., and Ellis, J.B. Designing
reference ||| audio aura. Proceedings of CHI 1998, pp. 566-573.
reference ||| 26. Mynatt, E.D., Rowan, J., Jacobs, A., and Craighill, S. Digital
reference ||| Family Portraits: Supporting Peace of Mind for Extended
reference ||| Family Members. Proceedings of CHI 2001, pp. 333-340.
reference ||| 27. My Yahoo!. http://my.yahoo.com/index.html
reference ||| 28. Ogden, C., and Richards I. The Meaning of Meaning.
reference ||| Routledge & Kegan. London, England. 1923.
reference ||| 29. Pederson, E. R., and Sokoler, T. AROMA: Abstract
reference ||| Representation of Presence Supporting Mutual Awareness.
reference ||| Proceedings of CHI 1997, pp.51-58.
reference ||| 30. Redstrom, J., Skog, T., and Hallanas, L. Informative Art:
reference ||| Using Amplified Artworks as Information Displays.
reference ||| Proceedings of DARE 2000, pp. 103-114.
reference ||| 31. Russel, D., Streitz, N., and Winograd, T. Building
reference ||| Disappearing Computers. Communications of the ACM.
reference ||| 48(3):42-48. 2005.
reference ||| 32. Stasko, J., Miller, T., Pousman Z., Plaue, C., and Ullah, O.
reference ||| Personalized Peripheral Information Awareness through
reference ||| Information Art. Proceedings of UbiComp 2004, pp. 18-35.
reference ||| 33. Streitz, N., Tandler, P., Muller-Tomfelde, C., and Konomi,
reference ||| S. Roomware: Towards the Next Generation of Human-
reference ||| Computer Interaction based on an Integrated Design of Real
reference ||| and Virtual Worlds. In: J. Carroll (Ed.): Human-Computer
reference ||| Interaction in the New Millennium, Addison-Wesley. pp.
reference ||| 553-578. 2001.
reference ||| 34. Van Dantzich, M., Robbins, D., Horvitz, E., and Czerwinski,
reference ||| M. Scope: Providing Awareness of Multiple Notifications at
reference ||| a Glance. Proceedings of AVI 2002. pp. 157-166.
reference ||| 35. Weiser, M. and Brown, J.S. Designing Calm Technology.
reference ||| PowerGrid Journal, 1:1, 1996.
reference ||| 36. Zhao, A., and Stasko, J. What's Happening?: Promoting
reference ||| Community Awareness through Opportunistic, Peripheral
reference ||| Interfaces. Proceedings of AVI 2002, pp. 69-74.
page ||| 74

title ||| A Two-Phase Sampling Technique for Information
title ||| Extraction from Hidden Web Databases
author ||| Y.L. Hedley, M. Younas, A. James
affiliation ||| School of Mathematical and Information Sciences
affiliation ||| Coventry University, Coventry CV1 5FB, UK
email ||| {y.hedley, m.younas, a.james}@coventry.ac.uk
email ||| ABSTRACT
bodyText ||| Hidden Web databases maintain a collection of specialised
bodyText ||| documents, which are dynamically generated in response to users’
bodyText ||| queries. However, the documents are generated by Web page
bodyText ||| templates, which contain information that is irrelevant to queries.
bodyText ||| This paper presents a Two-Phase Sampling (2PS) technique that
bodyText ||| detects templates and extracts query-related information from the
bodyText ||| sampled documents of a database. In the first phase, 2PS queries
bodyText ||| databases with terms contained in their search interface pages and
bodyText ||| the subsequently sampled documents. This process retrieves a
bodyText ||| required number of documents. In the second phase, 2PS detects
bodyText ||| Web page templates in the sampled documents in order to extract
bodyText ||| information relevant to queries. We test 2PS on a number of real-
bodyText ||| world Hidden Web databases. Experimental results demonstrate
bodyText ||| that 2PS effectively eliminates irrelevant information contained in
bodyText ||| Web page templates and generates terms and frequencies with
bodyText ||| improved accuracy.
sectionHeader ||| Categories and Subject Descriptors
category ||| H.3.5 [Information Storage and Retrieval]: Online Information
category ||| Services – Web-based services.
sectionHeader ||| General Terms
keyword ||| Algorithms, Experimentation.
sectionHeader ||| Keywords
keyword ||| Hidden Web Databases, Document Sampling, Information
keyword ||| Extraction.
sectionHeader ||| 1. INTRODUCTION
bodyText ||| An increasing number of databases on the Web maintain a
bodyText ||| collection of documents such as archives, user manuals or news
bodyText ||| articles. These databases dynamically generate documents in
bodyText ||| response to users’ queries and are referred to as Hidden Web
bodyText ||| databases [5]. As the number of databases proliferates, it has
bodyText ||| become prohibitive for specialised search services (such as
bodyText ||| search.com) to evaluate databases individually in order to answer
bodyText ||| users’ queries.
bodyText ||| Current techniques such as database selection and categorisation
copyright ||| Permission to make digital or hard copies of all or part of this work for
copyright ||| personal or classroom use is granted without fee provided that copies are
copyright ||| not made or distributed for profit or commercial advantage and that
copyright ||| copies bear this notice and the full citation on the first page. To copy
copyright ||| otherwise, or republish, to post on servers or to redistribute to lists,
copyright ||| requires prior specific permission and/or a fee.
note ||| WIDM’04, November 12–13, 2004, Washington, DC, USA.
copyright ||| Copyright 2004 ACM 1-58113-978-0/04/0011...$5.00.
copyright ||| M. Sanderson
affiliation ||| Department of Information Studies
affiliation ||| University of Sheffield, Sheffield, S1 4DP, UK
email ||| m.sanderson@sheffield.ac.uk
bodyText ||| have been employed to enhance the effectiveness of information
bodyText ||| retrieval from databases [2, 5, 10, 11, 15]. In the domain of the
bodyText ||| Hidden Web, knowledge about the contents of databases is often
bodyText ||| unavailable. Existing approaches such as in [2, 10, 15] acquire
bodyText ||| knowledge through sampling documents from databases. For
bodyText ||| instance, query-based sampling [2] queries databases with terms
bodyText ||| that are randomly selected from those contained in the sampled
bodyText ||| documents. The techniques in [10, 15] sample databases with
bodyText ||| terms obtained from Web logs to retrieve additional topic terms.
bodyText ||| A major issue associated with existing techniques is that they also
bodyText ||| extract information irrelevant to queries. That is, information
bodyText ||| extracted is often found in Web page templates, which contain
bodyText ||| navigation panels, search interfaces and advertisements.
bodyText ||| Consequently, the accuracy of terms and frequencies generated
bodyText ||| from sampled documents has been reduced.
bodyText ||| In addition, approximate string matching techniques are adopted
bodyText ||| by [13] to extract information from Web pages, but this approach
bodyText ||| is limited to textual contents only. Alternatively, the approaches
bodyText ||| proposed in [3, 4] analyse Web pages in tree-like structures.
bodyText ||| However, such an approach requires Web pages with well-
bodyText ||| conformed HTML tag trees. Furthermore, [3] discovers
bodyText ||| dynamically generated objects from Web pages, which are
bodyText ||| clustered into groups of similar structured pages based on a set of
bodyText ||| pre-defined templates, such as exception page templates and
bodyText ||| result page templates.
bodyText ||| In this paper, we propose a sampling and extraction technique,
bodyText ||| which is referred to as Two-Phase Sampling (2PS). 2PS aims to
bodyText ||| extract information relevant to queries in order to acquire
bodyText ||| information contents of underlying databases. Our technique is
bodyText ||| applied in two phases. First, it randomly selects a term from those
bodyText ||| found in the search interface pages of a database to initiate the
bodyText ||| process of sampling documents. Subsequently, 2PS queries the
bodyText ||| database with terms randomly selected from those contained in
bodyText ||| the sampled documents. Second, 2PS detects Web page templates
bodyText ||| and extracts query-related information from which terms and
bodyText ||| frequencies are generated to summarise the database contents.
bodyText ||| Our approach utilises information contained in search interface
bodyText ||| pages of a database to initiate the sampling process. This differs
bodyText ||| from current sampling techniques such as query-based sampling,
bodyText ||| which performs an initial query with a frequently used term.
bodyText ||| Furthermore, 2PS extracts terms that are relevant to queries thus
bodyText ||| generating statistics (i.e., terms and frequencies) that represent
bodyText ||| database contents with improved accuracy. By contrast, the
bodyText ||| approaches in [2, 10, 15] extract all terms from sampled
bodyText ||| documents, including those contained in Web page templates.
bodyText ||| Consequently, information that is irrelevant to queries is also
bodyText ||| extracted.
page ||| 1
figureCaption ||| Figure 1. The Two-Phase Sampling (2PS) technique.
bodyText ||| 2PS is implemented as a prototype system and tested on a number
bodyText ||| of real-world Hidden Web databases, which contain computer
bodyText ||| manuals, healthcare archives and news articles. Experimental
bodyText ||| results show that our technique effectively detects Web page
bodyText ||| templates and generates terms and frequencies (from sampled
bodyText ||| documents) that are relevant to the queries.
bodyText ||| The remainder of the paper is organised as follows. Section 2
bodyText ||| introduces current approaches to the discovery of information
bodyText ||| contents of Hidden Web databases. Related work on the
bodyText ||| information extraction from Web pages or dynamically generated
bodyText ||| documents is also discussed. Section 3 describes the proposed
bodyText ||| 2PS technique. Section 4 presents experimental results. Section 5
bodyText ||| concludes the paper.
sectionHeader ||| 2. RELATED WORK
bodyText ||| A major area of current research into the information retrieval of
bodyText ||| Hidden Web databases focuses on the automatic discovery of
bodyText ||| information contents of databases, in order to facilitate their
bodyText ||| selection or categorisation. For instance, the technique proposed
bodyText ||| in [6] analyses the hyperlink structures of databases in order to
bodyText ||| facilitate the search for databases that are similar in content. The
bodyText ||| approach adopted by [10, 15] examines the textual contents of
bodyText ||| search interface pages maintained by data sources to gather
bodyText ||| information about database contents.
bodyText ||| A different approach is to retrieve actual documents to acquire
bodyText ||| such information. However, in the domain of Hidden Web
bodyText ||| databases, it is difficult to obtain all documents from a database.
bodyText ||| Therefore, a number of research studies [2, 10, 15] obtain
bodyText ||| information by retrieving a set of documents through sampling.
bodyText ||| For instance, query-based sampling [2] queries databases with
bodyText ||| terms that are randomly selected from those contained in the
bodyText ||| sampled documents. The techniques in [10, 15] sample databases
bodyText ||| with terms extracted from Web logs to obtain additional topic
bodyText ||| terms. These techniques generate terms and frequencies from
bodyText ||| sampled documents, which are referred to as Language Models
bodyText ||| [2], Textual Models [10, 15] or Centroids [11].
bodyText ||| A key issue associated with the aforementioned sampling
bodyText ||| techniques is that they extract information that is often irrelevant
bodyText ||| to queries, since information contained in Web page templates
bodyText ||| such as navigation panels, search interfaces and advertisements is
bodyText ||| also extracted. For example, a language model generated from the
bodyText ||| sampled documents of the Combined Health Information
bodyText ||| Database (CHID) contains terms (such as ‘author’ and ‘format’)
bodyText ||| with high frequencies. These terms are not relevant to queries but
bodyText ||| are used for descriptive purposes. Consequently, the accuracy of
bodyText ||| terms and frequencies generated from sampled documents has
bodyText ||| been reduced. The use of additional stop-word lists has been
bodyText ||| considered in [2] to eliminate irrelevant terms - but it is
bodyText ||| maintained that such a technique can be difficult to apply in
bodyText ||| practice.
bodyText ||| Existing techniques in information extraction from Web pages are
bodyText ||| of varying degrees of complexity. For instance, approximate
bodyText ||| string matching techniques are adopted by [13] to extract texts
bodyText ||| that are different. This approach is limited to finding textual
bodyText ||| similarities and differences. The approaches proposed in [3, 4]
bodyText ||| analyse textual contents and tag structures in order to extract data
bodyText ||| from Web pages. However, such an approach requires Web pages
bodyText ||| that are produced with well-conformed HTML tag-trees.
bodyText ||| Computation is also needed to convert and analyse Web pages in
bodyText ||| a tree-like structure. Moreover, [3] identifies Web page templates
bodyText ||| based on a number of pre-defined templates, such as exception
bodyText ||| page templates and result page templates.
bodyText ||| Our technique examines Web documents based on textual
bodyText ||| contents and the neighbouring tag structures rather than analysing
bodyText ||| their contents in a tree-like structure. We also detect information
bodyText ||| contained in different templates through which documents are
bodyText ||| generated. Therefore, it is not restricted to a pre-defined set of
bodyText ||| page templates.
bodyText ||| Furthermore, we focus on databases that contain documents such
bodyText ||| as archives and new articles. A distinct characteristic of
bodyText ||| documents found in such a domain is that the content of a
bodyText ||| document is often accompanied by other information for
bodyText ||| supplementary or navigation purposes. The proposed 2PS
bodyText ||| technique detects and eliminates information contained in
bodyText ||| templates in order to extract the content of a document. This
bodyText ||| differs from the approaches in [1, 4], which attempt to extract a
bodyText ||| set of data from Web pages presented in a particular pattern. For
bodyText ||| example, the Web pages of a bookstore Web site contain
bodyText ||| information about authors followed by their associated list of
bodyText ||| publications. However, in the domain of document databases,
bodyText ||| information contained in dynamically generated Web pages is
bodyText ||| often presented in a structured fashion but irrelevant to queries.
bodyText ||| Other research studies [9, 8, 12] are specifically associated with
bodyText ||| the extraction of data from query forms in order to further the
bodyText ||| retrieval of information from the underlying databases.
sectionHeader ||| 3. TWO-PHASE SAMPLING
bodyText ||| This section presents the proposed technique for extracting
bodyText ||| information from Hidden Web document databases in two phases,
bodyText ||| which we refer to as Two-Phase Sampling (2PS). Figure 1 depicts
bodyText ||| the process of sampling a database and extracting query-related
page ||| 2
bodyText ||| information from the sampled documents. In phase one, 2PS
bodyText ||| obtains randomly sampled documents. In phase two, it detects
bodyText ||| Web page templates. This extracts information relevant to the
bodyText ||| queries and then generates terms and frequencies to summarise
bodyText ||| the database content. The two phases are detailed in section 3.1
bodyText ||| and 3.2.
subsectionHeader ||| 3.1 Phase One: Document Sampling
bodyText ||| In the first phase we initiate the process of sampling documents
bodyText ||| from a database with a randomly selected term from those
bodyText ||| contained in the search interface pages of the database. This
bodyText ||| retrieves top N documents where N represents the number of
bodyText ||| documents that are the most relevant to the query. A subsequent
bodyText ||| query term is then randomly selected from terms extracted from
bodyText ||| the sampled documents. This process is repeated until a required
bodyText ||| number of documents are sampled. The sampled documents are
bodyText ||| stored locally for further analysis.
bodyText ||| Figure 2 illustrates the algorithm that obtains a number of
bodyText ||| randomly sampled documents. tq denotes a term extracted from
bodyText ||| the search interface pages of a database, D. qtp represents a query
bodyText ||| term selected from a collection of terms, Q, qtp e Q, 1 <_ p <_ m;
bodyText ||| where m is the distinct number of terms extracted from the search
bodyText ||| interface pages and the documents that have been sampled. R
bodyText ||| represents the set of documents randomly sampled from D. tr is a
bodyText ||| term extracted from di. di represents a sampled document from D,
bodyText ||| di e D, 1 <_ i <_ n, where n is the number of document to sample.
figure ||| Algorithm SampleDocument
figure ||| Extract tq from search interface pages of D, Q = tq
figure ||| For i = 1 to n
figure ||| Randomly select qtp from Q
figure ||| If (qtp has not been selected previously)
figure ||| Execute the query with qtp on D
figure ||| j = 0
figure ||| While j <= N
figure ||| If (di o R)
figure ||| Retrieve di from D
figure ||| Extract tr from di,
figure ||| R = di
figure ||| Q = tr
figure ||| Increase j by 1
figure ||| End if
figure ||| End while
figure ||| End if
figure ||| End for
figureCaption ||| Figure 2. The algorithm for sampling documents from a
figureCaption ||| database.
bodyText ||| 2PS differs from query-based sampling in terms of selecting an
bodyText ||| initial query. The latter selects an initial term from a list of
bodyText ||| frequently used terms. 2PS initiates the sampling process with a
bodyText ||| term randomly selected from those contained in the search
bodyText ||| interface pages of the database. This utilises a source of
bodyText ||| information that is closely related to its content. Moreover, 2PS
bodyText ||| analyses the sampled documents in the second phase in order to
bodyText ||| extract query-related information. By contrast, query-based
bodyText ||| sampling does not analyse their contents to determine whether
bodyText ||| terms are relevant to queries.
subsectionHeader ||| 3.2 Phase Two: Document Content Extraction
subsectionHeader ||| and Summarisation
bodyText ||| The documents sampled from the first phase are further analysed
bodyText ||| in order to extract information relevant to the queries. This is then
bodyText ||| followed by the generation of terms and frequencies to represent
bodyText ||| the content of the underlying database. This phase is carried out
bodyText ||| through the following processes.
subsubsectionHeader ||| 3.2.1 Generate Document Content Representations
bodyText ||| The content of each sampled document is converted into a list of
bodyText ||| text and tag segments. Tag segments include start tags, end tags
bodyText ||| and single tags specified in HyperText Markup Language
bodyText ||| (HTML). Text segments are text that resides between two tag
bodyText ||| segments. The document content is then represented by text
bodyText ||| segments and their neighbouring tag segments, which we refer to
bodyText ||| as Text with Neighbouring Adjacent Tag Segments (TNATS). The
bodyText ||| neighbouring adjacent tag segments of a text segment are defined
bodyText ||| as the list of tag segments that are located immediately before and
bodyText ||| after the text segment until another text segment is reached. The
bodyText ||| neighbouring tag segments of a text segment describe how the
bodyText ||| text segment is structured and its relation to the nearest text
bodyText ||| segments. Assume that a document contains n segments, a text
bodyText ||| segment, txs, is defined as: txs = (txi, tg-lstj, tg-lstk), where txi is
bodyText ||| the textual content of the ith text segment, 1 <_ i <_ n; tg-lstj
bodyText ||| represents p tag segments located before txi and tg-lstk represents
bodyText ||| q tag segments located after txi until another text segment is
equation ||| reached. tg-lstj = (tg1, ..., tgp), 1 <_ j <_ p and tg-lstk = (tg1, ..., tgq),
equation ||| 1 <_ k <_ q.
figureCaption ||| Figure 3. A template-generated document from CHID.
bodyText ||| Figure 3 shows a template-generated document retrieved from the
bodyText ||| CHID database. The source code for this document is given in
bodyText ||| Figure 4. For example, text segment, ‘1. Equipos Mas Seguros:
bodyText ||| Si Te Inyectas Drogas.’, can be identified by the text (i.e., ‘1.
bodyText ||| Equipos Mas Seguros: Si Te Inyectas Drogas.’) and its
bodyText ||| neighbouring tag segments. These include the list of tags located
bodyText ||| before the text (i.e., </TITLE>, </HEAD>, <BODY>, <HR>,
bodyText ||| <H3>, <B> and <I>) and the neighbouring tags located after the
bodyText ||| text (i.e., </I>, </B>, </H3>, <I> and <B>). Thus, this segment is
bodyText ||| then represented as (‘1. Equipos Mas Seguros: Si Te Inyectas
bodyText ||| Drogas.’, (</TITLE>, </HEAD>, <BODY>, <HR>, <H3>, <B>
bodyText ||| ,<I>), (</I>, </B>, </H3>, <I>, <B>)). Figure 5 shows the content
page ||| 3
bodyText ||| representation of the CHID document (given in Figure 3)
bodyText ||| generated based on TNATS. Given a sampled document, d, with n
bodyText ||| text segments, the content of d is then represented as: Content(d)
bodyText ||| = {txs1, ..., txsn}, where txsi represents a text segment, 1 <_ i <_ n.
figureCaption ||| Figure 4. The source code for the CHID document.
figureCaption ||| Figure 5. The content representation of the CHID document
figureCaption ||| using TNATS.
subsubsectionHeader ||| 3.2.2 Detect Templates
bodyText ||| In the domain of Hidden Web databases, documents are often
bodyText ||| presented to users through one or more templates. Templates are
bodyText ||| typically employed in order to describe document contents or to
bodyText ||| assist users in navigation. For example, information contained in
bodyText ||| the document (as shown in Figure 3) can be classified into the two
bodyText ||| following categories:
listItem ||| (i) Template-Generated Information. This includes information
listItem ||| such as navigation panels, search interfaces and
listItem ||| advertisements. In addition, information may be given to
listItem ||| describe the content of a document. Such information is
listItem ||| irrelevant to a user’s query. For example, navigation links
listItem ||| (such as ‘Next Doc’ and ‘Last Doc’) and headings (such
listItem ||| ‘Subfile’ and ‘Format’) are found in the document.
listItem ||| (ii) Query-Related Information. This information is retrieved in
listItem ||| response to a user’s query, i.e., ‘1. Equipos Mas Seguros:
listItem ||| Si Te Inyectas Drogas. ...’.
bodyText ||| The 2PS technique detects Web page templates employed by
bodyText ||| databases to generate documents in order to extract information
bodyText ||| that is relevant to queries. Figure 6 describes the algorithm that
bodyText ||| detects information contained in Web page templates from n
bodyText ||| sampled documents. di represents a sampled document from the
bodyText ||| database D, di, e D, 1 <_ i <_ n. Content(di) denotes the content
bodyText ||| representation of di.
figure ||| Algorithm DetectTemplate
figure ||| For i = 1 to n
figure ||| If T = 0
figure ||| If S = 0
figure ||| S = di
figure ||| Else if S ;t� 0
figure ||| While l <= s AND T = 0
figure ||| Compare (Content(di),Content(dl))
figure ||| If Content(di) = Content(dl)
figure ||| wptk = Content(di) n Content(dl),
figure ||| Store wptk, T = wptk
figure ||| Delete (Content(di) n Content(dl)) from
figure ||| Content(di), Content(dl)
figure ||| Gk = di, Gk = dl
figure ||| Delete dl from S
figure ||| End if
figure ||| End while
figure ||| If T = 0
figure ||| S = di
figure ||| End if
figure ||| End if
figure ||| Else if T ;t� 0
figure ||| While k <= r AND di o Gk
figure ||| Compare (Content(wptk), Content(di))
figure ||| If Content(wptk) = Content(di)
figure ||| Delete (Content(wptk) n Content(di)) from
figure ||| Content(di)
figure ||| Gk = di
figure ||| End if
figure ||| End while
figure ||| If S ;t� 0 AND di o Gk
figure ||| While l <= s AND di o Gk
figure ||| Compare (Content(di),Content(dl))
figure ||| If Content(di) = Content(dl)
figure ||| wptk = Content(di) n Content(dl)
figure ||| Store wptk, T = wptk
figure ||| Delete (Content(di) n Content(dl)) from
figure ||| Content(di), Content(dl)
figure ||| Gk = di, Gk = dl
figure ||| Delete dl from S
figure ||| End if
figure ||| End while
figure ||| End if
figure ||| If di o Gk
figure ||| S = di
figure ||| End if
figure ||| End if
figure ||| End for
figureCaption ||| Figure 6. The algorithm for detecting and eliminating the
figureCaption ||| information contained in Web page templates.
figure ||| ...
figure ||| <HTML><HEAD><TITLE>CHID Document
figure ||| </TITLE></HEAD>
figure ||| <BODY>
figure ||| <HR><H3><B><I> 1. Equipos Mas Seguros: Si Te Inyectas
figure ||| Drogas.
figure ||| </I></B></H3>
figure ||| <I><B>Subfile: </B></I>
figure ||| AIDS Education<BR>
figure ||| <I><B>Format (FM): </B></I>
figure ||| 08 - Brochure.
figure ||| <BR>
figure ||| ...
figure ||| ...
figure ||| ‘CHID Document’, (<HTML>, <HEAD>, <TITLE>),
figure ||| (</TITLE>, </HEAD>, <BODY>, <HR>, <H3>, <B>,
figure ||| <I>);
figure ||| ‘1. Equipos Mas Seguros: Si Te Inyectas Drogas.’,
figure ||| (</TITLE>, </HEAD>, <BODY>, <HR>, <H3>, <B>,
figure ||| <I>), (</I>, </B>, </H3>, <I>, <B>);
figure ||| ‘Subfile:’, (</I>, </B>, </H3>, <I>, <B>), (</B>, </I>);
figure ||| ‘AIDS Education’, (</B>, </I>), (<BR>, <I>, <B>);
figure ||| ‘Format (FM):’, (<BR>, <I>, <B>), (</B>, </I>);
figure ||| ...
page ||| 4
bodyText ||| Similar to the representation for the contents of sampled
bodyText ||| documents, the content of a Web page template, wpt, is
bodyText ||| represented as Content(wpt) = {txs1, ..., txsq}, where q is the
bodyText ||| number of text segments, txsj, 1 ≤ j ≤ q. T represents a set of
bodyText ||| templates detected. T = {wpt1, ..., wptr}, where r is the distinct
bodyText ||| number of templates, wptk, 1 ≤ k ≤ r. Gk represents a group of
bodyText ||| documents generated from wptk. Furthermore, S represents the
bodyText ||| sampled documents from which no templates have yet been
bodyText ||| detected. Thus, S = {d1, ..., ds}, where s is the number of
bodyText ||| temporarily stored document, dl, 1 ≤ l ≤ s.
bodyText ||| The process of detecting templates is executed until all sampled
bodyText ||| documents are analysed. This results in the identification of one
bodyText ||| or more templates. For each template, two or more documents are
bodyText ||| assigned to a group associated with the template from which the
bodyText ||| documents are generated. Each document contains text segments
bodyText ||| that are not found in their respective template. These text
bodyText ||| segments are partially related to their queries. In addition to a set
bodyText ||| of templates, the content representations of zero or more
bodyText ||| documents in which no matched patterns are found are stored.
subsubsectionHeader ||| 3.2.3 Extract Query-Related Information
bodyText ||| This process analyses a group of documents associated with each
bodyText ||| template from which documents are generated. It further identifies
bodyText ||| any repeated patterns from the remaining text segments of the
bodyText ||| documents in order to extract query-related information.
bodyText ||| We compute cosine similarity [14] given in (1) to determine the
bodyText ||| similarities between the text segments of different documents that
bodyText ||| are associated the template where the documents are generated.
bodyText ||| The textual content of each text segment is represented as a vector
bodyText ||| of terms with weights. The weight of a term is obtained by its
bodyText ||| occurrence in the segment.
bodyText ||| from the document content (given in Figure 4) as a result of
bodyText ||| eliminating information contained in the Web page template.
subsubsectionHeader ||| 3.2.4 Generate Content Summary
bodyText ||| Frequencies are computed for the terms extracted from randomly
bodyText ||| sampled documents. These summarise the information content of
bodyText ||| a database, which we refer to as Content Summary.
figure ||| Algorithm ExtractQueryInfo
figure ||| For each (da ∈ Gk)
figure ||| For each (db ∈ Gk), da ≠ db
figure ||| Compare (Content(da),Content(db))
figure ||| If Content(da) = Content(db)
figure ||| Delete (Content(da) ∩ Content(db)) from
figure ||| Content(da), Content(db)
figure ||| End if
figure ||| End for
figure ||| End for
figure ||| For each (di ∈ Gk)
figure ||| Extract txm of txsm from Content(di)
figure ||| End for
figure ||| For each (dl ∈ S)
figure ||| Extract txn of txsn from Content(dl)
figure ||| End for
figureCaption ||| Figure 7. The algorithm for extracting query-related
figureCaption ||| information from template-generated documents.
figure ||| 1. Equipos Mas Seguros: Si Te Inyectas Drogas.
figure ||| AIDS Education
figure ||| ...
equation ||| t
equation ||| (	,	)	(	)	(	) 2	(	)
equation ||| txs txs	tw tw	tw	tw
equation ||| i	j	ik	jk	ik
equation ||| =	∗	∗
equation ||| ∑	∑	∑ jk
equation ||| k=1	k=1
figureCaption ||| (1)	Figure 8. The query-related information extracted from the
figureCaption ||| CHID document.
equation ||| COSINE
equation ||| t
equation ||| t
equation ||| 1
equation ||| =
equation ||| k
equation ||| 2
equation ||| .
bodyText ||| where txsi and txsj represent two text segments in a document; twik
bodyText ||| is the weight of term k in txsi, and twjk is the weight of term k in
bodyText ||| txsj . This is only applied to text segments with identical adjacent
bodyText ||| tag segments. Two segments are considered to be similar if their
bodyText ||| similarity exceeds a threshold value. The threshold value is
bodyText ||| determined experimentally.
bodyText ||| The algorithm that extracts information relevant to queries is
bodyText ||| illustrated in Figure 7. da and db represent the sampled documents
bodyText ||| from the database, D, da, db ∈ Gk, where Gk denotes a group of
bodyText ||| documents associated with the template, wptk, from which the
bodyText ||| documents are generated. txm represents the textual content of a
bodyText ||| text segment, txsm, contained in di, di ∈ Gk. txn represents the
bodyText ||| textual content of a text segment, txsn, contained in dl, dl ∈ S. S
bodyText ||| represents the sampled documents from which no templates are
bodyText ||| detected.
bodyText ||| The results of the above algorithm extract text segments with
bodyText ||| different tag structures. It also extracts text segments that have
bodyText ||| identical adjacent tag structures but are significantly different in
bodyText ||| their textual contents. Figure 8 shows the information extracted
bodyText ||| Previous experiments in [2] demonstrate that a number of
bodyText ||| randomly sampled documents (i.e., 300 documents) sufficiently
bodyText ||| represent the information content of a database.
bodyText ||| In the domain of Hidden Web databases, the inverse document
bodyText ||| frequency (idf), used in traditional information retrieval, is not
bodyText ||| applicable, since the total number of documents in a database is
bodyText ||| often unknown. Therefore, document frequency (df), collection
bodyText ||| term frequency (ctf) and average term frequency (avg_tf) initially
bodyText ||| used in [2] are applied in this paper. We consider the following
bodyText ||| frequencies to compute the content summary of a Hidden Web
bodyText ||| database.
listItem ||| •	Document frequency (df): the number of documents in the
bodyText ||| collection of documents sampled that contain term t,
bodyText ||| where d is the document and f is the frequency
listItem ||| •	Collection term frequency (ctf): the occurrence of a term
bodyText ||| in the collection of documents sampled, where c is the
bodyText ||| collection, t is the term and f is the frequency
listItem ||| •	Average term frequency (avg_tf): the average frequency
bodyText ||| of a term obtained from dividing collection term
bodyText ||| frequency by document frequency (i.e., avg_tf = ctf / df)
page ||| 5
tableCaption ||| Table 1. 3 Hidden Web databases used in the experiments
table ||| Database	URL	Subject	Content	Template
table ||| Help Site	www.help-site.com	Computer manuals	Homogeneous	Multiple templates
table ||| CHID	www.chid.nih.gov	Healthcare articles	Homogeneous	Single template
table ||| Wired News	www.wired.com	General news articles	Heterogeneous	Single template
bodyText ||| The content summary of a document database is defined as
bodyText ||| follows. Assume that a Hidden Web database, D, is sampled with
bodyText ||| N documents. Each sampled document, d, is represented as a
bodyText ||| vector of terms and their associated weights [14]. Thus d = (w1,
bodyText ||| ..., wm), where wi is the weight of term ti, and m is the number of
bodyText ||| distinct terms in d e D, 1 <_ i ≤ m. Each wi is computed using term
bodyText ||| frequency metric, avg_tf (i. e., wi = ctfi/dfi). The content summary
bodyText ||| is then denoted as CS(D), which is generated from the vectors of
bodyText ||| sampled documents. Assume that n is the number of distinct terms
bodyText ||| in all sampled documents. CS(D) is, therefore, expressed as a
bodyText ||| vector of terms: CS(D)= {w1, ..., wn}, where wi is computed by
bodyText ||| adding the weights of ti in the documents sampled from D and
bodyText ||| dividing the sum by the number of sampled documents that
bodyText ||| contain ti, 1 <_ i ≤ n.
sectionHeader ||| 4. EXPERIMENTAL RESULTS
bodyText ||| This section reports on a number of experiments conducted to
bodyText ||| assess the effectiveness of the 2PS technique in terms of: (i)
bodyText ||| detecting Web page templates, and (ii) extracting relevant
bodyText ||| information from the documents of a Hidden Web databases
bodyText ||| through sampling. The experimental results are compared with
bodyText ||| those from query-based sampling (abbreviated as QS). We
bodyText ||| compare 2PS with QS as it is a well-established technique and has
bodyText ||| also been widely adopted by other relevant studies [5, 10, 11, 15].
bodyText ||| Experiments are carried out on three real-world Hidden Web
bodyText ||| document databases including Help Site, CHID and Wired News,
bodyText ||| which provide information about user manuals, healthcare
bodyText ||| archives and news articles, respectively. Table 1 summarises
bodyText ||| these databases in terms of their subjects, contents and templates
bodyText ||| employed. For instance, Help Site and CHID contain documents
bodyText ||| relating to subjects on computing and healthcare, respectively.
bodyText ||| Their information contents are homogeneous in nature. By
bodyText ||| contrast, Wired News contains articles that relate to different
bodyText ||| subjects of interest.
bodyText ||| Where the number of templates is concerned, CHID and Wired
bodyText ||| News generate documents from one Web page template. Help
bodyText ||| Site maintains a collection of documents produced by other
bodyText ||| information sources. Subsequently, different Web page templates
bodyText ||| are found in Help Site sampled documents.
bodyText ||| The experiment conducted using QS initiates the first query to a
bodyText ||| database with a frequently used term to obtain a set of sampled
bodyText ||| documents. Subsequent query terms are randomly selected from
bodyText ||| those contained in the sampled documents. It extracts terms
bodyText ||| (including terms contained in Web page templates) and updates
bodyText ||| the frequencies after each document is sampled. By contrast, 2PS
bodyText ||| initiates the sampling process with a term contained in the search
bodyText ||| interface pages of a database. In addition, 2PS analyses the
bodyText ||| sampled documents in the second phase in order to extract query-
bodyText ||| related information, from which terms and frequencies are
bodyText ||| generated.
bodyText ||| Experimental results in [2] conclude that QS obtains
bodyText ||| approximately 80% of terms from a database, when 300
bodyText ||| documents are sampled and top 4 documents are retrieved for
bodyText ||| each query. These two parameters are used to obtain results for
bodyText ||| our experiments in which terms and frequencies are generated for
bodyText ||| QS and 2PS after 300 documents have been sampled. The results
bodyText ||| generated from QS provide the baseline for the experiments.
bodyText ||| Three sets of samples are obtained for each database and 300
bodyText ||| documents are retrieved for each sample. First, we manually
bodyText ||| examine each set of sampled documents to obtain the number of
bodyText ||| Web page templates used to generate the documents. This is then
bodyText ||| compared with the number of templates detected by 2PS. The
bodyText ||| detection of Web page templates from the sampled documents is
bodyText ||| important as this determines whether irrelevant information is
bodyText ||| effectively eliminated.
bodyText ||| Next, we compare the number of relevant terms (from top 50
bodyText ||| terms) retrieved using 2PS with the number obtained by QS.
bodyText ||| Terms are ranked according to their ctf frequencies to determine
bodyText ||| their relevancy to the queries. This frequency represents the
bodyText ||| occurrences of a term contained in the sampled documents. Ctf
bodyText ||| frequencies are used to demonstrate the effectiveness of
bodyText ||| extracting query-related information from sampled documents
bodyText ||| since the terms extracted from Web page templates are often
bodyText ||| ranked with high ctf frequencies.
tableCaption ||| Table 2. The number of templates employed by databases and
table ||| the number detected by 2PS
table ||| Databases		Number of templates
table ||| 		Employed	Detected
table ||| Help Site	Sample 1	17	15
table ||| 	Sample 2	17	16
table ||| 	Sample 3	19	17
table ||| CHID	Sample 1	1	1
table ||| 	Sample 2	1	1
table ||| 	Sample 3	1	1
table ||| Wired News	Sample 1	1	1
table ||| 	Sample 2	1	1
table ||| 	Sample 3	1	1
bodyText ||| Experimental results for QS and 2PS are summarised as follows.
bodyText ||| Firstly, Table 2 gives the number of Web page templates
bodyText ||| employed by the databases and the number detected by 2PS. It
bodyText ||| shows that 2PS effectively identifies the number of templates
bodyText ||| found in the sampled documents. However, a small number of
bodyText ||| templates are not detected from Help Site. For instance, 2PS does
bodyText ||| not detect two of the templates from the first set of sampled
bodyText ||| documents, since the two templates are very similar in terms of
bodyText ||| content and structure.
page ||| 6
bodyText ||| Table 3 summarises the number of relevant terms (from top 50
bodyText ||| terms ranked according to their ctf frequencies) obtained for the
bodyText ||| three databases. These terms are retrieved using 2PS and QS. We
bodyText ||| determine the relevancy of a term by examining whether the term
bodyText ||| is found in Web page templates. Table 3 gives the number of
bodyText ||| retrieved terms that do not appear in Web page templates. The
bodyText ||| results show that 2PS obtains more relevant terms. For instance,
bodyText ||| in the first set of documents sampled from CHID using 2PS, the
bodyText ||| number of relevant terms retrieved is 47. By comparison, the
bodyText ||| number of terms obtained for QS is 20.
bodyText ||| The results generated from CHID and Wired News demonstrate
bodyText ||| that 2PS retrieves more relevant terms, as a large number of terms
bodyText ||| contained in the templates have been successfully eliminated from
bodyText ||| the top 50 terms. However, the elimination of template terms is
bodyText ||| less noticeable for Help Site. Our observation is that template
bodyText ||| terms attain high frequencies since the CHID and Wired News
bodyText ||| databases generate documents using a single Web page template.
bodyText ||| By comparison, a larger number of Web page templates are found
bodyText ||| in the documents sampled from Help Site. As a result, terms
bodyText ||| contained in the templates do not attain high frequencies as those
bodyText ||| found in the templates employed by CHID and Wired News.
bodyText ||| Table 4 and 5 show the results of the top 50 terms ranked
bodyText ||| according to their ctf frequencies retrieved from the first set of
bodyText ||| sampled documents of the CHID database. Table 4 shows the top
bodyText ||| 50 terms retrieved for QS whereby terms contained in Web page
bodyText ||| templates are not excluded. As a result, a number of terms (such
bodyText ||| as ‘author’, ‘language’ and ‘format’) have attained much higher
bodyText ||| frequencies. By contrast, Table 5 lists the top 50 terms retrieved
bodyText ||| using 2PS. Our technique eliminates terms (such as ‘author’ and
bodyText ||| ‘format’) and obtains terms (such as ‘treatment’, ‘disease’ and
bodyText ||| ‘immunodeficiency’) in the higher rank.
tableCaption ||| Table 3. The number of relevant terms retrieved (from top 50
tableCaption ||| terms) according to ctf frequencies
table ||| Databases		Number of relevant terms
table ||| 		QS	2PS
table ||| Help Site	Sample 1	46	48
table ||| 	Sample 2	47	48
table ||| 	Sample 3	46	48
table ||| CHID	Sample 1	20	47
table ||| 	Sample 2	19	47
table ||| 	Sample 3	20	47
table ||| Wired News	Sample 1	14	42
table ||| 	Sample 2	10	43
table ||| 	Sample 3	11	39
sectionHeader ||| 5. CONCLUSION
bodyText ||| This paper presents a sampling and extraction technique, 2PS,
bodyText ||| which utilises information that is contained in the search interface
bodyText ||| pages and documents of a database in the sampling process. This
bodyText ||| technique extracts information relevant to queries from the
bodyText ||| sampled documents in order to generate terms and frequencies
bodyText ||| with improved accuracy. Experimental results demonstrate that
bodyText ||| our technique effectively eliminates information contained in
bodyText ||| Web page templates, thus attaining terms and frequencies that are
bodyText ||| of a higher degree of relevancy. This can also enhance the
bodyText ||| effectiveness of categorisation in which such statistics are used to
bodyText ||| represent the information contents of underlying databases.
bodyText ||| We obtain promising results by applying 2PS in the experiments
bodyText ||| on three databases that differ in nature. However, experiments on
bodyText ||| a larger number of Hidden Web databases are required in order to
bodyText ||| further assess the effectiveness of the proposed technique.
tableCaption ||| Table 4. Top 50 terms and frequencies ranked according to ctf generated from CHID when QS is applied
table ||| Rank	Term	Rank	Term	Rank	Term
table ||| 1	hiv	18	document	35	lg
table ||| 2	aids	19	disease	36	ve
table ||| 3	information	20	published	37	yr
table ||| 4	health	21	physical	38	ac
table ||| 5	prevention	22	subfile	39	corporate
table ||| 6	education	23	audience	40	mj
table ||| 7	tb	24	update	41	description
table ||| 8	accession	25	verification	42	www
table ||| 9	number	26	major	43	cn
table ||| 10	author	27	pamphlet	44	pd
table ||| 11	persons	28	chid	45	english
table ||| 12	language	29	human	46	national
table ||| 13	sheet	30	date	47	public
table ||| 14	format	31	abstract	48	immunodeficiency
table ||| 15	treatment	32	code	49	virus
table ||| 16	descriptors	33	ab	50	org
table ||| 17	availability	34	fm
page ||| 7
tableCaption ||| Table 5. Top 50 terms and frequencies ranked according to ctf generated from CHID when 2PS is applied
table ||| Rank	Term	Rank	Term	Rank	Term
table ||| 1	hiv	18	education	35	testing
table ||| 2	aids	19	virus	36	programs
table ||| 3	information	20	org	37	services
table ||| 4	health	21	notes	38	clinical
table ||| 5	prevention	22	nt	39	people
table ||| 6	tb	23	cdc	40	hepatitis
table ||| 7	persons	24	service	41	community
table ||| 8	sheet	25	box	42	world
table ||| 9	treatment	26	research	43	listed
table ||| 10	disease	27	department	44	professionals
table ||| 11	human	28	positive	45	training
table ||| 12	pamphlet	29	tuberculosis	46	diseases
table ||| 13	www	30	control	47	accession
table ||| 14	http	31	drug	48	network
table ||| 15	national	32	discusses	49	general
table ||| 16	public	33	ill	50	std
table ||| 17	immunodeficiency	34	organizations
sectionHeader ||| 6. REFERENCES
reference ||| [1] Arasu, A. and Garcia-Molina, H. Extracting Structured Data
reference ||| from Web Pages. In Proceedings of the 2003 ACM SIGMOD
reference ||| International Conference on Management, 2003, 337-348.
reference ||| [2] Callan, J. and Connell, M. Query-Based Sampling of Text
reference ||| Databases. ACM Transactions on Information Systems
reference ||| (TOIS), Vol. 19, No. 2, 2001, 97-130.
reference ||| [3] Caverlee, J., Buttler, D. and Liu, L. Discovering Objects in
reference ||| Dynamically-Generated Web Pages. Technical report,
reference ||| Georgia Institute of Technology, 2003.
reference ||| [4] Crescenzi, V., Mecca, G. and Merialdo, P. ROADRUNNER:
reference ||| Towards Automatic Data Extraction from Large Web Sites,
reference ||| In Proceedings of the 27th International Conference on Very
reference ||| Large Data Bases (VLDB), 2001, 109-118.
reference ||| [5] Gravano, L., Ipeirotis, P. G. and Sahami, M. QProber: A
reference ||| System for Automatic Classification of Hidden-Web
reference ||| Databases. ACM Transactions on Information Systems
reference ||| (TOIS), Vol. 21, No. 1, 2003.
reference ||| [6] Heß, M. and Drobnik, O. Clustering Specialised Web-
reference ||| databases by Exploiting Hyperlinks. In Proceedings of the
reference ||| Second Asian Digital Library Conference, 1999.
reference ||| [7] Hedley, Y.L., Younas, M., James, A. and Sanderson M.
reference ||| Query-Related Data Extraction of Hidden Web Documents.
reference ||| In Proceedings of the 27th Annual International ACM SIGIR
reference ||| Conference, 2004, 558-559.
reference ||| [8] Lage, J. P., da Silva, A. S., Golgher, P. B. and Laender, A.
reference ||| H. F. Automatic Generation of Agents for Collecting Hidden
reference ||| Web Pages for Data Extraction. Data & Knowledge
reference ||| Engineering, Vol. 49, No. 2, 2004, 177-196.
reference ||| [9] Liddle, S.W., Yau, S.H. and Embley, D. W. On the
reference ||| Automatic Extraction of Data from the Hidden Web. In
reference ||| Proceedings of the 20th International Conference on
reference ||| Conceptual Modeling, (ER) Workshops, 2001, 212-226.
reference ||| [ 10] Lin, K.I. and Chen, H. Automatic Information Discovery
reference ||| from the Invisible Web. International Conference on
reference ||| Information Technology: Coding and Computing (ITCC),
reference ||| 2002, 332-337.
reference ||| [ 11 ] Meng, W., Wang, W., Sun, H. and Yu, C. Concept
reference ||| Hierarchy Based Text Database Categorization.
reference ||| International Journal on Knowledge and Information
reference ||| Systems, Vol. 4, No. 2, 2002, 132-150.
reference ||| [ 12] Raghavan, S. and Garcia-Molina, H. Crawling the Hidden
reference ||| Web. In Proceedings of the 27th International Conference on
reference ||| Very Large Databases (VLDB), 2001, 129-138.
reference ||| [ 13] Rahardjo, B. and Yap, R. Automatic Information Extraction
reference ||| from Web Pages, In Proceedings of the 24th Annual
reference ||| International ACM SIGIR Conference, 2001, 430-431.
reference ||| [ 14] Salton, G. and McGill, M. Introduction to Modern
reference ||| Information Retrieval. New York, McCraw-Hill, 1983.
reference ||| [ 15] Sugiura, A. and Etzioni, O. Query Routing for Web Search
reference ||| Engines: Architecture and Experiments. In Proceedings of
reference ||| the 9th International World Wide Web Conference: The
reference ||| Web: The Next Generation, 2000, 417-430.
page ||| 8

title ||| Accelerated Focused Crawling through
title ||| Online Relevance Feedback*
author ||| Soumen Chakrabartit	Kunal Punera	Mallela Subramanyam
affiliation ||| IIT Bombay	IIT Bombay	University of Texas, Austin
sectionHeader ||| Abstract
bodyText ||| The organization of HTML into a tag tree structure, which
bodyText ||| is rendered by browsers as roughly rectangular regions with
bodyText ||| embedded text and HREF links, greatly helps surfers locate
bodyText ||| and click on links that best satisfy their information need.
bodyText ||| Can an automatic program emulate this human behavior
bodyText ||| and thereby learn to predict the relevance of an unseen
bodyText ||| HREF target page w.r.t. an information need, based on
bodyText ||| information limited to the HREF source page? Such a
bodyText ||| capability would be of great interest in focused crawling and
bodyText ||| resource discovery, because it can fine-tune the priority of
bodyText ||| unvisited URLs in the crawl frontier, and reduce the number
bodyText ||| of irrelevant pages which are fetched and discarded.
bodyText ||| We show that there is indeed a great deal of usable
bodyText ||| information on a HREF source page about the relevance
bodyText ||| of the target page. This information, encoded suitably, can
bodyText ||| be exploited by a supervised apprentice which takes online
bodyText ||| lessons from a traditional focused crawler by observing
bodyText ||| a carefully designed set of features and events associated
bodyText ||| with the crawler. Once the apprentice gets a sufficient
bodyText ||| number of examples, the crawler starts consulting it to
bodyText ||| better prioritize URLs in the crawl frontier. Experiments on
bodyText ||| a dozen topics using a 482-topic taxonomy from the Open
bodyText ||| Directory (Dmoz) show that online relevance feedback can
bodyText ||| reduce false positives by 30% to 90%.
category ||| Categories and subject descriptors:
category ||| H.5.4 [Information interfaces and presentation]:
category ||| Hypertext/hypermedia; I.5.4 [Pattern recognition]:
category ||| Applications, Text processing; I.2.6 [Artificial
category ||| intelligence]: Learning; I.2.8 [Artificial intelligence]:
category ||| Problem Solving, Control Methods, and Search.
keyword ||| General terms: Algorithms, performance,
keyword ||| measurements, experimentation.
sectionHeader ||| Keywords: Focused crawling, Document object model,
sectionHeader ||| Reinforcement learning.
sectionHeader ||| 1 Introduction
bodyText ||| Keyword search and clicking on links are the dominant
bodyText ||| modes of accessing hypertext on the Web. Support for
bodyText ||| keyword search through crawlers and search engines is very
bodyText ||| mature, but the surfing paradigm is not modeled or assisted
footnote ||| *(Note: The HTML version of this paper is best viewed using
footnote ||| Microsoft Internet Explorer. To view the HTML version using
footnote ||| Netscape, add the following line to your ~/.Xdefaults or
footnote ||| ~/.Xresources file:
footnote ||| Netscape*documentFonts.charset*adobe-fontspecific: iso-8859-1
footnote ||| For printing use the PDF version, as browsers may not print the
footnote ||| mathematics properly.)
footnote ||| tContact author, email soumen@cse.iitb.ac.in
copyright ||| Copyright is held by the author/owner(s).
note ||| WWW2002, May 7–11, 2002, Honolulu, Hawaii, USA.
note ||| ACM 1-58113-449-5/02/0005
figureCaption ||| Figure 1: A basic focused crawler controlled by one topic
figureCaption ||| classifier/learner.
bodyText ||| as well. Support for surfing is limited to the basic interface
bodyText ||| provided by Web browsers, except for a few notable research
bodyText ||| prototypes.
bodyText ||| While surfing, the user typically has a topic-specific
bodyText ||| information need, and explores out from a few known
bodyText ||| relevant starting points in the Web graph (which may be
bodyText ||| query responses) to seek new pages relevant to the chosen
bodyText ||| topic/s. While deciding for or against clicking on a specific
bodyText ||| link (u, v), humans use a variety of clues on the source
bodyText ||| page u to estimate the worth of the (unseen) target page
bodyText ||| v, including the tag tree structure of u, text embedded in
bodyText ||| various regions of that tag tree, and whether the link is
bodyText ||| relative or remote. “Every click on a link is a leap of faith”
bodyText ||| [19], but humans are very good at discriminating between
bodyText ||| links based on these clues.
bodyText ||| Making an educated guess about the worth of clicking
bodyText ||| on a link (u, v) without knowledge of the target v is
bodyText ||| central to the surfing activity. Automatic programs which
bodyText ||| can learn this capability would be valuable for a number
bodyText ||| of applications which can be broadly characterized as
bodyText ||| personalized, topic-specific information foragers.
bodyText ||| Large-scale, topic-specific information gatherers are
bodyText ||| called focused crawlers [1, 9, 14, 28, 30]. In contrast to giant,
bodyText ||| all-purpose crawlers which must process large portions of
bodyText ||| the Web in a centralized manner, a distributed federation of
bodyText ||| focused crawlers can cover specialized topics in more depth
bodyText ||| and keep the crawl more fresh, because there is less to cover
bodyText ||| for each crawler.
bodyText ||| In its simplest form, a focused crawler consists of a
bodyText ||| supervised topic classifier (also called a ‘learner’) controlling
bodyText ||| the priority of the unvisited frontier of a crawler (see
bodyText ||| Figure 1). The classifier is trained a priori on document
bodyText ||| samples embedded in a topic taxonomy such as Yahoo!
bodyText ||| or Dmoz. It thereby learns to label new documents as
bodyText ||| belonging to topics in the given taxonomy [2, 5, 21]. The
bodyText ||| goal of the focused crawler is to start from nodes relevant
bodyText ||| to a focus topic c* in the Web graph and explore links to
bodyText ||| selectively collect pages about c*, while avoiding fetching
bodyText ||| pages not about c*.
bodyText ||| Suppose the crawler has collected a page u and
figure ||| If Pr(c*|u) is large enough
figure ||| then enqueue all outlinks v of u
figure ||| with priority Pr(c*|u)
figure ||| Dmoz
figure ||| topic
figure ||| taxonomy
figure ||| Class models
figure ||| consisting of
figure ||| term stats
figure ||| Frontier URLS
figure ||| priority queue
figure ||| Pick
figure ||| best
figure ||| Crawler
figure ||| Seed
figure ||| URLs
figure ||| Baseline learner
figure ||| Submit page for classification
figure ||| Newly fetched
figure ||| page u
figure ||| Crawl
figure ||| database
page ||| 148
bodyText ||| encountered in u an unvisited link to v. A simple crawler
bodyText ||| (which we call the baseline) will use the relevance of u
bodyText ||| to topic c* (which, in a Bayesian setting, we can denote
bodyText ||| Pr(c*lu)) as the estimated relevance of the unvisited page
bodyText ||| v. This reflects our belief that pages across a hyperlink
bodyText ||| are more similar than two randomly chosen pages on the
bodyText ||| Web, or, in other words, topics appear clustered in the
bodyText ||| Web graph [11, 23]. Node v will be added to the crawler’s
bodyText ||| priority queue with priority Pr(c*lu). This is essentially a
bodyText ||| “best-first” crawling strategy. When v comes to the head
bodyText ||| of the queue and is actually fetched, we can verify if the
bodyText ||| gamble paid off, by evaluating Pr(c* lv). The fraction of
bodyText ||| relevant pages collected is called the harvest rate. If V
bodyText ||| is the set of nodes collected, the harvest rate is defined
bodyText ||| as (1/lVl) E vEVPr(c*lv). Alternatively, we can measure
bodyText ||| the loss rate, which is one minus the harvest rate, i.e., the
bodyText ||| (expected) fraction of fetched pages that must be thrown
bodyText ||| away. Since the effort on relevant pages is well-spent,
bodyText ||| reduction in loss rate is the primary goal and the most
bodyText ||| appropriate figure of merit.
bodyText ||| For focused crawling applications to succeed, the “leap
bodyText ||| of faith” from u to v must pay off frequently. In other words,
bodyText ||| if Pr(c*lv) is often much less than the preliminary estimate
bodyText ||| Pr(c*lu), a great deal of network traffic and CPU cycles
bodyText ||| are being wasted eliminating bad pages. Experience with
bodyText ||| random walks on the Web show that as one walks away
bodyText ||| from a fixed page u0 relevant to topic c0, the relevance of
bodyText ||| successive nodes u1, u2,... to c0 drops dramatically within
bodyText ||| a few hops [9, 23]. This means that only a fraction of out-
bodyText ||| links from a page is typically worth following. The average
bodyText ||| out-degree of the Web graph is about 7 [29]. Therefore, a
bodyText ||| large number of page fetches may result in disappointment,
bodyText ||| especially if we wish to push the utility of focused crawling
bodyText ||| to topic communities which are not very densely linked.
bodyText ||| Even w.r.t. topics that are not very narrow, the
bodyText ||| number of distracting outlinks emerging from even fairly
bodyText ||| relevant pages has grown substantially since the early
bodyText ||| days of Web authoring [4]. Template-based authoring,
bodyText ||| dynamic page generation from semi-structured databases,
bodyText ||| ad links, navigation panels, and Web rings contribute many
bodyText ||| irrelevant links which reduce the harvest rate of focused
bodyText ||| crawlers. Topic-based link discrimination will also reduce
bodyText ||| these problems.
subsectionHeader ||| 1.1 Our contribution: Leaping with more faith
subsectionHeader ||| In this paper we address the following questions:
bodyText ||| How much information about the topic of the HREF
bodyText ||| target is available and/or latent in the HREF source page,
bodyText ||| its tag-tree structure, and its text? Can these sources be
bodyText ||| exploited for accelerating a focused crawler?
bodyText ||| Our basic idea is to use two classifiers. Earlier, the regular
bodyText ||| baseline classifier was used to assign priorities to unvisited
bodyText ||| frontier nodes. This no longer remains its function. The role
bodyText ||| of assigning priorities to unvisited URLs in the crawl frontier
bodyText ||| is now assigned to a new learner called the apprentice, and
bodyText ||| the priority of v is specific to the features associated with
bodyText ||| the (u, v) link which leads to it1. The features used by the
bodyText ||| apprentice are derived from the Document Object Model or
footnote ||| 'If many u’s link to a single v, it is easiest to freeze the priority of
bodyText ||| v when the first-visited u linking to v is assessed, but combinations
bodyText ||| of scores are also possible.
figureCaption ||| Figure 2: The apprentice is continually presented with
figureCaption ||| training cases (u, v) with suitable features. The apprentice
figureCaption ||| is interposed where new outlinks (u, v) are registered with
figureCaption ||| the priority queue, and helps assign the unvisited node v a
figureCaption ||| better estimate of its relevance.
bodyText ||| DOM (http://www.w3.org/DOM/) of u. Meanwhile, the role
bodyText ||| of the baseline classifier becomes one of generating training
bodyText ||| instances for the apprentice, as shown in Figure 2. We may
bodyText ||| therefore regard the baseline learner as a critic or a trainer,
bodyText ||| which provides feedback to the apprentice so that it can
bodyText ||| improve “on the job.”
bodyText ||| The critic-apprentice paradigm is related to reinforce-
bodyText ||| ment learning and AI programs that learn to play games
bodyText ||| [26, §1.2]. We argue that this division of labor is natural
bodyText ||| and effective. The baseline learner can be regarded as
bodyText ||| a user specification for what kind of content is desired.
bodyText ||| Although we limit ourselves to a generative statistical model
bodyText ||| for this specification, this can be an arbitrary black-box
bodyText ||| predicate. For rich and meaningful distinction between
bodyText ||| Web communities and topics, the baseline learner needs
bodyText ||| to be fairly sophisticated, perhaps leveraging off human
bodyText ||| annotations on the Web (such as topic directories). In
bodyText ||| contrast, the apprentice specializes in how to locate pages
bodyText ||| to satisfy the baseline learner. Its feature space is more
bodyText ||| limited, so that it can train fast and adapt nimbly to
bodyText ||| changing fortunes at following links during a crawl. In
bodyText ||| Mitchell’s words [27], the baseline learner recognizes “global
bodyText ||| regularity” while the apprentice helps the crawler adapt
bodyText ||| to “local regularity.” This marked asymmetry between
bodyText ||| the classifiers distinguishes our approach from Blum and
bodyText ||| Mitchell’s co-training technique [3], in which two learners
bodyText ||| train each other by selecting unlabeled instances.
bodyText ||| Using a dozen topics from a topic taxonomy derived
bodyText ||| from the Open Directory, we compare our enhanced crawler
bodyText ||| with the baseline crawler. The number of pages that are
bodyText ||| thrown away (because they are irrelevant), called the loss
bodyText ||| rate, is cut down by 30–90%. We also demonstrate that
bodyText ||| the fine-grained tag-tree model, together with our synthesis
bodyText ||| and encoding of features for the apprentice, are superior to
bodyText ||| simpler alternatives.
sectionHeader ||| 1.2 Related work
bodyText ||| Optimizing the priority of unvisited URLs on the crawl
bodyText ||| frontier for specific crawling goals is not new. FISHSEARCH
bodyText ||| by De Bra et al. [12, 13] and SHARKSEARCH by Hersovici
bodyText ||| et al. [16] were some of the earliest systems for localized
bodyText ||| searches in the Web graph for pages with specified keywords.
figure ||| ... submit (u,v)
figure ||| to the apprentice
figure ||| If Pr(c*|u)is
figure ||| large enough...
figure ||| Dmoz
figure ||| topic
figure ||| taxonomy
figure ||| Submit page for classification
figure ||| Baseline learner (Critic)
figure ||| + -
figure ||| Apprentice
figure ||| assigns more
figure ||| accurate priority
figure ||| to node v	Frontier URLS
figure ||| priority queue
figure ||| Class models
figure ||| consisting of
figure ||| term stats
figure ||| Apprentice learner
figure ||| Class
figure ||| models
figure ||| Newly fetched
figure ||| page u
figure ||| Crawler
figure ||| Pick
figure ||| best
figure ||| Online
figure ||| training
figure ||| An instance (u,v)
figure ||| for the apprentice
figure ||| Pr(c*|v)
figure ||| u
figure ||| Crawl
figure ||| database
figure ||| Pr(c|u) for
figure ||| all classes c
figure ||| v
page ||| 149
bodyText ||| In another early paper, Cho et al. [10] experimented with a
bodyText ||| variety of strategies for prioritizing how to fetch unvisited
bodyText ||| URLs. They used the anchor text as a bag of words to
bodyText ||| guide link expansion to crawl for pages matching a specified
bodyText ||| keyword query, which led to some extent of differentiation
bodyText ||| among out-links, but no trainer-apprentice combination was
bodyText ||| involved. No notion of supervised topics had emerged at
bodyText ||| that point, and simple properties like the in-degree or the
bodyText ||| presence of specified keywords in pages were used to guide
bodyText ||| the crawler.
bodyText ||| Topical locality on the Web has been studied for a few
bodyText ||| years. Davison made early measurements on a 100000-
bodyText ||| node Web subgraph [11] collected by the DISCOWEB system.
bodyText ||| Using the standard notion of vector space TFIDF similarity
bodyText ||| [31], he found that the endpoints of a hyperlink are much
bodyText ||| more similar to each other than two random pages, and that
bodyText ||| HREFs close together on a page link to documents which are
bodyText ||| more similar than targets which are far apart. Menczer has
bodyText ||| made similar observations [23]. The HYPERCLASS hypertext
bodyText ||| classifier also uses such locality patterns for better semi-
bodyText ||| supervised learning of topics [7], as does IBM’s Automatic
bodyText ||| Resource Compilation (ARC) and Clever topic distillation
bodyText ||| systems [6, 8].
bodyText ||| Two important advances have been made beyond the
bodyText ||| baseline best-first focused crawler: the use of context graphs
bodyText ||| by Diligenti et al. [14] and the use of reinforcement learning
bodyText ||| by Rennie and McCallum [30]. Both techniques trained
bodyText ||| a learner with features collected from paths leading up to
bodyText ||| relevant nodes rather than relevant nodes alone. Such paths
bodyText ||| may be collected by following backlinks.
bodyText ||| Diligenti et al. used a classifier (learner) that regressed
bodyText ||| from the text of u to the estimated link distance from u to
bodyText ||| some relevant page w, rather than the relevance of u or an
bodyText ||| outlink (u, v), as was the case with the baseline crawler.
bodyText ||| This lets their system continue expanding u even if the
bodyText ||| reward for following a link is not immediate, but several
bodyText ||| links away. However, they do favor links whose payoffs
bodyText ||| are closest. Our work is specifically useful in conjunction
bodyText ||| with the use of context graphs: when the context graph
bodyText ||| learner predicts that a goal is several links away, it is crucial
bodyText ||| to offer additional guidance to the crawler based on local
bodyText ||| structure in pages, because the fan-out at that radius could
bodyText ||| be enormous.
bodyText ||| Rennie and McCallum [30] also collected paths leading
bodyText ||| to relevant nodes, but they trained a slightly different
bodyText ||| classifier, for which:
listItem ||| 9 An instance was a single HREF link like (u, v).
listItem ||| 9 The features were terms from the title and headers
listItem ||| (<h1> ... </h1> etc.) of u, together with the text
listItem ||| in and ‘near’ the anchor (u, v). Directories and
listItem ||| pathnames were also used. (We do not know the
listItem ||| precise definition of ‘near’, or how these features were
listItem ||| encoded and combined.)
listItem ||| 9 The prediction was a discretized estimate of the
listItem ||| number of relevant nodes reachable by following (u, v),
listItem ||| where the reward from goals distant from v was
listItem ||| geometrically discounted by some factor γ < 1/2 per
listItem ||| hop.
bodyText ||| Rennie and McCallum obtained impressive harvests of
bodyText ||| research papers from four Computer Science department
bodyText ||| sites, and of pages about officers and directors from 26
bodyText ||| company Websites.
bodyText ||| Lexical proximity and contextual features have been
bodyText ||| used extensively in natural language processing for disam-
bodyText ||| biguating word sense [15]. Compared to plain text, DOM
bodyText ||| trees and hyperlinks give us a richer set of potential features.
bodyText ||| Aggarwal et al. have proposed an “intelligent crawling”
bodyText ||| framework [1] in which only one classifier is used, but similar
bodyText ||| to our system, that classifier trains as the crawl progresses.
bodyText ||| They do not use our apprentice-critic approach, and do not
bodyText ||| exploit features derived from tag-trees to guide the crawler.
bodyText ||| The “intelligent agents” literature has brought forth
bodyText ||| several systems for resource discovery and assistance to
bodyText ||| browsing [19]. They range between client- and site-level
bodyText ||| tools. Letizia [18], Powerscout, and WebWatcher [17] are
bodyText ||| such systems. Menczer and Belew proposed InfoSpiders
bodyText ||| [24], a collection of autonomous goal-driven crawlers without
bodyText ||| global control or state, in the style of genetic algorithms. A
bodyText ||| recent extensive study [25] comparing several topic-driven
bodyText ||| crawlers including the best-first crawler and InfoSpiders
bodyText ||| found the best-first approach to show the highest harvest
bodyText ||| rate (which our new system outperforms).
bodyText ||| In all the systems mentioned above, improving the
bodyText ||| chances of a successful “leap of faith” will clearly reduce
bodyText ||| the overheads of fetching, filtering, and analyzing pages.
bodyText ||| Furthermore, whereas we use an automatic first-generation
bodyText ||| focused crawler to generate the input to train the apprentice,
bodyText ||| one can envisage specially instrumented browsers being used
bodyText ||| to monitor users as they seek out information.
bodyText ||| We distinguish our work from prior art in the following
bodyText ||| important ways:
bodyText ||| Two classifiers: We use two classifiers. The first one is
bodyText ||| used to obtain ‘enriched’ training data for the second one.
bodyText ||| (A breadth-first or random crawl would have a negligible
bodyText ||| fraction of positive instances.) The apprentice is a simplified
bodyText ||| reinforcement learner. It improves the harvest rate, thereby
bodyText ||| ‘enriching’ the data collected and labeled by the first learner
bodyText ||| in turn.
bodyText ||| No manual path collection: Our two-classifier frame-
bodyText ||| work essentially eliminates the manual effort needed to
bodyText ||| create reinforcement paths or context graphs. The input
bodyText ||| needed to start off a focused crawl is just a pre-trained topic
bodyText ||| taxonomy (easily available from the Web) and a few focus
bodyText ||| topics.
bodyText ||| Online training: Our apprentice trains continually, ac-
bodyText ||| quiring ever-larger vocabularies and improving its accuracy
bodyText ||| as the crawl progresses. This property holds also for the
bodyText ||| “intelligent crawler” proposed by Aggarwal et al., but they
bodyText ||| have a single learner, whose drift is controlled by precise
bodyText ||| relevance predicates provided by the user.
bodyText ||| No manual feature tuning: Rather than tune ad-hoc
bodyText ||| notions of proximity between text and hyperlinks, we encode
bodyText ||| the features of link (u, v) using the DOM-tree of u, and
bodyText ||| automatically learn a robust definition of ‘nearness’ of a
bodyText ||| textual feature to (u, v). In contrast, Aggarwal et al
bodyText ||| use many tuned constants combining the strength of text-
bodyText ||| and link-based predictors, and Rennie et al. use domain
bodyText ||| knowledge to select the paths to goal nodes and the word
bodyText ||| bags that are submitted to their learner.
page ||| 150
sectionHeader ||| 2 Methodology and algorithms
bodyText ||| We first review the baseline focused crawler and then
bodyText ||| describe how the enhanced crawler is set up using the
bodyText ||| apprentice-critic mechanism.
subsectionHeader ||| 2.1 The baseline focused crawler
bodyText ||| The baseline focused crawler has been described in detail
bodyText ||| elsewhere [9, 14], and has been sketched in Figure 1. Here
bodyText ||| we review its design and operation briefly.
bodyText ||| There are two inputs to the baseline crawler.
listItem ||| •	A topic taxonomy or hierarchy with example URLs
listItem ||| for each topic.
listItem ||| •	One or a few topics in the taxonomy marked as the
listItem ||| topic(s) of focus.
bodyText ||| Although we will generally use the terms ‘taxonomy’ and
bodyText ||| ‘hierarchy’, a topic tree is not essential; all we really need is
bodyText ||| a two-way classifier where the classes have the connotations
bodyText ||| of being ‘relevant’ or ‘irrelevant’ to the topic(s) of focus.
bodyText ||| A topic hierarchy is proposed purely to reduce the tedium
bodyText ||| of defining new focused crawls. With a two-class classifier,
bodyText ||| the crawl administrator has to seed positive and negative
bodyText ||| examples for each crawl. Using a taxonomy, she composes
bodyText ||| the ‘irrelevant’ class as the union of all classes that are not
bodyText ||| relevant. Thanks to extensive hierarchies like Dmoz in the
bodyText ||| public domain, it should be quite easy to seed topic-based
bodyText ||| crawls in this way.
bodyText ||| The baseline crawler maintains a priority queue on the
bodyText ||| estimated relevance of nodes v which have not been visited,
bodyText ||| and keeps removing the highest priority node and visiting it,
bodyText ||| expanding its outlinks and checking them into the priority
bodyText ||| queue with the relevance score of v in turn. Despite its
bodyText ||| extreme simplicity, the best-first crawler has been found to
bodyText ||| have very high harvest rates in extensive evaluations [25].
bodyText ||| Why do we need negative examples and negative classes
bodyText ||| at all? Instead of using class probabilities, we could maintain
bodyText ||| a priority queue on, say, the TFIDF cosine similarity
bodyText ||| between u and the centroid of the seed pages (acting as an
bodyText ||| estimate for the corresponding similarity between v and the
bodyText ||| centroid, until v has been fetched). Experience has shown
bodyText ||| [32] that characterizing a negative class is quite important to
bodyText ||| prevent the centroid of the crawled documents from drifting
bodyText ||| away indefinitely from the desired topic profile.
bodyText ||| In this paper, the baseline crawler also has the implicit
bodyText ||| job of gathering instances of successful and unsuccessful
bodyText ||| “leaps of faith” to submit to the apprentice, discussed next.
subsectionHeader ||| 2.2 The basic structure of the apprentice
subsectionHeader ||| learner
bodyText ||| In estimating the worth of traversing the HREF (u, v), we
bodyText ||| will limit our attention to u alone. The page u is modeled
bodyText ||| as a tag tree (also called the Document Object Model or
bodyText ||| DOM). In principle, any feature from u, even font color and
bodyText ||| site membership may be perfect predictors of the relevance
bodyText ||| of v. The total number of potentially predictive features will
bodyText ||| be quite staggering, so we need to simplify the feature space
bodyText ||| and massage it into a form suited to conventional learning
bodyText ||| algorithms. Also note that we specifically study properties
bodyText ||| of u and not larger contexts such as paths leading to u,
bodyText ||| meaning that our method may become even more robust and
bodyText ||| useful in conjunction with context graphs or reinforcement
bodyText ||| along paths.
bodyText ||| Initially, the apprentice has no training data, and passes
bodyText ||| judgment on (u, v) links according to some fixed prior
bodyText ||| obtained from a baseline crawl run ahead of time (e.g., see
bodyText ||| the statistics in §3.3). Ideally, we would like to train the
bodyText ||| apprentice continuously, but to reduce overheads, we declare
bodyText ||| a batch size between a few hundred and a few thousand
bodyText ||| pages. After every batch of pages is collected, we check if any
bodyText ||| page u fetched before the current batch links to some page
bodyText ||| v in the batch. If such a (u, v) is found, we extract suitable
bodyText ||| features for (u, v) as described later in this section, and add
bodyText ||| ((u, v), Pr(c* |v)� as another instance of the training data for
bodyText ||| the apprentice. Many apprentices, certainly the simple naive
bodyText ||| Bayes and linear perceptrons that we have studied, need not
bodyText ||| start learning from scratch; they can accept the additional
bodyText ||| training data with a small additional computational cost.
subsubsectionHeader ||| 2.2.1 Preprocessing the DOM tree
bodyText ||| First, we parse u and form the DOM tree for u. Sadly,
bodyText ||| much of the HTML available on the Web violates any
bodyText ||| HTML standards that permit context-free parsing, but
bodyText ||| a variety of repair heuristics (see, e.g., HTML Tidy,
bodyText ||| available at http://www.w3.org/People/Raggett/tidy/)
bodyText ||| let us generate reasonable DOM trees from bad HTML.
figureCaption ||| Figure 3: Numbering of DOM leaves used to derive offset
figureCaption ||| attributes for textual tokens. ‘@’ means “is at offset”.
bodyText ||| Second, we number all leaf nodes consecutively from left
bodyText ||| to right. For uniformity, we assign numbers even to those
bodyText ||| DOM leaves which have no text associated with them. The
bodyText ||| specific <a href ... > which links to v is actually an internal
bodyText ||| node a,, which is the root of the subtree containing the
bodyText ||| anchor text of the link (u, v). There may be other element
bodyText ||| tags such as <em> or <b> in the subtree rooted at a,. Let
bodyText ||| the leaf or leaves in this subtree be numbered f(a,) through
bodyText ||| r(a,) ≥ f(a,). We regard the textual tokens available from
bodyText ||| any of these leaves as being at DOM offset zero w.r.t. the
bodyText ||| (u, v) link. Text tokens from a leaf numbered p, to the left of
bodyText ||| f(a,), are at negative DOM offset p — f(a,). Likewise, text
bodyText ||| from a leaf numbered p to the right of r(a,) are at positive
bodyText ||| DOM offset p — r(a,). See Figure 3 for an example.
subsubsectionHeader ||| 2.2.2 Features derived from the DOM and text
subsubsectionHeader ||| tokens
bodyText ||| Many related projects mentioned in §1.2 use a linear notion
bodyText ||| of proximity between a HREF and textual tokens. In the
bodyText ||| ARC system, there is a crude cut-off distance measured
figure ||| @-2		@-1		@0		@0		@1		@2		@3
figure ||| TEXT
figure ||| tt
figure ||| li
figure ||| TEXT
figure ||| TEXT
figure ||| ul
figure ||| li
figure ||| a
figure ||| HREF
figure ||| font
figure ||| TEXT
figure ||| TEXT
figure ||| li
figure ||| TEXT em
figure ||| TEXT
figure ||| li
page ||| 151
bodyText ||| in bytes to the left and right of the anchor. In the
bodyText ||| Clever system, distance is measured in tokens, and the
bodyText ||| importance attached to a token decays with the distance.
bodyText ||| In reinforcement learning and intelligent predicate-based
bodyText ||| crawling, the exact specification of neighborhood text is not
bodyText ||| known to us. In all cases, some ad-hoc tuning appears to be
bodyText ||| involved.
bodyText ||| We claim (and show in §3.4) that the relation between
bodyText ||| the relevance of the target v of a HREF (u, v) and the
bodyText ||| proximity of terms to (u, v) can be learnt automatically. The
bodyText ||| results are better than ad-hoc tuning of cut-off distances,
bodyText ||| provided the DOM offset information is encoded as features
bodyText ||| suitable for the apprentice.
bodyText ||| One obvious idea is to extend the Clever model: a page
bodyText ||| is a linear sequence of tokens. If a token t is distant x from
bodyText ||| the HREF (u, v) in question, we encode it as a feature (t, x).
bodyText ||| Such features will not be useful because there are too many
bodyText ||| possible values of x, making the (t, x) space too sparse to
bodyText ||| learn well. (How many HREFS will be exactly five tokens
bodyText ||| from the term ‘basketball’?)
bodyText ||| Clearly, we need to bucket x into a small number of
bodyText ||| ranges. Rather than tune arbitrary bucket boundaries by
bodyText ||| hand, we argue that DOM offsets are a natural bucketing
bodyText ||| scheme provided by the page author. Using the node
bodyText ||| numbering scheme described above, each token t on page u
bodyText ||| can be annotated w.r.t. the link (u, v) (for simplicity assume
bodyText ||| there is only one such link) as (t, d), where d is the DOM
bodyText ||| offset calculated above. This is the main set of features
bodyText ||| used by the apprentice. We shall see that the apprentice
bodyText ||| can learn to limit IdI to less than dmax = 5 in most cases,
bodyText ||| which reduces its vocabulary and saves time.
bodyText ||| A variety of other feature encodings suggest themselves.
bodyText ||| We are experimenting with some in ongoing work (§4),
bodyText ||| but decided against some others. For example, we do not
bodyText ||| expect gains from encoding specific HTML tag names owing
bodyText ||| to the diversity of authoring styles. Authors use <div>,
bodyText ||| <span>, <layer> and nested tables for layout control in
bodyText ||| non-standard ways; these are best deflated to a nameless
bodyText ||| DOM node representation. Similar comments apply to
bodyText ||| HREF collections embedded in <ul>, <ol>, <td> and
bodyText ||| <dd>. Font and lower/upper case information is useful
bodyText ||| for search engines, but would make features even sparser
bodyText ||| for the apprentice. Our representation also flattens two-
bodyText ||| dimensional tables to their “row-major” representation.
bodyText ||| The features we ignore are definitely crucial for other
bodyText ||| applications, such as information extraction. We did not
bodyText ||| see any cases where this sloppiness led to a large loss rate.
bodyText ||| We would be surprised to see tables where relevant links
bodyText ||| occurred in the third column and irrelevant links in the fifth,
bodyText ||| or pages where they are rendered systematically in different
bodyText ||| fonts and colors, but are not otherwise demarcated by the
bodyText ||| DOM structure.
subsubsectionHeader ||| 2.2.3 Non-textual features
bodyText ||| Limiting d may lead us to miss features of u that may be
bodyText ||| useful at the whole-page level. One approach would be to use
bodyText ||| “d = oo” for all d larger in magnitude than some threshold.
bodyText ||| But this would make our apprentice as bulky and slow to
bodyText ||| train as the baseline learner.
bodyText ||| Instead, we use the baseline learner to abstract u for
bodyText ||| the apprentice. Specifically, we use a naive Bayes baseline
bodyText ||| learner to classify u, and use the vector of class probabilities
bodyText ||| returned as features for the apprentice. These features can
bodyText ||| help the apprentice discover patterns such as
bodyText ||| “Pages about /Recreation/Boating/Sailing often
bodyText ||| link to pages about /Sports/Canoe_and_Kayaking.”
bodyText ||| This also covers for the baseline classifier confusing between
bodyText ||| classes with related vocabulary, achieving an effect similar
bodyText ||| to context graphs.
bodyText ||| Another kind of feature can be derived from co-citation.
bodyText ||| If v1 has been fetched and found to be relevant and HREFS
bodyText ||| (u, v1) and (u, v2) are close to each other, v2 is likely to
bodyText ||| be relevant. Just like textual tokens were encoded as (t, d)
bodyText ||| pairs, we can represent co-citation features as (p, d), where
bodyText ||| p is a suitable representation of relevance.
bodyText ||| Many other features can be derived from the DOM tree
bodyText ||| and added to our feature pool. We discuss some options
bodyText ||| in §4. In our experience so far, we have found the (t, d)
bodyText ||| features to be most useful. For simplicity, we will limit our
bodyText ||| subsequent discussion to (t, d) features only.
subsectionHeader ||| 2.3 Choices of learning algorithms for the
subsectionHeader ||| apprentice
bodyText ||| Our feature set is thus an interesting mix of categorical,
bodyText ||| ordered and continuous features:
listItem ||| 9 Term tokens (t, d) have a categorical component t and
listItem ||| a discrete ordered component d (which we may like to
listItem ||| smooth somewhat). Term counts are discrete but can
listItem ||| be normalized to constant document length, resulting
listItem ||| in continuous attribute values.
listItem ||| 9 Class names are discrete and may be regarded as
bodyText ||| synthetic terms. The probabilities are continuous.
bodyText ||| The output we desire is an estimate of Pr(c* Iv), given all the
bodyText ||| observations about u and the neighborhood of (u, v) that
bodyText ||| we have discussed. Neural networks are a natural choice
bodyText ||| to accommodate these requirements. We first experimented
bodyText ||| with a simple linear perceptron, training it with the delta
bodyText ||| rule (gradient descent) [26]. Even for a linear perceptron,
bodyText ||| convergence was surprisingly slow, and after convergence,
bodyText ||| the error rate was rather high. It is likely that local
bodyText ||| optima were responsible, because stability was generally
bodyText ||| poor, and got worse if we tried to add hidden layers or
bodyText ||| sigmoids. In any case, convergence was too slow for use
bodyText ||| as an online learner. All this was unfortunate, because the
bodyText ||| direct regression output from a neural network would be
bodyText ||| convenient, and we were hoping to implement a Kohonen
bodyText ||| layer for smoothing d.
bodyText ||| In contrast, a naive Bayes (NB) classifier worked very
bodyText ||| well. A NB learner is given a set of training documents,
bodyText ||| each labeled with one of a finite set of classes/topic. A
bodyText ||| document or Web page u is modeled as a multiset or bag
bodyText ||| of words, {(T,n(u,T))} where T is a feature which occurs
bodyText ||| n(u, T) times in u. In ordinary text classification (such as
bodyText ||| our baseline learner) the features T are usually single words.
bodyText ||| For our apprentice learner, a feature T is a (t, d) pair.
bodyText ||| NB classifiers can predict from a discrete set of classes,
bodyText ||| but our prediction is a continuous (probability) score. To
bodyText ||| bridge this gap, We used a simple two-bucket (low/high
bodyText ||| relevance) special case of Torgo and Gama’s technique of
bodyText ||| using classifiers for discrete labels for continuous regression
bodyText ||| [33], using “equally probable intervals” as far as possible.
page ||| 152
bodyText ||| Torgo and Gama recommend using a measure of centrality,
bodyText ||| such as the median, of each interval as the predicted value of
bodyText ||| that class. Rennie and McCallum [30] corroborate that 2–3
bodyText ||| bins are adequate. As will be clear from our experiments, the
bodyText ||| medians of our ‘low’ and ‘high’ classes are very close to zero
bodyText ||| and one respectively (see Figure 5). Therefore, we simply
bodyText ||| take the probability of the ‘high’ class as the prediction from
bodyText ||| our naive Bayes apprentice.
bodyText ||| The prior probability of class c, denoted Pr(c) is the
bodyText ||| fraction of training documents labeled with class c. The NB
bodyText ||| model is parameterized by a set of numbers 0c,T which is
bodyText ||| roughly the rate of occurrence of feature τ in class c, more
bodyText ||| exactly,
equation ||| ITI + Pu T n(u τ,), (1)
bodyText ||| where Vc is the set of Web pages labeled with c and T is the
bodyText ||| entire vocabulary. The NB learner assumes independence
bodyText ||| between features, and estimates
equation ||| Pr(cIu) a Pr(c) Pr(uIc) ≈ Pr(c) 11 0n (u,T)
equation ||| c,T. (2)
equation ||| TEu
bodyText ||| Nigam et al. provide further details [22].
sectionHeader ||| 3 Experimental study
bodyText ||| Our experiments were guided by the following requirements.
bodyText ||| We wanted to cover a broad variety of topics, some ‘easy’ and
bodyText ||| some ‘di cult’, in terms of the harvest rate of the baseline
bodyText ||| crawler. Here is a quick preview of our results.
listItem ||| •	The apprentice classifier achieves high accuracy in
listItem ||| predicting the relevance of unseen pages given (t, d)
listItem ||| features. It can determine the best value of dmax to
listItem ||| use, typically, 4–6.
listItem ||| •	Encoding DOM offsets in features improves the
listItem ||| accuracy of the apprentice substantially, compared
listItem ||| to a bag of ordinary words collected from within the
listItem ||| same DOM offset window.
listItem ||| •	Compared to a baseline crawler, a crawler that is
listItem ||| guided by an apprentice (trained offiine) has a 30%
listItem ||| to 90% lower loss rate. It finds crawl paths never
listItem ||| expanded by the baseline crawler.
listItem ||| •	Even if the apprentice-guided crawler is forced to
listItem ||| stay within the (inferior) Web graph collected by the
listItem ||| baseline crawler, it collects the best pages early on.
listItem ||| •	The apprentice is easy to train online. As soon as it
bodyText ||| starts guiding the crawl, loss rates fall dramatically.
listItem ||| •	Compared to (t, d) features, topic- or cocitation-based
listItem ||| features have negligible effect on the apprentice.
bodyText ||| To run so many experiments, we needed three highly
bodyText ||| optimized and robust modules: a crawler, a HTML-to-DOM
bodyText ||| converter, and a classifier.
bodyText ||| We started with the w3c-libwww crawling library from
bodyText ||| http://www.w3c.org/Library/, but replaced it with our
bodyText ||| own crawler because we could effectively overlap DNS
bodyText ||| lookup, HTTP access, and disk access using a select over
bodyText ||| all socket/file descriptors, and prevent memory leaks visible
bodyText ||| in w3c-libwww. With three caching DNS servers, we could
bodyText ||| achieve over 90% utilization of a 2Mbps dedicated ISP
bodyText ||| connection.
bodyText ||| We used the HTML parser libxml2 library to extract
bodyText ||| the DOM from HTML, but this library has memory leaks,
bodyText ||| and does not always handle poorly written HTML well. We
bodyText ||| had some stability problems with HTML Tidy (http: //www.
bodyText ||| w3.org/People/Raggett/tidy/), the well-known HTML
bodyText ||| cleaner which is very robust to bad HTML. At present we
bodyText ||| are using libxml2 and are rolling our own HTML parser and
bodyText ||| cleaner for future work.
bodyText ||| We intend to make our crawler and HTML parser code
bodyText ||| available in the public domain for research use.
bodyText ||| For both the baseline and apprentice classifier we used
bodyText ||| the public domain BOW toolkit and the Rainbow naive
bodyText ||| Bayes classifier created by McCallum and others [20]. Bow
bodyText ||| and Rainbow are very fast C implementations which let us
bodyText ||| classify pages in real time as they were being crawled.
subsectionHeader ||| 3.1 Design of the topic taxonomy
bodyText ||| We downloaded from the Open Directory (http://dmoz.
bodyText ||| org/) an RDF file with over 271954 topics arranged in a
bodyText ||| tree hierarchy with depth at least 6, containing a total of
bodyText ||| about 1697266 sample URLs. The distribution of samples
bodyText ||| over topics was quite non-uniform. Interpreting the tree as
bodyText ||| an is-a hierarchy meant that internal nodes inherited all
bodyText ||| examples from descendants, but they also had their own
bodyText ||| examples. Since the set of topics was very large and many
bodyText ||| topics had scarce training data, we pruned the Dmoz tree
bodyText ||| to a manageable frontier by following these steps:
listItem ||| 1. Initially we placed example URLs in both internal and
listItem ||| leaf nodes, as given by Dmoz.
listItem ||| 2.We fixed a minimum per-class training set size of k =
listItem ||| 300 documents.
listItem ||| 3.We iteratively performed the following step as long
listItem ||| as possible: we found a leaf node with less than k
listItem ||| example URLs, moved all its examples to its parent,
listItem ||| and deleted the leaf.
listItem ||| 4.To each internal node c, we attached a leaf
listItem ||| subdirectory called Other. Examples associated
listItem ||| directly with c were moved to this Other subdirectory.
listItem ||| 5. Some topics were populated out of proportion, either
listItem ||| at the beginning or through the above process. We
listItem ||| made the class priors more balanced by sampling
listItem ||| down the large classes so that each class had at most
listItem ||| 300 examples.
bodyText ||| The resulting taxonomy had 482 leaf nodes and a total
bodyText ||| of 144859 sample URLs. Out of these we could successfully
bodyText ||| fetch about 120000 URLs. At this point we discarded the
bodyText ||| tree structure and considered only the leaf topics. Training
bodyText ||| time for the baseline classifier was about about two hours
bodyText ||| on a 729MHz Pentium III with 256kB cache and 512MB
bodyText ||| RAM. This was very fast, given that 1.4GB of HTML text
bodyText ||| had to be processed through Rainbow. The complete listing
bodyText ||| of topics can be obtained from the authors.
subsectionHeader ||| 3.2 Choice of topics
bodyText ||| Depending on the focus topic and prioritization strategy,
bodyText ||| focused crawlers may achieve diverse harvest rates. Our
equation ||| 0c,T =
equation ||| 1 + Pu∈VC n(u, τ)
page ||| 153
bodyText ||| early prototype [9] yielded harvest rates typically between
bodyText ||| 0.25 and 0.6. Rennie and McCallum [30] reported recall
bodyText ||| and not harvest rates. Diligenti et al. [14] focused on very
bodyText ||| specific topics where the harvest rate was very low, 4–6%.
bodyText ||| Obviously, the maximum gains shown by a new idea in
bodyText ||| focused crawling can be sensitive to the baseline harvest
bodyText ||| rate.
bodyText ||| To avoid showing our new system in an unduly positive
bodyText ||| or negative light, we picked a set of topics which were fairly
bodyText ||| diverse, and appeared to be neither too broad to be useful
bodyText ||| (e.g., /Arts, /Science) nor too narrow for the baseline
bodyText ||| crawler to be a reasonable adversary. We list our topics
bodyText ||| in Figure 4. We chose the topics without prior estimates of
bodyText ||| how well our new system would work, and froze the list
bodyText ||| of topics. All topics that we experimented with showed
bodyText ||| visible improvements, and none of them showed deteriorated
bodyText ||| performance.
subsectionHeader ||| 3.3 Baseline crawl results
bodyText ||| We will skip the results of breadth-first or random crawling
bodyText ||| in our commentary, because it is known from earlier work
bodyText ||| on focused crawling that our baseline crawls are already
bodyText ||| far better than breadth-first or random crawls. Figure 5
bodyText ||| shows, for most of the topics listed above, the distribution
bodyText ||| of page relevance after running the baseline crawler to
bodyText ||| collect roughly 15000 to 25000 pages per topic. The E
bodyText ||| baseline crawler used a standard naive Bayes classifier on
bodyText ||| the ordinary term space of whole pages. We see that the
bodyText ||| relevance distribution is bimodal, with most pages being
bodyText ||| very relevant or not at all. This is partly, but only partly, a
bodyText ||| result of using a multinomial naive Bayes model. The naive
bodyText ||| Bayes classifier assumes term independence and multiplies
bodyText ||| together many (small) term probabilities, with the result
bodyText ||| that the winning class usually beats all others by a large
bodyText ||| margin in probability. But it is also true that many outlinks
bodyText ||| lead to pages with completely irrelevant topics. Figure 5
bodyText ||| gives a clear indication of how much improvement we can
bodyText ||| expect for each topic from our new algorithm.
subsectionHeader ||| 3.4 DOM window size and feature selection
bodyText ||| A key concern for us was how to limit the maximum window
bodyText ||| width so that the total number of synthesized (t, d) features
bodyText ||| remains much smaller than the training data for the baseline
bodyText ||| classifier, enabling the apprentice to be trained or upgraded
bodyText ||| in a very short time. At the same time, we did not want
bodyText ||| to lose out on medium- to long-range dependencies between
bodyText ||| significant tokens on a page and the topic of HREF targets
bodyText ||| in the vicinity. We eventually settled for a maximum DOM
bodyText ||| window size of 5. We made this choice through the following
bodyText ||| experiments.
bodyText ||| The easiest initial approach was an end-to-end cross-
bodyText ||| validation of the apprentice for various topics while
bodyText ||| increasing dm x. We observed an initial increase in the
bodyText ||| validation accuracy when the DOM window size was
bodyText ||| increased beyond 0. However, the early increase leveled
bodyText ||| off or even reversed after the DOM window size was
bodyText ||| increased beyond 5. The graphs in Figure 6 display these
bodyText ||| results. We see that in the Chess category, though the
bodyText ||| validation accuracy increases monotonically, the gains are
bodyText ||| less pronounced after dm x exceeds 5. For the AI category,
bodyText ||| accuracy fell beyond dm x = 4.
figure ||| Topic	#Good	#Bad
figure ||| /Arts/Music/Styles/Classical/Composers	24000	13000
figure ||| /Arts/Performing-Arts/Dance/Folk-Dancing	7410	8300
figure ||| /Business/Industries.../Livestock/Horses...	17000	7600
figure ||| /Computers/Artificial-Intelligence	7701	14309
figure ||| /Computers/Software/Operating-Systems/Linux	17500	9300
figure ||| /Games/Board-Games/C/Chess	17000	4600
figure ||| /Health/Conditions-and-Diseases/Cancer	14700	5300
figure ||| /Home/Recipes/Soups-and-Stews	20000	3600
figure ||| /Recreation/Outdoors/Fishing/Fly-Fishing	12000	13300
figure ||| /Recreation/Outdoors/Speleology	6717	14890
figure ||| /Science/Astronomy	14961	5332
figure ||| /Science/Earth-Sciences/Meteorology	19205	8705
figure ||| /Sports/Basketball	26700	2588
figure ||| /Sports/Canoe-and-Kayaking	12000	12700
figure ||| /Sports/Hockey/Ice-Hockey	17500	17900
figureCaption ||| Figure 4: We chose a variety of topics which were neither
figureCaption ||| too broad nor too narrow, so that the baseline crawler
figureCaption ||| was a reasonable adversary. #Good (#Bad) show the
figureCaption ||| approximate number of pages collected by the baseline
figureCaption ||| crawler which have relevance above (below) 0.5, which
figureCaption ||| indicates the relative difficulty of the crawling task.
figureCaption ||| Figure 5: All of the baseline classifiers have harvest rates
figureCaption ||| between 0.25 and 0.6, and all show strongly bimodal
figureCaption ||| relevance score distribution: most of the pages fetched are
figureCaption ||| very relevant or not at all.
bodyText ||| It is important to notice that the improvement in
bodyText ||| accuracy is almost entirely because with increasing number
bodyText ||| of available features, the apprentice can reject negative
bodyText ||| (low relevance) instances more accurately, although the
bodyText ||| accuracy for positive instances decreases slightly. Rejecting
bodyText ||| unpromising outlinks is critical to the success of the
bodyText ||| enhanced crawler. Therefore we would rather lose a little
bodyText ||| accuracy for positive instances rather than do poorly on the
bodyText ||| negative instances. We therefore chose dm x to be either 4
bodyText ||| or 5 for all the experiments.
bodyText ||| We verified that adding offset information to text tokens
bodyText ||| was better than simply using plain text near the link [8].
bodyText ||| One sample result is shown in Figure 7. The apprentice
bodyText ||| accuracy decreases with dm x if only text is used, whereas
bodyText ||| it increases if offset information is provided. This highlights
figure ||| d #pages
figure ||| 100000
figure ||| 10000
figure ||| 1000
figure ||| 100
figure ||| 10
figure ||| Relevance probability
figure ||| AI
figure ||| Astronomy
figure ||| Basketball
figure ||| Cancer
figure ||| Chess
figure ||| Composers
figure ||| FlyFishing
figure ||| FolkDance
figure ||| Horses
figure ||| IceHockey
figure ||| Kayaking
figure ||| Linux
figure ||| Meteorology
figure ||| Soups
figure ||| Tobacco
page ||| 154
figure ||| Chess
figureCaption ||| Figure 6: There is visible improvement in the accuracy
figureCaption ||| of the apprentice if dmax is made larger, up to about 5–
figureCaption ||| 7 depending on topic. The effect is more pronounced on
figureCaption ||| the the ability to correctly reject negative (low relevance)
figureCaption ||| outlink instances. ‘Average’ is the microaverage over all
figureCaption ||| test instances for the apprentice, not the arithmetic mean
figureCaption ||| of ‘Positive’ and ‘Negative’.
figureCaption ||| Figure 7: Encoding DOM offset information with textual
figureCaption ||| features boosts the accuracy of the apprentice substantially.
figureCaption ||| the importance of designing proper features.
bodyText ||| To corroborate the useful ranges of dmax above, we
bodyText ||| compared the value of average mutual information gain for
bodyText ||| terms found at various distances from the target HREF.
bodyText ||| The experiments revealed that the information gain of terms
bodyText ||| found further away from the target HREF was generally
bodyText ||| lower than those that were found closer, but this reduction
bodyText ||| was not monotonic. For instance, the average information
figureCaption ||| Figure 8: Information gain variation plotted against
figureCaption ||| distance from the target HREF for various DOM window
figureCaption ||| sizes. We observe that the information gain is insensitive to
figureCaption ||| dmax.
bodyText ||| gain at d = —2 was higher than that at d = —1; see Figure 8.
bodyText ||| For each DOM window size, we observe that the information
bodyText ||| gain varies in a sawtooth fashion; this intriguing observation
bodyText ||| is explained shortly. The average information gain settled
bodyText ||| to an almost constant value after distance of 5 from the
bodyText ||| target URL. We were initially concerned that to keep the
bodyText ||| computation cost manageable, we would need some cap on
bodyText ||| dmax even while measuring information gain, but luckily,
bodyText ||| the variation of information gain is insensitive to dmax, as
bodyText ||| Figure 8 shows. These observations made our final choice of
bodyText ||| dmax easy.
bodyText ||| In a bid to explain the occurrence of the unexpected
bodyText ||| saw-tooth form in Figure 8 we measured the rate B(t,d) at
bodyText ||| which term t occurred at offset d, relative to the total count
bodyText ||| of all terms occurring at offset d. (They are roughly the
bodyText ||| multinomial naive Bayes term probability parameters.) For
bodyText ||| fixed values of d, we calculated the sum of B values of terms
bodyText ||| found at those offsets from the target HREF. Figure 9(a)
bodyText ||| shows the plot of these sums to the distance(d) for various
bodyText ||| categories. The B values showed a general decrease as the
bodyText ||| distances from the target HREF increased, but this decrease,
bodyText ||| like that of information gain, was not monotonic. The B
bodyText ||| values of the terms at odd numbered distances from the
bodyText ||| target HREF were found to be lower than those of the
bodyText ||| terms present at the even positions. For instance, the sum
bodyText ||| of B values of terms occurring at distance —2 were higher
bodyText ||| than that of terms at position —1. This observation was
bodyText ||| explained by observing the HTML tags that are present
bodyText ||| at various distances from the target HREF. We observed
bodyText ||| that tags located at odd d are mostly non-text tags, thanks
bodyText ||| to authoring idioms such as <li><a ... ><li><a ... > and
bodyText ||| <a...><br><a ... ><br> etc. A plot of the frequency of
bodyText ||| HTML tags against the distance from the HREF at which
figure ||| 0	2	4	6	8
figure ||| d_max
figure ||| 90
figure ||| 85
figure ||| AI
figure ||| 80
figure ||| 75
figure ||| 70
figure ||| 65
figure ||| Negative
figure ||| Positive
figure ||| Average
figure ||| 0 2 dm6 8
figure ||| ax
figure ||| 100
figure ||| 95
figure ||| 90
figure ||| 85
figure ||| 80
figure ||| 75
figure ||| 70
figure ||| 65
figure ||| Negative
figure ||| Positive
figure ||| Average
figure ||| 0	1	2	3	4	5	6	7	8
figure ||| d_max
figure ||| Text
figure ||| Offset
figure ||| 86
figure ||| 84
figure ||| 82
figure ||| 80
figure ||| 78
figure ||| 76
figure ||| AI
figure ||| Chess
figure ||| d_max=8
figure ||| d_max=5
figure ||| d_max=4
figure ||| d_max=3
figure ||| -8	-6	-4	-2	0	2	4	6	8
figure ||| d
figure ||| 0.0002
figure ||| 0.00018
figure ||| 0.00016
figure ||| 0.00014
figure ||| 0.00012
figure ||| 0.0001
figure ||| 0.00008
figure ||| 0.00006
figure ||| 0.00004
figure ||| 0.00002
figure ||| AI
figure ||| -8	-6	-4	-2	0	2	4	6
figure ||| d
figure ||| 9.00E-05
figure ||| 8.00E-05
figure ||| 6.00E-05
figure ||| 5.00E-05
figure ||| 4.00E-05
figure ||| 7.00E-05
figure ||| 1.00E-04
figure ||| d_max=8
figure ||| d_max=5
figure ||| d_max=4
figure ||| d_max=3
page ||| 155
figureCaption ||| Figure 9: Variation of (a) relative term frequencies and
figureCaption ||| (b) frequencies of HTML tags plotted against d.
bodyText ||| they were found is shown in Figure 9(b). (The <a...> tag
bodyText ||| obviously has the highest frequency and has been removed
bodyText ||| for clarity.)
bodyText ||| These were important DOM idioms, spanning many
bodyText ||| diverse Web sites and authoring styles, that we did not
bodyText ||| anticipate ahead of time. Learning to recognize these
bodyText ||| idioms was valuable for boosting the harvest of the enhanced
bodyText ||| crawler. Yet, it would be unreasonable for the user-supplied
bodyText ||| baseline black-box predicate or learner to capture crawling
bodyText ||| strategies at such a low level. This is the ideal job of
bodyText ||| the apprentice. The apprentice took only 3–10 minutes
bodyText ||| to train on its (u, v) instances from scratch, despite a
bodyText ||| simple implementation that wrote a small file to disk for
bodyText ||| each instance of the apprentice. Contrast this with several
bodyText ||| hours taken by the baseline learner to learn general term
bodyText ||| distribution for topics.
subsectionHeader ||| 3.5 Crawling with the apprentice trained
subsectionHeader ||| off-line
bodyText ||| In this section we subject the apprentice to a “field test” as
bodyText ||| part of the crawler, as shown in Figure 2. To do this we
bodyText ||| follow these steps:
listItem ||| 1. Fix a topic and start the baseline crawler from all
listItem ||| example URLs available from the given topic.
listItem ||| 2. Run the baseline crawler until roughly 20000–25000
listItem ||| pages have been fetched.
listItem ||| 3. For all pages (u, v) such that both u and v have
listItem ||| been fetched by the baseline crawler, prepare an
listItem ||| instance from (u, v) and add to the training set of
listItem ||| the apprentice.
listItem ||| 4. Train the apprentice. Set a suitable value for dmax.
listItem ||| Folk Dancing
figure ||| 0	2000	4000	6000	8000	10000
figure ||| #Pages fetched
figure ||| Ice Hockey
figureCaption ||| Figure 10: Guidance from the apprentice significantly
figureCaption ||| reduces the loss rate of the focused crawler.
listItem ||| 5. Start the enhanced crawler from the same set of pages
listItem ||| that the baseline crawler had started from.
listItem ||| 6. Run the enhanced crawler to fetch about the same
listItem ||| number of pages as the baseline crawler.
listItem ||| 7. Compare the loss rates of the two crawlers.
bodyText ||| Unlike with the reinforcement learner studied by Rennie
bodyText ||| and McCallum, we have no predetermined universe of URLs
bodyText ||| which constitute the relevant set; our crawler must go
bodyText ||| forth into the open Web and collect relevant pages from
bodyText ||| an unspecified number of sites. Therefore, measuring recall
bodyText ||| w.r.t. the baseline is not very meaningful (although we do
bodyText ||| report such numbers, for completeness, in §3.6). Instead, we
bodyText ||| measure the loss (the number of pages fetched which had to
bodyText ||| be thrown away owing to poor relevance) at various epochs
bodyText ||| in the crawl, where time is measured as the number of pages
bodyText ||| fetched (to elide fluctuating network delay and bandwidth).
bodyText ||| At epoch n, if the pages fetched are v1, ... , vn, then the total
bodyText ||| expected loss is (1/n) Pi (1− Pr(c*|vi)).
bodyText ||| Figure 10 shows the loss plotted against the number of
bodyText ||| pages crawled for two topics: Folk dancing and Ice hockey.
bodyText ||| The behavior for Folk dancing is typical; Ice hockey is
bodyText ||| one of the best examples. In both cases, the loss goes up
bodyText ||| substantially faster with each crawled page for the baseline
bodyText ||| crawler than for the enhanced crawler. The reduction of loss
bodyText ||| for these topics are 40% and 90% respectively; typically, this
bodyText ||| number is between 30% and 60%. In other words, for most
figure ||| -5 -4 -3 -2 -1	0	1	2	3	4	5
figure ||| AI
figure ||| Chess
figure ||| Horses
figure ||| Cancer
figure ||| IceHockey
figure ||| Linux
figure ||| Bball+
figure ||| Bball-
figure ||| 9000	Tags at various DOM offsets
figure ||| 8000
figure ||| 7000
figure ||| 6000
figure ||| 5000
figure ||| 4000
figure ||| 3000
figure ||| font
figure ||| td
figure ||| img
figure ||| b
figure ||| br
figure ||| p
figure ||| tr
figure ||| li
figure ||| comment
figure ||| div
figure ||| table
figure ||| center
figure ||| i
figure ||| span
figure ||| hr
figure ||| 2000
figure ||| 1000
figure ||| 0
figure ||| -5 -4 -3 -2 -1 0	1	2 3	4 5 d
figure ||| 0.2
figure ||| 0.18
figure ||| 0.16
figure ||| 0.14
figure ||| 0.12
figure ||| 0.1
figure ||| 0.08
figure ||| 0.06
figure ||| 0.04
figure ||| 0.02
figure ||| d
figure ||| Baseline
figure ||| Apprentice
figure ||| Baseline
figure ||| Apprentice
figure ||| 8000
figure ||| 4000
figure ||| 0
figure ||| 0	4000 8000 12000 16000 20000
figure ||| #Pages fetched
figure ||| 	6000
figure ||| 	4000
figure ||| 	2000
figure ||| 	0
page ||| 156
bodyText ||| topics, the apprentice reduces the number of useless pages
bodyText ||| fetched by one-third to two-thirds.
bodyText ||| In a sense, comparing loss rates is the most meaningful
bodyText ||| evaluation in our setting, because the network cost of
bodyText ||| fetching relevant pages has to be paid anyway, and can be
bodyText ||| regarded as a fixed cost. Diligenti et al. show significant
bodyText ||| improvements in harvest rate, but for their topics, the loss
bodyText ||| rate for both the baseline crawler as well as the context-
bodyText ||| focused crawler were much higher than ours.
subsectionHeader ||| 3.6 URL overlap and recall
bodyText ||| The reader may feel that the apprentice crawler has an
bodyText ||| unfair advantage because it is first trained on DOM-derived
bodyText ||| features from the same set of pages that it has to crawl
bodyText ||| again. We claim that the set of pages visited by the baseline
bodyText ||| crawler and thea(off-linentrained) enhanced crawler have
bodyText ||| small overlap, and the superior results for the crawler guided 4011 8168 2199
bodyText ||| by the apprentice are in large part because of generalizable
bodyText ||| learning. Thisgcan be seen from the examples in Figure 11.
figureCaption ||| Figure 11: The apprentice-guided crawler follows paths
figureCaption ||| which are quite different from the baseline crawler because
figureCaption ||| of its superior priority estimation technique. As a result
figureCaption ||| there is little overlap between the URLs harvested by these
figureCaption ||| two crawlers.
bodyText ||| Given that the overlap between the baseline and the
bodyText ||| enhanced crawlers is small, which is ‘better’? As per the
bodyText ||| verdict of the baseline classifier, clearly the enhanced crawler
bodyText ||| is better. Even so, we report the loss rate of a different
bodyText ||| version of the enhanced crawler which is restricted to visiting
bodyText ||| only those pages which were visited by the baseline learner.
bodyText ||| We call this crawler the recall crawler. This means that in
bodyText ||| the end, both crawlers have collected exactly the same set
bodyText ||| of pages, and therefore have the same total loss. The test
bodyText ||| then is how long can the enhanced learner prevent the loss
bodyText ||| from approaching the baseline loss. These experiments are a
bodyText ||| rough analog of the ‘recall’ experiments done by Rennie and
bodyText ||| McCallum. We note that for these recall experiments, the
bodyText ||| apprentice does get the benefit of not having to generalize,
bodyText ||| so the gap between baseline loss and recall loss could be
bodyText ||| optimistic. Figure 12 compares the expected total loss of
bodyText ||| the baseline crawler, the recall crawler, and the apprentice-
bodyText ||| guided crawler (which is free to wander outside the baseline
bodyText ||| collection) plotted against the number of pages fetched, for a
bodyText ||| few topics. As expected, the recall crawler has loss generally
figure ||| Ice Hockey
figure ||| 0	1000 2000 3000 4000 5000 6000
figure ||| #Pages fetched
figure ||| Kayaking
figure ||| 0	5000	10000	15000	20000
figure ||| #Pages fetched
figureCaption ||| Figure 12: Recall for a crawler using the apprentice but
figureCaption ||| limited to the set of pages crawled earlier by the baseline
figureCaption ||| crawler.
bodyText ||| somewhere between the loss of the baseline and the enhanced
bodyText ||| crawler.
subsectionHeader ||| 3.7 Effect of training the apprentice online
bodyText ||| Next we observe the effect of a mid-flight correction when
bodyText ||| the apprentice is trained some way into a baseline and
bodyText ||| switched into the circuit. The precise steps were:
listItem ||| 1. Run the baseline crawler for the first n page fetches,
listItem ||| then stop it.
listItem ||| 2. Prepare instances and train the apprentice.
listItem ||| 3. Re-evaluate the priorities of all unvisited pages v in
listItem ||| the frontier table using the apprentice.
listItem ||| 4. Switch in the apprentice and resume an enhanced
listItem ||| crawl.
bodyText ||| We report our experience with “Folk Dancing.” The baseline
bodyText ||| crawl was stopped after 5200 pages were fetched. Re-
bodyText ||| evaluating the priority of frontier nodes led to radical
bodyText ||| changes in their individual ranks as well as the priority
bodyText ||| distributions. As shown in Figure 13(a), the baseline learner
bodyText ||| is overly optimistic about the yield it expects from the
bodyText ||| frontier, whereas the apprentice already abandons a large
bodyText ||| fraction of frontier outlinks, and is less optimistic about
figure ||| 35%
figure ||| Baseline
figure ||| Apprentice
figure ||| Intersect
figure ||| Baseline
figure ||| Apprentice
figure ||| Intersect
figure ||| Basketball
figure ||| 4%
figure ||| FolkDance
figure ||| 9%
figure ||| 47%
figure ||| Baseline
figure ||| Apprentice
figure ||| Intersect
figure ||| 3%
figure ||| 39%
figure ||| 34%
figure ||| Baseline
figure ||| Apprentice
figure ||| Intersect
figure ||| 17%
figure ||| 57%
figure ||| FlyFishing
figure ||| 48%
figure ||| 49%
figure ||| 58%
figure ||| IceHockey
figure ||| Baseline
figure ||| Recall
figure ||| Apprentice
figure ||| 1000
figure ||| 0
figure ||| Baseline
figure ||| Recall
figure ||| Apprentice
figure ||| 	10000
figure ||| 	5000
figure ||| 	0
figure ||| 157
figure ||| Folk Dancing
figureCaption ||| Figure 13: The effect of online training of the apprentice.
bodyText ||| The apprentice makes sweeping changes in the
bodyText ||| estimated promise of unvisited nodes in the crawl frontier.
bodyText ||| (b) Resuming the crawl under the guidance of the
bodyText ||| apprentice immediately shows significant reduction in the
bodyText ||| loss accumulation rate.
bodyText ||| the others, which appears more accurate from the Bayesian
bodyText ||| perspective.
bodyText ||| Figure 13(b) shows the effect of resuming an enhanced
bodyText ||| crawl guided by the trained apprentice. The new (u, v)
bodyText ||| instances are all guaranteed to be unknown to the apprentice
bodyText ||| now. It is clear that the apprentice’s prioritization
bodyText ||| immediately starts reducing the loss rate. Figure 14 shows
bodyText ||| an even more impressive example. There are additional mild
bodyText ||| gains from retraining the apprentice at later points. It may
bodyText ||| be possible to show a more gradual online learning effect
bodyText ||| by retraining the classifier at a finer interval, e.g., every
bodyText ||| 100 page fetches, similar to Aggarwal et al. In our context,
bodyText ||| however, losing a thousand pages at the outset because of
bodyText ||| the baseline crawler’s limitation is not a disaster, so we need
bodyText ||| not bother.
subsectionHeader ||| 3.8 Effect of other features
bodyText ||| We experimented with two other kinds of feature, which we
bodyText ||| call topic and cocitation features.
bodyText ||| Our limiting dmax to 5 may deprive the apprentice of
bodyText ||| important features in the source page u which are far from
bodyText ||| the link (u, v). One indirect way to reveal such features
bodyText ||| to the apprentice is to classify u, and to add the names
bodyText ||| of some of the top-scoring classes for u to the instance
bodyText ||| (u, v). §2.2.3 explains why this may help. This modification
bodyText ||| resulted in a 1% increase in the accuracy of the apprentice.
bodyText ||| A further increase of 1% was observed if we added all
figureCaption ||| Figure 14: Another example of training the apprentice
figureCaption ||| online followed by starting to use it for crawl guidance.
figureCaption ||| Before guidance, loss accumulation rate is over 30%, after,
figureCaption ||| it drops to only 6%.
bodyText ||| prefixes of the class name. For example, the full name
bodyText ||| for the Linux category is /Computers/Software/Operating-
bodyText ||| Systems/Linux. We added all of the following to the
bodyText ||| feature set of the source page: /, /Computers, /Computers/
bodyText ||| Software, /Computers/Software/Operating-Systems and
bodyText ||| /Computers/Software/Operating-Systems/Linux. We also
bodyText ||| noted that various class names and some of their prefixes
bodyText ||| appeared amongst the best discriminants of the positive and
bodyText ||| negative classes.
bodyText ||| Cocitation features for the link (u, v) are constructed by
bodyText ||| looking for other links (u, w) within a DOM distance of dmax
bodyText ||| such that w has already been fetched, so that Pr(c*Iw) is
bodyText ||| known. We discretize Pr(c*Iw) to two values HiGH and Low
bodyText ||| as in §2.3, and encode the feature as (Low, d) or (HiGH, d).
bodyText ||| The use of cocitation features did not improve the accuracy
bodyText ||| of the apprentice to any appreciable extent.
bodyText ||| For both kinds of features, we estimated that random
bodyText ||| variations in crawling behavior (because of fluctuating
bodyText ||| network load and tie-breaking frontier scores) may prevent
bodyText ||| us from measuring an actual benefit to crawling under
bodyText ||| realistic operating conditions. We note that these ideas may
bodyText ||| be useful in other settings.
sectionHeader ||| 4 Conclusion
bodyText ||| We have presented a simple enhancement to a focused
bodyText ||| crawler that helps assign better priorities to the unvisited
bodyText ||| URLs in the crawl frontier. This leads to a higher rate of
bodyText ||| fetching pages relevant to the focus topic and fewer false
bodyText ||| positives which must be discarded after spending network,
bodyText ||| CPU and storage resources processing them. There is no
bodyText ||| need to manually train the system with paths leading to
bodyText ||| relevant pages. The key idea is an apprentice learner which
bodyText ||| can accurately predict the worth of fetching a page using
bodyText ||| DOM features on pages that link to it. We show that the
bodyText ||| DOM features we use are superior to simpler alternatives.
bodyText ||| Using topics from Dmoz, we show that our new system can
bodyText ||| cut down the fraction of false positives by 30–90%.
bodyText ||| We are exploring several directions in ongoing work.
bodyText ||| We wish to revisit continuous regression techniques for the
bodyText ||| apprentice, as well as more extensive features derived from
bodyText ||| the DOM. For example, we can associate with a token t the
bodyText ||| length $ of the DOM path from the text node containing t to
figure ||| 0	0-.2	.2-.4.4-.6	.6-.8.8-1
figure ||| Estimated relevance of outlinks
figure ||| Baseline
figure ||| Apprentice
figure ||| (b)	4500	#Pages crawled	5500
figure ||| Collect instances
figure ||| for apprentice
figure ||| Train
figure ||| apprentice
figure ||| Apprentice
figure ||| guides crawl
figure ||| Folk Dancing
figure ||| 2700
figure ||| 2600
figure ||| 2500
figure ||| 2400
figure ||| 2300
figure ||| 2200
figure ||| 2100
figure ||| 12000
figure ||| 10000
figure ||| 8000
figure ||| 6000
figure ||| 4000
figure ||| 2000
figure ||| 0
figure ||| 1800
figure ||| 1600
figure ||| 1400
figure ||| 1200
figure ||| 1000
figure ||| 800
figure ||| 600
figure ||| 2000 3000 4000 5000 6000 7000 8000
figure ||| #Pages fetched
figure ||| Collect
figure ||| instances for
figure ||| apprentice
figure ||| Classical Composers
figure ||| Train
figure ||| apprentice
figure ||| Apprentice
figure ||| guides crawl
page ||| 158
bodyText ||| the HREF to v, or the depth of their least common ancestor
bodyText ||| in the DOM tree. We cannot use these in lieu of DOM offset,
bodyText ||| because regions which are far apart lexically may be close
bodyText ||| to each other along a DOM path. (t, f, d) features will be
bodyText ||| more numerous and sparser than (t, d) features, and could
bodyText ||| be harder to learn. The introduction of large numbers of
bodyText ||| strongly dependent features may even reduce the accuracy
bodyText ||| of the apprentice. Finally, we wish to implement some form
bodyText ||| of active learning where only those instances (u, v) with the
bodyText ||| largest I Pr(c* Iu) - Pr(c* Iv) I are chosen as training instances
bodyText ||| for the apprentice.
bodyText ||| Acknowledgments: Thanks to the referees for suggest-
bodyText ||| ing that we present Figure 7.
sectionHeader ||| References
reference ||| [1] C. C. Aggarwal, F. Al-Garawi, and P. S. Yu. Intelligent
reference ||| crawling on the World Wide Web with arbitrary predicates. In
reference ||| WWW2001, Hong Kong, May 2001. ACM. Online at http:
reference ||| //www10.org/cdrom/papers/110/.
reference ||| [2] C. Apte, F. Damerau, and S. M. Weiss. Automated learning
reference ||| of decision rules for text categorization. ACM Transactions on
reference ||| Information Systems, 1994. IBM Research Report RC18879.
reference ||| [3] A. Blum and T. M. Mitchell. Combining labeled and unlabeled
reference ||| data with co-training. In Computational Learning Theory,
reference ||| pages 92–100,1998.
reference ||| [4] S. Chakrabarti. Integrating the document object model with
reference ||| hyperlinks for enhanced topic distillation and information
reference ||| extraction. In WWW 10, Hong Kong, May 2001. Online at
reference ||| http://www10.org/cdrom/papers/489.
reference ||| [5] S. Chakrabarti, B. Dom, R. Agrawal, and P. Raghavan.
reference ||| Scalable feature selection, classification and signature generation
reference ||| for organizing large text databases into hierarchical topic
reference ||| taxonomies. VLDB Journal, Aug. 1998. Online at http:
reference ||| //www.cs.berkeley.edu/~soumen/VLDB54_3.PDF.
reference ||| [6] S. Chakrabarti, B. Dom, D. Gibson, J. Kleinberg, P. Raghavan,
reference ||| and S. Rajagopalan.	Automatic resource compilation by
reference ||| analyzing hyperlink structure and associated text. In 7th World-
reference ||| wide web conference (WWW7), 1998. Online at http://www7.
reference ||| scu.edu.au/programme/fullpapers/1898/com1898.html.
reference ||| [7] S. Chakrabarti, B. Dom, and P. Indyk. Enhanced hypertext
reference ||| categorization using hyperlinks. In SIGMOD Conference. ACM,
reference ||| 1998. Online at http://www.cs.berkeley.edu/~soumen/sigmod98.
reference ||| ps.
reference ||| [8] S. Chakrabarti, B. E. Dom, D. A. Gibson, R. Kumar,
reference ||| P. Raghavan, S. Rajagopalan, and A. Tomkins. Topic distillation
reference ||| and spectral filtering. Artificial Intelligence Review, 13(5–
reference ||| 6):409–435, 1999.
reference ||| [9] S. Chakrabarti, M. van den Berg, and B. Dom. Focused
reference ||| crawling: a new approach to topic-specific web resource
reference ||| discovery. Computer Networks, 31:1623–1640, 1999. First
reference ||| appeared in the 8th International World Wide Web Conference,
reference ||| Toronto, May 1999. Available online at http://www8.org/
reference ||| w8-papers/5a-search-query/crawling/index.html.
reference ||| [10] J. Cho, H. Garcia-Molina, and L. Page. Efficient crawling
reference ||| through URL ordering. In 7th World Wide Web Conference,
reference ||| Brisbane, Australia, Apr. 1998. Online at http://www7.scu.edu.
reference ||| au/programme/fullpapers/1919/com1919.htm.
reference ||| [11] B. D. Davison. Topical locality in the Web. In Proceedings
reference ||| of the 23rd Annual International Conference on Research and
reference ||| Development in Information Retrieval (SIGIR 2000), pages
reference ||| 272–279, Athens, Greece, July 2000. ACM. Online at http://
reference ||| www.cs.rutgers.edu/~davison/pubs/2000/sigir/.
reference ||| [12] P. M. E. De Bra and R. D. J. Post. Information retrieval
reference ||| in the world-wide web: Making client-based searching feasible.
reference ||| In Proceedings of the First International World Wide Web
reference ||| Conference, Geneva, Switzerland, 1994. Online at http://www1.
reference ||| cern.ch/PapersWWW94/reinpost.ps.
reference ||| [13] P. M. E. De Bra and R. D. J. Post. Searching for arbitrary
reference ||| information in the WWW: The fish search for Mosaic. In Second
reference ||| World Wide Web Conference ’9¢: Mosaic and the Web,
reference ||| Chicago, Oct. 1994. Online at http://archive.ncsa.uiuc.edu/
reference ||| SDG/IT94/Proceedings/Searching/debra/article.html and http:
reference ||| //citeseer.nj.nec.com/172936.html.
reference ||| [14] M. Diligenti, F. Coetzee, S. Lawrence, C. L. Giles, and M. Gori.
reference ||| Focused crawling using context graphs. In A. E. Abbadi, M. L.
reference ||| Brodie, S. Chakravarthy, U. Dayal, N. Kamel, G. Schlageter,
reference ||| and K.-Y. Whang, editors, VLDB 2000, Proceedings of
reference ||| 26th International Conference on Very Large Data Bases,
reference ||| September 10-1¢, 2000, Cairo, Egypt, pages 527–534. Morgan
reference ||| Kaufmann, 2000. Online at http://www.neci.nec.com/~lawrence/
reference ||| papers/focus-vldb00/focus-vldb00.pdf.
reference ||| [15] W. A. Gale, K. W. Church, and D. Yarowsky. A method for
reference ||| disambiguating word senses in a large corpus. Computer and
reference ||| the Humanities, 26:415–439, 1993.
reference ||| [16] M. Hersovici, M. Jacovi, Y. S. Maarek, D. Pelleg, M. Shtalhaim,
reference ||| and S. Ur. The shark-search algorithm—an application: Tailored
reference ||| Web site mapping. In WWW7, 1998. Online at http://www7.scu.
reference ||| edu.au/programme/fullpapers/1849/com1849.htm.
reference ||| [17] T. Joachims, D. Freitag, and T. Mitchell. Web Watcher: A tour
reference ||| guide for the web. In IJCAI, Aug. 1997. Online at http://www.
reference ||| cs.cmu.edu/~webwatcher/ijcai97.ps.
reference ||| [18] H. Leiberman. Letizia: An agent that assists Web browsing. In
reference ||| International Joint Conference on Artificial Intelligence (IJ-
reference ||| CAI), Montreal, Aug. 1995. See Website at http://lieber.www.
reference ||| media.mit.edu/people/lieber/Lieberary/Letizia/Letizia.html.
reference ||| [19] H. Leiberman, C. Fry, and L. Weitzman. Exploring the Web
reference ||| with reconnaissance agents. CACM, 44(8):69–75, Aug. 2001.
reference ||| http://www.acm.org/cacm.
reference ||| [20] A. McCallum. Bow: A toolkit for statistical language modeling,
reference ||| text retrieval, classification and clustering. Software available
reference ||| from http://www.cs.cmu.edu/~mccallum/bow/,1998.
reference ||| [21] A. McCallum and K. Nigam. A comparison of event models for
reference ||| naive Bayes text classification. In AAAI/ICML-98 Workshop
reference ||| on Learning for Teat Categorization, pages 41–48. AAAI Press,
reference ||| 1998. Online at http://www.cs.cmu.edu/~knigam/.
reference ||| [22] A. McCallum and K. Nigam. A comparison of event models for
reference ||| naive Bayes text classification. In AAAI/ICML-98 Workshop
reference ||| on Learning for Teat Categorization, pages 41–48. AAAI Press,
reference ||| 1998. Also technical report WS-98-05, CMU; online at http:
reference ||| //www.cs.cmu.edu/~knigam/papers/multinomial-aaaiws98.pdf.
reference ||| [23] F. Menczer. Links tell us about lexical and semantic
reference ||| Web content. Technical Report Computer Science Abstract
reference ||| CS.IR/0108004, arXiv.org, Aug. 2001. Online at http://arxiv.
reference ||| org/abs/cs.IR/0108004.
reference ||| [24] F. Menczer and R. K. Belew. Adaptive retrieval agents:
reference ||| Internalizing local context and scaling up to the Web. Machine
reference ||| Learning, 39(2/3):203–242, 2000. Longer version available as
reference ||| Technical Report CS98-579, http://dollar.biz.uiowa.edu/~fil/
reference ||| Papers/MLJ.ps, University of California, San Diego.
reference ||| [25] F. Menczer, G. Pant, M. Ruiz, and P. Srinivasan. Evaluating
reference ||| topic-driven Web crawlers. In SIGIR, New Orleans, Sept. 2001.
reference ||| ACM.	Online at http://dollar.biz.uiowa.edu/~fil/Papers/
reference ||| sigir-01.pdf.
reference ||| [26] T. Mitchell. Machine Learning. McGraw Hill, 1997.
reference ||| [27] T. Mitchell. Mining the Web. In SIGIR 2001, Sept. 2001. Invited
reference ||| talk.
reference ||| [28] S. Mukherjea. WTMS: a system for collecting and analyzing
reference ||| topic-specific Web information. WWW9/Computer Networks,
reference ||| 33(1–6):457–471, 2000. Online at http://www9.org/w9cdrom/293/
reference ||| 293.html.
reference ||| [29] S. RaviKumar, P. Raghavan, S. Rajagopalan, D. Sivakumar,
reference ||| A. Tomkins, and E. Upfal. Stochastic models for the Web graph.
reference ||| In FOCS, volume 41, pages 57–65. IEEE, nov 2000. Online at
reference ||| http://www.cs.brown.edu/people/eli/papers/focs00.ps.
reference ||| [30] J. Rennie and A. McCallum. Using reinforcement learning to
reference ||| spider the web efficiently. In ICML, 1999. Online at http://
reference ||| www.cs.cmu.edu/~mccallum/papers/rlspider-icml99s.ps.gz.
reference ||| [31] G. Salton and M. J. McGill. Introduction to Modern
reference ||| Information Retrieval. McGraw-Hill, 1983.
reference ||| [32] M. Subramanyam, G. V. R. Phanindra, M. Tiwari, and M. Jain.
reference ||| Focused crawling using TFIDF centroid. Hypertext Retrieval
reference ||| and Mining (CS610) class project, Apr. 2001. Details available
reference ||| from manyam@cs.utexas.edu.
reference ||| [33] L. Torgo and J. Gama. Regression by classification. In D. Borges
reference ||| and C. Kaestner, editors, Brasilian AI Symposium, volume 1159
reference ||| of Lecture Notes in Artificial Intelligence, Curitiba, Brazil,
reference ||| 1996. Springer-Verlag. Online at http://www.ncc.up.pt/~ltorgo/
reference ||| Papers/list_pub.html.
page ||| 159

title ||| A Computational Approach to Reflective Meta-Reasoning about
title ||| Languages with Bindings *
author ||| Aleksey Nogin Alexei Kopylov Xin Yu Jason Hickey
affiliation ||| Department of Computer Science
affiliation ||| California Institute of Technology
address ||| M/C 256-80, Pasadena, CA 91125
email ||| {nogin,kopylov,xiny,jyh}@cs.caltech.edu
sectionHeader ||| Abstract
bodyText ||| We present a foundation for a computational meta-theory of lan-
bodyText ||| guages with bindings implemented in a computer-aided formal rea-
bodyText ||| soning environment. Our theory provides the ability to reason ab-
bodyText ||| stractly about operators, languages, open-ended languages, classes
bodyText ||| of languages, etc. The theory is based on the ideas of higher-order
bodyText ||| abstract syntax, with an appropriate induction principle parameter-
bodyText ||| ized over the language (i. e. a set of operators) being used. In our ap-
bodyText ||| proach, both the bound and free variables are treated uniformly and
bodyText ||| this uniform treatment extends naturally to variable-length bind-
bodyText ||| ings. The implementation is reflective, namely there is a natural
bodyText ||| mapping between the meta-language of the theorem-prover and the
bodyText ||| object language of our theory. The object language substitution op-
bodyText ||| eration is mapped to the meta-language substitution and does not
bodyText ||| need to be defined recursively. Our approach does not require de-
bodyText ||| signing a custom type theory; in this paper we describe the im-
bodyText ||| plementation of this foundational theory within a general-purpose
bodyText ||| type theory. This work is fully implemented in the MetaPRL the-
bodyText ||| orem prover, using the pre-existing NuPRL-like Martin-L¨of-style
bodyText ||| computational type theory. Based on this implementation, we lay
bodyText ||| out an outline for a framework for programming language experi-
bodyText ||| mentation and exploration as well as a general reflective reasoning
bodyText ||| framework. This paper also includes a short survey of the existing
bodyText ||| approaches to syntactic reflection.
sectionHeader ||| Categories and Subject Descriptors D.3.1 [Programming Lan-
sectionHeader ||| guages]: Formal Definitions and Theory—Syntax; F.4.3 [Math-
sectionHeader ||| ematical Logic and Formal Languages]: Formal Languages—
sectionHeader ||| Operations on languages
sectionHeader ||| General Terms Languages, Theory, Verification
sectionHeader ||| Keywords Higher-Order Abstract Syntax, Reflection, Type The-
sectionHeader ||| ory, Meta PRL, N uPRL, Programming Language Experimentation,
sectionHeader ||| Languages with Bindings.
footnote ||| * An extended version of this paper is available as Caltech Technical Report
footnote ||| CaltechCSTR:2005.003 [NKYH05]
copyright ||| Permission to make digital or hard copies of all or part of this work for personal or
copyright ||| classroom use is granted without fee provided that copies are not made or distributed
copyright ||| for profit or commercial advantage and that copies bear this notice and the full citation
copyright ||| on the first page. To copy otherwise, to republish, to post on servers or to redistribute
copyright ||| to lists, requires prior specific permission and/or a fee.
note ||| MERLIN’05 September 30, 2005, Tallinn, Estonia.
copyright ||| Copyright �c 2005 ACM 1-59593-072-8/05/0009...$5.00.
sectionHeader ||| 1. Introduction
subsectionHeader ||| 1.1 Reflection
bodyText ||| Very generally, reflection is the ability of a system to be “self-
bodyText ||| aware” in some way. More specifically, by reflection we mean the
bodyText ||| property of a computational or formal system to be able to access
bodyText ||| and internalize some of its own properties.
bodyText ||| There are many areas of computer science where reflection
bodyText ||| plays or should play a major role. When exploring properties of
bodyText ||| programming languages (and other languages) one often realizes
bodyText ||| that languages have at least two kinds of properties — semantic
bodyText ||| properties that have to do with the meaning of what the language’s
bodyText ||| constructs express and syntactic properties of the language itself.
bodyText ||| Suppose for example that we are exploring some language that
bodyText ||| contains arithmetic operations. And in particular, in this language
bodyText ||| one can write polynomials like x2 +2x + 1. In this case the number
bodyText ||| of roots of a polynomial is a semantic property since it has to do
bodyText ||| with the valuation of the polynomial. On the other hand, the degree
bodyText ||| of a polynomial could be considered an example of a syntactic
bodyText ||| property since the most natural way to define it is as a property of
bodyText ||| the expression that represents that polynomial. Of course, syntactic
bodyText ||| properties often have semantic consequences, which is what makes
bodyText ||| them especially important. In this example, the number of roots of
bodyText ||| a polynomial is bounded by its degree.
bodyText ||| Another area where reflection plays an important role is run-
bodyText ||| time code generation — in most cases, a language that supports
bodyText ||| run-time code generation is essentially reflective, as it is capable
bodyText ||| of manipulating its own syntax. In order to reason about run-time
bodyText ||| code generation and to express its semantics and properties, it is
bodyText ||| natural to use a reasoning system that is reflective as well.
bodyText ||| There are many different flavors of reflection. The syntactic
bodyText ||| reflection we have seen in the examples above, which is the ability
bodyText ||| of a system to internalize its own syntax, is just one of these
bodyText ||| many flavors. Another very important kind of reflection is logical
bodyText ||| reflection, which is the ability of a reasoning system or logic to
bodyText ||| internalize and reason about its own logical properties. A good
bodyText ||| example of a logical reflection is reasoning about knowledge —
bodyText ||| since the result of reasoning about knowledge is knowledge itself,
bodyText ||| the logic of knowledge is naturally reflective [Art04].
bodyText ||| In most cases it is natural for reflection to be iterated. In the
bodyText ||| case of syntactic reflection we might care not only about the syntax
bodyText ||| of our language, but also about the syntax used for expressing the
bodyText ||| syntax, the syntax for expressing the syntax for expressing the
bodyText ||| syntax and so forth. In the case of the logic of knowledge it is
bodyText ||| natural to have iterations of the form “I know that he knows that
bodyText ||| I know ...”.
bodyText ||| When a formal system is used to reason about properties of pro-
bodyText ||| gramming languages, iterated reflection magnifies the power of the
page ||| 2
bodyText ||| system, making it more natural to reason not just about individual
bodyText ||| languages, but also about classes of languages, language schemas,
bodyText ||| and so on. More generally, reflection adds a lot of additional power
bodyText ||| to a formal reasoning system [GS89, Art99]. In particular, it is
bodyText ||| well-known [G¨od36, Mos52, EM71, Par71] that reflection allows
bodyText ||| a super-exponential reduction in the size of certain proofs. In addi-
bodyText ||| tion, reflection could be a very useful mechanism for implement-
bodyText ||| ing proof search algorithms [ACU93, GWZ00, CFW04]. See also
bodyText ||| [Har95] for a survey of reflection in theorem proving.
subsectionHeader ||| 1.2 Uniform Reflection Framework
bodyText ||| For each of the examples in the previous section there are many
bodyText ||| ad-hoc ways of achieving the specific benefits of a specific fla-
bodyText ||| vor of reflection. This work aims at creating a unifying reflective
bodyText ||| framework that would allow achieving most of these benefits in a
bodyText ||| uniform manner, without having to reinvent and re-implement the
bodyText ||| basic reflective methodology every time. We believe that such a
bodyText ||| framework will increase the power of the formal reasoning tools,
bodyText ||| and it may also become an invaluable tool for exploring the proper-
bodyText ||| ties of novel programming languages, for analyzing run-time code
bodyText ||| generation, and for formalizing logics of knowledge.
bodyText ||| This paper establishes a foundation for the development of this
bodyText ||| framework — a new approach to reflective meta-reasoning about
bodyText ||| languages with bindings. We present a theory of syntax that:
listItem ||| •	in a natural way provides both a higher-order abstract syntax
listItem ||| (HOAS) approach to bindings and a de Bruijn-style approach
listItem ||| to bindings, with easy and natural translation between the two;
listItem ||| •	provides a uniform HOAS-style approach to both bound and
listItem ||| free variables that extends naturally to variable-length “vectors”
listItem ||| of binders;
listItem ||| •	permits meta-reasoning about languages — in particular, the
listItem ||| operators, languages, open-ended languages, classes of lan-
listItem ||| guages etc. are all first-class objects that can be reasoned about
listItem ||| both abstractly and concretely;
listItem ||| •	comes with a natural induction principle for syntax that can be
listItem ||| parameterized by the language being used;
listItem ||| •	provides a natural mapping between the object syntax and meta-
listItem ||| syntax that is free of exotic terms, and allows mapping the
listItem ||| object-level substitution operation directly to the meta-level one
listItem ||| (i.e. P-reduction);
listItem ||| •	is fully derived in a pre-existing type theory in a theorem
listItem ||| prover;
listItem ||| •	is designed to serve as a foundation for a general reflective
listItem ||| reasoning framework in a theorem prover;
listItem ||| •	is designed to serve as a foundation for a programming lan-
listItem ||| guage experimentation framework.
bodyText ||| The paper is structured as follows. Our work inherits a large
bodyText ||| number of ideas from previous efforts and we start in Section 2
bodyText ||| with a brief survey of existing techniques for formal reasoning
bodyText ||| about syntax. Next in Section 3 we outline our approach to rea-
bodyText ||| soning about syntax and in Section 4 we present a formal account
bodyText ||| of our theory based on a Martin-L¨of style computational type the-
bodyText ||| ory [CAB+86, HAB+] and the implementation of that account in
bodyText ||| the MetaPRL theorem prover [Hic97, Hic99, Hic01, HNC+03,
bodyText ||| HNK+, HAB+]. Then in Section 5 we outline our plan for building
bodyText ||| a uniform reflection framework based on the syntactic reflection.
bodyText ||| Finally, in Section 6 we resume the discussion of related work that
bodyText ||| was started in Section 2.
bodyText ||| 1.3 Notation and Terminology
bodyText ||| We believe that our approach to reasoning about syntax is fairly
bodyText ||| general and does not rely on any special features of the theo-
bodyText ||| rem prover we use. However, since we implement this theory in
bodyText ||| MetaPRL, we introduce some basic knowledge about MetaPRL
bodyText ||| terms.
bodyText ||| A MetaPRL term consists of:
listItem ||| 1. An operator name (like “sum”), which is a unique name indi-
listItem ||| cating the logic and component of a term;
listItem ||| 2. A list of parameters representing constant values; and
listItem ||| 3. A set of subterms with possible variable bindings.
bodyText ||| We use the following syntax to describe terms, based on the N u P R L
bodyText ||| definition [ACHA90]:
bodyText ||| In addition, MetaPRL has a meta-syntax somewhat similar to
bodyText ||| the higher-order abstract syntax presented in Pfenning and Elliott
bodyText ||| [PE88]. MetaPRL uses the second-order variables in the style of
bodyText ||| Huet and Lang [HL78] to describe term schemas. For example,
bodyText ||| Xx.V [x], where V is a second-order variable of arity 1, is a schema
bodyText ||| that stands for an arbitrary term whose top-level operator is X.
bodyText ||| This meta-syntax requires that every time a binding occurrence
bodyText ||| is explicitly specified in a schema, all corresponding bound occur-
bodyText ||| rences have to be specified as well. This requirement makes it very
bodyText ||| easy to specify free variable restrictions — for example, Xx.V,
bodyText ||| where V is a second-order meta-variable of arity 0, is a schema
bodyText ||| that stands for an arbitrary term whose top-level operator is X and
bodyText ||| whose body does not have any free occurrences of the variable
bodyText ||| bound by that X. In particular, the schema Xx. V matches the term
bodyText ||| Xy.1, but not the term Xx.x.
bodyText ||| In addition, this meta-language allows specifying certain term
bodyText ||| transformations, including implicit substitution specifications. For
bodyText ||| example, a beta reduction transformation may be specified using
bodyText ||| the following schema:
equation ||| (Xx.V1 [x]) V2 H V1 [V2]
bodyText ||| Here the substitution of V2 for x in V1 is specified implicitly.
bodyText ||| Throughout this paper we will use this second-order notation to
bodyText ||| denote arbitrary terms — namely, unless stated otherwise, when we
bodyText ||| write “Xx.t[x]” we mean an arbitrary term of this form, not a term
bodyText ||| containing a concrete second-order variable named “t”.
bodyText ||| As in LF [HHP93] we assume that object level variables (i.e.
bodyText ||| the variables of the language whose syntax we are expressing)
bodyText ||| are directly mapped to meta-theory variables (i.e. the variable of
bodyText ||| the language that we use to express the syntax). Similarly, we
bodyText ||| assume that the object-level binding structure is mapped to the
bodyText ||| meta-level binding structure. In other words, the object-level notion
bodyText ||| of the “binding/bound occurrence” is a subset of that in the meta-
bodyText ||| language. We also consider a-equal terms — both on the object
bodyText ||| level and on the meta-level — to be identical and we assume that
bodyText ||| substitution avoids capture by renaming.
bodyText ||| The sequent schema language we use [NH02] contains a num-
bodyText ||| ber of more advanced features in addition to those outlined here.
bodyText ||| However, for the purposes of this presentation, the basic features
bodyText ||| outlined above are sufficient.
sectionHeader ||| 2. Previous Models of Reflection
bodyText ||| In 1931 G¨odel used reflection to prove his famous incompleteness
bodyText ||| theorem [G¨od31]. To express arithmetic in arithmetic itself, he
bodyText ||| assigned a unique number (a G¨odel number) to each arithmetic
equation ||| opname
equation ||| �- J
equation ||| operator name
equation ||| [p1; .. .; pn] f�v1.t1; . . . ; �vm.tm}
equation ||| Y	Y	J
equation ||| parameters	subterms
page ||| 3
bodyText ||| formula. A G¨odel number of a formula is essentially a numeric
bodyText ||| code of a string of symbols used to represent that formula.
bodyText ||| A modern version of the G¨odel’s approach was used by Aitken
bodyText ||| et al. [ACHA90, AC92, ACU93, Con94] to implement reflection
bodyText ||| in the NuPRL theorem prover [CAB+86, ACE+00]. A large part
bodyText ||| of this effort was essentially a reimplementation of the core of the
bodyText ||| NuPRL prover inside NuPRL’s logical theory.
bodyText ||| In G¨odel’s approach and its variations (including Aitken’s one),
bodyText ||| a general mechanism that could be used for formalizing one logical
bodyText ||| theory in another is applied to formalizing a logical theory in itself.
bodyText ||| This can be very convenient for reasoning about reflection, but for
bodyText ||| our purposes it turns out to be extremely impractical. First, when
bodyText ||| formalizing a theory in itself using generic means, the identity
bodyText ||| between the theory being formalized and the one in which the
bodyText ||| formalization happens becomes very obfuscated, which makes it
bodyText ||| almost impossible to relate the reflected theory back to the original
bodyText ||| one. Second, when one has a theorem proving system that already
bodyText ||| implements the logical theory in question, creating a completely
bodyText ||| new implementation of this logical theory inside itself is a very
bodyText ||| tedious redundant effort. Another practical disadvantage of the
bodyText ||| G¨odel numbers approach is that it tends to blow up the size of
bodyText ||| the formulas; and iterated reflection would cause the blow-up to
bodyText ||| be iterated as well, making it exponential or worse.
bodyText ||| A much more practical approach is being used in some pro-
bodyText ||| gramming languages, such as Lisp and Scheme. There, the com-
bodyText ||| mon solution is for the implementation to expose its internal syntax
bodyText ||| representation to user-level code by the quote constructor (where
bodyText ||| quote (t) prevents the evaluation of the expression t). The prob-
bodyText ||| lems outlined above are solved instantly by this approach: there is
bodyText ||| no blow-up, there is no repetition of structure definitions, there is
bodyText ||| even no need for verifying that the reflected part is equivalent to the
bodyText ||| original implementation since they are identical. Most Scheme im-
bodyText ||| plementations take this even further: the eval function is the inter-
bodyText ||| nal function for evaluating a Scheme expression, which is exposed
bodyText ||| to the user-level; Smith [Smi84] showed how this approach can
bodyText ||| achieve an infinite tower of processors. A similar language with the
bodyText ||| quotation and antiquotation operators was introduced in [GMO03].
bodyText ||| This approach, however, violates the congruence property with
bodyText ||| respect to computation: if two terms are computationally equal then
bodyText ||| one can be substituted for the other in any context. For instance,
bodyText ||| although 2 * 2 is equal to 4, the expressions “2*2” and “4” are
bodyText ||| syntactically different, thus we can not substitute 2*2 by 4 in
bodyText ||| the expression quote(2*2). The congruence property is essential
bodyText ||| in many logical reasoning systems, including the NuPRL system
bodyText ||| mentioned above and the MetaPRL system [HNC+03, HNK+,
bodyText ||| HAB+] that our group uses.
bodyText ||| A possible way to expose the internal syntax without violat-
bodyText ||| ing the congruence property is to use the so-called “quoted” or
bodyText ||| “shifted” operators [AA99, Bar01, Bar05] rather than quoting the
bodyText ||| whole expression at once. For any operator op in the original lan-
bodyText ||| guage, we add the quoted operator (denoted as op) to represent a
bodyText ||| term built with the operator op. For example, if the original lan-
bodyText ||| guage contains the constant “0” (which, presumably, represents the
bodyText ||| number 0), then in the reflected language, 0 would stand for the
bodyText ||| term that denotes the expression “0”. Generally, the quoted opera-
bodyText ||| tor has the same arity as the original operator, but it is defined on
bodyText ||| syntactic terms rather than on semantic objects. For instance, while
bodyText ||| * is a binary operator on numbers, * is a binary operator on terms.
bodyText ||| Namely, if t1 and t2 are syntactic terms that stand for expressions
bodyText ||| e1 and e2 respectively, then t1 *t2 is a new syntactic term that stands
bodyText ||| for the expression e1 *e2. Thus, the quotation of the expression 1 *2
bodyText ||| would be 1 * 2.
bodyText ||| In general, the well-formedness (typing) rule for a quoted oper-
bodyText ||| ator is the following:
equation ||| t1 E Term	...	tn E Term
equation ||| op{t1; ... ; tn} E Term
equation ||| where Term is a type of terms.
bodyText ||| Note that quotations can be iterated arbitrarily many times,
bodyText ||| allowing us to quote quoted terms. For instance, 1 stands for the
bodyText ||| term that denotes the term that denotes the numeral 1.
bodyText ||| Problems arise when quoting expressions that contain binding
bodyText ||| variables. For example, what is the quotation of Xx.x? There are
bodyText ||| several possible ways of answering this question. A commonly
bodyText ||| used approach [PE88, DH94, DFH95, ACM02, ACM03] in logical
bodyText ||| frameworks such as Elf [Pfe89], LF [HHP93], and Isabelle [PN90,
bodyText ||| Pau94] is to construct an object logic with a concrete X operator
bodyText ||| that has a type like
equation ||| (Term -+ Term) -+ Term or (Var -+ Term) -+ Term.
bodyText ||| In this approach, the quoted Xx.x might look like X(Xx.x) and the
bodyText ||| quoted Xx.1 might look like X(Xx.1). Note that in these examples
bodyText ||| the quoted terms have to make use of both the syntactic (i. e. quoted)
bodyText ||| operator X and the semantic operator X.
bodyText ||| Exotic Terms. Naive implementations of the above approach
bodyText ||| suffer from the well-known problem of exotic terms [DH95,
bodyText ||| DFH95]. The issue is that in general we can not allow applying
bodyText ||| the X operator to an arbitrary function that maps terms to terms (or
bodyText ||| variables to terms) and expect the result of such an application to
bodyText ||| be a “proper” reflected term.
bodyText ||| Consider for example the following term:
equation ||| X(Xx. if x = 1 then 1 else 2)
bodyText ||| It is relatively easy to see that it is not a real syntactic term and
bodyText ||| can not be obtained by quoting an actual term. (For comparison,
bodyText ||| consider X(Xx. if x = 1 then 1 else 2), which is a quotation of
bodyText ||| Xx. if x = 1 then 1 else 2).
bodyText ||| How can one ensure that Xe denotes a “real” term and not an
bodyText ||| “exotic” one? That is, is it equal to a result of quoting an actual
bodyText ||| term of the object language? One possibility is to require e to be
bodyText ||| a substitution function; in other words it has to be equal to an
bodyText ||| expression of the form Xx.t[x] where t is composed entirely of term
bodyText ||| constructors (i.e. quoted operators) and x, while using destructors
bodyText ||| (such as case analysis, the if operator used in the example above,
bodyText ||| etc) is prohibited.
bodyText ||| There are a number of approaches to enforcing the above restric-
bodyText ||| tion. One of them is the usage of logical frameworks with restricted
bodyText ||| function spaces [PE88, HHP93], where X-terms may only con-
bodyText ||| tain constructors. Another is to first formalize the larger type that
bodyText ||| does include exotic terms and then to define recursively a predicate
bodyText ||| describing the “validity” or “well-formedness” of a term [DH94,
bodyText ||| DFH95] thus removing the exotic terms from consideration. Yet
bodyText ||| another approach is to create a specialized type theory that com-
bodyText ||| bines the idea of restricted function spaces with a modal type oper-
bodyText ||| ator [DPS97, DL99, DL01]. There the case analysis is disallowed
bodyText ||| on objects of “pure” type T, but is allowed on objects of a special
bodyText ||| type ❑T. This allows expressing both the restricted function space
bodyText ||| “T1 -+ T2” and the unrestricted one “(�T1) -+ T2” within a single
bodyText ||| type theory.
bodyText ||| Another way of regarding the problem of exotic terms is that it
bodyText ||| is caused by the attempt to give a semantic definition to a primarily
bodyText ||| syntactic property. A more syntax-oriented approach was used by
bodyText ||| Barzilay et al. [BA02, BAC03, Bar05]. In Barzilay’s approach, the
bodyText ||| quoted version of an operator that introduces a binding has the
bodyText ||| same shape (i.e. the number of subterms and the binding structure)
bodyText ||| as the original one and the variables (both the binding and the
none ||| (1)
page ||| 4
bodyText ||| bound occurrences) are unaffected by the quotation. For instance,
bodyText ||| the quotation of Xx.x is just Xx.x.
bodyText ||| The advantages of this approach include:
listItem ||| •	This approach is simple and clear.
listItem ||| •	Quoted terms have the same structure as original ones, inherit-
listItem ||| ing a lot of properties of the object syntax.
listItem ||| •	In all the above approaches, the a-equivalence relation for
listItem ||| quoted terms is inherited “for free”. For example, Xx.x and
listItem ||| Xy.y are automatically considered to be the same term.
listItem ||| •	Substitution is also easy: we do not need to re-implement the
listItem ||| substitution that renames binding variables to avoid the capture
listItem ||| of free variables; we can use the substitution of the original
listItem ||| language instead.
bodyText ||| To prune exotic terms, Barzilay says that Xx.t[x] is a valid term
bodyText ||| when Xx.t[x] is a substitution function. He demonstrates that it is
bodyText ||| possible to formalize this notion in a purely syntactical fashion. In
bodyText ||| this setting, the general well-formedness rule for quoted terms with
bodyText ||| bindings is the following:
equation ||| is substk {x1, · · · , xk.t["x]}	· · ·	is substl {z 1, · · · , zl.s["z]}
equation ||| op{x1, · · · , xk.t["x]; · · · ; z1, · · · , zl.s["z]} E Term
bodyText ||| (2)
bodyText ||| where is substn {x1 , · · · , xn.t["x]} is the proposition that t is a sub-
bodyText ||| stitution function over variables x1 , · · · , xn (in other words, it is a
bodyText ||| syntactic version of the Valid predicate of [DH94, DFH95]). This
bodyText ||| proposition is defined syntactically by the following two rules:
equation ||| is substn {x1, · · · , xn . xi}
equation ||| and
equation ||| is substn+k{x1, · · · , xn,y1, · · · , yk.t["x;"y]}
equation ||| ...
equation ||| is substn+l {x1, · · · , xn, z1, ··· , zl.s["x; "z]}}
equation ||| is substn {x1 · · ·xn.op{y1 · · ·yk.t["x; "y]; · · · ; z1 · · ·zl.s["x; "z]}}
bodyText ||| In this approach the is substn {} and X operators are essentially
bodyText ||| untyped (in NuPRL type theory, the computational properties of
bodyText ||| untyped terms are at the core of the semantics; types are added on
bodyText ||| top of the untyped computational system).
bodyText ||| Recursive Definition and Structural Induction Principle. A
bodyText ||| difficulty shared by both the straightforward implementations of
bodyText ||| the (Term -+ Term) -+ Term approach and by the Barzilay’s one
bodyText ||| is the problem of recursively defining the Term type. We want to
bodyText ||| define the Term type as the smallest set satisfying rules (1) and (2).
bodyText ||| Note, however, that unlike rule (1), rule (2) is not monotonic in the
bodyText ||| sense that is substk {x1, · · · , xk.t["x]} depends non-monotonically
bodyText ||| on the Term type. For example, to say whether Xx.t[x] is a term, we
bodyText ||| should check whether t is a substitution function over x. It means at
bodyText ||| least thatfor every x in Term, t[x] should be in Term as well. Thus
bodyText ||| we need to define the whole type Term before using (2), which
bodyText ||| produces a logical circle. Moreover, since X has type (Term -+
bodyText ||| Term) -+ Term, it is hard to formulate the structural induction
bodyText ||| principle for terms built with the X term constructor.
bodyText ||| Variable-Length Lists of Binders. In Barzilay’s approach, for
bodyText ||| each number n, is substn {} is considered to be a separate operator
bodyText ||| — there is no way to quantify over n, and there is no way to
bodyText ||| express variable-length lists of binders. This issue of expressing the
bodyText ||| unbounded-length lists of binders is common to some of the other
bodyText ||| approaches as well.
bodyText ||| Meta-Reasoning. Another difficulty that is especially apparent
bodyText ||| in Barzilay’s approach is that it only allows reasoning about con-
bodyText ||| crete operators in concrete languages. This approach does not pro-
bodyText ||| vide the ability to reason about operators abstractly; in particular,
bodyText ||| there is no way to state and prove meta-theorems that quantify over
bodyText ||| operators or languages, much less classes of languages.
sectionHeader ||| 3. Higher-Order Abstract Syntax
sectionHeader ||| with Inductive Definitions
bodyText ||| Although it is possible to solve the problems outlined in the previ-
bodyText ||| ous Section (and we will return to the discussion of some of those
bodyText ||| solutions in Section 6), our desire is to avoid these difficulties from
bodyText ||| the start. We propose a natural model of reflection that manages to
bodyText ||| work around those difficulties. We will show how to give a sim-
bodyText ||| ple recursive definition of terms with binding variables, which does
bodyText ||| not allow the construction of exotic terms and does allow structural
bodyText ||| induction on terms.
bodyText ||| In this Section we provide a conceptual overview of our ap-
bodyText ||| proach; details are given in Section 4.
subsectionHeader ||| 3.1 Bound Terms
bodyText ||| One of the key ideas of our approach is how we deal with terms
bodyText ||| containing free variables. We extend to free variables the principle
bodyText ||| that variable names do not really matter. In fact, we model free
bodyText ||| variables as bindings that can be arbitrarily a-renamed. Namely,
bodyText ||| we will write bterm{x1, · · · , xn.t["x]} for a term t over variables
bodyText ||| x1, · · ·, xn. For example, instead of term x*y we will use the
bodyText ||| term bterm{x, y.x*y} when it is considered over variables x and
bodyText ||| y and bterm{x, y, z.x*y} when it is considered over variables x,
bodyText ||| y and z. Free occurrences of xi in t["x] are considered bound
bodyText ||| in bterm{x1, · · · , xn.t["x]} and two a-equal bterm{} expressions
bodyText ||| (“bterms”) are considered to be identical.
bodyText ||| Not every bterm is necessarily well-formed. We will define the
bodyText ||| type of terms in such a way as to eliminate exotic terms. Consider
bodyText ||| for example a definition of lambda-terms.
construct ||| EXAMPLE 1. We can define a set of reflected lambda-terms as the
construct ||| smallest set such that
listItem ||| •	bterm{x1, · · · , xn.xi}, where 1 < i < n, is a lambda-term (a
listItem ||| variable);
listItem ||| •	ifbterm{x1, · · · , xn, xn+1.t["x] ) is a lambda-term, then
listItem ||| bterm{x1 , · · · , xn .Xxn+1 .t["x])
listItem ||| is also a lambda-term (an abstraction);
listItem ||| •	if bterm{x1, · · · , xn.t1 ["x]} and bterm{x1, · · · , xn.t2["x]} are
listItem ||| lambda-terms, then
listItem ||| bterm{x1; · · · ; xn.apply{t1 ["x]; t2["x]}}
listItem ||| is also a lambda-term (an application).
bodyText ||| In a way, bterms could be understood as an explicit coding for
bodyText ||| Barzilay’s substitution functions. And indeed, some of the basic
bodyText ||| definitions are quite similar. The notion of bterms is also very
bodyText ||| similar to that of local variable contexts [FPT99].
subsectionHeader ||| 3.2 Terminology
bodyText ||| Before we proceed further, we need to define some terminology.
construct ||| DEFINITION 1. We change the notion of subterm so that the sub-
construct ||| terms of a bterm are also bterms. For example, the immediate sub-
construct ||| terms of bterm{x, y.x*y} are bterm{x, y.x} and bterm{x, y.y}; the
construct ||| immediate subterm ofbterm{x.Xy.x} is bterm{x, y.x}.
construct ||| DEFINITION 2. We call the number of outer binders in a bterm
construct ||| expression its binding depth. Namely, the binding depth of the
construct ||| bterm bterm{x1, · · · , xn.t["x]} is n.
construct ||| DEFINITION 3. Throughout the rest of the paper we use the notion
construct ||| of operator shape. The shape ofan operator is a list ofnatural num-
construct ||| bers each stating how many new binders the operator introduces on
page ||| 5
bodyText ||| the corresponding subterm. The length of the shape list is therefore
bodyText ||| the arity of the operator. For example, the shape of the + operator
bodyText ||| is [0; 0] and the shape of the X operator is [1].
bodyText ||| The mapping from operators to shapes is also sometimes called
bodyText ||| a binding signature of a language [FPT99, Plo90].
construct ||| DEFINITION 4. Let op be an operator with shape [d1; · · · ; dN],
construct ||| and let btl be a list of bterms [b1; · · · ; bM]. We say that btl is
construct ||| compatible with op at depth n when,
listItem ||| 1. N=M;
listItem ||| 2. the binding depth of bterm bj is n + dj for each 1 < j < N.
subsectionHeader ||| 3.3 Abstract Operators
bodyText ||| Expressions of the form bterm{"x.op{· · · }} can only be used to ex-
bodyText ||| press syntax with concrete operators. In other words, each expres-
bodyText ||| sion of this form contains a specific constant operator op. However,
bodyText ||| we would like to reason about operators abstractly; in particular,
bodyText ||| we want to make it possible to have variables of the type “Op” that
bodyText ||| can be quantified over and used in the same manner as operator
bodyText ||| constants. In order to address this we use explicit term constructors
bodyText ||| in addition to bterm{"x.op{· · · }} constants.
bodyText ||| The expression mk bterm{n; “op”; btl}, where “op” is some en-
bodyText ||| coding of the quoted operator op, stands for a bterm with binding
bodyText ||| depth n, operator op and subterms btl. Namely,
equation ||| mk bterm{n; op; bterm{x1 , · · · , xn, "y1 .t1 ["x; "y1]} :: · · · ::
equation ||| bterm{x1, · · · ,xn,"yk.tk["x; "yk]} :: nil}
equation ||| is bterm{x1, · · · , xn.op {"y1 .t1 ["x; "y1]; · · · ; "yk.tk["x; "yk]}}. Here,
equation ||| nil is the empty list and :: is the list cons operator and there-
equation ||| fore the expression b1 :: · · · :: bn :: nil represents the concrete list
equation ||| [b1; ··· ; bn].
bodyText ||| Note that if we know the shape of the operator op and we know
bodyText ||| that the mk bterm expression is well-formed (or, more specifically,
bodyText ||| if we know that btl is compatible with op at depth n), then it
bodyText ||| would normally be possible to deduce the value of n (since n is
bodyText ||| the difference between the binding depth of any element of the list
bodyText ||| btl and the corresponding element of the shape(op) list). There are
bodyText ||| two reasons, however, for supplying n explicitly:
listItem ||| •	When btl is empty (in other words, when the arity of op is 0),
listItem ||| the value of n can not be deduced this way and still needs to be
listItem ||| supplied somehow. One could consider 0-arity operators to be a
listItem ||| special case, but this results in a significant loss of uniformity.
listItem ||| •	When we do not know whether an mk bterm expression is
listItem ||| necessarily well-formed (and as we will see it is often useful
listItem ||| to allow this to happen), then a lot of definitions and proofs
listItem ||| are greatly simplified when the binding depth of mk bterm
listItem ||| expressions is explicitly specified.
bodyText ||| Using the mk bterm constructor and a few other similar con-
bodyText ||| structors that will be introduced later, it becomes easy to reason ab-
bodyText ||| stractly about operators. Indeed, the second argument to mk bterm
bodyText ||| can now be an arbitrary expression, not just a constant. This has a
bodyText ||| cost of making certain definitions slightly more complicated. For
bodyText ||| example, the notion of “compatible with op at depth n” now be-
bodyText ||| comes an important part of the theory and will need to be explicitly
bodyText ||| formalized. However, this is a small price to pay for the ability to
bodyText ||| reason abstractly about operators, which easily extends to reason-
bodyText ||| ing abstractly about languages, classes of languages and so forth.
subsectionHeader ||| 3.4 Inductively Defining the Type of Well-Formed Bterms
bodyText ||| There are two equivalent approaches to inductively defining the
bodyText ||| general type (set) of all well-formed bterms. The first one follows
bodyText ||| the same idea as in Example 1:
listItem ||| •	bterm{x1 , · · · , xn.xi } is a well-formed bterm for 1 < i < n;
listItem ||| •	mk bterm{n; op; btl} is a well-formed bterm when op is a well-
listItem ||| formed quoted operator and btl is a list of well-formed bterms
listItem ||| that is compatible with op at some depth n.
bodyText ||| If we denote bterm{x1, · · · , xl, y, z1, · · · , zr.y} as var{l; r},
bodyText ||| we can restate the base case of the above definition as “var{l; r},
bodyText ||| where l and r are arbitrary natural numbers, is a well-formed
bodyText ||| bterm”. Once we do this it becomes apparent that the above def-
bodyText ||| inition has a lot of similarities with de Bruijn-style indexing of
bodyText ||| variables [dB72]. Indeed, one might call the numbers l and r the
bodyText ||| left and right indices of the variable var{l; r}.
bodyText ||| It is possible to provide an alternate definition that is closer to
bodyText ||| pure HOAS:
listItem ||| •	bnd{x.t[x]}, where t is a well-formed substitution function, is
listItem ||| a well-formed bterm (the bnd operation increases the binding
listItem ||| depth of t by one by adding x to the beginning of the list of t’s
listItem ||| outer binders).
listItem ||| •	mk term{op; btl}, where op is a well-formed quoted operator,
listItem ||| and btl is a list of well-formed bterms that is compatible with
listItem ||| op at depth 0, is a well-formed bterm (of binding depth 0).
bodyText ||| Other than better capturing the idea of HOAS, the latter defini-
bodyText ||| tion also makes it easier to express the reflective correspondence
bodyText ||| between the meta-syntax (the syntax used to express the theory of
bodyText ||| syntax, namely the one that includes the operators mk bterm, bnd,
bodyText ||| etc.) and the meta-meta-syntax (the syntax that is used to express
bodyText ||| the theory of syntax and the underlying theory, in other words, the
bodyText ||| syntax that includes the second-order notations.) Namely, provided
bodyText ||| that we define the subst{bt; t} operation to compute the result of
bodyText ||| substituting a closed term t for the first outer binder of the bterm
bodyText ||| bt, we can state that
equation ||| subst{bnd{x.t1 [x]} ; t2} ≡ t1 [t2] (3)
equation ||| (where t1 and t2 are literal second-order variables). In other words,
equation ||| we can state that the substitution operator subst and the implicit
equation ||| second-order substitution in the “meta-meta-” language are equiv-
equation ||| alent.
bodyText ||| The downside of the alternate definition is that it requires defin-
bodyText ||| ing the notion of “being a substitution function”.
subsectionHeader ||| 3.5 Our Approach
bodyText ||| In our work we try to combine the advantages of both approaches
bodyText ||| outlined above. In the next Section we present a theory that includes
bodyText ||| both the HOAS-style operations (bnd, mk term) and the de Bruijn-
bodyText ||| style ones (var, mk bterm). Our theory also allows deriving the
bodyText ||| equivalence (3). In our theory the definition of the basic syntactic
bodyText ||| operations is based on the HOAS-style operators; however, the
bodyText ||| recursive definition of the type of well-formed syntax is based on
bodyText ||| the de Bruijn-style operations. Our theory includes also support for
bodyText ||| variable-length lists of binders.
sectionHeader ||| 4. Formal Implementation in a Theorem Prover
bodyText ||| In this Section we describe how the foundations of our theory are
bodyText ||| formally defined and derived in the NuPRL-style Computational
bodyText ||| Type Theory in the MetaPRL Theorem Prover. For brevity, we
bodyText ||| will present a slightly simplified version of our implementation;
bodyText ||| full details are available in the extended version of this paper
bodyText ||| [NKYH05, Appendix].
subsectionHeader ||| 4.1 Computations and Types
bodyText ||| In our work we make heavy usage of the fact that our type theory
bodyText ||| allows us to define computations without stating upfront (or even
bodyText ||| knowing) what the relevant types are. In NuPRL-style type theo-
page ||| 6
bodyText ||| ries (which some even dubbed “untyped type theory”), one may de-
bodyText ||| fine arbitrary recursive functions (even potentially nonterminating
bodyText ||| ones). Only when proving that such function belongs to a particular
bodyText ||| type, one may have to prove termination. See [All87a, All87b] for
bodyText ||| a semantics that justifies this approach.
bodyText ||| The formal definition of the syntax of terms consists of two
bodyText ||| parts:
listItem ||| •	The definition of untyped term constructors and term oper-
listItem ||| ations, which includes both HOAS-style operations and de
listItem ||| Bruijn-style operations. As it turns out, we can establish most
listItem ||| of the reduction properties without explicitly giving types to all
listItem ||| the operations.
listItem ||| •	The definition of the type of terms. We will define the type of
listItem ||| terms as the type that contains all terms that can be legitimately
listItem ||| constructed by the term constructors.
subsectionHeader ||| 4.2 HOAS Constructors
bodyText ||| At the core of our term syntax definition are two basic HOAS-style
bodyText ||| constructors:
listItem ||| •	bnd{x.t[x]} is meant to represent a term with a free variable x.
listItem ||| The intended semantics (which will not become explicit until
listItem ||| later) is that bnd{x.t[x]} will only be considered well-formed
listItem ||| when t is a substitution function.
bodyText ||| Internally, bnd{x.t[x]} is implemented simply as the pair
bodyText ||| (0, Xx.t[x]). This definition is truly internal and is used only
bodyText ||| to prove the properties of the two destructors presented below;
bodyText ||| it is never used outside of this Section (Section 4.2).
listItem ||| •	mk term{op; ts} pairs op with ts. The intended usage of this
listItem ||| operation (which, again, will only become explicit later) is that
listItem ||| it represents a closed term (i.e. a bterm of binding depth 0) with
listItem ||| operator op and subterms ts. It will be considered well-formed
listItem ||| when op is an operator and ts is a list of terms that is compatible
bodyText ||| with op at depth 0. For example, mk term{X; bnd{x.x}} is Xx.x.
bodyText ||| Internally, mk term{op; ts} is implemented as the nested pair
bodyText ||| (1, (op, ts)). Again, this definition is never used outside of this
bodyText ||| Section.
bodyText ||| We also implement two destructors:
listItem ||| •	subst{bt; t} is meant to represent the result of substituting term
listItem ||| t for the first variable of the bterm bt. Internally, subst{bt; t}
listItem ||| is defined simply as an application (bt.2) t (where bt.2 is the
listItem ||| second element of the pair bt).
bodyText ||| We derive the following property of this substitution operation:
equation ||| subst{bnd{x.t1 [x]} ; t2} ≡ t1 [t2]
equation ||| where “≡” is the computational equality relation1 and t1 and
equation ||| t2 may be absolutely arbitrary, even ill-typed. This derivation
equation ||| is the only place where the internal definition of subst{bt; t} is
equation ||| used.
bodyText ||| Note that the above equality is exactly the “reflective property
bodyText ||| of substitution” (3) that was one of the design goals for our
bodyText ||| theory.
listItem ||| •	weak dest {bt; bcase; op, ts.mkt case[op; ts]} is designed to
listItem ||| provide a way to find out whether bt is a bnd{} or a mk term{op; ts}
footnote ||| 1 In NuPRL-style type theories the computational equality relation (which
footnote ||| is also sometimes called “squiggle equality” and is sometimes denoted
bodyText ||| as“∼” or “←-+”) is the finest-grained equality relation in the theory.
bodyText ||| When a ≡ b is true, a may be replaced with b in an arbitrary context.
bodyText ||| Examples of computational equality include beta-reduction Xx.a[x]b ≡
bodyText ||| a[b], arithmetical equalities (1 + 2 ≡ 3), and definitional equality (an
bodyText ||| abstraction is considered to be computationally equal to its definition).
bodyText ||| and to “extract” the op and ts in the latter case. In the rest of
bodyText ||| this paper we will use the “pretty-printed” form for weak dest
bodyText ||| — “match bt with bnd{ } -+ bcase I mk term{op; ts} -+
bodyText ||| mkt case[op; ts]”. Internally, it is defined as
bodyText ||| if bt.1 = 0 then bcase else mkt case[bt.2.1; bt.2.2].
bodyText ||| From this internal definition we derive the following properties
bodyText ||| of weak dest:
equation ||| ⎛	⎞
equation ||| matchbnd{x.t[x]} with
equation ||| ⎝bnd{ } -+ bcase	⎠
equation ||| bcase
equation ||| mk term{op; ts} -+ mkt case[op; ts]≡
equation ||| ⎛
equation ||| matchmk term{op; ts} with
equation ||| ⎝bnd{ } -+ bcase
equation ||| Imk term{o; t} -+ mkt case[o; t]
equation ||| 4.3 Vector HOAS Operations
bodyText ||| As we have mentioned at the end of Section 2, some approaches to
bodyText ||| reasoning about syntax make it hard or even impossible to express
bodyText ||| arbitrary-length lists of binders. In our approach, we address this
bodyText ||| challenge by allowing operators where a single binding in the meta-
bodyText ||| language stands for a list of object-level bindings. In particular, we
bodyText ||| allow representing bnd{x1.bnd{x2. · · · bnd{xn.t[x1; ... ; xn]} · · ·}}
bodyText ||| as
bodyText ||| vbnd{n; x.t[nth{1; x}; . . . ; nth{n; x}]}, where “nth{i; l}” is the “i-
bodyText ||| th element of the list l” function.
bodyText ||| We define the following vector-style operations:
listItem ||| •	vbnd{n; x.t[x]} represents a “telescope” of nested bnd opera-
listItem ||| tions. It is defined by induction2 on the natural number n as
listItem ||| follows:
equation ||| vbnd{0; x.t[x]}:= t[nil]
equation ||| vbnd{n + 1; x.t[x]}:= bnd{v.vbnd{n; x.t[v :: x]}}
bodyText ||| We also introduce vbnd{n; t} as a simplified notation for
bodyText ||| vbnd{n; x.t} when t does not have free occurrences of x.
listItem ||| •	vsubst{bt; ts} is a “vector” substitution operation that is meant
listItem ||| to represent the result of simultaneous substitution of the terms
listItem ||| in the ts list for the first ItsI variables of the bterm bt (here IlI is
listItem ||| the length of the list l). vsubst{bt; ts} is defined by induction on
listItem ||| the list ts as follows:
equation ||| vsubst{bt; nil}:= bt
equation ||| vsubst{bt; t :: ts}:= vsubst{subst{bt; t} ; ts}
bodyText ||| Below are some of the derived properties of these operations:
equation ||| 	bnd{v.t[v]} ≡ vbnd{1; hd(v)}	(4)
equation ||| Vm , n E N.
equation ||| �vbnd{m +n; x.t[x]} ≡ vbnd{m; y.vbnd{n; z.t[y@z]}}) (5)
equation ||| 	Vl E List. (vsubst{vbnd{Il I; v.t[v]} ;l} ≡ t[l])	(6)
equation ||| Vl E List.Vn E N. �(n ≥ IlI) ⇒	(7)
equation ||| (vsubst{vbnd{n; v.t[v]} ;l} ≡ vbnd{n − IlI; v.bt[l@v]}))
equation ||| Vn E N.	(8)
equation ||| vbnd{n; l.vsubst{vbnd{n; v.t[v]} ;l}} ≡ vbnd{n; l.t[l]})
bodyText ||| where “hd” is the list “head” operation, “@” is the list append
bodyText ||| operation, “List” is the type of arbitrary lists (the elements of a list
bodyText ||| do not have to belong to any particular type), N is the type of natural
bodyText ||| numbers, and all the variables that are not explicitly constrained to
bodyText ||| a specific type stand for arbitrary expressions.
footnote ||| 2 Our presentation of the inductive definitions is slightly simplified by
footnote ||| omitting some minor technical details. See [NKYH05, Appendix] for
footnote ||| complete details.
equation ||| ⎞⎠ ≡mkt case[op; ts]
page ||| 7
bodyText ||| Equivalence (5) allows the merging and splitting of vector bnd
bodyText ||| operations. Equivalence (6) is a vector variant of equivalence (3).
bodyText ||| Equivalence (8) is very similar to equivalence (6) applied in the
bodyText ||| vbnd{n; l. · · ·} context, except that (8) does not require l to be a
bodyText ||| member of any special type.
subsectionHeader ||| 4.4 De Bruijn-style Operations
bodyText ||| Based on the HOAS constructors defined in the previous two sec-
bodyText ||| tions, we define two de Bruijn-style constructors.
listItem ||| •	var{i; j} is defined as vbnd{i; bnd{v.vbnd{j; v}}}. It is easy to
listItem ||| see that this definition indeed corresponds to the informal
equation ||| bterm{x1,··· ,xl, y, z1,··· , zr .y}
equation ||| definition given in Section 3.4.
equation ||| •	mk bterm{n; op; ts} is meant to compute a bterm of binding
equation ||| depth n, with operator op, and with ts as its subterms. This op-
equation ||| eration is defined by induction on natural number n as follows:
equation ||| mk bterm{0; op; ts}:= mk term{op; ts}
equation ||| mk bterm{n + 1; op; ts}:=
equation ||| bnd{v.mk bterm{n; op; map Xt.subst{t; v} ts}}
bodyText ||| Note that, if ts is a list of bnd expressions (which is the intended
bodyText ||| usage of the mk bterm operation), then the
equation ||| bnd{v. · · · map Xt.subst{t; v} ts · · ·}
bodyText ||| has the effect of stripping the outer bnd from each of the mem-
bodyText ||| bers of the ts list and “moving” them into a single “merged” bnd
bodyText ||| on the outside.
bodyText ||| We also define a number of de Bruijn-style destructors, i.e., op-
bodyText ||| erations that compute various de Bruijn-style characteristics of a
bodyText ||| bterm. Since the var and mk bterm constructors are defined in terms
bodyText ||| of the HOAS constructors, the destructors have to be defined in
bodyText ||| terms of HOAS operations as well. Because of this, these defini-
bodyText ||| tions are often far from straightforward.
bodyText ||| It is important to emphasize that the tricky definitions that we
bodyText ||| use here are only needed to establish the basic properties of the
bodyText ||| operations we defined. Once the basic theory is complete, we can
bodyText ||| raise the level of abstraction and no usage of this theory will
bodyText ||| ever require using any of these definitions, being aware of these
bodyText ||| definitions, or performing similar tricks again.
listItem ||| •	bdepth{t} computes the binding depth of term t. It is defined
listItem ||| recursively using the Y combinator as
equation ||| rXb.matchb with
equation ||| Y	bnd{ } -+ 1 + f (subst{b; mk term{0; 0}})
equation ||| |mkterm{ ; }-+0
bodyText ||| In effect, this recursive function strips the outer binders from a
bodyText ||| bterm one by one using substitution (note that here we can use
bodyText ||| an arbitrary mk bterm expression as a second argument for the
bodyText ||| substitution function; the arguments to mk bterm do not have
bodyText ||| to have the “correct” type) and counts the number of times it
bodyText ||| needs to do this before the outermost mk bterm is exposed.
bodyText ||| We derive the following properties of bdepth:
equation ||| Vl, r E ICY. (bdepth {var{l; r}} ≡ (l +r + 1));
equation ||| Vn E ICY.(bdepth{mk bterm{n; op; ts}} ≡ n).
bodyText ||| Note that the latter equivalence only requires n to have the
bodyText ||| “correct” type, while op and ts may be arbitrary. Since the
bodyText ||| bdepth operator is needed for defining the type of Term of well-
bodyText ||| formed bterms, at this point we would not have been able to
bodyText ||| express what the “correct” type for ts would be.
bodyText ||| •	left{t} is designed to compute the “left index” of a var expres-
bodyText ||| sion. It is defined as
equation ||| 	�	�
equation ||| Xf.Xb.Xl.
equation ||| match b with	�
equation ||| 	Y	bnd{ } -+
equation ||| �1 + f (subst{b; mk term {l; 0}})(l + 1) � �
equation ||| |mk term{lf; ) -+ lf
bodyText ||| In effect, this recursive function substitutes mk term{0; 0}
bodyText ||| for the first binding of t, mk term{1; 0} for the second one,
bodyText ||| mk term{2; 0} for the next one and so forth. Once all the binders
bodyText ||| are stripped and a mk term{l; 0} is exposed, l is the index
bodyText ||| we were looking for. Note that here we intentionally supply
bodyText ||| mk term with an argument of a “wrong” type (ICY instead of
bodyText ||| Op); we could have avoided this, but then the definition would
bodyText ||| have been significantly more complicated.
bodyText ||| As expected, we derive that
equation ||| Vl, r E ICY.(left{var{l; r}} ≡ l).
listItem ||| •	right{t} computes the “right index” of a var expression. It
listItem ||| is trivial to define in terms of the previous two operators:
listItem ||| right{t}:= bdepth{t} − left{t} − 1.
listItem ||| •	get op{t; op} is an operation such that
equation ||| Vn E ICY.(get op{mk bterm{n; op; ts} ; opf) ≡ op),
equation ||| Vl, r E ICY. ((get op{var{i; j} ; op} ≡ op).
bodyText ||| Its definition is similar to that of left{}.
listItem ||| •	subterms{t} is designed to recover the last argument of a
listItem ||| mk bterm expression. The definition is rather technical and
listItem ||| complicated, so we omit it; see [NKYH05, Appendix C] for
listItem ||| details. The main property of the subterms operation that we
listItem ||| derive is
bodyText ||| Vn E ICY.Vbtl E List.(subterms{mk bterm{n; op; btl}} ≡
bodyText ||| map Xb.vbnd{n; v.vsubst{b; v}} btl)
bodyText ||| The right-hand side of this equivalence is not quite the plain
bodyText ||| “btl” that one might have hoped to see here. However, when
bodyText ||| btl is a list of bterms with binding depths at least n, which is
bodyText ||| necessarily the case for any well-formed mk bterm{n; op; btl},
bodyText ||| equivalence (8) would allow simplifying this right-hand side to
bodyText ||| the desired btl.
subsectionHeader ||| 4.5 Operators
bodyText ||| For this basic theory the exact representation details for operators
bodyText ||| are not essential and we define the type of operators Op abstractly.
bodyText ||| We only require that operators have decidable equality and that
bodyText ||| there exist a function of the type Op -+ ICY List that computes
bodyText ||| operators’ shapes.
bodyText ||| Using this shape function and the bdepth function from Sec-
bodyText ||| tion 4.4, it is trivial to formalize the “ts is compatible with op at
bodyText ||| depth n” predicate of Definition 4. We denote this predicate as
bodyText ||| shape compat{n; op; ts} and define it as
equation ||| |shape{op}| = |btl|A
equation ||| Vi E 1..|btl|.bdepth{nth{btl; i}} = n +nth{shape{op}; i}
subsectionHeader ||| 4.6 The Type of Terms
bodyText ||| In this section we will define the type of terms (i.e. well-formed
bodyText ||| bterms), Term, as the type of all terms that can be constructed by
bodyText ||| the de Bruijn constructors from Section 4.4. That is, the Term type
bodyText ||| contains all expressions of the forms:
listItem ||| •	var{i; j} for all natural numbers i, j; or
equation ||| )t
equation ||| t0
page ||| 8
listItem ||| • mk bterm{n; op; ts} for any natural number n, operator op, and
listItem ||| list of terms ts that is compatible with op at depth n.
bodyText ||| The Term type is defined as a fixpoint of the following function
bodyText ||| from types to types:
equation ||| Iter(X) := Image(dom(X); x.mk(x)),
bodyText ||| where
listItem ||| •	Image is a type constructor such that Image(T; x. f [xl) is the
listItem ||| type of all the f [tl for t e T (for it to be well-formed, T must
listItem ||| be a well-formed type and f must not have any free variables
listItem ||| except for x);
listItem ||| •	dom(X) is a type defined as
equation ||| (N×N)+(n:N× op:Op× {ts:X List I shape compat{n; op; ts}});
listItem ||| •	and mk(x) (where x is presumably a member of the type
listItem ||| dom(X)) is defined as
equation ||| matchx with
equation ||| inl (i, j) -+ var{i ; j}
equation ||| Iinr (n, op, ts) -+ mk bterm{n; op; ts} .
bodyText ||| The fixpoint of Iter is reached by defining
listItem ||| •	Term0 := Void (an empty type)
listItem ||| •	Termn+1 := Iter(Termn)
listItem ||| •	Term := U Termn
listItem ||| neN
bodyText ||| We derive the intended introduction rules for the Term type:
equation ||| i eN	j eN
equation ||| var{i ; j} e Term
equation ||| and
equation ||| n e N op e Op ts e TermList shape compat{n; op; ts}
equation ||| .
equation ||| mk bterm{n; op; ts} e Term
bodyText ||| Also, the structural induction principle is derived for the Term
bodyText ||| type. Namely, we show that to prove that some property P[tl holds
bodyText ||| for any term t, it is sufficient to prove
listItem ||| •	(Base case) P holds for all variables, that is, P[var{i ; j}l holds
listItem ||| for all natural numbers i and j;
listItem ||| •	(Induction step) P[mk bterm{n; op; ts}l is true for any natural
listItem ||| number n, any operator op, and any list of terms ts that is
listItem ||| compatible with op at depth n, provided P[tl is true for any
listItem ||| element t of the list ts.
bodyText ||| Note that the type of “terms over n variables” (where n = 0 cor-
bodyText ||| responds to closed terms) may be trivially defined using the Term
bodyText ||| type and the “subset” type constructor — {t : Term II bdepth{t} =
bodyText ||| n}.
sectionHeader ||| 5. Conclusions and Future Work
bodyText ||| In Sections 3 and 4 we have presented a basic theory of syntax
bodyText ||| that is fully implemented in a theorem prover. As we mentioned in
bodyText ||| the introduction, the approach is both natural and expressive, and
bodyText ||| provides a foundation for reflective reasoning about classes of lan-
bodyText ||| guages and logics. However, we consider this theory to be only
bodyText ||| the first step towards building a user-accessible uniform reflection
bodyText ||| framework and a user-accessible uniform framework for program-
bodyText ||| ming language reasoning and experimentation, where tasks similar
bodyText ||| to the ones presented in the POPLMARK challenge [ABF+05] can
bodyText ||| be performed easily and naturally. In this section we provide an out-
bodyText ||| line of our plans for building such frameworks on top of the basic
bodyText ||| syntactic theory.
subsectionHeader ||| 5.1 Higher-Level User Interface
bodyText ||| One obvious shortcoming of the theory presented in Sections 3
bodyText ||| and 4 is that it provides only the basic low-level operations such
bodyText ||| as bnd, var, subterms, etc. It presents a very low-level account of
bodyText ||| syntax in a way that would often fail to abstract away the details
bodyText ||| irrelevant to the user.
bodyText ||| To address this problem we are planning to provide user in-
bodyText ||| terface functionality capable of mapping the high-level concepts
bodyText ||| to the low-level ones. In particular, we are going to provide an
bodyText ||| interface that would allow instantiating general theorems to spe-
bodyText ||| cific collections of operators and specific languages. Thus, the user
bodyText ||| will be able to write something like “reflect language [Xx..;
bodyText ||| apply{.; .}] ” and the system will create all the components outlined
bodyText ||| in Example 1:
listItem ||| •	It will create a definition for the type
equation ||| Language[Xx..; apply{.; .}l
bodyText ||| of reflected lambda-terms (where Language[ll is a general def-
bodyText ||| inition of a language over a list of operators l);
listItem ||| •	It will state and derive the introduction rules for this type;
listItem ||| •	It will state and derive the elimination rule for this type (the
listItem ||| induction principle).
bodyText ||| Moreover, we are planning to support even more complicated lan-
bodyText ||| guage declarations, such as
equation ||| t := int I t -+ t; e := v I Xx : t.e[xl I apply{e; e}
bodyText ||| that would cause the system to create mutually recursive type
bodyText ||| definitions and appropriate rules.
bodyText ||| Finally, we are also planning to support “pattern bindings” that
bodyText ||| are needed for a natural encoding of ML-like pattern matching
bodyText ||| (such as the one sketched in the POPLMARK challenge [ABF+05]).
bodyText ||| As far as the underlying theory goes, we believe that the mecha-
bodyText ||| nisms very similar to the “vector bindings” presented in Section 4.3
bodyText ||| will be sufficient here.
subsectionHeader ||| 5.2 “Dereferencing” Quoted Terms
bodyText ||| As in Barzilay’s work, the quoted operator approach makes it easy
bodyText ||| to define the “unquoting” (or “dereferencing”) operator [lunq. If t
bodyText ||| is a syntactic term, then [tllunq is the value represented by t. By
bodyText ||| definition,
equation ||| [op{t1; ... ; tn}lunq = op{[t1lunq; ... ; [tnllunq}.
equation ||| For instance, [2 * 3lunq is 2 * 3 (i.e. 6).
bodyText ||| In order to define unquoting on terms with bindings, we need to
bodyText ||| introduce the “guard” operation hp pi such that [bt)llunq is t for an
bodyText ||| arbitrary expression t. Then [lunq can be defined as follows:
equation ||| [op{x1, ..., xk.t[x1; ... ; xkl; ... ;z1, ..., zl.s[z1; ... ; zll}lunq =
equation ||| op{x1, . . . ,xk.[[t[(ix1 ; ... ; Ixk�llunq;
equation ||| . . .	;
equation ||| z1, . . . , zl.[s[(z1�� ; ... ; (1zl�llunq}.
equation ||| For example, [[Xx.2*xlunq = Xx.[2*��x�llunq = Xx.[2lunq *
equation ||| [bx)lunq =Xx.2 * x.
bodyText ||| The unquote operation establishes the identity between the orig-
bodyText ||| inal syntax and the reflected syntax, making it a “true” reflection.
bodyText ||| Note that the type theory (which ensures, in particular, that
bodyText ||| only terminating functions may be shown to belong to a function
bodyText ||| type) would keep the [ llunq operation from introducing logical
bodyText ||| paradoxes.3
footnote ||| 3 This is, obviously, not a proper argument. While a proper argument can be
footnote ||| made here, it is outside of the scope of this particular paper.
page ||| 9
bodyText ||| Also, since the notion of the quoted operators is fully open-
bodyText ||| ended, each new language added to the system will automatically
bodyText ||| get to use the Q lunq operation for all its newly introduced opera-
bodyText ||| tors.
subsectionHeader ||| 5.3 Logical Reflection
bodyText ||| After defining syntactic reflection, it is easy to define logical reflec-
bodyText ||| tion. If we consider the proof system open-ended, then the logical
bodyText ||| reflection is trivial — when P is a quotation of a proposition, we
bodyText ||| can regard “QPlunq” as meaning “P is true”. The normal modal
bodyText ||| rules for the Qlunq modality are trivially derivable. For example
bodyText ||| modus ponens
equation ||| QP  =:�  Qlunq =:� QPlunq =:� QQQlunq
bodyText ||| is trivially true because if we evaluate the first Qllunq (remember,
equation ||| QP =:� Qlunq = (QPlunq =:� QQlunq)
bodyText ||| by definition of Qlunq), we get an obvious tautology
bodyText ||| (QPlunq =:� QQQlunq) =:� QPlunq =:� QQlunq.
bodyText ||| In order to consider a closed proof system (in other words, if
bodyText ||| we want to be able to do induction over derivations), we would
bodyText ||| need to define a provability predicate for that system. We are
bodyText ||| planning to provide user interface functionality that would allow
bodyText ||| users to describe a set of proof rules and the system would generate
bodyText ||| appropriate proof predicate definitions and derive appropriate rules
bodyText ||| (in a style similar to the one outlined in Section 5.1 for the case of
bodyText ||| language descriptions).
sectionHeader ||| 6. Related Work
bodyText ||| In Section 2 we have already discussed a number of approaches
bodyText ||| that we consider ourselves inheriting from. Here we would like to
bodyText ||| revisit some of them and mention a few other related efforts.
bodyText ||| Our work has a lot in common with the HOAS implemented in
bodyText ||| Coq by Despeyroux and Hirschowitz [DH94]. In both cases, the
bodyText ||| more general space of terms (that include the exotic ones) is later
bodyText ||| restricted in a recursive manner. In both cases, the higher-order
bodyText ||| analogs of first-order de Bruijn operators are defined and used as a
bodyText ||| part of the “well-formedness” specification for the terms. Despey-
bodyText ||| roux and Hirschowitz use functions over infinite lists of variables
bodyText ||| to define open terms, which is similar to our vector bindings.
bodyText ||| There are a number of significant differences as well. Our ap-
bodyText ||| proach is sufficiently syntactical, which allows eliminating all ex-
bodyText ||| otic terms, even those that are extensionally equal to the well-
bodyText ||| formed ones, while the more semantic approach of [DH94,
bodyText ||| DFH95] has to accept such exotic terms (their solution to this prob-
bodyText ||| lem is to consider an object term to be represented by the whole
bodyText ||| equivalence class of extensionally equal terms); more generally
bodyText ||| while [DH94] states that “this problem of extensionality is recur-
bodyText ||| rent all over our work”, most of our lemmas establish identity and
bodyText ||| not just equality, thus avoiding most of the issues of extensional
bodyText ||| equality. In our implementation, the substitution on object terms is
bodyText ||| mapped directly to P-reduction, while Despeyroux et al. [DFH95]
bodyText ||| have to define it recursively. In addition, we provide a uniform ap-
bodyText ||| proach to both free and bound variables that naturally extends to
bodyText ||| variable-length “vector” bindings.
bodyText ||| While our approach is quite different from the modal X-calculus
bodyText ||| one [DPS97, DL99, DL01], there are some similarities in the in-
bodyText ||| tuition behind it. Despeyroux et al. [DPS97] says “Intuitively, we
bodyText ||| interpret ❑B as the type of closed objects of type B. We can iter-
bodyText ||| ate or distinguish cases over closed objects, since all constructors
bodyText ||| are statically known and can be provided for.” The intuition be-
bodyText ||| hind our approach is in part based on the canonical model of the
bodyText ||| NuPRL type theory [All87a, All87b], where each type is mapped
bodyText ||| to an equivalence relations over the closed terms of that type.
bodyText ||| Gordon and Melham [GM96] define the type of X-terms as a
bodyText ||| quotient of the type of terms with concrete binding variables over
bodyText ||| a-equivalence. Michael Norrish [Nor04] builds upon this work by
bodyText ||| replacing certain variable “freshness” requirements with variable
bodyText ||| “swapping”. This approach has a number of attractive properties;
bodyText ||| however, we believe that the level of abstraction provided by the
bodyText ||| HOAS-style approaches makes the HOAS style more convenient
bodyText ||| and accessible.
bodyText ||| Ambler, Crole, and Momigliano [ACM02] have combined the
bodyText ||| HOAS with the induction principle using an approach which in
bodyText ||| some sense is opposite to ours. Namely, they define the HOAS
bodyText ||| operators on top of the de Bruijn definition of terms using higher
bodyText ||| order pattern matching. In a later work [ACM03] they have de-
bodyText ||| scribed the notion of “terms-in-infinite-context” which is quite sim-
bodyText ||| ilar to our approach to vector binding. While our vector bindings
bodyText ||| presented in Section 4.3 are finite length, the exact same approach
bodyText ||| would work for the infinite-length “vectors” as well.
sectionHeader ||| Acknowledgments
bodyText ||| The authors are grateful to Eli Barzilay whose ideas were an in-
bodyText ||| spiration for some of the work that lead to this paper. We are also
bodyText ||| grateful for his comments on an early draft of this paper.
bodyText ||| We are grateful to the anonymous reviewers for their very thor-
bodyText ||| ough and fair feedback and many helpful suggestions.
sectionHeader ||| References
reference ||| [AA99] Eric Aaron and Stuart Allen. Justifying calculational logic
reference ||| by a conventional metalinguistic semantics. Technical Report
reference ||| TR99-1771, Cornell University, Ithaca, New York, September
reference ||| 1999.
reference ||| [ABF+05] Brian E. Aydemir, Aaron Bohannon, Matthew Fairbairn,
reference ||| J. Nathan Foster, Benjamin C. Pierce, Peter Sewell, Dimitrios
reference ||| Vytiniotis, Geoffrey Washburn, Stephanie Weirich, and Steve
reference ||| Zdancewic. Mechanized metatheory for the masses: The
reference ||| POPLmark challenge. Available fromhttp://www.cis.
reference ||| upenn.edu/group/proj/plclub/mmm/,2005.
reference ||| [AC92] William Aitken and Robert L. Constable. Reflecting on
reference ||| NuPRL : Lessons 1–4. Technical report, Cornell University,
reference ||| Computer Science Department, Ithaca, NY, 1992.
reference ||| [ACE+00] Stuart Allen, Robert Constable, Richard Eaton, Christoph
reference ||| Kreitz, and Lori Lorigo. The NuPRL open logical envi-
reference ||| ronment. In David McAllester, editor, Proceedings of the
reference ||| 17th International Conference on Automated Deduction, vol-
reference ||| ume 1831 of Lecture Notes in Artificial Intelligence, pages
reference ||| 170–176. Springer Verlag, 2000.
reference ||| [ACHA90] Stuart F. Allen, Robert L. Constable, Douglas J. Howe,
reference ||| and William Aitken. The semantics of reflected proof. In
reference ||| Proceedings of the 5th Symposium on Logic in Computer
reference ||| Science, pages 95–197. IEEE Computer Society Press, June
reference ||| 1990.
reference ||| [ACM02] Simon Ambler, Roy L. Crole, and Alberto Momigliano.
reference ||| Combining higher order abstract syntax with tactical theorem
reference ||| proving and (co)induction. In TPHOLs ’02: Proceedings
reference ||| of the 15th International Conference on Theorem Proving
reference ||| in Higher Order Logics, pages 13–30, London, UK, 2002.
reference ||| Springer-Verlag.
reference ||| [ACM03] S. J. Ambler, R. L. Crole, and Alberto Momigliano. A
reference ||| definitional approach to primitive recursion over higher
reference ||| order abstract syntax. In Proceedings of the 2003 workshop
reference ||| on Mechanized reasoning about languages with variable
reference ||| binding, pages 1–11. ACM Press, 2003.
reference ||| [ACU93] William Aitken, Robert L. Constable, and Judith Underwood.
reference ||| Metalogical Frameworks II: Using reflected decision pro-
reference ||| cedures.Journal of Automated Reasoning, 22(2):171–221,
reference ||| 1993.
page ||| 10
reference ||| [All87a]	Stuart F. Allen. A Non-type-theoretic Definition of Martin-
reference ||| L¨of’s Types. In D. Gries, editor, Proceedings ofthe 2nd IEEE
reference ||| Symposium on Logic in Computer Science, pages 215–224.
reference ||| IEEE Computer Society Press, June 1987.
reference ||| [All87b]	Stuart F. Allen. A Non-Type-Theoretic Semantics for Type-
reference ||| Theoretic Language. PhD thesis, Cornell University, 1987.
reference ||| [Art99]	Sergei Artemov. On explicit reflection in theorem proving
reference ||| and formal verification. In Ganzinger [Gan99], pages 267–
reference ||| 281.
reference ||| [Art04]	Sergei Artemov. Evidence-based common knowledge.
reference ||| Technical Report TR-2004018, CUNY Ph.D. Program in
reference ||| Computer Science Technical Reports, November 2004.
reference ||| [BA02]	Eli Barzilay and Stuart Allen. Reflecting higher-order abstract
reference ||| syntax in NuPRL. In Victor A. Carre˜no, C´ezar A. Mu˜noz,
reference ||| and Sophi`ene Tahar, editors, Theorem Proving in Higher
reference ||| Order Logics; Track B Proceedings of the 15th International
reference ||| Conference on Theorem Proving in Higher Order Logics
reference ||| (TPHOLs 2002), Hampton, VA, August 2002, pages 23–32.
reference ||| National Aeronautics and Space Administration, 2002.
reference ||| [BAC03]	Eli Barzilay, Stuart Allen, and Robert Constable. Practical
reference ||| reflection in NuPRL. Short paper presented at 18th Annual
reference ||| IEEE Symposium on Logic in Computer Science, June 22–
reference ||| 25, Ottawa, Canada, 2003.
reference ||| [Bar01]	Eli Barzilay. Quotation and reflection in NuPRL and Scheme.
reference ||| Technical Report TR2001-1832, Cornell University, Ithaca,
reference ||| New York, January 2001.
reference ||| [Bar05]	Eli Barzilay. Implementing Reflection in NuPRL. PhD thesis,
reference ||| Cornell University, 2005. In preparation.
reference ||| [CAB+86] Robert L. Constable, Stuart F. Allen, H. M. Bromley, W. R.
reference ||| Cleaveland, J. F. Cremer, R. W. Harper, Douglas J. Howe,
reference ||| T. B. Knoblock, N. P. Mendler, P. Panangaden, James T.
reference ||| Sasaki, and Scott F. Smith. Implementing Mathematics with
reference ||| the NuPRL ProofDevelopment System. Prentice-Hall, NJ,
reference ||| 1986.
reference ||| [CFW04]	Luis Crus-Filipe and Freek Weidijk. Hierarchical reflection.
reference ||| In Slind et al. [SBG04], pages 66–81.
reference ||| [Con94]	Robert L. Constable. Using reflection to explain and enhance
reference ||| type theory. In Helmut Schwichtenberg, editor, Proof and
reference ||| Computation, volume 139 of NATO Advanced Study Insti-
reference ||| tute, International Summer School held in Marktoberdorf,
reference ||| Germany, July 20-August 1, NATO Series F, pages 65–100.
reference ||| Springer, Berlin, 1994.
reference ||| [dB72]	N. G. de Bruijn. Lambda calculus notation with nameless
reference ||| dummies, a tool for automatic formula manipulation, with
reference ||| application to the Church-Rosser theorem. Indagaciones
reference ||| Mathematische, 34:381–392, 1972. This also appeared in the
reference ||| Proceedings of the Koninklijke Nederlandse Akademie van
reference ||| Wetenschappen, Amsterdam, series A, 75, No. 5.
reference ||| [DFH95]	Jo¨elle Despeyroux, Amy Felty, and Andr´e Hirschowitz.
reference ||| Higher-order abstract syntax in Coq. In M. Dezani-
reference ||| Ciancaglini and G. Plotkin, editors, Proceedings of the
reference ||| International Conference on Typed Lambda Calculus and
reference ||| its Applications, volume 902 of Lecture Notes in Computer
reference ||| Science, pages 124–138. Springer-Verlag, April 1995. Also
reference ||| appears as INRIA research report RR-2556.
reference ||| [DH94]	Jo¨elle Despeyroux and Andr´e Hirschowitz. Higher-order
reference ||| abstract syntax with induction in Coq. In LPAR ’94:
reference ||| Proceedings of the 5th International Conference on Logic
reference ||| Programming and Automated Reasoning, volume 822
reference ||| of Lecture Notes in Computer Science, pages 159–173.
reference ||| Springer-Verlag, 1994. Also appears as INRIA research
reference ||| report RR-2292.
reference ||| [DH95]	James Davis and Daniel Huttenlocher. Shared annotations for
reference ||| cooperative learning. In Proceedings of the ACM Conference
reference ||| on Computer Supported Cooperative Learning, September
reference ||| 1995.
reference ||| [DL99]	Jo¨elle Despeyroux and Pierre Leleu. A modal lambda
reference ||| calculus with iteration and case constructs. In T. Altenkirch,
reference ||| W. Naraschewski, and B. Reus, editors, Types for Proofs
reference ||| and Programs: International Workshop, TYPES ’98, Kloster
reference ||| Irsee, Germany, March 1998, volume 1657 of Lecture Notes
reference ||| in Computer Science, pages 47–61, 1999.
reference ||| [DL01]	Jo¨elle Despeyroux and Pierre Leleu. Recursion over objects
reference ||| of functional type. Mathematical Structures in Computer
reference ||| Science, 11(4):555–572, 2001.
reference ||| [DPS97]	Jo¨elle Despeyroux, Frank Pfenning, and Carsten Sch¨urmann.
reference ||| Primitive recursion for higher–order abstract syntax. In
reference ||| R. Hindley, editor, Proceedings of the Third International
reference ||| Conference on Typed Lambda Calculus and Applications
reference ||| (TLCA’97), volume 1210 of Lecture Notes in Computer
reference ||| Science, pages 147–163. Springer-Verlag, April 1997. An
reference ||| extended version is available as Technical Report CMU-CS-
reference ||| 96-172, Carnegie Mellon University.
reference ||| [EM71]	Andrzej Ehrenfeucht and Jan Mycielski. Abbreviating
reference ||| proofs by adding new axioms. Bulletin of the American
reference ||| Mathematical Society, 77:366–367, 1971.
reference ||| [F+86]	Solomon Feferman et al., editors. Kurt G¨odel Collected
reference ||| Works, volume 1. Oxford University Press, Oxford,
reference ||| Clarendon Press, New York, 1986.
reference ||| [FPT99]	Marcelo Fiore, Gordon Plotkin, and Daniele Turi. Abstract
reference ||| syntax and variable binding. In Proceedings of 14th IEEE
reference ||| Symposium on Logic in Computer Science, pages 193+. IEEE
reference ||| Computer Society Press, 1999.
reference ||| [Gan99]	Harald Ganzinger, editor. Proceedings of the 16th Interna-
reference ||| tional Conference on Automated Deduction, volume 1632
reference ||| of Lecture Notes in Artificial Intelligence, Berlin, July 7–10
reference ||| 1999. Trento, Italy.
reference ||| [GM96]	A. D. Gordon and T. Melham. Five axioms of alpha-
reference ||| conversion. In J. von Wright, J. Grundy, and J. Harrison,
reference ||| editors, Theorem Proving in Higher Order Logics: 9th
reference ||| International Conference, Turku, Finland, August 1996:
reference ||| Proceedings, volume 1125 of Lecture Notes in Computer
reference ||| Science, pages 173–190. Springer-Verlag, 1996.
reference ||| [GMO03] Jim Grundy, Tom Melham, and John O’Leary. A reflective
reference ||| functional language for hardware design and theorem
reference ||| proving. Technical Report PRG-RR-03-16, Oxford Univerity,
reference ||| Computing Laboratory, 2003.
reference ||| [G¨od31 ]	Kurt G¨odel. ¨Uber formal unentscheidbare s¨atze der principia
reference ||| mathematica und verwandter systeme I. Monatshefte f¨ur
reference ||| Mathematik und Physik, 38:173–198, 1931. English version
reference ||| in [vH67].
reference ||| [G¨od36]	K. G¨odel. ¨Uber die L¨ange von beweisen. Ergebnisse
reference ||| eines mathematischen Kolloquiums, 7:23–24, 1936. English
reference ||| translation in [F+86], pages 397–399.
reference ||| [GS89]	F. Giunchiglia and A. Smaill. Reflection in constructive
reference ||| and non-constructive automated reasoning. In H. Abramson
reference ||| and M. H. Rogers, editors, Meta-Programming in Logic
reference ||| Programming, pages 123–140. MIT Press, Cambridge,
reference ||| Mass., 1989.
reference ||| [GWZ00] H. Geuvers, F. Wiedijk, and J. Zwanenburg. Equational rea-
reference ||| soning via partial reflection. In J. Harrison and M. Aagaard,
reference ||| editors, Theorem Proving in Higher Order Logics: 13th Inter-
reference ||| national Conference, TPHOLs 2000, volume 1869 of Lecture
reference ||| Notes in Computer Science, pages 162–178. Springer-Verlag,
reference ||| 2000.
reference ||| [HAB+]	Jason J. Hickey, Brian Aydemir, Yegor Bryukhov, Alexei
reference ||| Kopylov, Aleksey Nogin, and Xin Yu. A listing of Meta PRL
reference ||| theories. http://metaprl.org/theories.pdf.
reference ||| [Har95]	J. Harrison. Metatheory and reflection in theorem proving:
reference ||| A survey and critique. Technical Report CRC-53, SRI
reference ||| International, Cambridge Computer Science Research
reference ||| Centre, Millers Yard, Cambridge, UK, February 1995.
page ||| 11
reference ||| [HHP93]	Robert Harper, Furio Honsell, and Gordon Plotkin. A
reference ||| framework for defining logics. Journal of the Association
reference ||| for Computing Machinery, 40(1):143–184, January 1993. A
reference ||| revised and expanded verion of ’87 paper.
reference ||| [Hic97]	Jason J. Hickey. NuPRL-Light: An implementation
reference ||| framework for higher-order logics. In William McCune,
reference ||| editor, Proceedings of the 14th International Conference
reference ||| on Automated Deduction, volume 1249 of Lecture Notes in
reference ||| Artificial Intelligence, pages 395–399. Springer, July 13–17
reference ||| 1997. An extended version of the paper can be found at
reference ||| http://www.cs.caltech.edu/~jyh/papers/cade14_
reference ||| nl/default.html.
reference ||| [Hic99]	Jason J. Hickey. Fault-tolerant distributed theorem proving.
reference ||| In Ganzinger [Gan99], pages 227–231.
reference ||| [Hic01]	Jason J. Hickey. The MetaPRL Logical Programming
reference ||| Environment. PhD thesis, Cornell University, Ithaca, NY,
reference ||| January 2001.
reference ||| [HL78]	G´erard P. Huet and Bernard Lang. Proving and applying
reference ||| program transformations expressed with second-order
reference ||| patterns. Acta Informatica, 11:31–55,1978.
reference ||| [HNC+03] Jason Hickey, Aleksey Nogin, Robert L. Constable,
reference ||| Brian E. Aydemir, Eli Barzilay, Yegor Bryukhov, Richard
reference ||| Eaton, Adam Granicz, Alexei Kopylov, Christoph Kreitz,
reference ||| Vladimir N. Krupski, Lori Lorigo, Stephan Schmitt, Carl
reference ||| Witty, and Xin Yu. MetaPRL — A modular logical en-
reference ||| vironment. In David Basin and Burkhart Wolff, editors,
reference ||| Proceedings of the 16th International Conference on Theo-
reference ||| rem Proving in Higher OrderLogics (TPHOLs 2003), volume
reference ||| 2758 of Lecture Notes in Computer Science, pages 287–303.
reference ||| Springer-Verlag, 2003.
reference ||| [HNK+]	Jason J. Hickey, Aleksey Nogin, Alexei Kopylov, et al.
reference ||| MetaPRL home page. http://metaprl.org/.
reference ||| [Mos52]	Andrzej Mostowski. Sentences undecidable in formalized
reference ||| arithmetic: an exposition of the theory of Kurt G¨odel.
reference ||| Amsterdam: North-Holland, 1952.
reference ||| [NH02]	Aleksey Nogin and Jason Hickey. Sequent schema for
reference ||| derived rules. In Victor A. Carre˜no, C´ezar A. Mu˜noz,
reference ||| and Sophi`ene Tahar, editors, Proceedings of the 15th
reference ||| International Conference on Theorem Proving in Higher
reference ||| Order Logics (TPHOLs 2002), volume 2410 of Lecture Notes
reference ||| in Computer Science, pages 281–297. Springer-Verlag, 2002.
reference ||| [NKYH05] Aleksey Nogin, Alexei Kopylov, Xin Yu, and Jason Hickey.
reference ||| A computational approach to reflective meta-reasoning
reference ||| about languages with bindings. Technical Report Cal-
reference ||| techCSTR:2005.003, California Institure of Technology,
reference ||| 2005. Available at http://resolver.caltech.edu/
reference ||| CaltechCSTR:2005.003.
reference ||| [Nor04]	Michael Norrish. Recursive function definition for types with
reference ||| binders. In Slind et al. [SBG04], pages 241–256.
reference ||| [Par71]	R. Parikh. Existence and feasibility in arithmetic. The Journal
reference ||| ofSymbolic Logic, 36:494–508,1971.
reference ||| [Pau94]	Lawrence C. Paulson. Isabelle: A Generic Theorem Prover,
reference ||| volume 828 of Lecture Notes in Computer Science. Springer-
reference ||| Verlag, New York, 1994.
reference ||| [PE88]	Frank Pfenning and Conal Elliott. Higher-order abstract
reference ||| syntax. In Proceedings oftheACMSIGPLAN’88 Conference
reference ||| on Programming Language Design and Implementation
reference ||| (PLDI), volume 23(7) of SIGPLANNotices, pages 199–208,
reference ||| Atlanta, Georgia, June 1988. ACM Press.
reference ||| [Pfe89]	Frank Pfenning. Elf: a language for logic definition and
reference ||| verified metaprogramming. In Proceedings of the 4th IEEE
reference ||| Symposium on Logic in Computer Science, pages 313–322,
reference ||| Asilomar Conference Center, Pacific Grove, California, June
reference ||| 1989. IEEE Computer Society Press.
reference ||| [Plo90]	Gordon Plotkin. An illative theory of relations. In R. Cooper,
reference ||| K. Mukai, and J. Perry, editors, Situation Theory and Its
reference ||| Applications, Volume 1, number 22 in CSLI Lecture Notes,
reference ||| pages 133–146. Centre for the Study of Language and
reference ||| Information, 1990.
reference ||| [PN90]	L. Paulson and T. Nipkow. Isabelle tutorial and user’s man-
reference ||| ual. Technical report, University of Cambridge Computing
reference ||| Laboratory, 1990.
reference ||| [SBG04]	Konrad Slind, Annette Bunker, and Ganesh Gopalakrishnan,
reference ||| editors. Proceedings of the 17th International Conference
reference ||| on Theorem Proving in Higher Order Logics (TPHOLs
reference ||| 2004), volume 3223 of Lecture Notes in Computer Science.
reference ||| Springer-Verlag, 2004.
reference ||| [Sch01]	Carsten Sch¨urmann. Recursion for higher-order encodings.
reference ||| In L. Fribourg, editor, Computer Science Logic, Proceedings
reference ||| of the 10th Annual Conference of the EACSL, volume 2142
reference ||| of Lecture Notes in Computer Science, pages 585–599.
reference ||| Springer-Verlag, 2001.
reference ||| [Smi84]	B.C. Smith. Reflection and semantics in Lisp. Principles of
reference ||| Programming Languages, pages 23–35, 1984.
reference ||| [vH67]	J. van Heijenoort, editor. From Frege to G¨odel: A Source
reference ||| Book in Mathematical Logic, 1879–1931. Harvard University
reference ||| Press, Cambridge, MA, 1967.
page ||| 12

title ||| An expressive aspect language for system applications
title ||| with Arachne
author ||| R´emi Douence, Thomas Fritz, Nicolas Loriant,
author ||| Jean-Marc Menaud, Marc S´egura-Devillechaise, Mario S¨udholt
affiliation ||| OBASCO project
affiliation ||| ´Ecole des Mines de Nantes/INRIA
address ||| 4 rue Alfred Kastler
address ||| 44307 Nantes Cedex 3, France
email ||| {douence,tfritz,nloriant,jmenaud,msegura,sudholt}@emn.fr
sectionHeader ||| ABSTRACT
bodyText ||| C applications, in particular those using operating system
bodyText ||| level services, frequently comprise multiple crosscutting con-
bodyText ||| cerns: network protocols and security are typical examples
bodyText ||| of such concerns. While these concerns can partially be ad-
bodyText ||| dressed during design and implementation of an application,
bodyText ||| they frequently become an issue at runtime, e.g., to avoid
bodyText ||| server downtime. A deployed network protocol might not be
bodyText ||| efficient enough and may thus need to be replaced. Buffer
bodyText ||| overflows might be discovered that imply critical breaches in
bodyText ||| the security model of an application. A prefetching strategy
bodyText ||| may be required to enhance performance.
bodyText ||| While aspect-oriented programming seems attractive in
bodyText ||| this context, none of the current aspect systems is expres-
bodyText ||| sive and efficient enough to address such concerns. This
bodyText ||| paper presents a new aspect system to provide a solution to
bodyText ||| this problem. While efficiency considerations have played
bodyText ||| an important part in the design of the aspect language, the
bodyText ||| language allows aspects to be expressed more concisely than
bodyText ||| previous approaches. In particular, it allows aspect pro-
bodyText ||| grammers to quantify over sequences of execution points as
bodyText ||| well as over accesses through variable aliases. We show how
bodyText ||| the former can be used to modularize the replacement of net-
bodyText ||| work protocols and the latter to prevent buffer overflows.
bodyText ||| We also present an implementation of the language as an
bodyText ||| extension of Arachne, a dynamic weaver for C applications.
bodyText ||| Finally, we present performance evaluations supporting that
bodyText ||| Arachne is fast enough to extend high performance applica-
bodyText ||| tions, such as the Squid web cache.
sectionHeader ||| Keywords
keyword ||| aspect language, sequence pointcut, dynamic weaving, sys-
keyword ||| tem applications
copyright ||| Permission to make digital or hard copies of all or part of this work for
copyright ||| personal or classroom use is granted without fee provided that copies are
copyright ||| not made or distributed for profit or commercial advantage and that copies
copyright ||| bear this notice and the full citation on the first page. To copy otherwise, to
copyright ||| republish, to post on servers or to redistribute to lists, requires prior specific
copyright ||| permission and/or a fee.
note ||| AOSD 05 Chicago Illinois USA
copyright ||| Copyright 2005 ACM 1-59593-042-6/05/03 ...$ 5.00.
sectionHeader ||| 1. INTRODUCTION
bodyText ||| Real-world applications typically comprise multiple cross-
bodyText ||| cutting concerns. This applies, in particular, to C applica-
bodyText ||| tions using operating system level services. We have exam-
bodyText ||| ined three concerns which are typical for this domain in the
bodyText ||| context of a large application, the open source web cache
bodyText ||| Squid [36]. More concretely, we have considered translation
bodyText ||| of network protocols (which may be necessary for efficiency
bodyText ||| reasons), insertion of checks for buffer overflows (which are
bodyText ||| at the heart of many of today’s security issues), and in-
bodyText ||| troduction of prefetching strategies within the cache (which
bodyText ||| can be used to enhance efficiency of the web cache). We
bodyText ||| have found that all these concerns are scattered over large
bodyText ||| portions of the code of Squid.
bodyText ||| Hence, the three concerns are crosscutting in the sense
bodyText ||| of Aspect-Oriented Programming (AOP) [24] and aspects
bodyText ||| should therefore be a means of choice for their modular-
bodyText ||| ization. The concerns have three important characteristics.
bodyText ||| First, they must frequently be applied at runtime, e.g., in
bodyText ||| order to rapidly fix a buffer overflow and thus prevent secu-
bodyText ||| rity breaches without incurring server downtime. A dynamic
bodyText ||| aspect weaver is therefore needed. Second, they expose in-
bodyText ||| tricate relationships between execution points, e.g., network
bodyText ||| protocols are most concisely expressed in terms of sequences
bodyText ||| of execution points, not individual ones. The aspect system
bodyText ||| must therefore support expressive means for the definition of
bodyText ||| aspects, in particular pointcuts. Third, efficiency is crucial
bodyText ||| in the application domain we consider.
bodyText ||| To our knowledge, none of the current aspect systems for
bodyText ||| C meet these three requirements and is suitable for the mod-
bodyText ||| ularization of such concerns. Moreover, requirements for
bodyText ||| dynamic weaving and efficiency often trade off with expres-
bodyText ||| sivity. Squid should be as efficient as possible and therefore
bodyText ||| exploit any suitable operating system and hardware partic-
bodyText ||| ularity. Its code base is therefore difficult to understand and
bodyText ||| manipulate, thus hindering in particular modularization ef-
bodyText ||| forts. It is therefore highly questionable that the considered
bodyText ||| modularization problems can be solved without aspects.
bodyText ||| In this paper we propose a solution to the aspectization of
bodyText ||| such concerns of C applications. More concretely, we provide
bodyText ||| three main contributions. First, we provide a new expressive
bodyText ||| aspect language featuring a construct for quantification over
bodyText ||| sequences of execution points as well as over accesses to lo-
bodyText ||| cal aliases of global variables. We show how this aspect lan-
page ||| 27
bodyText ||| guage permits concise expression of the considered concerns
bodyText ||| as aspects. Second, we present how the aspect language can
bodyText ||| be implemented efficiently through runtime weaving into bi-
bodyText ||| nary code. Concretely, this is done by integrating the aspect
bodyText ||| language into our tool Arachne, a dynamic weaver for C ap-
bodyText ||| plications. Furthermore, we present how Arachne improves
bodyText ||| on our previous work µDyner [32]. Finally, we give evidence
bodyText ||| that our approach meets strong efficiency requirements by
bodyText ||| showing performance evaluations in the context of Squid.
bodyText ||| The paper is structured as follows. Section 2 presents the
bodyText ||| motivating concerns we identified within Squid. Section 3
bodyText ||| shows how to modularize these concerns as aspects and de-
bodyText ||| fines our aspect language. Section 4 describes its implemen-
bodyText ||| tation within Arachne. Section 5 assesses the performance
bodyText ||| of our implementation. Section 6 describes related work.
bodyText ||| Section 7 concludes and suggests futures work.
sectionHeader ||| 2. MOTIVATIONS
bodyText ||| Legacy C applications involve multiple crosscutting con-
bodyText ||| cerns. Many of them remain challenging, both in terms
bodyText ||| of expressiveness required to handle them properly in an
bodyText ||| aspect-oriented language and in terms of constraints posed
bodyText ||| on the weaver. This section describes three such concerns
bodyText ||| in C applications: switching the network protocol, buffer
bodyText ||| overflows and prefetching. The network protocol concern is
bodyText ||| typically scattered through the entire application. It is an
bodyText ||| issue when administrators discover at runtime that the re-
bodyText ||| tained protocol is not efficient enough. Likewise the security
bodyText ||| threats posed by buffer overflows is a real concrete problem
bodyText ||| for administrators. While guarding all buffers against over-
bodyText ||| flows might decrease performance considerably, administra-
bodyText ||| tors are left with no other option than accepting the trade-
bodyText ||| off between security and performance chosen at application’s
bodyText ||| design time. Prefetching is another well-known crosscutting
bodyText ||| concern [12]. Since prefetching aims at increasing perfor-
bodyText ||| mance, prefetching aspects make only sense with an efficient
bodyText ||| weaver. Yet, it is still difficult to modularize these three con-
bodyText ||| cerns in today’s aspect-oriented language. In this section,
bodyText ||| we first describe the context in which the concerns arise be-
bodyText ||| fore showing their crosscutting nature and finally explaining
bodyText ||| the lack in current aspect-oriented languages to handle them
bodyText ||| properly.
subsectionHeader ||| 2.1 TCP to UDP protocol
bodyText ||| HTTP was essentially designed as a file transfer proto-
bodyText ||| col running on top of TCP, a connection-oriented protocol
bodyText ||| ensuring communication reliability. While the average Web
bodyText ||| page size does not exceed 8 KB [4], the cost of retrieving
bodyText ||| a Web page is often dominated by data exchanged for con-
bodyText ||| trol purposes of TCP rather than by the page content itself.
bodyText ||| This is not a new problem, many researches have already
bodyText ||| pointed out that TCP is not suitable for short-lived connec-
bodyText ||| tions. While HTTP 1.1 has introduced persistent connec-
bodyText ||| tions allowing a client to retrieve multiple pages from the
bodyText ||| same server through the same TCP connection, the number
bodyText ||| of simultaneous TCP connections is limited by operating
bodyText ||| systems. Servers have a strong incentive to close HTTP
bodyText ||| connections as soon as possible. Hence, despite the per-
bodyText ||| sistent connection mechanism, many studies conclude that
bodyText ||| TCP should be replaced by UDP to retrieve short pages [10,
bodyText ||| 29, 7]. In spite of its performance improvements, the number
bodyText ||| of legacy Web applications has prevented a wide adoption
bodyText ||| of this solution. Typical legacy Web applications have to be
figureCaption ||| Figure 1: Typical usage of the TCP and UDP APIs.
bodyText ||| stopped to switch the protocol. The traditional approach
bodyText ||| to avoid depriving a subnetwork from Internet connectivity
bodyText ||| while stopping the cache is to swap the application between
bodyText ||| different machines. This approach is not only expensive in
bodyText ||| terms of hardware, it complicates the administrative task of
bodyText ||| the Web cache administrator and poses the problem of con-
bodyText ||| sistently transferring the runtime state of the application
bodyText ||| before restarting it. Stopping an e-commerce Web server
bodyText ||| means a loss of money and many small companies can not
bodyText ||| afford the cost of redundant servers. For a wide acceptance,
bodyText ||| a HTTP dialect using UDP as transport protocol should
bodyText ||| thus be deployable on demand at runtime.
bodyText ||| In addition, replacing TCP by UDP in an application is
bodyText ||| relatively difficult. The choice of a transport protocol is
bodyText ||| usually based on standards believed to be ever-lasting and
bodyText ||| made at an early design stage. Hence no particular effort is
bodyText ||| made to localize this design decision in a single piece of code.
bodyText ||| For example, despite a modularization effort, the TCP API
bodyText ||| provided by the operating system is used directly in 7 of the
bodyText ||| 104 ” . c” source files of the Squid Web cache.
bodyText ||| As shown in Fig. 1, the TCP API is built around a set of
bodyText ||| C functions to be invoked sequentially by the application. In
bodyText ||| a properly written program, TCP functions are first used to
bodyText ||| establish the connection (typically with socket, connect,
bodyText ||| bind and listen), exchange data through the connection
bodyText ||| (typically with read and write) and then close it (typically
bodyText ||| close). UDP uses similar but less functions. UDP applica-
bodyText ||| tions first direct the operating system to dedicate the appro-
bodyText ||| priate resources to exchange data (typically with socket and
bodyText ||| bind), then exchange data through these resources (typically
bodyText ||| with sendto and recvfrom) before releasing them (typically
bodyText ||| with close). Hence, the problem is not only difficult be-
bodyText ||| cause TCP-related function invocations are scattered but
bodyText ||| because the relative order of each invocation is important in
bodyText ||| order to map it onto the appropriate UDP function.
bodyText ||| This example is typical of protocol based APIs. When
bodyText ||| such an API is used in an undisciplined way, it becomes
bodyText ||| quickly impossible to replace it by another one. Today,
bodyText ||| aspect-oriented systems lack an appropriate sequencing con-
bodyText ||| struct in their language. Moreover, many do not provide the
bodyText ||| ability to weave aspects dynamically.
subsectionHeader ||| 2.2 Buffer overflows
bodyText ||| In C, the size of an array is fixed at allocation time. Ac-
bodyText ||| cording to ISO and ANSI standards [2], an invalid array
bodyText ||| access does not result in an immediate error but leads to
bodyText ||| an implementation-dependent behavior. Such behavior is
bodyText ||| increasingly exploited by hackers to circumvent security re-
figure ||| TCP Protocol	Time	UDP Protocol
figure ||| Server Network Client	Server Network Client
figure ||| bind
figure ||| listen
figure ||| accept
figure ||| read
figure ||| write
figure ||| close
figure ||| socket
figure ||| connect
figure ||| write
figure ||| read
figure ||| close
figure ||| socket
figure ||| socket
figure ||| bind
figure ||| recvfrom
figure ||| sendto
figure ||| close
figure ||| socket
figure ||| recvfrom
figure ||| close
figure ||| sendto
page ||| 28
bodyText ||| strictions [37]. It is therefore crucial for C programmers to
bodyText ||| ensure every access to an array to be valid. On the other
bodyText ||| hand, bound checking code is error prone: it is easy to for-
bodyText ||| get to check an access and even when the access is checked,
bodyText ||| it is easy to compare the index locating the access with an
bodyText ||| inappropriate bound. Therefore, researchers have proposed
bodyText ||| to make compilers responsible for enforcing proper array ac-
bodyText ||| cess [22, 31]. The problem is that even the most efficient
bodyText ||| system (CRED [31]) slows down an application up to 130%.
bodyText ||| Moreover, most frequently used compilers like gcc do not
bodyText ||| support bound checking.
bodyText ||| Today, administrators discovering a buffer overflow in pro-
bodyText ||| duction software are left with no other option than stopping
bodyText ||| the application and restarting a bug free version. This was
bodyText ||| the solution chosen when a buffer overflow was discovered
bodyText ||| in Squid in [6]. While widely used, this solution suffers from
bodyText ||| three major drawbacks. First, it does not enforce continuous
bodyText ||| servicing since the service delivered by the application is not
bodyText ||| available during the update. Second, this solution entails an
bodyText ||| important information loss: an administrator has no means
bodyText ||| to learn whether the buffer overflow has been exploited by
bodyText ||| a hacker or not. Third, it misunderstands the performance
bodyText ||| trade-off, i.e. it is not necessary to check every array access,
bodyText ||| it is only necessary to perform enough checking to discour-
bodyText ||| age hackers. Therefore, bound checking code should only
bodyText ||| run when an environment becomes hostile [23].
bodyText ||| Bound checking code tends to crosscut the entire applica-
bodyText ||| tion. For example, properly written C functions accepting
bodyText ||| an array argument commonly take a second argument hold-
bodyText ||| ing the array size: the first one allows the function to access
bodyText ||| the array while the second is used to ensure correctness of
bodyText ||| accesses. In Squid, bound checking code can be found in
bodyText ||| any of the 104 ” . c” files of its source code. On the 57635
bodyText ||| lines composing these ” . c” files, at least 485 check bounds.
bodyText ||| This problem fails to be handled properly in current as-
bodyText ||| pect languages as they lack the ability to trigger advices
bodyText ||| upon access made through the alias of a variable. Again,
bodyText ||| many aspect-oriented systems offer only static weaving ca-
bodyText ||| pabilities preventing the administrator to choose the trade-
bodyText ||| off security/performance suiting his needs.
subsectionHeader ||| 2.3 From fetching to prefetching
bodyText ||| Operations like retrieving a file on a local disk or over the
bodyText ||| Web can be sped up if the underlying software anticipates
bodyText ||| user requests and start to fetch documents beforehand. Such
bodyText ||| prefetching schemes distinguish themselves from each other
bodyText ||| in the way they predict future user requests. These ”ora-
bodyText ||| cles” actually prevent a clean encapsulation of prefetching
bodyText ||| in a single module communicating with the rest of the appli-
bodyText ||| cation through well-defined interfaces since predictions are
bodyText ||| based on information meant to be private to other modules.
bodyText ||| In addition, it is very likely that there is no universal per-
bodyText ||| fect oracle [19]. A statically linked prefetching module is
bodyText ||| therefore inappropriate, but prefetching modules along with
bodyText ||| the necessary oracles should be loaded and unloaded on the
bodyText ||| fly. Due to their crosscutting nature, prefetching modules
bodyText ||| including such oracles are better written with aspects [32].
bodyText ||| Coady et al. have already pointed out the crosscutting
bodyText ||| nature of prefetching in the FreeBSD OS [12]. In our pre-
bodyText ||| vious work considering the Squid Web cache, we reached a
bodyText ||| similar conclusion [32]. We have previously shown that this
bodyText ||| concern can be addressed with cflow-like constructs.
bodyText ||| Despite potential performance improvements, prefetching
bodyText ||| also increases resource consumption (e.g. network prefetch-
bodyText ||| ing consumes local storage and bandwidth). When the pres-
bodyText ||| sure on resources is too high, prefetching computation com-
bodyText ||| petes for them against regular user requests, and slows down
bodyText ||| their treatment instead of speeding it up. In such cases,
bodyText ||| prefetching should therefore be, temporarily, disabled. Squid
bodyText ||| essentially manages file descriptors, a resource only available
bodyText ||| in a limited quantity. A file descriptor is used between the
bodyText ||| underlying operating system and applications to describe a
bodyText ||| network connection or a file on the disk. Squid’s file descrip-
bodyText ||| tor management is based on a global variable that tracks the
bodyText ||| number of file descriptors currently in use. By comparing
bodyText ||| its value with the maximum number of file descriptors al-
bodyText ||| lowed by the operating system, it is possible to estimate that
bodyText ||| prefetching should be disabled or resumed.
bodyText ||| For this problem of file descriptor consumption, the cur-
bodyText ||| rent practice of checking if prefetching should be disabled or
bodyText ||| not within the advice, is a bad practice that impedes both
bodyText ||| readability and maintainability. A mechanism is needed
bodyText ||| within the aspect language to restraint the advice execu-
bodyText ||| tion at times where the pressure on resources is too high.
bodyText ||| This problem were not addressed in our previous work.
sectionHeader ||| 3. AN EXPRESSIVE ASPECT LANGUAGE
sectionHeader ||| FOR SYSTEM PROGRAMMING IN C
bodyText ||| While AOP seems to be the obvious choice to tackle the
bodyText ||| crosscutting concerns introduced above, none of the existing
bodyText ||| AO systems provides explicit support for some of their es-
bodyText ||| sential elements, in particular, join point sequences for pro-
bodyText ||| tocols, and references to aliases which are local to a function.
bodyText ||| In this section we introduce a new aspect language for
bodyText ||| system programming in C that allows such crosscutting con-
bodyText ||| cerns to be expressed concisely. In order to make this point,
bodyText ||| we first revisit the examples by concisely aspectizing them
bodyText ||| using our language. (Note that our aspect language is ex-
bodyText ||| pressive in the sense of enabling the concise definition of cer-
bodyText ||| tain types of aspects, especially compared to other tools for
bodyText ||| system-level manipulations, but not necessarily more expres-
bodyText ||| sive than existing approaches in a language-theoretic sense.)
bodyText ||| We then define the join point model underlying our language
bodyText ||| precisely, followed by the definition of its syntax and infor-
bodyText ||| mal semantics. Finally, we illustrate how its semantics can
bodyText ||| be formally defined in terms of a small-step operational se-
bodyText ||| mantics using the framework introduced in [14].
subsectionHeader ||| 3.1 Example crosscutting concerns revisited
bodyText ||| We now revisit the concerns discussed in section 2 in order
bodyText ||| to show our language in action and give evidence that it
bodyText ||| allows such concerns to be concisely modularized.
bodyText ||| The aspect shown in Fig. 2 translates transport protocols
bodyText ||| from TCP to UDP. A protocol defines a sequence of func-
bodyText ||| tion calls, so the top-level operator of this aspect is seq.
bodyText ||| The sequence aspect syntactically consists of a list of pairs
bodyText ||| of pointcut and advice (separated by then). In the exam-
bodyText ||| ple, the TCP protocol starts with a call to socket() with
bodyText ||| three constant arguments: AF INET, SOCK STREAM and
bodyText ||| 0. When such a call is matched, the second parameter is
bodyText ||| replaced by SOCK DGRAM as required by the UDP proto-
bodyText ||| col. The result of this transformed call, the file descriptor,
bodyText ||| is bound to fd by return(fd). Then the next call to con-
bodyText ||| nect() with the same file descriptor fd as its first parameter
bodyText ||| is matched. In this case the values of the other parameters
page ||| 29
figure ||| seq( call(int socket(int, int, int)) && args(AF INET, SOCK STREAM, 0) && return(fd)
figure ||| then socket(AF INET, SOCK DGRAM, 0);
figure ||| call(int connect(int, struct socketaddr*, socklen t)) && args(fd, address, length)
figure ||| then returnZero(); // where int returnZero() { return 0; }
figure ||| ( call(size t read(int, void*, size t)) && args(fd, readBuffer, readLength)
figure ||| then recvfrom(fd, readBuffer, readLength, 0, address, length);
figure ||| 11call(size t write(int, void*, size t)) && args(fd, writeBuffer, writeLength)
figure ||| then sendto(fd, writeBuffer, writeLength, 0, address, length);) *
figure ||| call(int close(int)) && args(fd) ; )
figure ||| Figure 2: An Aspect for Switching Transport Protocols, from TCP to UDP
figure ||| seq( call(void * malloc(size t))
figure ||| && args(allocatedSize) && return(buffer) ;
figure ||| write(buffer) && size(writtenSize)
figure ||| && if(writtenSize > allocatedSize)
figure ||| then reportOverflow(); *
figure ||| call(void free(void*)) )
figureCaption ||| Figure 3: An Aspect for Detecting Buffer Overflow
bodyText ||| are bound to arguments address and length, and the original
bodyText ||| call is replaced by returnZero(). Indeed, there is no connect
bodyText ||| step in the UDP protocol. After that, calls to read() and
bodyText ||| write() (using the ‘or’ on aspects: 11) on the same file de-
bodyText ||| scriptor fd are translated to UDP recvfrom() and sendto(),
bodyText ||| respectively. Note that sequences of such access are poten-
bodyText ||| tially translated (due to use of the repetition operator *).
bodyText ||| Finally, a call to close() on fd terminates the TCP protocol
bodyText ||| as well as the UDP protocol and thus is not modified (i.e.,
bodyText ||| there is no then clause). This last step is required to free
bodyText ||| the variables used in the sequence (here, fd, address and
bodyText ||| length). Indeed, this aspect can use numerous (instances of
bodyText ||| these) variables when it deals with interleaved sequences, as
bodyText ||| each call to socket() creates a new instance of the sequence.
bodyText ||| The aspect shown in Fig. 3 detects buffer overflows. The
bodyText ||| corresponding sequence starts when the function malloc()
bodyText ||| returns the buffer address which is then bound to buffer.
bodyText ||| Then, each time this address is accessed (through a global
bodyText ||| variable or a local alias) the size of the data to be written is
bodyText ||| compared with the size of the initially allocated memory. If
bodyText ||| the former exceeds the latter, an overflow is indicated. The
bodyText ||| sequence ends when the memory is deallocated using free().
bodyText ||| The aspect in Fig. 4 introduces prefetching in a web cache.
bodyText ||| The first controlf low phrase initializes prefetching when
bodyText ||| an HTTP response is built (clientBuildReply()) within the
bodyText ||| control flow of a client request (clientSendMoreData()). The
bodyText ||| until clause stops prefetching when the number of connec-
bodyText ||| tion becomes too large, a situation where prefetching would
bodyText ||| effectively degrade performance. The second controlf low
bodyText ||| phrase analyzes hyperlinks in a page being transmitted (i.e.,
bodyText ||| when comm write mbuf() is called within the control flow
bodyText ||| of clientSendMoreData()). Finally, the last call phrase pre-
bodyText ||| fetches hyperlinks analyzed by the second aspect. It does so
bodyText ||| by replacing the method call to clientWriteComplete() with
bodyText ||| retrieveHyperlinks(). Finally, note that the two require
bodyText ||| clauses at the top of the aspect declare the types of the
bodyText ||| global variables of the base program used in the aspects.
subsectionHeader ||| 3.2 Join points
bodyText ||| A join point model defines the points in the execution
bodyText ||| of the base program to which pointcuts may refer. In our
figure ||| JP::= callJP(valfunId( −→val))
figure ||| readGlobalJP(varId,val)
figure ||| readJP(@, val)
figure ||| writeGlobalJP(varId, val, size)
figure ||| writeJP(@, val, size)
figure ||| controlflowJP(−−−−→
figure ||| funId, cfEnd)
figure ||| controlflowstarJP(−−−−→
figure ||| funId, cfEnd)
figure ||| cfEnd::= callJP(val funId(−→val))
figure ||| 1readGlobalJP(varId,val)
figure ||| 1writeGlobalJP(varId, val, size)
figure ||| val::= 011121...	//int
figure ||| 1@0 1 @1 1 @2 1 ... // int*
figure ||| 1... // values of other C types
figureCaption ||| Figure 5: Join point model
bodyText ||| case, join points are defined by JP in the grammar shown
bodyText ||| in Fig. 5. A join point is either:
listItem ||| •	A call of a function callJP(v1 funId(−→v2)) with function
listItem ||| name funId, return value vi and a vector of arguments →−v2.
listItem ||| •	A read access which comes in two variants:
listItem ||| readGlobalJP(varId,v) denotes reading a global vari-
listItem ||| able with name varId holding the value v; readJP(@, v)
listItem ||| denotes reading a global variable or a local alias with
listItem ||| address @ holding the value v.
listItem ||| •	Write access which also comes in two variants:
listItem ||| writeGlobalJP(varId, v, size) denotes assignment to a global
listItem ||| variable with name varId of the value v of size size.
listItem ||| writeJP(@, v, size) denotes assignment to a global variable
listItem ||| or a local alias with address @ of the value v of size size.
listItem ||| •	A cflow expression controlflowJP( f Inu d, c), where
listItem ||| f Inu d = [funId1, .., funIda] is a stack of function names, and
listItem ||| c (either a function call or an access to a global variable) oc-
bodyText ||| curs within the body of function funId�. Such a join point
bodyText ||| requires a call to funId�+1 within the body of funId�.
listItem ||| •	A cflow expression controlflowstarJP( f unId, c), where
listItem ||| −−−−→
bodyText ||| f Inu d = [funId1, .., funIda] is a partial stack of function
bodyText ||| names, and c (either a function call or an access to a global
bodyText ||| variable) occurs within the control flow of function funId�.
bodyText ||| Such a join point requires a call to funId�+1 within the
bodyText ||| control flow of (i.e., not necessarily in the body of) funId�.
bodyText ||| Two features of this join point model may be surprising
bodyText ||| at first sight: distinction of accesses to aliases from those to
bodyText ||| global variables and explicit representation of control flow
page ||| 30
figure ||| require Number Of Fd as int*;
figure ||| require Squid MaxFd as int*;
figure ||| controlflow(call(void clientSendMoreData(void*, char*, size t)),
figure ||| call(HttpReply * clientBuildReply(clientHttpRequest*, char*, size t))
figure ||| && args( request, buffer, buffer Size ))
figure ||| then startPrefetching(request, buffer, bufferSize);
figure ||| && until(writeGlobal(int * Number Of Fd) && if((*Number Of Fd) * 100/(*Squid MaxFd) ≥ 75) ; )
figure ||| controlflow( call(void clientSendMoreData(void*, char*, size t)),
figure ||| call(void comm write mbuf(int, MemBuf, void*, void*))
figure ||| && args(fd, mb, handler, handlerData) && if (! isPre f etch(handler)) )
figure ||| then parseHyperlinks(fd, mb, handler, handlerData);
figure ||| call(void clientWriteComplete(int, char*, size t, int, void*))
figure ||| && args(fd, buf, size, error, data) && if(! isPre f etch(handler))
figure ||| then retrieveHyperlinks(fd, buf, size, error, data);
figureCaption ||| Figure 4: An Aspect for Prefetching
bodyText ||| expressions. Both are motivated by our quest for efficiency
bodyText ||| and are grounded in strong implementation constraints in
bodyText ||| the context of dynamic weaving of binary C code: an access
bodyText ||| to a local alias is several magnitudes slower than that to a
bodyText ||| global variable and matching of control flow join points can
bodyText ||| be done using an atomic test on the implementation level.
subsectionHeader ||| 3.3 Pointcuts
bodyText ||| We now present a pointcut language (see Fig. 6) that pro-
bodyText ||| vides constructs to match individual join points.
bodyText ||| Primitive pointcuts are defined by PPrim and comprise
bodyText ||| three basic pointcuts matching calls, global variable accesses,
bodyText ||| and control flow join points. Primitive pointcuts can also be
bodyText ||| combined using a logical “or” noted I I.
bodyText ||| A call pointcut PCall selects all function call join points
bodyText ||| −→
bodyText ||| callJP(val funId(val)), i.e., all calls to a function matching
bodyText ||| the signature type funId(t pe), where the arguments of the
bodyText ||| function can be bound to pointcut variables using argument
bodyText ||| binder args( −−−−−→
bodyText ||| pattern ) and the return value can be bound to
bodyText ||| a pointcut variable using a return clause return( pattern ).
bodyText ||| The two constructs args( −−−−−→
bodyText ||| pattern ) and return( pattern )
bodyText ||| can also provide pattern matching by using values (or al-
bodyText ||| ready bound pointcut variables) in pattern. Pointcuts can
bodyText ||| also depend on a boolean condition using the if-constructor.
bodyText ||| A global access pointcut PAccGlobal selects either all read
bodyText ||| join points readGlobalJP(varId, val) or all write join points
bodyText ||| writ eGlobalJP(varId, val, size) on the global base program
bodyText ||| variable varId. In these cases, the read or written value can
bodyText ||| be bound to a variable using value(pattern); in addition, the
bodyText ||| size of the written value can be bound with size(varName).
bodyText ||| Pattern matching can also be used for variable access.
bodyText ||| A control flow pointcut PCf of the form controlflow(
bodyText ||| PCallSig1,..., PCallSign, PCfEnd) matches all join points
bodyText ||| of the form controlflowJP(funId1, ..., funIdn, cfEnd), where
bodyText ||| the function identifier in PCallSigi is funIdi. Similarly, a
bodyText ||| control flow pointcut may match a global variable access
bodyText ||| for a given stack configuration. The pointcuts of the form
bodyText ||| controlflowstar(... ) select calls or global variable accesses
bodyText ||| in a stack context allowing for calls that are not directly
bodyText ||| nested within one another.
bodyText ||| Finally, PAcc, an access pointcut for a global variable or
bodyText ||| all of its local aliases, matches all join points of the form
bodyText ||| readJP or writeJP.
figure ||| Asp::= AspPrim [ && until( AspPrim) ]
figure ||| IAspSeq [ && until( AspPrim ) ]
figure ||| AspPrim::= PPrim Advice
figure ||| AspSeq::= seq( AspPrim
figure ||| AspSeqElts
figure ||| AspSeqElt )
figure ||| AspSeqElts ::_ [AspSeqElts] AspSeqElt [ * ]
figure ||| AspSeqElt::= AspPrim
figure ||| IPAcc Advice
figure ||| I(AspSeqElt II AspSeqElt)
figure ||| Advice::= [ then funId(pat�) ] ;
figureCaption ||| Figure 7: Aspect language
subsectionHeader ||| 3.4 Aspect Language
bodyText ||| The aspect language we propose is defined in Fig. 7. As-
bodyText ||| pects Asp are either primitive AspPrim, or sequences of
bodyText ||| primitive aspects AspSeq.
bodyText ||| A primitive aspect AspPrim combines a primitive point-
bodyText ||| cut with an advice that will be applied to all join points
bodyText ||| selected by the pointcut. If the primitive pointcut has the
bodyText ||| form p1 II p2, then all variables used in the advice have to
bodyText ||| be bound in both, p1 and p2.
bodyText ||| An advice (Advice) is a C function call that replaces a join
bodyText ||| point in the base program execution (similarly to around in
bodyText ||| AspectJ). It must have the same return type as the join
bodyText ||| point it replaces: the type of the global variable in case of a
bodyText ||| read access, void for a write access and the return type of
bodyText ||| the function for a call. When the advice is empty (no then
bodyText ||| clause), the original join point is executed. The original join
bodyText ||| point can be skipped by calling an empty C function.
bodyText ||| A sequence aspect is composed of a sequence of primitive
bodyText ||| aspects. A sequence starts when the first primitive aspect
bodyText ||| matches. Then the second primitive aspect becomes active
bodyText ||| instead of the first one. When it matches, the third aspect
bodyText ||| becomes active instead of the second one. And so on, until
bodyText ||| the last primitive aspect in the sequence. All but the first
bodyText ||| and last primitive aspects can be repeated zero or multiple
bodyText ||| times by using *: in this case, the primitive aspect is ac-
page ||| 31
figure ||| PPrim
figure ||| PCall
figure ||| PCallSig
figure ||| PIf
figure ||| PAccGlobal
figure ||| PCf	::=
figure ||| 1controlflowstar( PCallSigList, PCfEnd )
figure ||| PCallSigList ::= PCallSig [ , PCallSigList]
figure ||| PCall 1 PAccGlobal
figure ||| PCall
figure ||| 1PAccGlobal
figure ||| 1PCf
figure ||| 1PPrim11 PPrim
figure ||| ::=
figure ||| PCallSig [ && args(−−−−−→
figure ||| pattern) ] [ && return( pattern) ] [ && PIf ]
figure ||| call( type funId(t pe) )
figure ||| if( expr ) [ && PIf ]
figure ||| readGlobal( type varId) [ && value( pattern) ] [ && PIf ]
figure ||| 1writeGlobal( type varId) [ && value( pattern) ] [ && size( pattern) ] [ && PIf ]
figure ||| ::=
figure ||| ::=
figure ||| ::=
figure ||| ::=
figure ||| controlflow( PCallSigList, PCfEnd )
figure ||| PCf End	::=
figure ||| PAcc
figure ||| pattern	::=
figure ||| var 1 val
figure ||| read( var ) [ && value(pattern ) ] [ && PIf ]
figure ||| 1write( var ) [ && value( pattern ) ] [ && size( pattern) ] [ && PIf ]
figure ||| ::=
figureCaption ||| Figure 6: Pointcut language
figure ||| A::= A'
figure ||| 1A 11 A	; parallelism
figure ||| A'::= µa.A'	; recursive definition (a E Rec)
figure ||| 1C D I; A	; prefixing
figure ||| 1C D I; a	; end of sequence (a E Rec)
figure ||| 1C D I; STOP ; halting aspect
figure ||| 1A' ❑ A'	; choice
figureCaption ||| Figure 8: Tiny aspect language
bodyText ||| tive as long as the following one in the sequence does not
bodyText ||| match. Branching, i.e., a logical ‘or’ between two primitive
bodyText ||| aspects, can be introduced in a sequence by the operator 11.
bodyText ||| An element of the sequence can also match a global vari-
bodyText ||| able of the base program and accesses to its local aliases, as
bodyText ||| soon as its address is known (i.e., a previous primitive point-
bodyText ||| cut has already bound its address to a pointcut variable).
bodyText ||| Hence, an aspect matching accesses cannot start a sequence.
bodyText ||| Every join point matching the first primitive pointcut of a
bodyText ||| sequence starts a new instance of the sequence. The different
bodyText ||| instances are matched in parallel.
bodyText ||| A primitive or a sequence aspect a can be used in combi-
bodyText ||| nation with an expression until (a1 ), to restrict its scope. In
bodyText ||| this case, once a join point has been matched by a, the execu-
bodyText ||| tion of a proceeds as previously described until a1 matches.
bodyText ||| To conclude the presentation of our language, note that it
bodyText ||| does not include some features, such as named pointcuts as
bodyText ||| arguments to controlf lows and conjunctive terms, which
bodyText ||| are not necessary for the examples we considered but which
bodyText ||| could easily be added. (As an aside, note that such exten-
bodyText ||| sions of the pointcut language may affect the computability
bodyText ||| of advanced algorithmic problems, such as whether a point-
bodyText ||| cut matches some part of any base program [25].)
subsectionHeader ||| 3.5 Towards a formal semantics for expressive
subsectionHeader ||| aspects
bodyText ||| In the previous sections, we have given an informal se-
bodyText ||| mantics of our aspect language. We now illustrate how the
bodyText ||| aspect language could be formally defined by translating one
bodyText ||| of the example aspects into formal aspect language by ex-
bodyText ||| tension of that used in the formal framework of [14].
bodyText ||| The original formal language must be extended in order to
bodyText ||| deal with halting aspects, an unbounded number of sequen-
bodyText ||| tial aspects and arbitrary join point predicates. The gram-
bodyText ||| mar of the extension, our tiny aspect language, is defined in
bodyText ||| Figure 8. In this language, aspect expressions A consists of
bodyText ||| parallel combinations of aspects, C is a join point predicate
bodyText ||| (similar to our pointcut language) expressed as a conjunc-
bodyText ||| tion of a term pattern and possibly an expression from the
bodyText ||| constraint logic programming language CLP(R) [20].
bodyText ||| An aspect A' is either:
listItem ||| •	A recursive definition.
listItem ||| •	A sequence formed using the prefix operation C D I; X,
listItem ||| where X is an aspect or a recursion variable and I a piece
listItem ||| of code (i.e., an advice).
listItem ||| •	A choice construction A1 ❑ A2 which chooses the first
listItem ||| aspect that matches a join point (the other is thrown away).
listItem ||| If both match the same join point, A1 is chosen.
listItem ||| •	A parallel composition of two aspects A1 11 A2 that
listItem ||| cannot occur in choice construction.
listItem ||| •	A halting aspect STOP.
bodyText ||| The semantics of the protocol translation aspect (from
bodyText ||| TCP to UDP) is given in Fig. 9. A sequence can have sev-
bodyText ||| eral instances. This is translated into the language A by the
bodyText ||| expression a1 11 ... which starts a new sequence a1 once
bodyText ||| the first join point has been matched and continue to match
bodyText ||| the rest of the sequence in progress. The repetition oper-
bodyText ||| ator ∗ is translated into recursion on variable the a2. The
bodyText ||| branching operator 11 is translated into the choice operator
page ||| 32
figure ||| µa1. callJP(fd socket(AF INET,  SOCK  STREAM, 0)) D socket(AF INET, SOCK DGRAM, 0);
figure ||| a1 ( callJP(a connect(fd, address, length)) D returnZero();
figure ||| µa2. callJP(b close(fd)) D skip; STOP
figure ||| ❑	callJP(c read(fd, readBuffer, readLength)) D recvfrom(fd, readBuffer, readLength, 0, address, length); a2
figure ||| ❑	callJP(d write(fd, writeBuffer, writeLength)) D recvfrom(fd, writeBuffer, writeLength, 0, address, length); a2
figureCaption ||| Figure 9: Definition of the protocol translation using the tiny aspect language
bodyText ||| ❑. Finally, the last primitive aspect of the sequence occurs
bodyText ||| as the first aspect of a choice to get priority over the join
bodyText ||| points read and write because of the *. Note that we use
bodyText ||| pattern matching in A and that an overbar marks the first
bodyText ||| occurrence of a variable (i.e., its definition not a use).
bodyText ||| Note that formal definitions such as that of the protocol
bodyText ||| translation aspect precisely define several important issues,
bodyText ||| in particular, when new instances of the sequence aspect are
bodyText ||| created, and disambiguate of potentially non-deterministic
bodyText ||| situations, e.g., when two pointcuts of consecutive primitive
bodyText ||| aspects in the sequence match at the same time.
sectionHeader ||| 4. DYNAMIC WEAVING WITH ARACHNE
bodyText ||| Arachne is built around two tools, an aspect compiler and
bodyText ||| a runtime weaver. The aspect compiler translates the aspect
bodyText ||| source code into a compiled library that, at weaving time, di-
bodyText ||| rects the weaver to place the hooks in the base program. The
bodyText ||| hooking mechanisms used in Arachne are based on improved
bodyText ||| techniques originally developed for µDyner [32]. These tech-
bodyText ||| niques allow to rewrite the binary code of executable files
bodyText ||| on the fly i.e.without pausing the base program, as long
bodyText ||| as these files conform to the mapping defined by the Unix
bodyText ||| standard [35] between the C language and x86 assembly lan-
bodyText ||| guage. Arachne’s implementation is structured as an open
bodyText ||| framework that allows to experiment with new kinds of join
bodyText ||| points and pointcut constructs. Another important differ-
bodyText ||| ence between Arachne and µDyner is, that µDyner requires
bodyText ||| a compile time preparation of the base program, whereas
bodyText ||| Arachne does not. Hence Arachne is totally transparent for
bodyText ||| the base program while µDyner is not.
subsectionHeader ||| 4.1 The Arachne Open Architecture
bodyText ||| The Arachne open architecture is structured around three
bodyText ||| main entities: the aspect compiler, the instrumentation ker-
bodyText ||| nel, and the different rewriting strategies. The aspect com-
bodyText ||| piler translates the aspect source code into C before com-
bodyText ||| piling it. Weaving is accomplished through a command line
bodyText ||| tool weave that acts as a front end for the instrumentation
bodyText ||| kernel. weave relays weaving requests to the instrumen-
bodyText ||| tation kernel loaded in the address space of the program
bodyText ||| through Unix sockets. Upon reception of a weaving request,
bodyText ||| the instrumentation kernel selects the appropriate rewriting
bodyText ||| strategies referred by the aspects to be woven and instru-
bodyText ||| ments the base program accordingly. The rewriting strat-
bodyText ||| egy consults the pointcut analysis performed by the aspect
bodyText ||| compiler to locate the places where the binary code of the
bodyText ||| base program needs to be rewritten. It finally modifies the
bodyText ||| binary code to actually tie the aspects to the base program.
bodyText ||| With this approach, the Arachne core is independent of
bodyText ||| a particular aspect, of the aspect language, of the particu-
bodyText ||| lar processor architecture, and of a particular base program.
bodyText ||| In fact, all dependencies to aspect language implementation
bodyText ||| are limited to the aspect compiler. All dependencies to the
bodyText ||| operating system are localized in the instrumentation ker-
bodyText ||| nel and finally all dependencies to the underlying hardware
bodyText ||| architecture are modularized in the rewriting strategies.
subsubsectionHeader ||| 4.1.1 The Arachne aspect compilation process
bodyText ||| The aspect compilation scheme is relatively straightfor-
bodyText ||| ward: it transforms advices into regular C functions. Point-
bodyText ||| cuts are rewritten as C code driving hook insertions into
bodyText ||| the base program at weaving time. There are however cases
bodyText ||| where the sole introduction of hooks is insufficient to deter-
bodyText ||| mine whether an advice should be executed. In this case,
bodyText ||| the aspect compiler generates functions that complement
bodyText ||| the hooks with dynamic tests on the state of the base pro-
bodyText ||| gram. These dynamic tests are called residues in AspectJ
bodyText ||| and the rewritten instructions within the base program the
bodyText ||| shadow [16]. Once the aspects have been translated into C,
bodyText ||| the Arachne compiler uses a legacy C compiler to generate a
bodyText ||| dynamically linked library (DLL) for the compiled aspects.
subsubsectionHeader ||| 4.1.2 The Arachne weaving process
bodyText ||| From a user viewpoint, the Arachne weave and deweave
bodyText ||| command line programs the same syntax than µDyner’s ver-
bodyText ||| sion. They both take two arguments. The first identifies the
bodyText ||| process to weave aspects in or deweave aspects from, and
bodyText ||| the second indicates the aspect DLL. However, Arachne can
bodyText ||| target potentially any C application running on the machine
bodyText ||| while µDyner was limited to applications compiled with it
bodyText ||| running on the machine. When Arachne’s weave receives a
bodyText ||| request to weave an aspect in a process that does not con-
bodyText ||| tain the Arachne instrumentation kernel, it loads the kernel
bodyText ||| in the process address space using standard techniques [11].
bodyText ||| The instrumentation kernel is transparent for the base
bodyText ||| program as the latter cannot access the resources (mem-
bodyText ||| ory and sockets essentially) used by the former. Once in-
bodyText ||| jected, the kernel creates a thread with the Linux system
bodyText ||| call: clone. This thread handles the different weaving re-
bodyText ||| quests. Compared to the POSIX pthread create function,
bodyText ||| the usage of clone allows the instrumentation thread to pre-
bodyText ||| vent the base program to access its sockets. The instrumen-
bodyText ||| tation kernel allocates memory by using side effect free allo-
bodyText ||| cation routines (through the Linux mmap API). Because the
bodyText ||| allocation routines are side effect free, Arachne’s memory is
bodyText ||| totally invisible to the base program. It is up to the aspect
bodyText ||| to use Arachne’s memory allocation routines or base pro-
bodyText ||| gram specific allocation functions. This transparency turns
bodyText ||| out to be crucial in our experiments. Legacy applications
bodyText ||| such as Squid use dedicated resource management routines
bodyText ||| and expect any piece of code they run to use these routines.
bodyText ||| Failures will result in an application crash.
bodyText ||| After loading an aspect, the instrumentation kernel rewrites
bodyText ||| the binary code of the base program. These rewriting strate-
bodyText ||| gies are not included in the kernel and must be fetched on
bodyText ||| demand by each loaded aspect.
subsectionHeader ||| 4.2 Rewriting strategies
bodyText ||| Rewriting strategies are responsible for transforming the
bodyText ||| binary code of the base program to effectively tie aspects to
page ||| 33
figureCaption ||| Figure 10: Generic hook operations.
bodyText ||| the base program at weaving time. These strategies localize
bodyText ||| Arachne’s main dependencies to the underlying hardware
bodyText ||| architecture. In general, rewriting strategies need to col-
bodyText ||| lect information about the base program. These information
bodyText ||| typically consist of the addresses of the different shadows,
bodyText ||| their size, the symbol (i.e.function or global variable name)
bodyText ||| they manipulate, their length etc. In order to keep compiled
bodyText ||| aspects independent from the base program, this informa-
bodyText ||| tion is gathered on demand at runtime. The mapping be-
bodyText ||| tween a symbol name in the base program source code and
bodyText ||| its address in memory is inferred from linking information
bodyText ||| contained in the base program executable. However because
bodyText ||| these information can be costly to retrieve, Arachne collects
bodyText ||| and stores it into meta-information DLLs. these DLLs be-
bodyText ||| have as a kind of cache and lessen the problem of collecting
bodyText ||| the information required to instrument the base program.
bodyText ||| To implement our aspect language, Arachne provides a set
bodyText ||| of eight rewriting strategies that might eventually use each
bodyText ||| other.
subsubsectionHeader ||| 4.2.1 Strategiesfor call, readGlobal and writeGlobal
bodyText ||| In Arachne, call, readGlobal and writeGlobal allow an
bodyText ||| advice to be triggered upon a function call, a read on a
bodyText ||| global variable or a write respectively. While the implemen-
bodyText ||| tation of readGlobal and writeGlobal in Arachne is close
bodyText ||| to the one in µDyner, Arachne implements the strategy for
bodyText ||| call by rewriting function invocations found in the base
bodyText ||| program. µDyner instead rewrites the function body of the
bodyText ||| callee. On the Intel architecture, function calls benefit from
bodyText ||| the direct mapping to the x86 call assembly instruction
bodyText ||| that is used by almost, if not all, compilers. Write and read
bodyText ||| accesses to global variables are translated into instructions
bodyText ||| using immediate, hard coded addresses within the binary
bodyText ||| code of the base program. By comparing these addresses
bodyText ||| with linking information contained in the base program ex-
bodyText ||| ecutable, Arachne can determine where the global variable
bodyText ||| is being accessed. Therefore those primitive pointcuts do
bodyText ||| not involve any dynamic tests. The sole rewriting of the
bodyText ||| binary base program code is enough to trigger advice and
bodyText ||| residue1 executions at all appropriate points.
bodyText ||| The size of the x86 call instruction and the size of an x86
bodyText ||| jump (jmp) instruction are the same. Since the instruction
bodyText ||| performing an access to a global variable involves a hard
bodyText ||| coded address, x86 instructions that read or write a global
footnote ||| 1Residues (i.e. dynamic tests on the base program state) are
footnote ||| required when these primitive pointcuts are combined with
footnote ||| conditional pointcuts or when pattern matching is involved.
bodyText ||| variable have at least the size of a x86 jmp instruction. Hence
bodyText ||| at weaving time, Arachne rewrites them as a jmp instruction
bodyText ||| to a hook. Hooks are generated on the fly on freshly allo-
bodyText ||| cated memory. As shown in figure 10, hooks contain a few
bodyText ||| assembly instructions that save and restore the appropriate
bodyText ||| registers before and after an advice (or shadow) execution.
bodyText ||| A generic approach is to have hooks save the whole set of
bodyText ||| registers, then execute the appropriate residue and/or ad-
bodyText ||| vice code before restoring the whole set of registers; finally
bodyText ||| the instructions found at the join point shadow are executed
bodyText ||| to perform the appropriate side effects on the processor reg-
bodyText ||| isters. This is accomplished by relocating the instructions
bodyText ||| found at the join point shadow. Relocating the instructions
bodyText ||| makes the rewriting strategies handling read and write ac-
bodyText ||| cess to global variable independent from the instruction gen-
bodyText ||| erated by the compiler to perform the access 2. The limited
bodyText ||| number of x86 instructions used to invoke a function allows
bodyText ||| Arachne’s rewriting strategy to exploit more efficient, relo-
bodyText ||| cation free, hooks.
subsubsectionHeader ||| 4.2.2 Strategiesfor controlf low and controlflowstar
bodyText ||| Every time a C function is called, the Linux runtime
bodyText ||| creates an activation record on the call stack [35]. Like
bodyText ||| µDyner, Arachne’s implementation of the rewriting strat-
bodyText ||| egy for controlf low uses the most deeply nested function
bodyText ||| call (or global read or write access) in the control flow point-
bodyText ||| cut as shadow. This shadow triggers a residue. This residue
bodyText ||| uses the activation record’s chaining to check whether the
bodyText ||| remaining function calls of the control flow, are on the call
bodyText ||| stack maintained by the Linux runtime. An appropriate
bodyText ||| usage of hashtables that store the linking information con-
bodyText ||| tained in the base program executables can thereby de-
bodyText ||| crease the cost of determining if a specific function is the
bodyText ||| caller of another to a pointer comparison. Therefore, the
bodyText ||| residue for a controlf low with n directly nested functions
bodyText ||| implies exactly n pointer comparisons. However, the residue
bodyText ||| worst case runtime for the indirect control flow operator
bodyText ||| controlflowstar that allows for not directly nested func-
bodyText ||| tions, is proportional to the base program stack depth.
subsubsectionHeader ||| 4.2.3 Strategiesfor read and write
bodyText ||| read and write are new join points not included in µDyner
bodyText ||| that have been added to the latest version of Arachne. Their
bodyText ||| implementation relays on a page memory protection as al-
bodyText ||| lowed by the Linux operating system interface (i.e. mprotect)
bodyText ||| and the Intel processor specifications [18]. A read or write
bodyText ||| pointcut triggers a residue to relocate the bound variable
bodyText ||| into a memory page that the base program is not allowed
bodyText ||| to access and adds a dedicated signal handler. Any attempt
bodyText ||| made by the base program to access the bound variable iden-
bodyText ||| tified will then trigger the execution of the previously added
bodyText ||| signal handler. This handler will then inspect the binary
bodyText ||| instruction trying to access the protected page to determine
bodyText ||| whether it was a read or a write access before eventually
bodyText ||| executing the appropriate advice.
subsubsectionHeader ||| 4.2.4 Strategiesfor seq
bodyText ||| Like read and write, seq is a new language feature of
bodyText ||| Arachne. µDyner offers no equivalent construct. Arachne’s
bodyText ||| rewriting strategy of this operator associates a linked list to
footnote ||| 2About 250 x86 instruction mnemonics can directly manip-
footnote ||| ulate a global variable. This corresponds to more than one
footnote ||| thousand opcodes.
figure ||| execution flow
figure ||| Legacy base program
figure ||| shadow: rewriting
figure ||| site replaced by a
figure ||| jump
figure ||| B���piled baof sethe
figure ||| program
figure ||| x86 instruction
figure ||| x86 instruction
figure ||| x86 instruction
figure ||| x86 instruction
figure ||| Relocated tailored
figure ||| ���tructio��
figure ||| up���ng re���ters
figure ||| Hooks generated at weavingAspect DLL
figure ||| time	generated at aspect compile time
figure ||| Entry hook
figure ||| save registers
figure ||| Return hook
figure ||| Restore registers
figure ||| Residue (dynamic tests)
figure ||| and/or advices
page ||| 34
bodyText ||| every stage inside the sequence except the last one. Each
bodyText ||| stage in a sequence triggers a residue that updates these
bodyText ||| linked lists to reflect state transitions of currently match-
bodyText ||| ing execution flows. Upon matching of the first pointcut
bodyText ||| of the first primitive aspect in the seq, a node is allocated
bodyText ||| and added to the associated linked list. This node con-
bodyText ||| tains a structure holding variables shared among the dif-
bodyText ||| ferent pointcuts within the sequence. Once a join point
bodyText ||| matches a pointcut of an primitive aspect denoting a stage
bodyText ||| in the sequence, Arachne consults every node in the linked
bodyText ||| list associated with the previous stage and executes the cor-
bodyText ||| responding advice 3. Arachne eventually updates the node
bodyText ||| and in the absence of a * moves it to the list associated
bodyText ||| with the currently matched pointcut.If the matching point-
bodyText ||| cut corresponds to the end of the sequence, structures are
bodyText ||| not moved into another list but freed. Our aspect compiler
bodyText ||| includes an optimization where structures are allocated from
bodyText ||| a resizable pool and upon a sequence termination, structures
bodyText ||| are not freed but returned to the pool.
subsectionHeader ||| 4.3 Arachne limitations
bodyText ||| Aggressive optimizations of the base program might pre-
bodyText ||| vent Arachne to seamlessly weave aspects. Two optimiza-
bodyText ||| tions are not yet supported by Arachne. First if the compiler
bodyText ||| inlines a function in another one within the binary code of
bodyText ||| the base program, the Arachne weaver will fail to properly
bodyText ||| handle pointcuts referring to that function. Second, con-
bodyText ||| trol flow pointcuts are based on the chaining of activation
bodyText ||| records. On the x86 architecture, in leaf functions, opti-
bodyText ||| mizing compilers sometimes do not maintain this chaining
bodyText ||| to free one register for the rest of the computation. This
bodyText ||| however has not been a problem during our experiments
bodyText ||| as we used the open source C compiler gcc. Arachne sup-
bodyText ||| ports two of the three optimization levels proposed by gcc.
bodyText ||| Stripping that removes linking information and aggressive
bodyText ||| optimizations that break the interoperability between com-
bodyText ||| pilers and/or debuggers are incompatible with Arachne. In
bodyText ||| practice, Arachne can be used on applications compiled like
bodyText ||| squid with two of the three gcc optimization level.
sectionHeader ||| 5. PERFORMANCE EVALUATION
bodyText ||| Aspect-oriented solutions will be used if the aspect sys-
bodyText ||| tem’s language is expressive enough and if the aspect system
bodyText ||| overhead is low enough, for the task at hand. The purpose
bodyText ||| of this section is to study Arachne’s performance. We first
bodyText ||| present the speed of each Arachne language construct and
bodyText ||| compare it to similar C language constructs. We then study
bodyText ||| the overhead of extending Squid with a prefetching policy.
bodyText ||| This case study shows that even if the cost of some Arachne
bodyText ||| aspect language constructs might be high compared to C
bodyText ||| language constructs, this overhead is largely amortized in
bodyText ||| real applications.
subsectionHeader ||| 5.1 Evaluation of the language constructs
subsectionHeader ||| This performance evaluation focuses on studying the cost
subsectionHeader ||| of each construct of our aspect language. To estimate the
subsectionHeader ||| cost for each construct of our aspect language, we wrote an
subsectionHeader ||| aspect using this construct that behaves as an interpreter of
footnote ||| 3In case the previous stage pointcut was used with a star
footnote ||| *, Arachne examines nodes from linked list associated with
footnote ||| the last two previous stages, and so on, until a not starred
footnote ||| primitive aspect in the sequence is reached.
table ||| Execution times (cycles)
table ||| call	Arachne	Native	Ratio
table ||| 	28±2.3%	21±1.9%	1.3
table ||| seq	201±0.5%	63±1.7%	3.2
table ||| cflow	228±1.6%	42±1.8%	5.4
table ||| readGlobal	2762±4.3%	1±0.2%	2762
table ||| read	9729±4.9%	1±0.6%	9729
tableCaption ||| Table 1: Speed of each language construct used to
tableCaption ||| interpret the base program compared to a native
tableCaption ||| execution.
bodyText ||| the base program. For example, to study the performance
bodyText ||| of readGlobal, we wrote an aspect whose action returns the
bodyText ||| value of the global variable referred in the pointcut, i.e., we
bodyText ||| wrote aspects behaving like the base program. For each of
bodyText ||| these aspects, we compare the time required to perform the
bodyText ||| operation matching the pointcut, in case the operation is
bodyText ||| interpreted by the woven aspect with the time required to
bodyText ||| carry out the operation natively (without the woven aspect).
bodyText ||| For example, to study the performance of readGlobal, we
bodyText ||| first evaluate the time needed to retrieve the global variable
bodyText ||| value through the code generated by the C compiler gcc
bodyText ||| without any aspect woven and compare this value to the
bodyText ||| time needed to retrieve the global variable value through
bodyText ||| the aspect once it has been woven in the base program.
bodyText ||| We express our measurements as a ratio between these two
bodyText ||| durations to abstract from the experimentation platform.
bodyText ||| This approach requires the ability to measure short peri-
bodyText ||| ods of time. For instance, a global variable value is usually
bodyText ||| retrieved (readGlobal in our aspect language) in a single
bodyText ||| clock tick. Since standard time measurement APIs were
bodyText ||| not precise enough, our benchmarking infrastructure relies
bodyText ||| on the rdtsc assembly instruction [18]. This instruction re-
bodyText ||| turns the number of clock cycles elapsed since power up. The
bodyText ||| Pentium 4 processor has the ability to dynamically reorder
bodyText ||| the instructions it executes. To ensure the validity of our
bodyText ||| measurement, we thus insert mfence instructions in the gen-
bodyText ||| erated code whose execution speed is being measured. An
bodyText ||| mfence forces the preceding instructions to be fully executed
bodyText ||| before going on. The pipeline mechanism in the Pentium 4
bodyText ||| processor entails that the speed of a piece of assembly code
bodyText ||| depends from the preceding instructions. To avoid such hid-
bodyText ||| den dependencies, we place the operation whose execution
bodyText ||| time is being measured in a loop. We use gcc to unroll the
bodyText ||| loop at compile time and we measure the time to execute
bodyText ||| the complete loop. This measure divided by the number of
bodyText ||| loop repetitions yields an estimation of the time required
bodyText ||| to execute the operation. The number of times the loop is
bodyText ||| executed is chosen after the relative variations of the mea-
bodyText ||| sures ,i.e., we increased the number of repetitions until ten
bodyText ||| runs yields an average relative variation not exceeding 5%.
bodyText ||| To check the correctness of our experimental protocol, we
bodyText ||| measured the time needed to execute a nop assembly in-
bodyText ||| struction, that requires one processor cycle according to the
bodyText ||| Intel specification. The measures of nop presented a relative
bodyText ||| variation of 1.6%.
bodyText ||| Table 1 summarizes our experimental results. Using the
bodyText ||| aspect language to replace a function that returns immedi-
bodyText ||| ately is only 1.3 times slower than a direct, aspect-less, call
bodyText ||| to that empty function. Since the aspect compiler packages
bodyText ||| advices as regular C functions, and because a call pointcut
bodyText ||| involves no residue, this good result is not surprising. When
page ||| 35
figureCaption ||| Figure 11: controlflow, seq, and read performances
bodyText ||| an access to a global variable is replaced by an advice exe-
bodyText ||| cution, the hooks generated by the rewriting strategy need
bodyText ||| to prepare the processor to call the advice function. This
bodyText ||| increases the time spent in the hooks. In addition, while
bodyText ||| an access to a global variable is often performed by a sin-
bodyText ||| gle x86 instruction, an empty function is often composed
bodyText ||| of four instructions. Hence the relative cost of an aspect
bodyText ||| triggered upon a global variable access and a direct, aspect-
bodyText ||| less, access to a global variable is slightly higher than the
bodyText ||| corresponding ratio for functions. A seq of three invoca-
bodyText ||| tions of empty functions is only 3.2 time slower than the
bodyText ||| direct, aspect-less, three successive functions calls. Com-
bodyText ||| pared to the pointcuts used to delimit the different stages,
bodyText ||| the seq overhead is limited to a few pointer exchanges be-
bodyText ||| tween the linked lists holding the bound variable. On Intel
bodyText ||| x86, global variable accesses benefit from excellent hardware
bodyText ||| support. In the absence of aspects, a direct global variable
bodyText ||| read is usually carried out in a single unique cycle. To trig-
bodyText ||| ger the advice execution, the Arachne runtime has to save
bodyText ||| and restore the processor state to ensure the execution co-
bodyText ||| herency, as advices are packaged as regular C functions (see
bodyText ||| also 4.2.1). It is therefore not surprising that a global vari-
bodyText ||| able readGlobal appears as being 2762 times slower than
bodyText ||| a direct, aspect-less global variable read. read performance
bodyText ||| can be accounted in the same way: in the absence of aspect,
bodyText ||| local variables are accessed in a single unique cycle. The
bodyText ||| signal mechanism used in the read requires that the oper-
bodyText ||| ating system detects the base program attempt to read into
bodyText ||| a protected memory page before locating and triggering the
bodyText ||| signal handler set up by Arachne, as shown in 4.2.3. Such
bodyText ||| switches to and from kernel space remain slow. Using read
bodyText ||| to read a local variable is 9729 times slower than retrieving
bodyText ||| the local variable value directly, without aspects.
bodyText ||| seq and controlf low can refer to several points in the exe-
bodyText ||| cution of the base program (i.e. different stages for seq and
bodyText ||| different function invocations for the controlflow). The
bodyText ||| runtime of these pointcuts grows linearly with the number
bodyText ||| of execution points they refer to and with the number of
bodyText ||| matching instances. Figure 11 summarizes a few experimen-
bodyText ||| tal results for controlf low and seq proving these points.
subsectionHeader ||| 5.2 Case Study on a real application
bodyText ||| Since, depending on the aspect construct used, interpret-
bodyText ||| ing the base program with aspects can slow it down by a fac-
bodyText ||| tor ranging between 1.3 and 9729, we studied Arachne’s per-
bodyText ||| formance on a real world application, the Web cache Squid.
table ||| 	Arachne	Manual	Diff
table ||| 			(%)
table ||| 	Top1	Top1
table ||| 	Top2	Top2
table ||| Throughput	5.59	5.59
table ||| (request/s)	5.58	5.59
table ||| Response Time (ms)	1131.42	1146.07	1.2–-1
table ||| 	1085.31	1074.55
table ||| Miss response time (ms)	2533.50	2539.52	0.2– 1.8
table ||| 	2528.35	2525.34
table ||| Hit response time (ms)	28.96	28.76	-0.6 – 3.8
table ||| 	30.62	31.84
table ||| Hit ratio	59.76	59.35	-0.6 – 0.7
table ||| 	61.77	62.22
table ||| Errors	0.51	0.50	-1.9–0
table ||| 	0.34	0.34
tableCaption ||| Table 2: Performances comparison between manual
tableCaption ||| modification and Arachne, for prefechting policy in-
tableCaption ||| tegration in Squid
bodyText ||| We extended Squid with a prefetching policy [9]. As de-
bodyText ||| scribed in section 3.1, we implemented this policy as a set
bodyText ||| of aspects and made a second implementation of this policy
bodyText ||| by editing the Squid source code and recompiling it. This
bodyText ||| section compares the performance of these two implemen-
bodyText ||| tations using standard Web cache performance indicators:
bodyText ||| throughput, response time and hit ratio.
bodyText ||| Obtaining access traces adequate to study a Web cache
bodyText ||| performance is difficult. The trace must be long enough to
bodyText ||| fill the cache. Due to privacy issues, traces are usually not
bodyText ||| publicly available. Since traces do not include the content of
bodyText ||| the accessed pages, these pages must be downloaded again.
bodyText ||| In the meantime the page contents may have changed and
bodyText ||| even the URLs may have disappeared.
bodyText ||| Instead of traces, we based our evaluation on Web Poly-
bodyText ||| graph [30]. Polygraph is a benchmarking tool developed by
bodyText ||| the Squid team and featuring a realistic HTTP and SSL
bodyText ||| traffic generator and a flexible content simulator.
bodyText ||| We filled up the cache and simulated a one day workload
bodyText ||| with its two request rate peaks observed in real life environ-
bodyText ||| ments [30]. Table 2 shows results of our simulation. Mea-
bodyText ||| sures have been made during the two request peaks. The
bodyText ||| hit time and the miss time, time needed to deliver a docu-
bodyText ||| ment present, respectively not present, in the cache are very
bodyText ||| similar. It shows that differences are imperceptible between
bodyText ||| the version of Squid extended by Arachne and the one ex-
bodyText ||| tended manually (less than 1%). Hence, even if the cost
bodyText ||| of Arachne’s aspect language constructs might seem high,
bodyText ||| they are largely amortized in real applications. To give a
bodyText ||| typical example observed on our experimental platform: in
bodyText ||| case of a cache hit, a 3.8 MB page was retrieved in a single
bodyText ||| second, the time spent in prefetching advices amounted to
bodyText ||| 1801 µsec, and the time spent within Arachne to execute the
bodyText ||| hooks and dynamic tests to 0.45 µsec. In a miss case, on
bodyText ||| the average, a client retrieved the same page in 1.3 seconds,
bodyText ||| 16679 µsec were spent in the advices and 0.67 µsec within
bodyText ||| Arachne itself.
sectionHeader ||| 6. RELATED WORK
bodyText ||| Our work is directly related to other aspect weavers for
bodyText ||| C, approaches for expressive aspect languages, and dynamic
bodyText ||| weaving, in particular for C. In this section, we consider
bodyText ||| related work in each of these fields in turn.
bodyText ||| Apart from µDyner and Arachne, there are few aspect
figure ||| Sequence
figure ||| 1	2	3	4	5
figure ||| 1	2	3	4	5
figure ||| Number of imbricated calls	Number of matching instances
figure ||| Controlflow
figure ||| 10
figure ||| 3000
figure ||| 2000
figure ||| 30
figure ||| 20
figure ||| 5
figure ||| 1000
figure ||| 10
page ||| 36
bodyText ||| weavers for C (or even C like languages); some notewor-
bodyText ||| thy exceptions are AspectC [12] (no available implementa-
bodyText ||| tion), AspectC++ and [33]. All of these rely on source-code
bodyText ||| transformation and thus cannot apply aspects to running
bodyText ||| C applications as required by the applications we consider.
bodyText ||| Furthermore, none of these systems provides explicit sup-
bodyText ||| port for aspects over join point sequences.
bodyText ||| There is quite a large body of work now on the notion of
bodyText ||| expressive aspect languages where “more expressive” typi-
bodyText ||| cally compares to w.r.t. AspectJ’s pointcut and advice mod-
bodyText ||| els. Our work has been inspired by Event-based AOP [15],
bodyText ||| which aims at the definition of pointcuts in terms of arbi-
bodyText ||| trary relations between events. Nevertheless, many other
bodyText ||| approaches to expressive aspect languages exist: e.g., data-
bodyText ||| flow relations [26], logic programming [13], process algebras
bodyText ||| [3], graphs [5], and temporal logics [1], have all been pro-
bodyText ||| posed as a basis for the definition of expressive aspect lan-
bodyText ||| guages. However, few of these encompass dynamic weaving
bodyText ||| and only the latter has been applied to C code under effi-
bodyText ||| ciency considerations similar to our setting.
bodyText ||| Dynamic weaving is commonly realized in Java through
bodyText ||| preprocessing at load-time like [8] or through the JVM De-
bodyText ||| bugging Interface [28]. These tools rely on bytecode rewrit-
bodyText ||| ing techniques, have typically limited expressivity (some do
bodyText ||| not support field accesses) and incur a huge performance
bodyText ||| overhead. Dynamic weaving through modification at run-
bodyText ||| time is found infrequently for compiled languages. An ex-
bodyText ||| ception for Java is JasCo [21] whose most recent version (0.7)
bodyText ||| supports dynamic weaving through the new instrumentation
bodyText ||| API of Java 5.
bodyText ||| Many instrumentation techniques have been proposed to
bodyText ||| rewrite binary code on the fly. In these approaches, dif-
bodyText ||| ficulty issues range from the complexity to rewrite binary
bodyText ||| code to the lack of a well-defined relationship between source
bodyText ||| code and the compiler generated binary code. Hence many
bodyText ||| approaches work on an intermediate representation of the
bodyText ||| binary code and source language [34]. Producing this repre-
bodyText ||| sentation first and then regenerating the appropriate binary
bodyText ||| executable code has proven to be costly both in terms of
bodyText ||| memory consumption and in CPU time.
bodyText ||| A few other approaches have considered a direct rewrit-
bodyText ||| ing of the binary code at runtime. Dyninst [17] and dynamic
bodyText ||| probes [27] allow programmers to modify any binary instruc-
bodyText ||| tion belonging to an executable. Dyninst however relies on
bodyText ||| the Unix debugging API: ptrace. ptrace allows a third
bodyText ||| party process to read and write the base program memory.
bodyText ||| It is however highly inefficient: before using ptrace, the
bodyText ||| third party process has to suspend the execution of the base
bodyText ||| program and resume its execution afterwards. In compari-
bodyText ||| son, Arachne uses ptrace at most once, to inject its kernel
bodyText ||| DLL into the base program process. In addition, Dyninst
bodyText ||| does not free the programmer from dealing with low level
bodyText ||| details. For example, it seems difficult to trigger an advice
bodyText ||| execution upon a variable access with Dyninst: the transla-
bodyText ||| tion from the variable identifier to an effective address is left
bodyText ||| to the user. Worse, Dyninst does not grant that the manip-
bodyText ||| ulation of the binary instructions it performs will succeed.
bodyText ||| Dyninst uses an instrumentation strategy where several ad-
bodyText ||| jacent instructions are relocated. This is unsafe as one of
bodyText ||| the relocated instructions can be the target of branching
bodyText ||| instructions. In comparison, Arachne join point model has
bodyText ||| been carefully chosen to avoid these kind of issues; if an as-
bodyText ||| pect can be compiled with Arachne, it can always be woven.
bodyText ||| 7. CONCLUSION AND FUTURE WORK
bodyText ||| In this paper we have discussed three different crosscut-
bodyText ||| ting concerns which are typical for C applications using OS-
bodyText ||| level services and which frequently need to be applied at
bodyText ||| runtime. We have motivated that such concerns can be ex-
bodyText ||| pressed as aspects and have defined a suitable aspect lan-
bodyText ||| guage. This language is more expressive than those used in
bodyText ||| other aspect weavers for C in that it provides support for
bodyText ||| aspects defined over sequences of execution points as well as
bodyText ||| for variable aliases. We have presented an integration of this
bodyText ||| language into Arachne, a weaver for runtime weaving of as-
bodyText ||| pects in C applications. Finally, we have provided evidence
bodyText ||| that the integration is efficient enough to apply such aspects
bodyText ||| dynamically to high-performance applications, in particular
bodyText ||| the web cache “squid.”
bodyText ||| As future work, we intend to investigate the suitability of
bodyText ||| the proposed aspect language for other C-applications. We
bodyText ||| also intend to investigate Arachne extension to the C++
bodyText ||| language. Indeed, object-oriented programming heavily uses
bodyText ||| protocol-based interfaces collaboration (hence sequence as-
bodyText ||| pects). Along with its open architecture, extending Arachne
bodyText ||| to support C++, will pave the way to a relatively language
bodyText ||| independent aspect and weaving infrastructure. Finally,
bodyText ||| Arachne’s toolbox should be extended with support for as-
bodyText ||| pect interactions (e.g., analyses and composition operators).
sectionHeader ||| 8. REFERENCES
reference ||| [1] R. A. ºAberg, J. L. Lawall, M. SÄudholt, G. Muller, and
reference ||| A.-F. L. Meur. On the automatic evolution of an os
reference ||| kernel using temporal logic and AOP. In Proceedings
reference ||| of Automated Software Engineering (ASE’03), pages
reference ||| 196{204. IEEE, 2003.
reference ||| [2] American National Standards Institute.
reference ||| ANSI/ISO/IEC 9899-1999: Programming Languages
reference ||| — C. American National Standards Institute, 1430
reference ||| Broadway, New York, NY 10018, USA, 1999.
reference ||| [3] J. H. Andrews. Process-algebraic foundations of
reference ||| aspect-oriented programming. In Proceedings of the
reference ||| 3rd International Conference on Metalevel
reference ||| Architectures and Separation of Crosscutting
reference ||| Concerns, volume 2192 of LNCS. Springer Verlag,
reference ||| Sept. 2001.
reference ||| [4] M. Arlitt and T. Jin. A workload characterization
reference ||| study of the 1998 world cup web site. IEEE Network,
reference ||| 14(3):30{37, May 2000.
reference ||| [5] U. ABmann and A. Ludwig. Aspect weaving by graph
reference ||| rewriting. In U. W. Eisenecker and K. Czarnecki,
reference ||| editors, Generative Component-based Software
reference ||| Engineering (GCSE), Erfurt, Oct. 1999.
reference ||| [6] CERT - Carnegie Mellon University. Vulnerability
reference ||| note vu#613459, Feb. 2002. published on line:
reference ||| http://www.kb.cert.org/vuls/id/613459.
reference ||| [7] H. Chen and P. Mohapatra. Catp: A context-aware
reference ||| transportation protocol for http. In International
reference ||| Workshop on New Advances in Web Servers and
reference ||| Proxy Technologies Held with ICDCS, 2003.
reference ||| [8] S. Chiba and K. Nakagawa. Josh: An open
reference ||| AspectJ-like language. In Proceedings of the third
page ||| 37
reference ||| international conference on Aspect-oriented software
reference ||| development, pages 102–111. ACM Press, Mar. 2004.
reference ||| [9] K.-I. Chinen and S. Yamaguchi. An interactive
reference ||| prefetching proxy server for improvement of WWW
reference ||| latency. In Seventh Annual Conference of the Internet
reference ||| Society (INET’97), Kuala Lumpur, June 1997.
reference ||| [10] I. Cidon, A. Gupta, R. Rom, and C. Schuba. Hybrid
reference ||| tcp-udp transport for web traffic. In Proceedings of the
reference ||| 18th IEEE International Performance, Computing,
reference ||| and Communications Conference (IPCCC’99), pages
reference ||| 177–184, Feb. 1990.
reference ||| [11] S. Clowes. Injectso: Modifying and spying on running
reference ||| processes under linux. In Black hat briefings, 2001.
reference ||| [12] Y. Coady, G. Kiczales, M. Feeley, and G. Smolyn.
reference ||| Using AspectC to improve the modularity of
reference ||| Path-Specific customization in operating system code.
reference ||| In V. Gruhn, editor, Proc. of the Joint 8th European
reference ||| Software Engeneering Conference and 9th ACM
reference ||| SIGSOFT Symposium on the Foundation of Software
reference ||| Engeneering (ESEC/FSE-01), volume 26, 5 of
reference ||| SOFTWARE ENGINEERING NOTES, pages 88–98,
reference ||| New York, Sept. 10–14 2001. ACM Press.
reference ||| [13] K. de Volder. Aspect-oriented logic meta
reference ||| programming. In P. Cointe, editor, Meta-Level
reference ||| Architectures and Reflection, 2nd International
reference ||| Conference on Reflection, volume 1616 of LNCS,
reference ||| pages 250–272. Springer Verlag, 1999.
reference ||| [14] R. Douence, P. Fradet, and M. SÄudholt. A framework
reference ||| for the detection and resolution of aspect interactions.
reference ||| In Proceedings of the ACM SIGPLAN/SIGSOFT
reference ||| Conference on Generative Programming and
reference ||| Component Engineering (GPCE’02), volume 2487 of
reference ||| LLNCS, pages 173–188. Springer-Verlag, Oct. 2002.
reference ||| [15] R. Douence, O. Motelet, and M. SÄudholt. A formal
reference ||| definition of crosscuts. In Proceedings of the 3rd
reference ||| International Conference on Metalevel Architectures
reference ||| and Separation of Crosscutting Concerns, volume 2192
reference ||| of LNCS, pages 170–186. Springer Verlag, Sept. 2001.
reference ||| [16] E. Hilsdale and J. Hugunin. Advice weaving in
reference ||| aspectj. In Proceedings of the 3rd international
reference ||| conference on Aspect-oriented software development,
reference ||| pages 26–35. ACM Press, 2004.
reference ||| [17] J. K. Hollingsworth, B. P. Miller, M. J. R. Goncalves,
reference ||| O. Naim, Z. Xu, and L. Zheng. MDL: A language and
reference ||| compiler for dynamic program instrumentation. In
reference ||| IEEE Conference on Parallel Architectures and
reference ||| Compilation Techniques (PACT), pages 201–213, Nov.
reference ||| 1997.
reference ||| [18] Intel Corportation. IA-32 Intel Architecture Software
reference ||| Developer’s Manual. Intel Corportation, 2001.
reference ||| [19] V. Issarny, M. Ban^atre, B. Charpiot, and J.-M.
reference ||| Menaud. Quality of service and electronic newspaper:
reference ||| The Etel solution. Lecture Notes in Computer Science,
reference ||| 1752:472–496, 2000.
reference ||| [20] J. Jaffar, S. Michaylov, P. J. Stuckey, and R. H. C.
reference ||| Yap. The clp( r ) language and system. ACM Trans.
reference ||| Program. Lang. Syst., 14(3):339–395, 1992.
reference ||| [21] JasCo home page. http://ssel.vub.ac.be/jasco/.
reference ||| [22] R. Jones and P. Kelly. Backwards-compatible bounds
reference ||| checking for arrays and pointers in c programs. In
reference ||| M. Kamkar, editor, Proceedings of the Third
reference ||| International Workshop on Automatic Debugging,
reference ||| volume 2, pages 13–26, May 1997.
reference ||| [23] A. D. Keromytis. ”Patch on Demand” Saves Even
reference ||| More Time? IEEE Computer, 37(8):94–96, 2004.
reference ||| [24] G. Kiczales, J. Lamping, A. Menhdhekar, C. Maeda,
reference ||| C. Lopes, J.-M. Loingtier, and J. Irwin.
reference ||| Aspect-oriented programming. In M. Ak»sit and
reference ||| S. Matsuoka, editors, Proceedings European
reference ||| Conference on Object-Oriented Programming, volume
reference ||| 1241, pages 220–242. JyvÄaskylÄa, Finland, June 1997.
reference ||| [25] K. J. Lieberherr, J. Palm, and R. Sundaram.
reference ||| Expressiveness and complexity of crosscut languages.
reference ||| Technical Report NU-CCIS-04-10, Northeastern
reference ||| University, Sept. 2004.
reference ||| [26] H. Masuhara and K. Kawauchi. Dataflow pointcut in
reference ||| aspect-oriented programming. In First Asian
reference ||| Symposium on Programming Languages and Systems
reference ||| (APLAS’03), 2003.
reference ||| [27] R. J. Moore. Dynamic probes and generalised kernel
reference ||| hooks interface for Linux. In USENIX, editor,
reference ||| Proceedings of the 4th Annual Linux Showcase and
reference ||| Conference, Atlanta, October 10–14, 2000, Atlanta,
reference ||| Georgia, USA, Berkeley, CA, USA, 2000. USENIX.
reference ||| [28] A. Popovici, G. Alonso, and T. Gross. Just-in-time
reference ||| aspects: efficient dynamic weaving for Java. In
reference ||| Proceedings of the 2nd international conference on
reference ||| Aspect-oriented software development, pages 100–109,
reference ||| Boston, Massachusetts, Mar. 2003. ACM Press.
reference ||| [29] M. Rabinovich and H. Wang. DHTTP: An efficient
reference ||| and cache-friendly transfer protocol for web traffic. In
reference ||| INFOCOM, pages 1597–1606, 2001.
reference ||| [30] A. Rousskov and D. Wessels. High-performance
reference ||| benchmarking with Web Polygraph. Software Practice
reference ||| and Experience, 34(2):187–211, Feb. 2004.
reference ||| [31] O. Ruwase and M. S. Lam. A practical dynamic buffer
reference ||| overflow detector. In Proceedings of the 11th Annual
reference ||| Network and Distributed System Security Symposium.
reference ||| Internet Society, Feb. 2004.
reference ||| [32] M. S¶egura-Devillechaise, J.-M. Menaud, G. Muller,
reference ||| and J. Lawall. Web cache prefetching as an aspect:
reference ||| Towards a dynamic-weaving based solution. In
reference ||| Proceedings of the 2nd international conference on
reference ||| Aspect-oriented software development, pages 110–119,
reference ||| Boston, MA, USA, Mar. 2003. ACM Press.
reference ||| [33] O. Spinczyk, A. Gal, and W. Schroeder-Preikschat.
reference ||| AspectC++: an aspect-oriented extension to the C++
reference ||| programming language. In Proceedings of the Fortieth
reference ||| International Conference on Tools Pacific, pages
reference ||| 53–60. Australian Computer Society, Inc., 2002.
reference ||| [34] A. Srivastava and A. Edwards. Vulcan: Binary
reference ||| transformation in a distributed environment. Microsoft
reference ||| Research Tech. Rpt. MSR-TR-2001-50, 2001.
reference ||| [35] U. S. L. System Unix. System V Application Binary
reference ||| Interface Intel 386 Architecture Processor Supplement.
reference ||| Prentice Hall Trade, 1994.
reference ||| [36] D. Wessels. Squid: The Definitive Guide. O’Reilly and
reference ||| Associates, Jan. 2004.
reference ||| [37] J. Wilander and M. Kamkar. A comparison of publicly
reference ||| available tools for dynamic buffer overflow prevention.
reference ||| In Proceedings of the 10th Network and Distributed
reference ||| System Security Symposium, pages 149–162, San
reference ||| Diego, California, February 2003.
page ||| 38

title ||| An Intensional Approach to the Specification of Test Cases
title ||| for Database Applications
author ||| David Willmor
affiliation ||| School of Computer Science
affiliation ||| University of Manchester
address ||| Oxford Road, Manchester, UK
email ||| d.willmor@cs.manchester.ac.uk
email ||| ABSTRACT
bodyText ||| When testing database applications, in addition to creating
bodyText ||| in-memory fixtures it is also necessary to create an initial
bodyText ||| database state that is appropriate for each test case. Cur-
bodyText ||| rent approaches either require exact database states to be
bodyText ||| specified in advance, or else generate a single initial state
bodyText ||| (under guidance from the user) that is intended to be suit-
bodyText ||| able for execution of all test cases. The first method allows
bodyText ||| large test suites to be executed in batch, but requires con-
bodyText ||| siderable programmer effort to create the test cases (and
bodyText ||| to maintain them). The second method requires less pro-
bodyText ||| grammer effort, but increases the likelihood that test cases
bodyText ||| will fail in non-fault situations, due to unexpected changes
bodyText ||| to the content of the database. In this paper, we propose a
bodyText ||| new approach in which the database states required for test-
bodyText ||| ing are specified intensionally, as constrained queries, that
bodyText ||| can be used to prepare the database for testing automati-
bodyText ||| cally. This technique overcomes the limitations of the other
bodyText ||| approaches, and does not appear to impose significant per-
bodyText ||| formance overheads.
sectionHeader ||| Categories and Subject Descriptors
category ||| D.2.5 [Software Engineering]: Testing and Debugging—
category ||| Testing tools
sectionHeader ||| General Terms
keyword ||| Experimentation, Verification
sectionHeader ||| Keywords
keyword ||| databases, software testing, database testing
sectionHeader ||| 1. INTRODUCTION
bodyText ||| Modern information systems are typically organised as
bodyText ||| collections of independent application programs that com-
bodyText ||| municate with one another by means of a central database.
bodyText ||| The database records the state of the organisation that the
copyright ||| Permission to make digital or hard copies of all or part of this work for
copyright ||| personal or classroom use is granted without fee provided that copies are
copyright ||| not made or distributed for profit or commercial advantage and that copies
copyright ||| bear this notice and the full citation on the first page. To copy otherwise, to
copyright ||| republish, to post on servers or to redistribute to lists, requires prior specific
copyright ||| permission and/or a fee.
note ||| ICSE’06, May 20–28, 2006, Shanghai, China.
copyright ||| Copyright 2006 ACM 1-59593-085-X/06/0005 ...$5.00.
author ||| Suzanne M. Embury
affiliation ||| School of Computer Science
affiliation ||| University of Manchester
address ||| Oxford Road, Manchester, UK
email ||| s.m.embury@cs.manchester.ac.uk
bodyText ||| information system supports, while the application programs
bodyText ||| implement the business processes that manipulate the state.
bodyText ||| To take a simple but ubiquitous example, a database sys-
bodyText ||| tem might record details of customers, products and sales,
bodyText ||| while the application programs associated with it handle op-
bodyText ||| erations such as new product purchases and update of the
bodyText ||| product catalogue, as well as supporting decision making
bodyText ||| by generating reports regarding the most profitable product
bodyText ||| lines, names and addresses of loss-making customers, etc.
bodyText ||| In order to test such application programs, it is necessary
bodyText ||| to create test fixtures that simulate the presence of the rest
bodyText ||| of the information system. Fixtures for traditional test cases
bodyText ||| typically consist of in-memory objects and data structures
bodyText ||| that provide the inputs to the program being tested. This
bodyText ||| kind of fixture is also needed when testing database appli-
bodyText ||| cations (especially when performing unit testing); however,
bodyText ||| since it is unrealistic (and often incorrect) to execute test
bodyText ||| cases against an empty database, we need to create addi-
bodyText ||| tional fixture elements within the database itself.
bodyText ||| Current practice in the software industry is to maintain
bodyText ||| one or more test databases that can be used for testing in-
bodyText ||| dividual programs. These databases can be artificially gen-
bodyText ||| erated (e.g., using tools such as DBMonster1 and DataFac-
bodyText ||| tory2) or they may be subsets of the live database, taken
bodyText ||| as a snapshot at some recent point in time. Copies of the
bodyText ||| live data sets have the advantage that they are more likely
bodyText ||| to be representative of the patterns of data encountered in
bodyText ||| practice, while artificial data sets have the advantage that
bodyText ||| they can be made to embody specific characteristics (such
bodyText ||| as particular data skew patterns or volumes), which may be
bodyText ||| useful for load and stress testing.
bodyText ||| Both approaches, however, suffer from several disadvan-
bodyText ||| tages. The most significant problem occurs when none of
bodyText ||| the available test databases are suitable starting points for a
bodyText ||| particular test case. For example, suppose a particular test
bodyText ||| case executes a program which purges inactive customers,
bodyText ||| with the aim of verifying that the business rule forbidding
bodyText ||| deletion of customers with negative balances is correctly en-
bodyText ||| forced. If none of the test databases contains any inactive
bodyText ||| customers with negative balances, then the test case can-
bodyText ||| not be executed successfully. For a one-off test run, testing
bodyText ||| personnel can choose a database that is close to what is re-
bodyText ||| quired, and manually update it so that it is suitable for use
bodyText ||| with the test case. But if a complete test suite is to be exe-
bodyText ||| cuted (possibly including test cases which themselves make
bodyText ||| modifications to the database state) then in the worst case
footnote ||| 1http://DBMonster.kernelpanic.pl
footnote ||| 2http://www.quest.com/datafactory
page ||| 102
bodyText ||| this manual intervention will be required in between every
bodyText ||| test case execution. This is clearly undesirable if test suites
bodyText ||| are large or time-consuming to execute, or if the test suite
bodyText ||| is to be run in batch (as in the case of overnight regression
bodyText ||| testing, for example).
bodyText ||| Current research in testing for database systems proposes
bodyText ||| two approaches to this problem. One of these is to include
bodyText ||| within the test case description a full (extensional) specifica-
bodyText ||| tion of the database state against which it is to be run (and
bodyText ||| of the database state that should be produced if the test has
bodyText ||| executed successfully) [13, 14]. This solution is exemplified
bodyText ||| by DBUnit3, an extension of the JUnit testing framework4
bodyText ||| that is designed for testing database applications written in
bodyText ||| Java. Each DBUnit test case is accompanied by an XML
bodyText ||| file describing the data set required for the test. Before each
bodyText ||| test run, DBUnit clears the database state and inserts the
bodyText ||| data described by the XML file.
bodyText ||| This approach has the advantage of simplicity, but it places
bodyText ||| a considerable burden on testing personnel, especially when
bodyText ||| complex database states are required. It is also inefficient,
bodyText ||| since the database must be continually destroyed and recre-
bodyText ||| ated between tests, even when significant parts of the database
bodyText ||| might have been reused by the succeeding tests. Moreover,
bodyText ||| maintenance of a large suite of such tests is extremely chal-
bodyText ||| lenging, since any small change to the database schema may
bodyText ||| require corresponding changes to many test cases.
bodyText ||| The second approach that has been explored in the liter-
bodyText ||| ature is more efficient in that it requires the creation of only
bodyText ||| one database state per test suite (rather than one per test
bodyText ||| case). It is exemplified by the AGENDA database testing
bodyText ||| toolkit [6, 7], which can automatically generate a database
bodyText ||| state given information about the schema, some data gen-
bodyText ||| eration functions for individual attributes and some user-
bodyText ||| selected heuristics describing the kind of database state re-
bodyText ||| quired. The AGENDA tool also generates test cases from a
bodyText ||| simple analysis of the program being verified. The user must
bodyText ||| then add preconditions to each test case that are checked
bodyText ||| just before it is executed and that will prevent a case from
bodyText ||| being executed against an inappropriate database state. This
bodyText ||| approach successfully relieves the user of the need to specify
bodyText ||| complete database states in full detail, but at a cost. The
bodyText ||| user must accept that some of the test cases may not be
bodyText ||| executed because the database state fails the precondition,
bodyText ||| even when it would require only a small change to bring the
bodyText ||| database into a suitable state for the test. Since only one
bodyText ||| database state is created per test suite, this problem of failed
bodyText ||| tests is likely to become more severe as the size of the test
bodyText ||| suite grows. There is also a potential inefficiency involved
bodyText ||| in generating test descriptions and inputs, and in creating
bodyText ||| the additional log tables and constraints/triggers needed by
bodyText ||| the AGENDA tool, for test cases that are not in fact going
bodyText ||| to be executed.
bodyText ||| Ideally, we would prefer to be able to combine the advan-
bodyText ||| tages of both these approaches, to give a form of database
bodyText ||| test case that is quick and natural to specify, and which
bodyText ||| maximises the number of cases within the suite that can be
bodyText ||| executed while minimising the number of full test databases
bodyText ||| that need to be maintained. Our thesis is that this can
bodyText ||| be achieved by allowing testing personnel to describe the
bodyText ||| database states involved in their test cases intensionally, in
footnote ||| 3http://www.dbunit.org
footnote ||| 4http://www.junit.org
bodyText ||| the form of declarative conditions that the input database
bodyText ||| must satisfy, and by providing a testing harness that can
bodyText ||| automatically adjust the input database so that the test
bodyText ||| conditions are satisfied [19].
bodyText ||| In this paper, we present a language for specifying such
bodyText ||| intensional database tests, and describe its semantics and
bodyText ||| operational behaviour (Section 2). We present an algorithm
bodyText ||| for automatically modifying database states so that test pre-
bodyText ||| conditions are satisfied (Section 3), thus ensuring that all
bodyText ||| test cases can be executed without requiring any human
bodyText ||| intervention. We further describe how we have extended the
bodyText ||| JUnit testing framework to allow intensional database tests
bodyText ||| to be specified and executed in practice (Section 4). Finally,
bodyText ||| we present the results of an evaluation of the performance
bodyText ||| of the techniques (Section 5) and conclude (Section 6).
sectionHeader ||| 2. SPECIFYING INTENSIONAL TESTS
bodyText ||| A conventional test case is typically modelled as a triple
bodyText ||| < p, i, o >, which denotes a test that executes program p
bodyText ||| with inputs (e.g., parameters) denoted by i. If no faults are
bodyText ||| encountered during the test execution, the output that will
bodyText ||| be produced is o. In the case of test cases for database ap-
bodyText ||| plications, we must add two further elements—the specifica-
bodyText ||| tion of the database state against which p is to be executed,
bodyText ||| and some statement of the database state that should result
bodyText ||| from the execution of p if it is operating correctly according
bodyText ||| to its specification.
bodyText ||| For example, consider the example program mentioned
bodyText ||| in Section 1 that prunes inactive customer details from the
bodyText ||| database. For this test case, we require a database state that
bodyText ||| contains at least one inactive customer. This could easily
bodyText ||| be stated as a predicate logic condition over the database,
bodyText ||| assuming the obvious mapping between stored relations and
bodyText ||| predicates, e.g.:
construct ||| (3custNo, lastOrderOn, a, b, c)
construct ||| customer(custNo, a, b, c, lastOrderOn) n
construct ||| lastOrderOn < today — 90
bodyText ||| The program in question does not access any parts of the
bodyText ||| database other than the customer table. Therefore, we do
bodyText ||| not care what values the other tables contain and need not
bodyText ||| mention them in the intensional specification of the test.
bodyText ||| This approach works equally well for observing the results
bodyText ||| of the test. For example, when testing the customer pruning
bodyText ||| behaviour, we might require that no inactive customer with
bodyText ||| a non-negative balance should exist in the database after
bodyText ||| the test:
construct ||| -((3custNum, lastOrderDate, a, b, c)
construct ||| customer(custNum, a, bal, c, lastOrderDate) n
construct ||| lastOrderDate < today — 90 n bal > 0)
bodyText ||| Effectively, the test case describes a set of valid (i.e., fault-
bodyText ||| free) state transition for the database, as a classic pre/post-
bodyText ||| condition pair.
bodyText ||| This first-order-logic style of database specification does
bodyText ||| not work so well when we consider the testing problem in
bodyText ||| more depth, however. The problem is that we need to do
bodyText ||| more than test the input database for compliance with the
bodyText ||| requirements of the test case; we also need to extract in-
bodyText ||| formation from it to be used to instantiate other elements
page ||| 103
bodyText ||| of the test case. For example, suppose we wish to test a
bodyText ||| program that deletes details of individual customers. Such
bodyText ||| programs typically require some input from the user, identi-
bodyText ||| fying the specific customer record that is to be deleted (e.g.,
bodyText ||| by supplying the relevant customer code as a parameter).
bodyText ||| This could be achieved by requiring the tester to embed the
bodyText ||| customer code into the test case elements, as literal values.
bodyText ||| Alternatively, we could search for a suitable customer that
bodyText ||| already exists in the database, using a standard database
bodyText ||| query, and use the values from that in specifying the inputs
bodyText ||| for the test case. This would minimise the amount of work
bodyText ||| required to prepare the database for test execution (since we
bodyText ||| would be using data already present in the database), and it
bodyText ||| would also mean that test cases can be written very quickly,
bodyText ||| since the user does not need to specify every last detail of
bodyText ||| the data to be used.
bodyText ||| Under this approach, the specification of the input database
bodyText ||| state now has a dual role: it must state the condition that
bodyText ||| determines whether the database state is suitable for execu-
bodyText ||| tion of the test case and it must also return bindings for the
bodyText ||| free variables that appear in the remaining components of
bodyText ||| the test case. For the latter purpose, we would prefer to use
bodyText ||| a straightforward query language, while for the former we
bodyText ||| require the ability to place conditions on the data. With a
bodyText ||| simple extension of a standard query language such as SQL,
bodyText ||| we can combine both these purposes in a single statement.
bodyText ||| For example, the following statement:
construct ||| ANY :cn GENERATED BY
construct ||| SELECT custNo FROM customer
construct ||| WHERE lastOrderDate < today() - 90
construct ||| AND balance < 0
bodyText ||| retrieves the customer code of some record that meets the
bodyText ||| given conditions (an inactive customer with negative bal-
bodyText ||| ance) from the database, and binds it to the variable : cn.
bodyText ||| It also places a cardinality constraint on the result of the
bodyText ||| query, that at least one such binding must exist (implied by
bodyText ||| the use of the keyword ANY).
bodyText ||| The variable : cn can then be used to specify other ele-
bodyText ||| ments of the test case. The obvious usage in this example is
bodyText ||| in specifying the inputs to the program being tested, but it
bodyText ||| can also be used in describing the expected outputs of the
bodyText ||| program. In this example test case, the correct behaviour
bodyText ||| of the DeleteCustomer program is to reject the deletion
bodyText ||| of : cn, since customers with a negative balance cannot be
bodyText ||| purged from the database. We might therefore give the fol-
bodyText ||| lowing specification of the desired output database state:
construct ||| AT LEAST 1 :cn2 GENERATED BY
construct ||| SELECT custNo FROM customer
construct ||| WHERE custNo = :cn
bodyText ||| Of course, not all test cases are best specified in terms of
bodyText ||| values retrieved from the database. For example, suppose
bodyText ||| that we wish to write test cases for a program that adds new
bodyText ||| customers to the database. The inputs to this program are
bodyText ||| the details of the new customer, and the precondition for one
bodyText ||| particular test case states that no customer should exist that
bodyText ||| has the same customer code as that of the customer being
bodyText ||| created. We cannot retrieve the customer details from the
bodyText ||| database in this case, as they have not yet been stored in it.
bodyText ||| Again, we could force the user to include the required values
bodyText ||| as literals in the test case, but ideally we would like to give
figure ||| <CONDITION>::= <TYPE> <BINDINGLIST>
figure ||| GENERATED BY <SELECT>
figure ||| <TYPE>::= ANY I NO I AT LEAST <i> I
figure ||| AT MOST <i> EXACTLY <i> |
figure ||| ALL I FIRST
figure ||| <i>::= {0-9}
figure ||| <BINDINGLIST>
figure ||| ::=<BINDING> { ‘,’ <BINDINGLIST> }
figure ||| <BINDING>::= {A-Z I a-z}
figure ||| <SELECT> ::= ...
figureCaption ||| Figure 1: Simplified BNF Grammar for SQL Exten-
figureCaption ||| sions
bodyText ||| more support to the process of test case generation. One
bodyText ||| way to achieve this is to allow user-defined data generator
bodyText ||| functions to be incorporated within queries as though they
bodyText ||| were relations. For example, the following expression states
bodyText ||| our requirements for this test case, while also binding the
bodyText ||| variables needed for input to the program:
construct ||| ANY :cn, :name, :addr, :bal GENERATED BY
construct ||| SELECT gc.custno, gc.name, gc.addr, 0
construct ||| FROM genCustomerDetails() AS gc
construct ||| WHERE gc.custno NOT IN (
construct ||| SELECT custno
construct ||| FROM customer
construct ||| WHERE balance > 0)
bodyText ||| Here, the data generator function getCustomerDetails ( )
bodyText ||| is used as if it were a normal relation, whereas in fact the
bodyText ||| results it returns are computed on the fly. In fact, several
bodyText ||| of the main commercial database management systems al-
bodyText ||| ready allow user-defined functions to be embedded in queries
bodyText ||| in this way, so this does not require a further extension of
bodyText ||| SQL. Figure 1 shows the minimal extensions that are needed
bodyText ||| to support all the kinds of constrained query shown above
bodyText ||| using the SQL99 standard [17].
subsectionHeader ||| 2.1 Test Case Semantics
bodyText ||| Clearly, the semantics of these intensional database test
bodyText ||| cases is more complex than for traditional extensional tests.
bodyText ||| However, we can define their semantics formally in terms
bodyText ||| of a mapping from intensional tests to sets of equivalent
bodyText ||| extensional database test cases. We first present a formal
bodyText ||| definition of the structure of our intensional test cases:
construct ||| DefInItIOn 1. An intensional database test case is a quin-
construct ||| tuple < p, i, DBi, o, DBo >, where:
listItem ||| •	p is the program to be executed in the test,
listItem ||| •	i is a tuple of n variables and literals that describes the
listItem ||| inputs to be given to program p, where n is the number
listItem ||| of parameters expected by p,
listItem ||| •	DBi is a set of constrained queries that together specify
listItem ||| the initial database state.
listItem ||| •	o is a tuple of m variables and literal that describes the
listItem ||| expected outputs from the program p.
listItem ||| •	DBo is a set of constrained queries that together specify
listItem ||| the conditions that must hold in the database state after
listItem ||| execution of p if no fault has been encountered.
page ||| 104
bodyText ||| A constrained query has the form < Q, min, max, vars >,
bodyText ||| where Q is a standard relational algebra query, min and
bodyText ||| max describe the constraints on the cardinality of the query
bodyText ||| result set, and vars is the list of variables bound by the
bodyText ||| query result.
bodyText ||| A database test case is well-formed for use with a partic-
bodyText ||| ular database schema Σ iff:
listItem ||| 9 for every variable v that occurs free in i, DBi, o and
listItem ||| DBo, there exists a query in DBi that provides a bind-
listItem ||| ing for v,
listItem ||| 9 for every query < q, n, m, vs > in DBi U DBo, q is a
listItem ||| well-formed query over Σ that returns k-tuples, where
listItem ||| IvsI = k, and
listItem ||| 9 there are no circular variable dependencies amongst
listItem ||| the queries in DBi.
bodyText ||| We can now define a semantics for the intensional database
bodyText ||| test cases as follows. Every intensional test case is equivalent
bodyText ||| to a set of extensional test cases. An extensional test case
bodyText ||| defines a specific test run, in terms of actual inputs and
bodyText ||| outputs, rather than expressions denoting sets of inputs and
bodyText ||| outputs. The set of all possible extensional test cases is
bodyText ||| given by:
equation ||| PxGnxDBxGxDB
bodyText ||| where P is the set of all programs, G is the set of all lit-
bodyText ||| erals, Gn is the set of all n-tuples formed from G and DB
bodyText ||| is the set of all database states (relative to all schemas)5.
bodyText ||| The components of each extensional test are the program
bodyText ||| to be tested, the input values, the initial database state,
bodyText ||| the expected output and the expected final database state,
bodyText ||| respectively.
bodyText ||| An intensional test case is effectively a shorthand expres-
bodyText ||| sion for a set of extensional test cases that are all derived
bodyText ||| from the same equivalence partition of the test case inputs.
bodyText ||| An intensional database test < p, i, DBi, o, DBo >, where
bodyText ||| DBi = {< qi, ni, mi, vi >} and DBo = {< qo, no, mo, vo >},
bodyText ||| is equivalent to the following set of extensional tests:
equation ||| {< p, i[vi/v], dbi, o[vi/v], dbo > I
equation ||| dbi E DB n
equation ||| (ni <_ Iqi(dbi)I <_ mi) n
equation ||| v E qi(dbi) n
equation ||| dbo E DB n
equation ||| (no <_ I (qo [vi /v])(dbo)I <_ mo)}
bodyText ||| We use the notation exp[01/02] to express the substitution of
bodyText ||| the values in 01 by the corresponding values in 02 whereever
bodyText ||| they occur in exp. Therefore, this expression denotes the set
bodyText ||| of extensional tests where the input database satisfies the
bodyText ||| constraints imposed by the initial constrained query, and
bodyText ||| where the bindings from execution of that query (here ex-
bodyText ||| pressed as the tuple of variables v) are substituted into the
footnote ||| 5For simplicity of presentation, we assume that all programs
footnote ||| require the same number of inputs (n). In practice, n can
footnote ||| be the largest number of inputs required by any program,
footnote ||| and the unused values can be filled with nulls.
bodyText ||| expressions defining the inputs, expected output and ex-
bodyText ||| pected final database state before they too are evaluated 6.
bodyText ||| The idea underlying this notion of an intensional test is
bodyText ||| that when any of its corresponding extensional sets are ex-
bodyText ||| ecuted, the intensional test is itself deemed to have been
bodyText ||| executed. Thus, the use of intensional tests allows much
bodyText ||| greater freedom at test execution time, since we may choose
bodyText ||| any of the possible extensional tests, depending on which is
bodyText ||| closest to our starting environment. In the next section, we
bodyText ||| will consider the practical ramifications of this approach to
bodyText ||| testing, and describe how the semantics just described can
bodyText ||| be implemented in practice.
sectionHeader ||| 3. DATABASE PREPARATION
bodyText ||| The execution of an intensional database test case con-
bodyText ||| sists of three distinct phases: 1) preparation of the environ-
bodyText ||| ment for test execution; 2) execution of the test with the
bodyText ||| prepared inputs; and 3) capture and storage of the results,
bodyText ||| for later analysis. Since all the work of finding bindings
bodyText ||| for the variables in the test case specification is done in the
bodyText ||| preparation phase, the final two phases are straightforward
bodyText ||| and differ little from standard testing procedures. When
bodyText ||| program execution is complete, the constrained query that
bodyText ||| determines whether the test has been successful or not is
bodyText ||| evaluated against the database, and the output from the
bodyText ||| program is checked against what is expected. In the case
bodyText ||| of test failure, the details of the actual extensional test that
bodyText ||| was executed are recorded, for diagnosis purposes.
bodyText ||| The first phase, however, is more complex. If we were
bodyText ||| content to execute only those test cases which happen to
bodyText ||| be suitable for use with the initial database state, then the
bodyText ||| preparation phase would simply be a matter of executing
bodyText ||| the input constrained queries against the database and, if
bodyText ||| they are all successful, using the bindings thus produced
bodyText ||| to instantiate the remaining components of the test case.
bodyText ||| However, thanks to the declarative nature of our test case
bodyText ||| specifications, the testing framework can be pro-active in
bodyText ||| cases where the given database is not suitable for use by
bodyText ||| the test case, and can automatically generate a sequence of
bodyText ||| updates that will cause the constrained queries to produce
bodyText ||| the required number of bindings.
bodyText ||| In fact, this problem is similar (though not identical) to
bodyText ||| one that has been studied by the database and artificial in-
bodyText ||| telligence communities for many years. It is known variously
bodyText ||| as the view update problem [9], the knowledge base update
bodyText ||| problem [12], and the transaction repair problem [10]. Many
bodyText ||| database systems have the capability to define views on top
bodyText ||| of the basic database. A view is a kind of virtual relation.
bodyText ||| To the user, it appears to be a normal relation, but it con-
bodyText ||| tains no stored data. Instead, the contents of the view are
bodyText ||| defined by a expression over other relations, and attempts
bodyText ||| to retrieve data from the view are converted into queries
bodyText ||| over these relations. To take a simple example for illustra-
bodyText ||| tion, we might create a view called Debtors which appears
bodyText ||| to be a relation of the same name containing all customers
bodyText ||| with a negative balance. Attempts to retrieve Debtors is
footnote ||| 6For simplicity of presentation, we assume here that there
footnote ||| is only one query in each of DBi and DBo. In practice,
footnote ||| it may be necessary to include several queries, each pro-
footnote ||| ducing different bindings and imposing different cardinality
footnote ||| constraints. In this case, the constraints must be conjoined,
footnote ||| and the full set of bindings can be retrieved by performing
footnote ||| a natural join of all the queries, with join condition true.
page ||| 105
bodyText ||| converted into a query against the customer table with an
bodyText ||| added constraint on the balance.
bodyText ||| If views are truly to act as normal relations then it should
bodyText ||| be possible to update them as well query them. But what
bodyText ||| does it mean to update a virtual relation? In this case, the
bodyText ||| view update must be converted into a sequence of updates
bodyText ||| on the stored relations that will cause the desired change in
bodyText ||| the contents of the view itself. This is a non-trivial problem
bodyText ||| for realistic view languages, and becomes even more difficult
bodyText ||| when we move into the context of knowledge bases, where
bodyText ||| virtual relations can be defined using rules over other rela-
bodyText ||| tions, and when we add integrity constraints that must be
bodyText ||| maintained by all updates [1, 2, 3, 4, 5, 8, 11].
bodyText ||| Only in very narrow circumstances does a view update
bodyText ||| have a single translation into real updates [15, 18]. Various
bodyText ||| heuristics for selecting from amongst the possible transla-
bodyText ||| tions have been proposed (of which the most common is to
bodyText ||| choose the update that results in the smallest change to the
bodyText ||| existing data set [2]), but in real applications user input is
bodyText ||| needed in order to identify the translation that corresponds
bodyText ||| most closely to the real world state that the database should
bodyText ||| reflect [10].
bodyText ||| In the case of intensional database tests, we have a query
bodyText ||| (the constrained query that describes our requirements for
bodyText ||| the test) that does not produce the correct number of an-
bodyText ||| swers when executed against the test database. We need to
bodyText ||| find a sequence of updates to the base data that will cause
bodyText ||| our query to produce the number of answers we need. How-
bodyText ||| ever, in this case, there is no requirement to find the set of
bodyText ||| updates that matches the state of reality — any sensible up-
bodyText ||| date that satisfies the query conditions will be acceptable.
bodyText ||| This simplifies the problem considerably, removing the need
bodyText ||| for complex search procedures and for any user input.
subsectionHeader ||| 3.1 The Preparation Algorithm
bodyText ||| One of the advantages of using a query-based language
bodyText ||| for test specification (as opposed to a predicate calculus-
bodyText ||| based language) is that we can make use of a very common
bodyText ||| and easy-to-analyse internal form for (relational) database
bodyText ||| queries, called relational algebra. This form provides a small
bodyText ||| number of operations on relations that can be combined to
bodyText ||| form complex queries. For example, the three most basic
bodyText ||| (and useful) relational algebra operators are:
listItem ||| 9 The projection operator, πAttsR, which creates a re-
listItem ||| lation from R by deleting all attributes not in Atts.
listItem ||| For example, π[Country]Customer produces a relation
listItem ||| that contains just the countries that appear in the
listItem ||| Customer relation.
listItem ||| 9 The selection operator, QcR, which creates a relation
listItem ||| that contains all the rows from relation R that satisfy
listItem ||| the condition c. For example, Qbal<0 Customer returns
listItem ||| a relation containing details of all customers with neg-
listItem ||| ative balances.
listItem ||| 9 The join operator, R ✶c S, which creates a relation
listItem ||| containing rows from the cross product of R and S that
listItem ||| satisfy the join condition c. The query Debtor ✶dNo=WNo
listItem ||| Inactive returns details of all debtors who are also in-
listItem ||| active.
bodyText ||| Since the result of each relational algebra operator is itself
bodyText ||| a relation, together they form a closed algebra. This means
bodyText ||| that we can form arbitrarily complex queries by applying
bodyText ||| operators to the results of other operators. For example, a
bodyText ||| query which retrieves the customer number of all customers
bodyText ||| with a negative balance would be written as:
equation ||| π[custNo] (Qbalance<0 Customer)
bodyText ||| A common way to visualise such expressions is as a tree of
bodyText ||| operators. The tree for the above query is shown in Figure 2.
figureCaption ||| Figure 2: Relational Algebra Tree for Negative Bal-
figureCaption ||| ance Query.
bodyText ||| Our algorithm for preparing a database for testing is based
bodyText ||| around this notion of a relational algebra tree. We take the
bodyText ||| cardinality constraints from the test specification, and push
bodyText ||| them down through the nodes of the input database query
bodyText ||| tree, collecting up additional conditions as we go. When we
bodyText ||| reach a leaf node (i.e. a base relation), we make updates
bodyText ||| to the database so that the pushed-down constraints are
bodyText ||| satisfied for that relation.
bodyText ||| At each stage, we collect up the different kinds of con-
bodyText ||| straint and push them further down into the tree. These
bodyText ||| constraint types are:
listItem ||| 9 Min and Max, the upper and lower bounds on the de-
listItem ||| sired cardinality of the result set.
listItem ||| 9 SelC, the selection conditions on the relations that we
listItem ||| are interested in.
listItem ||| 9 UAtts, the collection of attributes that are used in the
listItem ||| constrained query, and that must be populated in any
listItem ||| new data that we insert.
bodyText ||| We also build up a collection of queries that describe the
bodyText ||| data that has been prepared for testing so far, as we progress
bodyText ||| through the tree. We call these queries “bindings” (Bgs),
bodyText ||| since they give us values for the variables that occur within
bodyText ||| the selection and join conditions. At each stage, the bindings
bodyText ||| should contain one query for each leaf node that has so far
bodyText ||| been prepared.
bodyText ||| It is easiest to see how this works by considering a simple
bodyText ||| example, such as that shown in Figure 2. Let us assume we
bodyText ||| have a constrained query that requires at least one customer
bodyText ||| with negative balance to exist, and that our database does
bodyText ||| not currently contain any such customers. We begin at the
bodyText ||| root node of the tree, with only the cardinality constraints
bodyText ||| extracted from the test specification:
equation ||| Min = 1, Max = null, SelC = true,
equation ||| UAtts = 0, Bgs = 0
bodyText ||| The top node is a projection operator. Projection does not
bodyText ||| affect the cardinality of the result set, nor impose any condi-
bodyText ||| tions, but it does tell us something about the attributes used
page ||| 106
figureCaption ||| Figure 3: Relational Algebra Tree Showing Multiple
figureCaption ||| Joins
bodyText ||| by the query. We therefore add the projection attributes to
bodyText ||| UAtts and push the constraints down to the next node:
equation ||| Min = 1, Max = null, SelC = true,
equation ||| UAtts = {custNo}, Bgs = 0
bodyText ||| Next we must deal with the selection node. Selection nodes
bodyText ||| reduce the cardinality of their input, so we need to push
bodyText ||| down the selection conditions to ensure that any updates
bodyText ||| we may make affect the correct tuples. We also need to add
bodyText ||| any attributes appearing in the selection condition to UAtts:
equation ||| Min = 1, Max = null, SelC = balance < 0,
equation ||| UAtts = {custNo, balance}, Bgs = 0
bodyText ||| The final node is the leaf node, representing the Customer
bodyText ||| relation. We construct a query from the conditions on that
bodyText ||| relation and execute it, to find out how many answers are
bodyText ||| currently in the database. In this case, there are none, so
bodyText ||| we need to insert a new Customer record with at least
bodyText ||| the custNo and balance attributes populated, and with
bodyText ||| a negative balance. If there are any integrity constraints
bodyText ||| on this relation, then we need to make sure they are also
bodyText ||| satisfied by the new data.
bodyText ||| We use the DBMonster data generator mentioned earlier
bodyText ||| to create the new data. It allows generation functions to
bodyText ||| be specified for attributes, and additional constraints to be
bodyText ||| placed on them. It will also maintain primary key, foreign
bodyText ||| key, non-null and domain constraints if configured appro-
bodyText ||| priately using the information present in the pushed-down
bodyText ||| constraints.
bodyText ||| Of course, this is a very simple example. In general, we
bodyText ||| can expect to have to deal with more complicated queries
bodyText ||| involving several joins, such as that shown in Figure 3. This
bodyText ||| relational algebra tree is equivalent to the following con-
bodyText ||| strained query:
construct ||| ANY :orderNo, :productNo GENERATED BY
construct ||| SELECT o.orderno, p.productno
construct ||| FROM Order o, Orderdetail d, Product p
construct ||| WHERE o.orderno = d.orderno AND
construct ||| d.productno = p.productno AND
construct ||| p.price > 50
bodyText ||| which requires that at least one order must exist that in-
bodyText ||| volves the purchase of at least one product that costs more
bodyText ||| than £50. Joins complicate the process of preparing the
bodyText ||| database, because they introduce dependencies between the
bodyText ||| updates that take place at different leaf nodes. For example,
bodyText ||| imagine that we have processed the tree shown in Figure 3 as
bodyText ||| far as the leaf node representing the OrderDetail relation.
bodyText ||| Join operators further constrain the selection condition (by
bodyText ||| conjoining in their join condition), but add no other con-
bodyText ||| straints. So, by the time we reach this leaf node, SelC will
bodyText ||| have been set to:
equation ||| o.orderno = d.orderno A d.productno = p.productno
bodyText ||| We need to find out whether a suitable OrderDetail record
bodyText ||| exists within the database. However, in order to do this,
bodyText ||| we need to know something about what preparation actions
bodyText ||| were performed when the Product leaf node was processed.
bodyText ||| Maybe there were already plenty of £50-plus products in
bodyText ||| the catalogue, or maybe there were none and one had to
bodyText ||| be created. How is this information passed through to the
bodyText ||| OrderDetail node so that the correct tuple can be identi-
bodyText ||| fied or created?
bodyText ||| In the current version of our algorithm, we have chosen
bodyText ||| to use the database itself to communicate these values. If
bodyText ||| there are many suitable Product records, then we can find
bodyText ||| one by querying the database directly once again. If a new
bodyText ||| product had to be created, then it will now be present in
bodyText ||| the database, so we can still retrieve it by querying. The
bodyText ||| information needed to construct these queries is present in
bodyText ||| the selection conditions that have been considered during
bodyText ||| the processing of the relational algebra tree up to this point.
bodyText ||| For example, in order to search for an OrderDetail tuple
bodyText ||| that is connected to a suitable Product, we need to issue
bodyText ||| the following query:
construct ||| SELECT d.* FROM OrderDetail d, Product p
construct ||| WHERE d.productno = p.productno AND
construct ||| p.price > 50
bodyText ||| This query cannot be constructed from only the constraints
bodyText ||| pushed-down from the parent nodes of the leaf node; instead,
bodyText ||| we need to collect up the constraints imposed by all nodes
bodyText ||| visited before the current node, so that they are available for
bodyText ||| query formation. This is done using the Bgs data structure
bodyText ||| mentioned earlier.
bodyText ||| Figure 4 presents the complete algorithm, showing the be-
bodyText ||| haviour required for each different type of operator. The al-
bodyText ||| gorithm is presented as a side-effecting function which takes
bodyText ||| the constrained query that is to be satisfied by the database,
bodyText ||| and a set of initial conditions that state the required cardi-
bodyText ||| nality bounds and initialise SelC to true, UAtts to 0 and Bgs
bodyText ||| to 0. The function returns a set of bindings, but these are
bodyText ||| discarded. The main task of the algorithm is carried out
bodyText ||| by the side-effecting updates that occur when leaf nodes are
bodyText ||| processed.
sectionHeader ||| 4. DOT-UNIT TESTING FRAMEWORK
bodyText ||| The intensional database test language and accompanying
bodyText ||| preparation algorithm have been implemented within a test-
bodyText ||| ing tool, called DOT- Unit. This tool is part of a larger Data-
bodyText ||| Oriented Testing7 framework that is under development at
bodyText ||| the University of Manchester [20]. DOT-Unit has been im-
bodyText ||| plemented as an extension to the JUnit testing framework
footnote ||| 7http://www.cs.man.ac.uk/—willmord/dot/
page ||| 107
figure ||| Projection operator
figure ||| prepare(irattsQ, Min, Max, UAtts, SelC, Bgs)
figure ||| = prepare(Q, Min, Max, UAtts U Atts, SelC, Bgs)
figure ||| Selection operator
figure ||| prepare(acQ, Min, Max, UAtts, SelC, Bgs)
figure ||| = prepare(Q, Min, Max, UAtts, SelC n c, Bgs)
figure ||| Join operator
figure ||| prepare(Q1 ✶jc Q2, Min, Max, UAtts, SelC, Bgs)
figure ||| = prepare(Q2, Min, Max, UAtts, SelC n jc,
figure ||| prepare(Q1, Min, Max, UAtts, SelC, Bgs))
figure ||| Relation (leaf node)
figure ||| prepare(Rasv, Min, Max, UAtts, SelC, Bgs)
figure ||| Q = bindingQuery(v, SelC, Bgs)
figure ||| Execute Q to produce result set RS
figure ||| if IRSI < Min then
figure ||| Invoke DBMonster to create (Min - IRSI) more
figure ||| instances of R that satisfy the conditions in Q
figure ||| else if IRSI > Max then
figure ||| Delete the first (IRSI - Max) tuples in RS
figure ||| else
figure ||| No preparation updates needed
figure ||| return (Bgs U binding(v, Q))
figureCaption ||| Figure 4: The Database Preparation Algorithm
bodyText ||| for the unit testing of Java applications [16]. We have sub-
bodyText ||| classed the standard JUnit TestCase class, to create a ded-
bodyText ||| icated DatabaseTestCase class for specifying and man-
bodyText ||| aging intensional database tests. DatabaseTestCase pro-
bodyText ||| vides facilities for specifying pre-conditions on database state,
bodyText ||| generating and manipulating the bindings that are produced
bodyText ||| by such pre-conditions, and evaluating post-conditions on
bodyText ||| the database state after the test has been completed. The
bodyText ||| standard JUnit methods for determining the results of test
bodyText ||| execution on the in-memory fixture can also be used.
figureCaption ||| Figure 5 shows an example DatabaseTestCase that in-
figureCaption ||| cludes two individual tests. The first verifies that when a
figureCaption ||| customer with a non-negative balance is deleted, all cus-
figureCaption ||| tomers with that customer number really do disappear from
figureCaption ||| the database. The second uses a data generation function to
figureCaption ||| propose attribute values for a new customer record (includ-
figureCaption ||| ing a unique customer number), and checks that after the
figureCaption ||| program has executed only one customer with the generated
figureCaption ||| customer number exists.
bodyText ||| We use a prefixed colon to indicate variables that are
bodyText ||| shared amongst the test components — a notation that will
bodyText ||| be familiar to many database programmers, since it is com-
bodyText ||| monly used in various forms of embedded SQL. The shared
bodyText ||| variables acquire their values when the test harness evalu-
bodyText ||| ates the precondition (and performs any necessary database
bodyText ||| preparation steps). These values can then be accessed us-
bodyText ||| ing the binding method, and can be used in arbitrarily
bodyText ||| complex assert conditions, as well as in instantiating the
bodyText ||| post-condition query.
bodyText ||| One of the main advantages of using the JUnit framework
bodyText ||| as the basis for the implementation of DOT-Unit is that it
bodyText ||| allows us to integrate our tool seamlessly into existing de-
bodyText ||| velopment environments, such as Eclipse8. Thus, DOT-Unit
bodyText ||| tests are executed in exactly the same way as a standard JU-
bodyText ||| nit test case, and the results are displayed using the same
bodyText ||| interface components. This allows testing of database and
bodyText ||| non-database components to be interleaved in a convenient
bodyText ||| and natural manner.
footnote ||| 8http://www.eclipse.org
sectionHeader ||| 5. EVALUATION
bodyText ||| The practicality of this intensional test case approach de-
bodyText ||| pends largely on the performance overhead imposed by the
bodyText ||| database preparation algorithm. If the time required to ex-
bodyText ||| ecute each individual test case is significantly higher using
bodyText ||| our approach than with DBUnit, say, then fewer tests will
bodyText ||| be able to be executed in the time available and the benefits
bodyText ||| of faster test development and fewer spurious test failures
bodyText ||| will be negated.
bodyText ||| To gain a handle on the degree of performance overhead
bodyText ||| to be expected from DOT-Unit, we made use of an exist-
bodyText ||| ing extensional DB test suite that we created for earlier
bodyText ||| work [20]. This suite was designed for mp3cd browser9, an
bodyText ||| open-source Java/JDBC program that stories information
bodyText ||| about mp3 files in a MySQL 5.0 database10. The schema
bodyText ||| of the database consists of 6 relations with 22 attributes, 7
bodyText ||| primary key constraints and 6 foreign key constraints. We
bodyText ||| created an equivalent intensional test suite, consisting of 20
bodyText ||| test cases, from the extensional suite by converting each test
bodyText ||| case into DOT-Unit pre- and post-conditions. We also re-
bodyText ||| placed each hard-coded test parameter in the original tests
bodyText ||| into constrained query bindings.
bodyText ||| We wanted to investigate two specific aspects of the per-
bodyText ||| formance of DOT-Unit. First, we wanted to compare its
bodyText ||| performance with that of DBUnit over the equivalent test
bodyText ||| cases as the database size grows. Second, we wanted to gain
bodyText ||| some idea of what aspects of DB preparation and testing
bodyText ||| were dominating the performance of DOT-Unit. The re-
bodyText ||| sults of the experiments we performed are presented below.
bodyText ||| All experiments were run on a Pentium-M 2.0GHz machine,
bodyText ||| with 1Gb RAM, running Ubuntu Linux.
subsectionHeader ||| 5.1 Comparison with DBUnit
bodyText ||| At first sight, the extensional approach, as exemplified
bodyText ||| by DBUnit, would seem to be the more efficient method
bodyText ||| of the two, as the testing harness does not need to spend
bodyText ||| any time figuring out what updates need to be made prior
bodyText ||| to each test—it only needs to execute them. This does
footnote ||| 9http://mp3cdbrowser.sourceforge.net/mp3cd/
footnote ||| 10http://www.mysql.com
page ||| 108
figure ||| public class ProgramTest extends DatabaseTestCase {
figure ||| public void testDeleteCustomer() {
figure ||| preCondition("ANY :cn GENERATED BY SELECT custNo FROM customer WHERE balance > 0;");
figure ||| Program p = new Program();
figure ||| p.deleteCustomer(binding(":cn"));
figure ||| postCondition("NO :cn2 GENERATED BY SELECT custno FROM customer WHERE custNo = :cn;");
figure ||| }
figure ||| public void testNewCustomer() {
figure ||| preCondition("ANY :cn, :name, :addr GENERATED BY SELECT gc.custNo, gc.name, gc.addr FROM
figure ||| genCustomerDetails() AS gc WHERE gc.custNo NOT IN (SELECT custNo FROM customer);");
figure ||| Program p = new Program();
figure ||| boolean b = p.newCustomer(binding(":cn"), binding(":name"), binding(":addr"));
figure ||| assertTrue(b);
figure ||| postCondition("EXACTLY 1 :cn, :name, :addr GENERATED BY SELECT custno, name, addr
figure ||| FROM customer;");
figure ||| }
figure ||| }
figureCaption ||| Figure 5: Example DOT-Unit Test Case
bodyText ||| not happen by accident, but because a human programmer
bodyText ||| has spent time earlier, deciding exactly what the database
bodyText ||| should look like for each test case. However, when writing
bodyText ||| DBUnit tests, it is common to try to reuse database de-
bodyText ||| scriptions for multiple test cases where possible, to reduce
bodyText ||| the amount of programming and maintenance time. In this
bodyText ||| case, some redundant updates will be made before each test
bodyText ||| case - updates that our extensional approach will not bother
bodyText ||| to make. It is also the case that DBUnit makes its updates
bodyText ||| blindly, whether they are needed or not, whereas the inten-
bodyText ||| sional approach will be able to reuse much of the existing
bodyText ||| database state for each new test case.
bodyText ||| Given this, it seems likely that the performance of DBUnit
bodyText ||| will be better when the database state required for each
bodyText ||| test case is relatively small, but that the situation will be
bodyText ||| reversed when the database state grows much larger. In
bodyText ||| order to gauge the point at which this change occurs, we
bodyText ||| ran our two test suites (extensional and intensional) with
bodyText ||| databases of varying sizes, and measured the execution time
bodyText ||| taken to execute the whole test suite.
bodyText ||| In each case, we generated initial database states of vary-
bodyText ||| ing sizes at random - either populating the database directly
bodyText ||| (for the intensional test cases) or generating XML descrip-
bodyText ||| tions of the required state (for the extensional test cases).
bodyText ||| The results are shown in Figure 6.
figureCaption ||| Figure 6: Comparison of Approaches as DB Size
figureCaption ||| Increases
bodyText ||| To our surprise, although the performance of DOT-Unit was
bodyText ||| initially worse than that of DBUnit, it overtook its com-
bodyText ||| petitor at a comparatively small database size of around 20
bodyText ||| tuples per relation. Obviously, this experiment is a little
bodyText ||| unfair to DBUnit, since programmers are unlikely to create
bodyText ||| database descriptions consisting of 1000s of tuples per re-
bodyText ||| lation. However, tests of this scale will be needed at some
bodyText ||| point in the development cycle, in order to verify the be-
bodyText ||| haviour of the system on more realistic data sets.
bodyText ||| In order to assess the behaviour of DOT-Unit more pre-
bodyText ||| cisely, consider the graph in Figure 7, which shows the re-
bodyText ||| sults at small databases sizes in more detail. It can be ob-
bodyText ||| served that the performance of DOT-Unit first improves and
bodyText ||| then begins to degrade again at a database size of around
bodyText ||| 50 tuples per relation.
figureCaption ||| Figure 7: Detailed Comparison of Approaches
bodyText ||| One possible explanation for this initial improvement in per-
bodyText ||| formance is that, as the database size rises, so does the
bodyText ||| probability that the data needed for the test case is al-
bodyText ||| ready present in the database. For the very small states,
bodyText ||| a lot of preparation work is required to create the needed
bodyText ||| data, whereas less work is needed for a more fully populated
bodyText ||| database. As the database size increases further, however,
bodyText ||| the costs of making the queries needed to test the precondi-
bodyText ||| tions and formulate the preparation updates rises, pushing
bodyText ||| up the time required for the entire preparation step. This
page ||| 109
bodyText ||| behaviour may be a peculiarity of the particular test suite
bodyText ||| used, of course, and further, more extensive studies will be
bodyText ||| required in order to completely characterise the performance
bodyText ||| of the DOT-Unit test harness.
bodyText ||| From these initial results, however, DOT-Unit appears to
bodyText ||| scale well relative to database size, and the execution times
bodyText ||| are of the same order of magnitude as those resulting from
bodyText ||| DBUnit. This suggests that the intensional approach may
bodyText ||| provide a good compromise between saving expensive pro-
bodyText ||| grammer time in developing new test cases and expenditure
bodyText ||| of cheaper processing time in executing the test cases.
subsectionHeader ||| 5.2 Effect of Constraint Complexity
bodyText ||| A further concern was the effect of increasing constraint
bodyText ||| complexity on the performance of DOT-Unit test cases. How
bodyText ||| much additional overhead is added for conditions involving
bodyText ||| a higher number of selection conditions and (most impor-
bodyText ||| tantly) joins? In order to assess this, we grouped the test
bodyText ||| cases into three groups, according to their complexity:
listItem ||| 9 A: queries with one or more selections and no joins,
listItem ||| 9 B: queries with one or more selections and a join be-
listItem ||| tween two relations,
listItem ||| 9 C: queries with one or more selections and joins be-
listItem ||| tween three relations.
bodyText ||| This gave a test suite with 5 test cases in each of these
bodyText ||| categories, which we executed against a randomly generated
bodyText ||| database state with 500 tuples per relation that does not
bodyText ||| satisfy any of the test case pre-conditions. Figure 8 shows
bodyText ||| the results obtained for the three complexity categories. We
bodyText ||| measured the average time taken to execute the test cases
bodyText ||| in each category, including a breakdown of where the time
bodyText ||| is spent in each case:
listItem ||| 9 Test: the time required to execute the procedural as-
listItem ||| pects of the test case;
listItem ||| 9 Query: the time required to execute the query aspect
listItem ||| of the test case condition;
listItem ||| 9 Prepare the time required to execute the preparation
listItem ||| aspect of the test case condition.
bodyText ||| While the overall time required to execute the test cases rises
bodyText ||| as the complexity rises (unsurprisingly), the relative propor-
bodyText ||| tions of time spent in the various phases remains roughly the
bodyText ||| same. The preparation phase seems to account for slightly
bodyText ||| more than half of the time in each case, indicating that sig-
bodyText ||| nificant improvements could be achieved with a less-naive
bodyText ||| preparation algorithm.
sectionHeader ||| 6. CONCLUSIONS
bodyText ||| We have presented a new approach to the specification
bodyText ||| of test cases for database systems that attempts to reduce
bodyText ||| the amount of manual intervention required in between test
bodyText ||| case runs while also minimising the number of spurious test
bodyText ||| failures due to inappropriate input database states. The ap-
bodyText ||| proach has the further advantage that it sits naturally on top
bodyText ||| of test data sets taken from live databases, and this allows
bodyText ||| testing to be carried out using realistic data sets without re-
bodyText ||| quiring significant programmer effort to tailor the data set to
bodyText ||| the test cases. In effect, the intensional approach we have
figureCaption ||| Figure 8: The Affect of Changing Constraint Com-
figureCaption ||| plexity
bodyText ||| described allows software developers to trade programmer
bodyText ||| time for test execution time
bodyText ||| Our experience has indicated that intensional test cases
bodyText ||| are quick and natural to write for anyone who is familiar
bodyText ||| with SQL and database programming, although a study
bodyText ||| with an independent testing team would be necessary be-
bodyText ||| fore we can make any strong claims in this regard. How-
bodyText ||| ever, compared with what is involved in writing pure JDBC
bodyText ||| database test cases and DBUnit test cases, we found that
bodyText ||| the self-contained nature of the intensional test cases was a
bodyText ||| definite advantage. Writing DBUnit test cases requires the
bodyText ||| programmer to continually check that the test case is com-
bodyText ||| patible with the database description. Moreover, since it is
bodyText ||| common to try to reuse database descriptions for multiple
bodyText ||| test cases by combining their requirements into one database
bodyText ||| state, it becomes very easy to break one test case by chang-
bodyText ||| ing the database description in order to ready it for another.
bodyText ||| These problems do not arise with intensional testing, since
bodyText ||| all the information about the test case is present in a single
bodyText ||| file (the Java class file).
bodyText ||| We designed this first version of the preparation algorithm
bodyText ||| for simplicity and correctness rather than efficiency, and as
bodyText ||| such it performs rather stupidly in many cases. We are cur-
bodyText ||| rently exploring options for improving the algorithm, includ-
bodyText ||| ing more intelligent selection of the order in which the rela-
bodyText ||| tional algebra tree is traversed, alternating between passing
bodyText ||| query bindings and passing literal value bindings as is most
bodyText ||| efficient, and making use of modifications to existing tuples
bodyText ||| as well as simply adding and deleting tuples (both of which
bodyText ||| are comparatively expensive operations). The complexity of
bodyText ||| the conditions we can handle is at present limited by the
bodyText ||| capabilities of DBMonster, and can be expanded by devel-
bodyText ||| opment of a custom data generation facility. We also need
bodyText ||| to expand the range of queries that can be handled, beyond
bodyText ||| simple select-project-join queries. For example, standard
bodyText ||| SQL also allows aggregation and ordering within queries—
bodyText ||| both of which offer challenges in terms of automatic prepa-
bodyText ||| ration.
bodyText ||| A further problem with our current algorithm is that it
bodyText ||| may sometimes fail to find a solution to the database prepa-
bodyText ||| ration problem, even though one exists. This is due to the
bodyText ||| fact that updates are made at leaf nodes before the full set of
bodyText ||| constraints on those nodes has been encountered. It should
page ||| 110
bodyText ||| be possible to address the problem with more sophisticated
bodyText ||| querying techniques (this is an example of a fairly standard
bodyText ||| constrained search problem, after all), although this will add
bodyText ||| to the performance overhead. A thorough study of the trade-
bodyText ||| offs between spurious failures and more intelligent searching
bodyText ||| will need to be carried out before any concrete recommen-
bodyText ||| dations can be made.
bodyText ||| Finally, we note that where it is important to test large
bodyText ||| numbers of frame constraints (i.e. aspects of the original
bodyText ||| database state that are not affected by the execution of the
bodyText ||| program under test), it may be easier to express the test case
bodyText ||| using DBUnit, rather than cluttering up the intensional test
bodyText ||| with many such constraints.
bodyText ||| Our work presents a number of possible avenues for future
bodyText ||| work beyond the improvements mentioned above, of which
bodyText ||| the most urgent is the question of ordering of test cases
bodyText ||| within suites. This ordering can be in terms of reducing the
bodyText ||| cost of the modifications to database state or to maximise
bodyText ||| fault coverage. There is also the question of whether the
bodyText ||| modifications to database state should always persist be-
bodyText ||| tween test cases or under certain conditions discarded. For
bodyText ||| example, a test case may specify that a relation be empty
bodyText ||| and to satisfy the condition the content is discarded. How-
bodyText ||| ever, this relation may be required by later test cases and so
bodyText ||| by discarding its contents we increase the divide between the
bodyText ||| test state and the real world. This could be accomplished
bodyText ||| by either embedding the modifications inside of a transac-
bodyText ||| tion which can then be aborted or by using a hypothetical
bodyText ||| database engine.
sectionHeader ||| 7. ACKNOWLEDGMENTS
bodyText ||| We thank Leonardo Mariani and the anonymous reviewers
bodyText ||| for comments on earlier drafts of this paper. David Willmor
bodyText ||| is supported by a research studentship from the UK Engi-
bodyText ||| neering and Physical Sciences Research Council.
sectionHeader ||| 8. REFERENCES
reference ||| [1] M. Arenas, L. E. Bertossi, and J. Chomicki.
reference ||| Consistent query answers in inconsistent databases. In
reference ||| Proceedings of the 18th ACM
reference ||| SIGACT-SIGMOD-SIGART Symposium on Principles
reference ||| of Database Systems (PODS), pages 68–79. ACM
reference ||| Press, 1999.
reference ||| [2] L. E. Bertossi and J. Chomicki. Query answering in
reference ||| inconsistent databases. In J. Chomicki, R. van der
reference ||| Meyden, and G. Saake, editors, Logics for Emerging
reference ||| Applications of Databases, pages 43–83. Springer,
reference ||| 2003.
reference ||| [3] P. Bohannon, M. Flaster, W. Fan, and R. Rastogi. A
reference ||| cost-based model and effective heuristic for repairing
reference ||| constraints by value modification. In Proceedings of
reference ||| the SIGMOD Conference, pages 143–154. ACM, 2005.
reference ||| [4] L. Bravo and L. E. Bertossi. Logic programs for
reference ||| consistently querying data integration systems. In
reference ||| G. Gottlob and T. Walsh, editors, Proceedings of the
reference ||| 18th International Joint Conference on Artificial
reference ||| Intelligence (IJCAI), pages 10–15. Morgan Kaufmann,
reference ||| August 2003.
reference ||| [5] A. Cali, D. Lembo, and R. Rosati. On the decidability
reference ||| and complexity of query answering over inconsistent
reference ||| and incomplete databases. In Proceedings of the 22nd
reference ||| ACM SIGACT-SIGMOD-SIGART Symposium on
reference ||| Principles of Database Systems (PODS), pages
reference ||| 260–271. ACM, June 2003.
reference ||| [6] D. Chays, S. Dan, P. G. Frankl, F. I. Vokolos, and
reference ||| E. J. Weber. A framework for testing database
reference ||| applications. In Proceedings of the International
reference ||| Symposium on Software Testing and Analysis
reference ||| (ISSTA), pages 147–157, August 2000.
reference ||| [7] D. Chays, Y. Deng, P. G. Frankl, S. Dan, F. I.
reference ||| Vokolos, and E. J. Weyuker. An AGENDA for testing
reference ||| relational database applications. Software Testing,
reference ||| Verification and Reliability, 14(1):17–44, 2004.
reference ||| [8] J. Chomicki and J. Marcinkowski. On the
reference ||| computational complexity of minimal-change integrity
reference ||| maintenance in relational databases. In L. E. Bertossi,
reference ||| A. Hunter, and T. Schaub, editors, Inconsistency
reference ||| Tolerance, volume 3300 of Lecture Notes in Computer
reference ||| Science, pages 119–150. Springer, 2005.
reference ||| [9] S. S. Cosmadakis and C. H. Papadimitriou. Updates
reference ||| of relational views. Journal of the ACM,
reference ||| 31(4):742–760, 1984.
reference ||| [10] S. M. Embury, S. M. Brandt, J. S. Robinson,
reference ||| I. Sutherland, F. A. Bisby, W. A. Gray, A. C. Jones,
reference ||| and R. J. White. Adapting integrity enforcement
reference ||| techniques for data reconciliation. Information
reference ||| Systems, 26(8):657–689, 2001.
reference ||| [11] G. Greco, S. Greco, and E. Zumpano. A logical
reference ||| framework for querying and repairing inconsistent
reference ||| databases. IEEE Transactions on Knowledge and
reference ||| Data Engineering, 15(6):1389–1408, 2003.
reference ||| [12] A. Guessoum and J. W. Lloyd. Updating knowledge
reference ||| bases. New Generation Computing, 8(1):71–89, 1990.
reference ||| [13] F. Haftmann, D. Kossmann, and A. Kreutz. Efficient
reference ||| regression tests for database applications. In
reference ||| Proceedings of the 2nd Biennial Conference on
reference ||| Innovative Data Systems Research (CIDR), pages
reference ||| 95–106. Online Proceedings, January 2005.
reference ||| [14] G. M. Kapfhammer and M. L. Soffa. A family of test
reference ||| adequacy criteria for database-driven applications. In
reference ||| Proceedings of the 11th ACM SIGSOFT Symposium
reference ||| on Foundations of Software Engineering, pages
reference ||| 98–107. ACM, September 2003.
reference ||| [15] R. Langerak. View updates in relational databases
reference ||| with an independent scheme. ACM Transactions on
reference ||| Database Systems (TODS), 15(1):40–66, 1990.
reference ||| [16] P. Louridas. Junit: Unit testing and coding in
reference ||| tandem. IEEE Software, 22(4):12 – 15, July-Aug 2005.
reference ||| [17] J. Melton and A. R. Simon. SQL:1999 Understanding
reference ||| Relational Language Components. Morgan Kaufmann,
reference ||| 2002.
reference ||| [18] H. Shu. Using constraint satisfaction for view update.
reference ||| Journal of Intelligent Information Systems,
reference ||| 15(2):147–173, 2000.
reference ||| [19] D. Willmor and S. M. Embury. Exploring test
reference ||| adequacy for database systems. In Proceedings of the
reference ||| 3rd UK Software Testing Research Workshop
reference ||| (UKTest), pages 123–133. The University of Sheffield,
reference ||| September 2005.
reference ||| [20] D. Willmor and S. M. Embury. A safe regression test
reference ||| selection technique for database–driven applications.
reference ||| In Proceedings of the 21st International Conference on
reference ||| Software Maintenance (ICSM), pages 421–430. IEEE
reference ||| Computer Society, September 2005.
page ||| 111

title ||| Analysis of Soft Handover Measurements
title ||| in 3G Network
author ||| Kimmo Raivio
affiliation ||| Adaptive Informatics Research Centre
affiliation ||| Helsinki University of Technology
address ||| P.O. Box 5400, FIN-02015 HUT, Finland
email ||| kimmo.raivio@hut.fi
sectionHeader ||| ABSTRACT
bodyText ||| A neural network based clustering method for the analysis
bodyText ||| of soft handovers in 3G network is introduced. The method
bodyText ||| is highly visual and it could be utilized in explorative anal-
bodyText ||| ysis of mobile networks. In this paper, the method is used
bodyText ||| to find groups of similar mobile cell pairs in the sense of
bodyText ||| handover measurements. The groups or clusters found by
bodyText ||| the method are characterized by the rate of successful han-
bodyText ||| dovers as well as the causes of failing handover attempts.
bodyText ||| The most interesting clusters are those which represent cer-
bodyText ||| tain type of problems in handover attempts. By comparing
bodyText ||| variable histograms of a selected cluster to histograms of
bodyText ||| the whole data set an application domain expert may find
bodyText ||| some explanations on problems. Two clusters are investi-
bodyText ||| gated further and causes of failing handover attempts are
bodyText ||| discussed.
sectionHeader ||| Categories and Subject Descriptors
category ||| H.4.3 [Information Systems Applications]: Communi-
category ||| cations Applications—Information browsers; I.5.3 [Pattern
category ||| Recognition]: Clustering
sectionHeader ||| General Terms
keyword ||| Algorithms, Management, Performance
sectionHeader ||| Keywords
keyword ||| 3G network, soft handover, mobility management, data min-
keyword ||| ing, hierarchical clustering, neural networks
sectionHeader ||| 1. INTRODUCTION
bodyText ||| Mobility management is a great challenge in current and
bodyText ||| future radio access networks. In third generation (3G) net-
bodyText ||| works user experienced quality of service (QoS) under a
bodyText ||| move of mobile station (MS) from one mobile cell to an-
bodyText ||| other cell has been improved by implementing soft handover
copyright ||| Permission to make digital or hard copies of all or part of this work for
copyright ||| personal or classroom use is granted without fee provided that copies are
copyright ||| not made or distributed for profit or commercial advantage and that copies
copyright ||| bear this notice and the full citation on the first page. To copy otherwise, to
copyright ||| republish, to post on servers or to redistribute to lists, requires prior specific
copyright ||| permission and/or a fee.
note ||| MSWIM’06, October 2–6, 2006, Torremolinos, Malaga, Spain.
copyright ||| Copyright 2006 ACM 1-59593-477-4/06/0010 ...$5.00.
bodyText ||| (SHO). Soft handover makes it possible to have connections
bodyText ||| on several base stations (BS) simultaneously.
bodyText ||| In this paper, a set of measurements which can be used for
bodyText ||| soft handover decision making are analyzed and compared
bodyText ||| with other measurements in which statistics of successful-
bodyText ||| ness of handover attempts have been collected. We do not
bodyText ||| know exactly the parameters of used SHO algorithm. SHOs
bodyText ||| are investigated only on basis of data set and some general
bodyText ||| knowledge of 3G systems. Mobile cell pairs with handovers
bodyText ||| (HO) are divided in groups using clustering algorithm. Cell
bodyText ||| pairs in which SHOs are similar with each other fall in same
bodyText ||| group. Different types of SHO failures are analyzed using
bodyText ||| clustering information and distributions of measurements in
bodyText ||| each cluster.
bodyText ||| In Section 2 the soft handover concept, the measurements
bodyText ||| and used neural network algorithm are shortly introduced.
bodyText ||| Analysis methods which have been used are described in
bodyText ||| Section 3. Preliminary results are shown and discussed in
bodyText ||| Section 4. Finally, some conclusions are drawn in the last
bodyText ||| section.
sectionHeader ||| 2. BACKGROUND
bodyText ||| In this section, the basics of soft handover in 3G network
bodyText ||| is explained and the available data set is introduced. Neural
bodyText ||| network algorithm used in data clustering is also presented.
subsectionHeader ||| 2.1 Soft handover
bodyText ||| Soft handover is a state of MS being connected to several
bodyText ||| BSs simultaneously. In GSM networks, a fixed threshold for
bodyText ||| handover from one cell to another is used. In 3G networks,
bodyText ||| each MS is connected to a network via a set of BSs called
bodyText ||| active set. Members of active set are updated on basis of
bodyText ||| measurements made by MS. The advantage of having con-
bodyText ||| nections on several BS simultaneously is realized when MS
bodyText ||| is moving towards another BS, the MS should have a con-
bodyText ||| nection at least on one BS all the time. In GSM system, the
bodyText ||| older connection has to be terminated before the new one
bodyText ||| can be setup. The connection setup phases are the most
bodyText ||| vulnerable steps in a call. The connection between MS and
bodyText ||| BS is setup in a beginning of a call or later when handover
bodyText ||| occurs. If the setup is not successful, it is useful to have an
bodyText ||| existing connection to another BS or otherwise the call will
bodyText ||| be abnormally terminated.
bodyText ||| Handover can occur due to signal quality reasons or when
bodyText ||| the traffic capacity in a cell has reached its maximum or is
bodyText ||| approaching it. In the latter case, traffic load in the network
bodyText ||| can be distributed more uniformly by handing over some
bodyText ||| users from the most crowded cells. The above method is
page ||| 330
bodyText ||| called cell breathing. Use of cell breathing without giving
bodyText ||| the information to the analyzer increases the complexity of
bodyText ||| the analysis and can mix up a lot in the analysis process.
bodyText ||| For a user soft handover means power saving (in uplink)
bodyText ||| and less abnormally terminated calls. For an operator lower
bodyText ||| MS transmitting powers mean less interference. When MS
bodyText ||| is in SHO, several BSs listen the same uplink channel, but
bodyText ||| all BSs have their own downlink channel. The offered diver-
bodyText ||| sity is resource consuming in downlink direction. There is
bodyText ||| a tradeoff between better QoS in mobility management and
bodyText ||| consumption of resources.
bodyText ||| Decision of soft handover is made in mobile station by
bodyText ||| comparing the signal-to-noise ratios of active and candidate
bodyText ||| BSs Common Pilot Channel (CPICH) [2]. Members of ac-
bodyText ||| tive set are selected on basis of powers of this pilot signal [5,
bodyText ||| 12, 16] .
bodyText ||| BSs which are not in the active set but next from it in the
bodyText ||| sense of measured quantity are in candidate set. Candidate
bodyText ||| set BSs are constantly monitored whether their offer better
bodyText ||| connection than cells in active set. Cells not in active or
bodyText ||| candidate set are monitored less frequently whether their
bodyText ||| can enter the candidate set. Cell is either added to the
bodyText ||| active set if the maximum amount of cells in the active set
bodyText ||| is not reached or cell replaces the cell which offers the lowest
bodyText ||| quality connection. Cells which are no more able to offer
bodyText ||| a connection which is good enough are removed from the
bodyText ||| active set.
bodyText ||| Thresholds are used in adding, replacing and removing
bodyText ||| BSs from active set by BSs in candidate set to avoid ping
bodyText ||| pong effect. This means that a value of measured quantity
bodyText ||| should be with a certain threshold better than the old one
bodyText ||| for changing cells in active set. If measurement which is only
bodyText ||| slightly better (i.e. with zero threshold) is enough for chang-
bodyText ||| ing cells in sets, it is quite possible that the same change is
bodyText ||| performed in opposite direction very soon. Thus, the origi-
bodyText ||| nal update of the set was useless and resource consuming in
bodyText ||| the sense of all required signaling.
subsectionHeader ||| 2.2 Data
bodyText ||| Three data sets of Key Performance Indicator (KPI) level
bodyText ||| measurements related on handover events are saved. Each
bodyText ||| set consists of measurements collected during one hour. KPI
bodyText ||| is considered as an important measure to be followed. It can
bodyText ||| be a measurement by itself or it has been computed from a
bodyText ||| group of raw counters [10]. One data vector consists of prob-
bodyText ||| abilities, means, sums and counters computed over one hour
bodyText ||| of one source target cell pair. Here, source refers on cell
bodyText ||| in active set and target on another cell which is measured
bodyText ||| and possibly added in active or candidate set. Measure-
bodyText ||| ments of target cell are compared with those of source cell.
bodyText ||| Handover decisions are made in MS on basis of measured
bodyText ||| and computed base stations received signal signal-to-noise
bodyText ||| ratios (Ec/N0). For each source and target cell pair mean
bodyText ||| of signal-to-noise ratio differences is computed using
equation ||| EcnoDiffMean = mean {[Ec/N0]target — [Ec/N0] source}
bodyText ||| Mean value and number off made comparisons (EcnoDiffNum)
bodyText ||| are saved. Four bin pdfs of these measurements are also
bodyText ||| stored with bin centers in -6, -3, 0 and 3dB, correspond-
bodyText ||| ingly.
bodyText ||| In addition to Ec/N0 measurements, averages of received
bodyText ||| pilot signal power ratios between BS pairs (av rscp ratio)
bodyText ||| have been computed and stored in database. The time and
bodyText ||| probability of being in SHO with each other have also been
bodyText ||| measured. Time of target and source cell being in SHO with
bodyText ||| each other simultaneously is counted in variable t act. Then,
bodyText ||| at least one MS is in SHO having both source and target cell
bodyText ||| in its active set. The measurement is symmetric for a switch
bodyText ||| of source and target cells. Time of target cell being in SHO
bodyText ||| with source cell is stored in t act dir. Cell total time in
bodyText ||| SHO is saved in tot time sho. It has been counted over all
bodyText ||| the targets of fixed source cell. Probability of target and
bodyText ||| source being in same active set is stored in variable p act.
bodyText ||| Total number of SHO attempts to add target to active
bodyText ||| set is stored in SHO total att. Ratio of successful SHO at-
bodyText ||| tempts which lead to addition of target cell in active set is
bodyText ||| saved in add ratio. In addition to those above, the num-
bodyText ||| ber of SHO failures is stored in pfail total and ratios of four
bodyText ||| different failure causes are saved. Failure occurs in setup
bodyText ||| or active time phase of SHO and it is either radio channel
bodyText ||| problem or not. Probability of cell being in monitored state
bodyText ||| is also measured (p4th 5th). All the measurements used in
bodyText ||| the analysis are shortly described in Table 1.
bodyText ||| A lot of data has been saved in data sets, but also some
bodyText ||| very important information is missing. Due to missing in-
bodyText ||| formation on cell capacities, their locations and performed
bodyText ||| manual and automatic tuning operations on network config-
bodyText ||| uration between successive data set saves, only preliminary
bodyText ||| analysis can be performed. The rest of the analysis process
bodyText ||| is described on theoretical level.
subsectionHeader ||| 2.3 Self-Organizing Map
bodyText ||| Self-Organizing Map (SOM) [8] is an unsupervised neu-
bodyText ||| ral network algorithm which adapts the codebook vectors
bodyText ||| of neurons so that they approximate the input data distri-
bodyText ||| bution. When the training has converged topological areas
bodyText ||| or domains corresponding to certain types of inputs can be
bodyText ||| found from the map. The topology and the size of the net-
bodyText ||| work is fixed before adaptation.
bodyText ||| In the SOM algorithm, the codebook vectors wj of the
bodyText ||| SOM are at first initialized. Then, the following steps are
bodyText ||| repeated for each input vector x: Find the index of best-
bodyText ||| matching or nearest codebook vector using
equation ||| i(x) = argminI Ix — wj I I,
bodyText ||| in which j goes through all the neurons in the map. Next,
bodyText ||| the codebook vectors of winner neuron and its neighbors are
bodyText ||| updated using
equation ||| wj (t + 1) = wj (t) + αhij (x)(x(t) — wj (t)).
bodyText ||| Here, α is the learning rate and hij (x) is the neighborhood
bodyText ||| function centered around the winner neuron. Input sample
bodyText ||| x defines the winner neuron and the topological distance
bodyText ||| between indexes i and j defines how much the neuron is
bodyText ||| updated. Neighborhood function is typically Gaussian or
bodyText ||| bubble function i.e. function which decrease monotonically
bodyText ||| and even goes to zero when the distance increases.
bodyText ||| In this paper, a batch version of the SOM algorithm is
bodyText ||| used. In batch SOM, all codebook vectors of the SOM are
bodyText ||| computed after the best-matching units of all input data
bodyText ||| vectors have been found. The same data set is used several
bodyText ||| times.
sectionHeader ||| 3. METHODS
bodyText ||| Handover related measurement from 3G network can be
bodyText ||| analyzed using standard data mining methods [1]. In this
page ||| 331
tableCaption ||| Table 1: Measurements in the analysis. Data set has one sample vector for each source target cell pair.
table ||| Variable	Explanation	Type
table ||| EcnoDiffNum	Computed Ec/N0 differences	number
table ||| EcnoDiffMean	Computed Ec/N0 differences	mean
table ||| EcnoDiffPdf-6.0	-6 dB bin of Ec/N0 difference pdf	ratio
table ||| EcnoDiffPdf-3.0	-3 dB bin of Ec/N0 difference pdf	ratio
table ||| EcnoDiffPdf0.0	0 dB bin of Ec/N0 difference pdf	ratio
table ||| EcnoDiffPdf3.0	3 dB bin of Ec/N0 difference pdf	ratio
table ||| t act	Target and source simultaneously in SHO	mean
table ||| t act dir	Time of target being in SHO with source	mean
table ||| tot time sho	Cell total time in SHO	sum
table ||| p act	Target in active set of source	ratio
table ||| SHO total att	SHO attempts to add Target to active set	number
table ||| add ratio	Successful attempts leading to addition	ratio
table ||| pfail total	Failures	number
table ||| pfail ini	Setup phase failures due to non-radio	ratio
table ||| pfail ini radio	Setup phase failures due to radio	ratio
table ||| pfail act	Active time failures due to non-radio	ratio
table ||| pfail act radio	Active time failures due to radio	ratio
table ||| p4th 5th	Cell is in monitored state (=4th or 5th)	ratio
table ||| av rscp ratio	Target / Source Received power ratio	mean
table ||| r fail	Ratio pfail total / SHO total att	ratio
table ||| r EcnoDNum	Ratio EcnoDiffNum / SHO total att	ratio
table ||| * Variable defined in the analysis.
bodyText ||| study, methods presented in Figure 1 are used. At first,
bodyText ||| the miner have to decide what could be interesting in this
bodyText ||| data. The analysis task has to be defined. On basis of that
bodyText ||| the first choice of variables will be done. Next, the selected
bodyText ||| variables are preprocessed, in order to be able to use them
bodyText ||| in later analysis.
bodyText ||| In data mining tasks, variable selection and preprocessing
bodyText ||| are the most critical phases, because in this step the miner
bodyText ||| decides which variables are important and how should they
bodyText ||| be processed. The whole data mining process consists of sev-
bodyText ||| eral cycles performed repeatedly. The cycles include testing
bodyText ||| how different variable selections and preprocessing methods
bodyText ||| effect on final results. The process has inner loops in which
bodyText ||| some tasks or parameters are fixed on basis of selections
bodyText ||| made in outer loop. The inner loops are performed more
bodyText ||| frequently. Loops with more general task like the defini-
bodyText ||| tion of mining task are repeated less frequently. When the
bodyText ||| mining task is defined the analyzer should be able to decide
bodyText ||| what is (s)he looking out for.
bodyText ||| Now, the analysis task is defined as finding groups of sim-
bodyText ||| ilarly behaving cell pairs in SHO situations. Importance of
bodyText ||| measurements can also be highlighted using proper weight-
bodyText ||| ing of variables. In addition to clustering, also other tasks
bodyText ||| for data analysis can be defined. One possibility is to try to
bodyText ||| find cells or cell pairs with anomalous behavior. Anomalies
bodyText ||| can also be found by clustering, but expert knowledge in
bodyText ||| variable selection and preprocessing steps are very impor-
bodyText ||| tant.
bodyText ||| Using different variables, preprocessing methods and weight-
bodyText ||| ing of variables different clustering results can be found. To
bodyText ||| find out which of them is useful, interpretation of clusters is
bodyText ||| needed. This can be done using histograms or rules defined
bodyText ||| by data samples falling in clusters. The results which have
bodyText ||| been found using clustering methods should be visualized
bodyText ||| together with spatial locations to be able to understand the
bodyText ||| usefulness of results. Methods should be performed repeat-
bodyText ||| edly to analyze successive data sets under the knowledge of
bodyText ||| performed tuning operations. Thus, there is a possibility to
bodyText ||| find explanations to changing results. In this study, results
bodyText ||| of only one data set are shown, because more information
bodyText ||| on application domain is needed to be able to combine and
bodyText ||| compare successive clustering results.
subsectionHeader ||| 3.1 Preprocessing
bodyText ||| Different preprocessing methods have been tested. The
bodyText ||| final method was selected on basis of histograms and the
bodyText ||| clusters which were found using the selected method. At
bodyText ||| the first step, the distributions are truncated. Outliers in
bodyText ||| the selected variables were replaced by their maximum per-
bodyText ||| mitted values. Two variables, pfail total and EcnoDiffNum,
bodyText ||| were scaled using the number of performed soft handover
bodyText ||| attempts (see Table 1). Logarithms of some of the variables
bodyText ||| were taken, but finally only scaled EcnoDiffNum was prepro-
bodyText ||| cessed with logarithmic function. Sample vectors with high
bodyText ||| amount of undefined measurements were canceled. Used
bodyText ||| clustering method (see section 3.2) allows using sample vec-
bodyText ||| tors in which some variables are undefined. However, they
bodyText ||| are not so useful when the rate of undefined values increases.
bodyText ||| Here, sample vectors with 15 or more missing values in 20
bodyText ||| variables are canceled.
bodyText ||| In Figure 2 the histograms of the most interesting vari-
bodyText ||| ables preprocessed using selected methods are visualized.
bodyText ||| Some of the variables have quite high peaks in distributions,
bodyText ||| but due to the origin of variables no other preprocessing
bodyText ||| have been performed. For example, handover failure reasons
bodyText ||| pfail ini, pfail ini radio, pfail act radio and pfail act sum up
bodyText ||| to unity. However, pfail act is not analyzed because it is zero
bodyText ||| all the time in the first data set.
page ||| 332
figureCaption ||| Figure 1: Used data analysis method. Steps con-
figureCaption ||| nected with solid arrows have been performed.
subsectionHeader ||| 3.2 Clustering
bodyText ||| Cluster analysis is used to divide data vectors in groups.
bodyText ||| Data vectors falling in same cluster are similar with each
bodyText ||| other. Here, clustering is performed using a two-phase
bodyText ||| method [15]. In this method, data vectors are at first used
bodyText ||| to train a Self-Organizing Map. Neurons of the SOM adapt
bodyText ||| to incoming data so that the input data can in later analysis
bodyText ||| be represented by the codebook vectors of neurons. Number
bodyText ||| of these codebook vectors is much smaller than the number
bodyText ||| of original data vectors. Thus, computational complexity of
bodyText ||| the final crisp clustering algorithm is decreased. Another
bodyText ||| advantage of using a SOM based two-phase method instead
bodyText ||| of direct clustering of data vectors is the visualization capa-
bodyText ||| bility of SOM.
bodyText ||| In addition to preprocessing, SOM algorithm provides an-
bodyText ||| other possibility to emphasize important properties of data.
bodyText ||| Larger weights in distance computation are given to the
bodyText ||| most important properties defined by the analyzer. Smaller
bodyText ||| or even zero weight can be given to those variables which
bodyText ||| are not used in organization of the SOM i.e. in building clus-
bodyText ||| ters. However, values of them can be compared to those with
bodyText ||| larger weights using various visualization methods. Weight-
bodyText ||| ing by variable importance can also be built into SOM train-
bodyText ||| ing algorithm by utilizing learning distance metrics [7].
figureCaption ||| Figure 2: Logarithmic histograms after distribution
figureCaption ||| cuts, logarithmic preprocessing of r EcnoDNum and
figureCaption ||| scaling of all variables between [0,1]
bodyText ||| The codebook vectors are further clustered using k-means
bodyText ||| or some hierarchical clustering method. In this paper, Ward
bodyText ||| agglomerative clustering method has been used [4]. In the
bodyText ||| beginning of hierarchical clustering, each codebook vector
bodyText ||| is a cluster of its own. In the next step, the most similar
bodyText ||| clusters are combined and this is continued until all vectors
bodyText ||| are in same cluster. The clustering results form a tree struc-
bodyText ||| ture called dendrogram. In visualization of a dendrogram,
bodyText ||| the clusters combined in each step and the distance between
bodyText ||| them are shown. Final clustering is selected by cutting this
bodyText ||| tree at certain level. The number of clusters can be selected
bodyText ||| manually or some cluster validation index can be utilized
bodyText ||| to find the optimum. In this paper, Davies-Bouldin vali-
bodyText ||| dation index has been used [3]. Similar clustering methods
bodyText ||| have earlier been used in the analysis of both GSM and 3G
bodyText ||| network BTSs [9, 11, 13].
bodyText ||| As a result of clustering, each data vector is represented
bodyText ||| by index of one neuron or by the codebook vector stored in
bodyText ||| that neuron. Furthermore, the neuron and the data vectors
bodyText ||| the neuron represents belong to same cluster. On basis of
bodyText ||| the clustering result, some clusters can be selected for more
bodyText ||| specific analysis. Cluster selection is usually done on basis
bodyText ||| of found higher values of some critical variables. It is pos-
bodyText ||| sible to build a system in which rules are found for clusters
bodyText ||| [14, 9] and these are used to select interesting clusters au-
bodyText ||| tomatically. Here, interesting clusters are selected manually
bodyText ||| on basis of clusterwise variable mean values and histograms.
sectionHeader ||| 4. RESULTS
bodyText ||| In this section, handover measurement data is used to
bodyText ||| train a Self-Organizing Map of size 17 x 12. Then, the code-
bodyText ||| book vectors of the SOM are clustered using hierarchical
bodyText ||| Ward method. Results of clustering are described and two
bodyText ||| clusters are then selected for more specific analysis. Charac-
bodyText ||| teristics of sample vectors falling in those clusters are studied
bodyText ||| using histograms.
bodyText ||| Only the most interesting variables are used to find the
figure ||| Task definition
figure ||| Variable selection
figure ||| Clustering
figure ||| Interpretation
figure ||| of clusters
figure ||| Preprocessing
figure ||| Visualization
figure ||| with locations
figure ||| Parameter tuning
page ||| 333
bodyText ||| nearest neuron of input data vector. These variables have
bodyText ||| nonzero mask which can also be considered as a weighting
bodyText ||| factor in a search for the best-matching neuron. Rest of
bodyText ||| the variables have zero mask, which means that they can
bodyText ||| be visualized and updated using SOM algorithm, but they
bodyText ||| do not have an effect on organization of the SOM and on
bodyText ||| selection of the cluster in which the sample belongs to.
bodyText ||| In Figure 3 all other component planes of SOM with pos-
bodyText ||| itive mask are shown, except Ec/N0 difference distributions
bodyText ||| which are shown in Figure 6. In component plane visual-
bodyText ||| ization, distributions of components (or variables) of SOM
bodyText ||| codebook vectors are shown. Component values of one code-
bodyText ||| book vector are visualized using grayscaling and their locate
bodyText ||| in the same position at each plane. For example, values of
bodyText ||| one codebook vector are shown at upper right corner in each
bodyText ||| plane.
figureCaption ||| Figure 3: Component planes of SOM with denor-
figureCaption ||| malized scales. Shown variables have nonzero mask
figureCaption ||| and they are not describing Ec/N0 difference distri-
figureCaption ||| butions.
bodyText ||| Some component values which were not used in SOM
bodyText ||| training (i.e. they were masked out) are shown in Figure
bodyText ||| 4. Although, they have no effect on SOM organization, they
bodyText ||| are adapted to be able to compare their distributions even
bodyText ||| with those used in organizing the SOM.
bodyText ||| By visual comparison of variables in Figures 3 and 4, it can
bodyText ||| be seen that the total number of SHO attempts
bodyText ||| (SHO total att) and Ec/N0 difference measurements
bodyText ||| (EcnoDiffNum) is higher in upper part of the SOM. How-
bodyText ||| ever, when the latter is scaled by total number of attempts,
bodyText ||| higher rate of measurements (r EcnoDNum) is in lower part
bodyText ||| of the map. Also, the total number of failuring SHO at-
bodyText ||| tempts (pfail total) is high in upper right corner, but scal-
bodyText ||| ing this by number of attempts tells us that the failure rate
bodyText ||| (r fail) in upper right corner is quite moderate. Instead,
bodyText ||| higher failure rates exists in both lower corners i.e. in clus-
bodyText ||| ters 5 and 8 (see Figure 5).
bodyText ||| Trained SOM codebook vectors are clustered using hier-
bodyText ||| archical Ward algorithm. The clustering result selected by
bodyText ||| Davies-Bouldin index is shown in Figure 5. Four bin Ec/N0
bodyText ||| difference histograms are visualized on top of clustered SOM
figureCaption ||| Figure 4: Denormalized component planes of vari-
figureCaption ||| ables which were not used in SOM training.
bodyText ||| in Figure 6. When component values of SOM (see Figures
bodyText ||| 3, 4 and 6) are compared with clustering result (see Figure
bodyText ||| 5) several types of source target pairs can be found. Most of
bodyText ||| them are behaving as expected, but some of them represent
bodyText ||| handover attempts with certain type of problems.
figureCaption ||| Figure 5: SOM which is clustered using hierarchical
figureCaption ||| Ward method and Davies-Bouldin validation index.
bodyText ||| To find out the most interesting clusters of the SOM for
bodyText ||| further investigations, distribution of data samples on SOM
bodyText ||| is visualized. In Figure 7a hits of all samples on SOM nodes
bodyText ||| are visualized and in Figure 7b hits of samples with SHO
bodyText ||| failure rate (r fail) larger than 22% are shown. Samples are
bodyText ||| distributed all over the map, only some edge nodes have
bodyText ||| slightly larger hit rate. Lower part of the map has more hits
bodyText ||| when samples with increased failure rate are considered.
bodyText ||| In Figure 8 hits of samples which represent two differ-
page ||| 334
figure ||| (a) All	(b) SHO failure rate > 22%
figureCaption ||| Figure 7: Sample vector hits on SOM nodes. Size of
figureCaption ||| black hexagonal on SOM node denotes the number
figureCaption ||| of hits. Maximum number of hits per node is shown
figureCaption ||| above the plot.
figureCaption ||| Figure 6: EcnoDiff distributions on top of clustered
figureCaption ||| SOM. In each SOM node a four bin Ec/N0 histogram
figureCaption ||| is shown.
bodyText ||| ent types of SHO failures are shown. Samples are from cell
bodyText ||| pairs in which the rate of selected type of failures is larger
bodyText ||| than 75%. However, handover initialization failures due to
bodyText ||| some other reason than radio channel resources (i.e. pfail ini
bodyText ||| type failures) are obviously more frequent than failures due
bodyText ||| to radio channel initialization problems (pfail ini radio type
bodyText ||| failures). Cell pairs with SHO failures originating mainly
bodyText ||| from these two reasons are mapped on separate clusters.
bodyText ||| All SHO failures due to radio channel initialization are in
bodyText ||| cluster 9 (see Figures 5 and 8b) and most of all other ini-
bodyText ||| tialization failures are in cluster 5 (see Figures 5 and 8a). In
bodyText ||| the following, these two clusters are studied in more detail.
bodyText ||| In Figures 9 and 10 histograms of samples which belong
bodyText ||| to clusters 5 and 9 are shown. These histograms should
bodyText ||| be compared with histograms of whole data set which were
bodyText ||| shown in Figure 2. In histograms of cluster 5 (see Figure
bodyText ||| 9), the average received signal power ratio (av rscp ratio) is
bodyText ||| slightly lower than in general. Distributions of three largest
bodyText ||| Ec/N0 difference measurement bins are completely different
bodyText ||| than corresponding distributions from the whole data set.
bodyText ||| In cluster 5 most of the samples have about 3dB Ec/N0 dif-
bodyText ||| ference (EcnodiffPdf3.0) which means that at least this mea-
bodyText ||| surement makes successful SHOs possible and SHO should
bodyText ||| be performed. Exceptional Ec/N0 difference measurements
figure ||| (a) pfail ini	(b) pfail ini radio
figureCaption ||| Figure 8: Hits of samples of two failure types. Sam-
figureCaption ||| ples of which more than 75% are failuring due to
figureCaption ||| selected cause are counted.
bodyText ||| of this cluster can also be seen in Figure 6. All the failing
bodyText ||| cell pairs fail in initialization due to other than radio chan-
bodyText ||| nel reasons (pfail ini). Total rate of failures is very high
bodyText ||| (r fail). One reason for high rate of failures can be that all
bodyText ||| the capacity is in use.
bodyText ||| In histograms of cluster 9 (see Figure 10), the average re-
bodyText ||| ceived power ratios are a bit higher than usual, but there are
bodyText ||| no samples with high rate of 3dB Ec/N0 differences (EcnoD-
bodyText ||| iffPdf3.0). However, in such a situation it should be possible
bodyText ||| to perform successful SHOs. The rate of initialization fail-
bodyText ||| ures in radio channels (pfail ini radio) is higher than usually,
bodyText ||| but because only a small part of samples in this cluster have
bodyText ||| above mentioned problems the total SHO failure rate is not
bodyText ||| higher than usually. The total number of samples or cell
bodyText ||| pairs with high rate of initialization failures in SHO is so
bodyText ||| small, that it is impossible to make any further inferences
bodyText ||| from these clusters. It is possible to check histograms of
bodyText ||| only those samples which fulfill the failure rate criteria, but
bodyText ||| the number of samples is anyway quite low.
page ||| 335
figureCaption ||| Figure 9: Histograms of data vectors of cluster 5.
bodyText ||| Cell pairs with high rate of radio channel initialization
bodyText ||| failures in SHO attempts vary from data set to another,
bodyText ||| but without any information on network topology and with
bodyText ||| uncomplete information on performed tuning operations, it
bodyText ||| is impossible to make any further inferences.
bodyText ||| Figure 10: Histograms of data vectors of cluster 9.
sectionHeader ||| 5. CONCLUSIONS
bodyText ||| In this paper, a data analysis method based on a neu-
bodyText ||| ral network has been presented. The method is utilized in
bodyText ||| data visualization and clustering. The presented method is
bodyText ||| only one possibility for finding data clusters. However, the
bodyText ||| benefits of the proposed method are the decrease in compu-
bodyText ||| tational complexity due to used two-phase clustering algo-
bodyText ||| rithm and the visualization capability of the method. Thus,
bodyText ||| it is well suitable for this kind of explorative data analysis.
bodyText ||| It is desirable to find clusters with characteristics which
bodyText ||| differ from one cluster to another. In the presented method,
bodyText ||| selection of variables and variable weighting factors have
bodyText ||| been used to find interesting clusters. In the preprocess-
bodyText ||| ing phase, also the number of permitted undefined measure-
bodyText ||| ment values in sample vector has an effect on found clusters.
bodyText ||| Sample vectors with high rate of missing values are not so
bodyText ||| usable and describable as samples without them. Vectors
bodyText ||| with missing values can be used in the SOM training but
bodyText ||| the benefit of using them decreases when the rate of unde-
bodyText ||| fined values increases.
bodyText ||| In this study, histograms are used both when preprocess-
bodyText ||| ing methods are decided and when an interpretation for the
bodyText ||| found clusters are looked for. However, clusters can also be
bodyText ||| compared using other visual methods, finding limiting rules
bodyText ||| for variable values in clusters or comparing distributions of
bodyText ||| variable values in clusters using more sophisticated distribu-
bodyText ||| tion comparison measures like Kullback-Leibler divergences
bodyText ||| [6].
bodyText ||| The results which have been obtained using all available
bodyText ||| data sets differ slightly from each other, but due to uncom-
bodyText ||| plete information on network configuration and parameter
bodyText ||| tuning, further inferences cannot be made. However, adding
bodyText ||| this information would offer interesting possibilities to con-
bodyText ||| tinue this study.
sectionHeader ||| 6. REFERENCES
reference ||| [1] P. Chapman, J. Clinton, T. Khabaza, T. Reinartz,
reference ||| and R. Wirth. CRISP-DM 1.0 step-by-step data
reference ||| mining guide. Technical report, CRISM-DM
reference ||| consortium, 2000. http://www.crisp-dm.org.
reference ||| [2] Y. Chen. Soft Handover Issues in Radio Resource
reference ||| Management for 3G WCDMA Networks. PhD thesis,
reference ||| Queen Mary, University of London, 2003.
reference ||| [3] D. Davies and D. Bouldin. A cluster separation
reference ||| measure. IEEE Transactions on Pattern Analysis and
reference ||| Machine Intelligence, 1(2):224–227, April 1979.
reference ||| [4] B. Everitt. Cluster Analysis. Arnold, 1993.
reference ||| [5] V. K. Garg. Wireless Network Evolution: 2G to 3G.
reference ||| Prentice-Hall, Inc., 2002.
reference ||| [6] S. Haykin. Neural Networks, a Comprehensive
reference ||| Foundation. Macmillan, 1999.
reference ||| [7] S. Kaski and J. Sinkkonen. Metrics that learn
reference ||| relevance. In Proceedings of the International Joint
reference ||| Conference on Neural Networks, volume 5, pages
reference ||| 547–552, 2000.
reference ||| [8] T. Kohonen. Self-Organizing Maps. Springer-Verlag,
reference ||| Berlin, 1995.
reference ||| [9] J. Laiho, K. Raivio, P. Lehtim¨aki, K. H¨at¨onen, and
reference ||| O. Simula. Advanced analysis methods for 3G cellular
reference ||| networks. IEEE Transactions on Wireless
reference ||| Communications, 4(3):930–942, May 2005.
reference ||| [10] J. Laiho, A. Wacker, and T. Novosad, editors. Radio
reference ||| Network Planning and Optimisation for UMTS. John
reference ||| Wiley & Sons Ltd., 2001.
reference ||| [11] P. Lehtim¨aki and K. Raivio. A SOM based approach
reference ||| for visualization of GSM network performance data.
reference ||| In IEA/AIE, pages 588–598, 2005.
reference ||| [12] R. Prakash and V. Veeravalli. Locally optimal soft
reference ||| handoff algorithms. IEEE Transactions on Vehicular
reference ||| Technology, 52(2):347–356, March 2003.
reference ||| [13] K. Raivio, O. Simula, and J. Laiho. Neural analysis of
reference ||| mobile radio access network. In IEEE International
page ||| 336
reference ||| Conference on Data Mining, pages 457–464, San Jose,
reference ||| California, USA, November 29 - December 2 2001.
reference ||| [14] M. Siponen, J. Vesanto, O. Simula, and P. Vasara. An
reference ||| approach to automated interpretation of SOM. In
reference ||| N. Allinson, H. Yin, L. Allinson, and J. Slack, editors,
reference ||| Advances in Self-Organizing Maps, pages 89–94.
reference ||| Springer, 2001.
reference ||| [15] J. Vesanto and E. Alhoniemi. Clustering of the
reference ||| self-organizing map. IEEE Transactions on Neural
reference ||| Networks, 11(3):586–600, May 2000.
reference ||| [16] J. Zander. Radio Resource Management for Wireless
reference ||| Networks. Artech House, Inc., 2001.
page ||| 337

title ||| Automated Rich Presentation of a Semantic Topic
author ||| Lie Lu and Zhiwei Li
affiliation ||| Microsoft Research Asia
email ||| {llu, zli}@microsoft.com
sectionHeader ||| ABSTRACT
bodyText ||| To have a rich presentation of a topic, it is not only expected that
bodyText ||| many relevant multimodal information, including images, text,
bodyText ||| audio and video, could be extracted; it is also important to
bodyText ||| organize and summarize the related information, and provide
bodyText ||| users a concise and informative storyboard about the target topic.
bodyText ||| It facilitates users to quickly grasp and better understand the
bodyText ||| content of a topic. In this paper, we present a novel approach to
bodyText ||| automatically generating a rich presentation of a given semantic
bodyText ||| topic. In our proposed approach, the related multimodal informa-
bodyText ||| tion of a given topic is first extracted from available multimedia
bodyText ||| databases or websites. Since each topic usually contains multiple
bodyText ||| events, a text-based event clustering algorithm is then performed
bodyText ||| with a generative model. Other media information, such as the
bodyText ||| representative images, possibly available video clips and flashes
bodyText ||| (interactive animates), are associated with each related event. A
bodyText ||| storyboard of the target topic is thus generated by integrating each
bodyText ||| event and its corresponding multimodal information. Finally, to
bodyText ||| make the storyboard more expressive and attractive, an incidental
bodyText ||| music is chosen as background and is aligned with the storyboard.
bodyText ||| A user study indicates that the presented system works quite well
bodyText ||| on our testing examples.
sectionHeader ||| Categories and Subject Descriptors
category ||| H.5.3 [Information Interfaces and Presentation]: Group and
category ||| Organization Interfaces - Organizational design; H.3.1 [Informa-
category ||| tion Storage and Retrieval]: Content Analysis and Indexing -
category ||| abstracting methods.
sectionHeader ||| General Terms
keyword ||| Algorithms, Design, Management, Experimentation, Theory
sectionHeader ||| Keywords
keyword ||| Rich presentation, multimodality, multimedia authoring, story-
keyword ||| board, events clustering, multimedia fusion
sectionHeader ||| 1. INTRODUCTION
bodyText ||| In the multimedia field, a major objective of content analysis is to
bodyText ||| discover the high-level semantics and structures from the low-
bodyText ||| level features, and thus to facilitate indexing, browsing, searching,
bodyText ||| and managing the multimedia database. In recent years, a lot of
copyright ||| Permission to make digital or hard copies of all or part of this work for
copyright ||| personal or classroom use is granted without fee provided that copies are
copyright ||| not made or distributed for profit or commercial advantage and that
copyright ||| copies bear this notice and the full citation on the first page. To copy
copyright ||| otherwise, or republish, to post on servers or to redistribute to lists,
copyright ||| requires prior specific permission and/or a fee.
note ||| MM’05, November 6–11, 2005, Singapore.
copyright ||| Copyright 2005 ACM 1-59593-044-2/05/0011...$5.00.
bodyText ||| technologies have been developed for various media types,
bodyText ||| including images, video, audio and etc. For example, various
bodyText ||| approaches and systems have been proposed in image content
bodyText ||| analysis, such as semantic classification [1], content-based image
bodyText ||| retrieval [2] and photo album management [3]. There are also a lot
bodyText ||| of research focuses on video analysis, such as video segmentation
bodyText ||| [4], highlight detection [5], video summarization [6][7], and video
bodyText ||| structure analysis [8], applied in various data including news
bodyText ||| video, movie and sports video. Since audio information is very
bodyText ||| helpful for video analysis, many research works on audio are also
bodyText ||| developed to enhance multimedia analysis, such as audio
bodyText ||| classification [9], and audio effect detection in different audio
bodyText ||| streams [10]. Most recently, there are more and more approaches
bodyText ||| and systems integrating multimodal information in order to
bodyText ||| improve analysis performance [11][12].
bodyText ||| The main efforts of the above mentioned research have focused on
bodyText ||| understanding the semantics (including a topic, an event or the
bodyText ||| similarity) from the multimodal information. That is, after the
bodyText ||| multimedia data is given, we want to detect the semantics implied
bodyText ||| in these data. In this paper, we propose a new task, Rich
bodyText ||| Presentation, which is an inverse problem of the traditional
bodyText ||| multimedia content analysis. That is, if we have a semantic topic,
bodyText ||| how can we integrate its relevant multimodal information,
bodyText ||| including image, text, audio and video, to richly present the target
bodyText ||| topic and to provide users a concise and informative storyboard?
bodyText ||| In this paper, the so-called “semantic topic” is a generic concept.
bodyText ||| It could be any keyword representing an event or events, a
bodyText ||| person’s name, or anything else. For example, “World Cup 2002”
bodyText ||| and “US election” could be topics, as well as “Halloween” and
bodyText ||| “Harry Potter”. In this paper, our task is to find sufficient
bodyText ||| information on these topics, extract the key points, fuse the
bodyText ||| information from different modalities, and then generate an
bodyText ||| expressive storyboard.
bodyText ||| Rich presentation can be very helpful to facilitate quickly
bodyText ||| grasping and better understanding the corresponding topic.
bodyText ||| People usually search information from (multimedia) database or
bodyText ||| the Internet. However, what they get is usually a bulk of
bodyText ||| unorganized information, with many duplicates and noise. It is
bodyText ||| tedious and costs a long time to get what they want by browsing
bodyText ||| the search results. If there is a tool to help summarize and
bodyText ||| integrate the multimodal information, and then produce a concise
bodyText ||| and informative storyboard, it will enable users to quickly figure
bodyText ||| out the overview contents of a topic that they want to understand.
bodyText ||| Rich presentation provides such a tool, and thus it could have
bodyText ||| many potential applications, such as education and learning,
bodyText ||| multimedia authoring, multimedia retrieval, documentary movie
bodyText ||| production, and information personalization.
bodyText ||| In this paper, we will present the approach to rich presentation. In
bodyText ||| order to produce a concise and informative storyboard to richly
bodyText ||| present a target topic, we need to answer the following questions.
bodyText ||| 1) How to extract the relevant information regarding the target
page ||| 745
bodyText ||| topic? 2) How to extract the key points from the relevant
bodyText ||| information and build a concise and informative storyboard? 3)
bodyText ||| How to fuse all the information from different modality? and 4)
bodyText ||| how to design the corresponding rendering interface?
figure ||| A Target Topic
figure ||| Rich Presentation
figureCaption ||| Fig. 1 The system framework of rich presentation of a target
figureCaption ||| semantic topic. It is mainly composed of three steps, relevant
figureCaption ||| multimodal information extraction, media analysis, and rich
figureCaption ||| presentation generation.
bodyText ||| In this paper, we propose a number of novel approaches to deal
bodyText ||| with the above issues and also present an example system. Fig. 1
bodyText ||| illustrates the proposed system framework of rich presentation. It
bodyText ||| is mainly composed of three steps, relevant multimodal informa-
bodyText ||| tion extraction, media analysis including multiple events cluster-
bodyText ||| ing, representative media detection and music rhythm analysis;
bodyText ||| and the final storyboard generation and music synchronization.
bodyText ||| In the proposed system, given the semantic topic, the relevant
bodyText ||| information, including text, image, video and music, is first
bodyText ||| extracted from the available multimedia database or the web data-
bodyText ||| base. User interaction is also allowed to provide extra relevant
bodyText ||| material or give relevant feedback. Then, the information is
bodyText ||| summarized, with an event clustering algorithm, to give a concise
bodyText ||| representation of the topic and figure out the overview of the
bodyText ||| contents. Other multimedia materials, such as representative
bodyText ||| images (or image sequences) and geographic information, are
bodyText ||| subsequently associated with each event. In the next step, all the
bodyText ||| above information is integrated to generate a storyboard, in which
bodyText ||| each event is presented as one or multiple slides. An incidental
bodyText ||| music, which is also possibly relevant to the topic, is finally
bodyText ||| synchronized with the storyboard to improve its expressiveness
bodyText ||| and attractiveness. Thus, with these steps, a concise and
bodyText ||| informative rich presentation regarding the target topic is gener-
bodyText ||| ated.
bodyText ||| The rest of the paper is organized as follows. Section 2 discusses
bodyText ||| the relevant information extraction corresponding to the target
bodyText ||| topic. Section 3 presents our approach to the topic representation,
bodyText ||| including multiple events clustering, event description, and
bodyText ||| representative media selection. Section 4 describes the approach
bodyText ||| to rich presentation generation, including storyboard generation,
bodyText ||| incidental music analysis and synchronization. Experiments and
bodyText ||| evaluations are presented in the Section 5. Conclusions are given
bodyText ||| in the Section 6.
sectionHeader ||| 2. OBTAINING RELEVANT INFORMATION
bodyText ||| To obtain the multimodal information which is relevant to the
bodyText ||| input topic (keyword), generally, we could search them from
bodyText ||| various databases which have been indexed with the “state-of-the-
bodyText ||| art” multimedia analysis techniques. However, in current stage,
bodyText ||| there is lack of such publicly available multimedia databases. The
bodyText ||| public search engine like MSN or Google indexes all the Internet
bodyText ||| web-pages and can return a lot of relevant information, but the
bodyText ||| search results usually contain much noise. We could also build a
bodyText ||| private database for this system to provide more relevant and
bodyText ||| clean results, but it will be too much expensive to collect and
bodyText ||| annotate sufficient multimedia data for various topics. In order to
bodyText ||| obtain relatively accurate and sufficient data for an arbitrary topic,
bodyText ||| in our system, we chose to collect the relevant multimodal
bodyText ||| information of the given topic from the news websites such as
bodyText ||| MSNBC, BBC and CNN, instead of building an available
bodyText ||| database from the scratch. These news websites are usually well
bodyText ||| organized and managed; and contain various kinds of high quality
bodyText ||| information including text, image and news video clips. Although
bodyText ||| the news websites are used as the information sources in our
bodyText ||| system, other various multimedia databases can be also easily
bodyText ||| incorporated into the system if they are available.
bodyText ||| Instead of directly submitting the topic as a query and getting the
bodyText ||| returned results by using the search function provided by the
bodyText ||| websites, in our system, we crawled the news documents from
bodyText ||| these websites in advance and then build a full-text index. It
bodyText ||| enables us to quickly obtain the relevant documents, and also en-
bodyText ||| able us to use some traditional information retrieval technologies,
bodyText ||| such as query expansion [13], to remove the query ambiguousness
bodyText ||| and get more relevant documents.
bodyText ||| In our approach, user interaction is also allowed to provide more
bodyText ||| materials relevant to the topic, or give relevant feedback on the
bodyText ||| returned results. For example, from the above websites, we can
bodyText ||| seldom find a music clip relevant to the target topic. In this case,
bodyText ||| users could provide the system a preferred music, which will be
bodyText ||| further used as incidental music to accompany with the storyboard
bodyText ||| presentation. Users could also give some feedbacks on the
bodyText ||| obtained documents. For example, if he gives a thumb-up to a
bodyText ||| document, the relevant information of the document needs to be
bodyText ||| presented in the final storyboard. On the other side, users could
bodyText ||| also thumb-down a document to remove the related information.
sectionHeader ||| 3. TOPIC REPRESENTATION
bodyText ||| A semantic topic is usually a quite broad concept and it usually
bodyText ||| contains multiple events. For example, in the topic “Harry Potter”,
bodyText ||| the publication of each book and the release of each movie could
bodyText ||| be considered as an event; while in the topic “World Cup 2002”,
bodyText ||| each match could also be taken as an event. For each event, there
bodyText ||| are usually many documents reporting it. Therefore, in order to
bodyText ||| generate an informative and expressive storyboard to present the
bodyText ||| topic, it would be better to decompose the obtained information
bodyText ||| and cluster the documents into different events.
bodyText ||| However, event definition is usually subjective, different
bodyText ||| individuals may have different opinions. It is also confusing in
bodyText ||| which scale an event should be defined. Also take “World Cup”
bodyText ||| as an example, in a larger scale, “World Cup 2002” and “World
bodyText ||| Cup 2006” could also be considered as a big event. Therefore,
bodyText ||| due to the above vagueness, in this paper, we do not strictly define
figure ||| Relevant multimodal information Retrieval
figure ||| User
figure ||| Interaction
figure ||| Music
figure ||| Text
figure ||| Relevant Media
figure ||| Rhythm Analysis
figure ||| •	Onset/Beat Sequence
figure ||| •	Strength confidence
figure ||| Multiple Events Clustering
figure ||| •	Event summary (4w + time)
figure ||| •	Geographic information
figure ||| Media Association
figure ||| •	Representative images
figure ||| •	Relevant video clips
figure ||| Storyboard Generation
figure ||| Event presentation, multimodal information fusion, layout design
figure ||| Storyboard
figure ||| Music and storyboard synchronization
page ||| 746
bodyText ||| each event of the target topic. Following our previous works on
bodyText ||| news event detection [14], an event is assumed as some similar
bodyText ||| information describing similar persons, similar keywords, similar
bodyText ||| places, and similar time duration. Therefore, in our system, an
bodyText ||| event is represented by four primary elements: who (persons),
bodyText ||| when (time), where (locations) and what (keywords); and event
bodyText ||| clustering is to group the documents reporting similar primary
bodyText ||| elements. As for the scale of event, in the paper, it could be
bodyText ||| adaptively determined by the time range of the obtained
bodyText ||| documents or the required event number.
bodyText ||| In this section, we present a novel clustering approach based on a
bodyText ||| generative model proposed in [14], instead of using traditional
bodyText ||| clustering methods such as K-means. After event clusters are
bodyText ||| obtained, the corresponding event summary is then extracted and
bodyText ||| other representative media is associated with each event.
subsectionHeader ||| 3.1 Multiple Event Clustering
bodyText ||| To group the documents into different events, essentially, we need
bodyText ||| to calculate p(ej I xi), which represents the probability that a docu-
bodyText ||| ment xi belongs to an event ej. Here, as mentioned above, an
bodyText ||| event ej (and thus the document xi describing the event) is
bodyText ||| represented by four primary elements: who (persons), when (time),
bodyText ||| where (locations) and what (keywords). That is,
equation ||| Event / Docment = {persons, locations, keywords, time}
bodyText ||| Assuming that a document is always caused by an event [14] and
bodyText ||| the four primary elements are independent, to calculate the
bodyText ||| probability p(ej I xi), in our approach, we first determine the likeli-
bodyText ||| hood that the document xi is generated from event ej, p(xi I ej)
bodyText ||| which could be further represented by the following generative
bodyText ||| model,
equation ||| p(xi | ej) =p(namei | ej)p(loci | ej)p(keyi | ej)p(timei | ej) (1)
bodyText ||| where namei, loci, keyi, and timei are the feature vectors
bodyText ||| representing persons, locations, keywords and time in the
bodyText ||| document xi, respectively. In our approach, the above entities are
bodyText ||| extracted by the BBN NLP tools [15]. The tool can extract seven
bodyText ||| types of entities, including persons, organizations, locations, date,
bodyText ||| time, money and percent. In our approach, the obtained organiza-
bodyText ||| tion entity is also considered as a person entity; and all the words
bodyText ||| except of persons, locations, and other stop-words are taken as
bodyText ||| keywords.
bodyText ||| In more detail, namei (similarly, loci and keyi) is a vector <ci1,
bodyText ||| ci2, ..., ciNp>, where cin is the occurrence frequency of the personn
bodyText ||| appears in the document xi, and personn is the nth person in the
bodyText ||| person vocabulary, which is composed of all the persons appeared
bodyText ||| in all the obtained documents (similarly, we can define keyword
bodyText ||| vocabulary and location vocabulary). Assuming Np is the size of
bodyText ||| person vocabulary, p(nameiI ej) could be further expressed by
equation ||| Np(namei | ej) = n p(personn | ej )cin (2)
equation ||| n=1
bodyText ||| Since the person, location and keyword are discrete variables
bodyText ||| represented by words, and the probability of the location and
bodyText ||| keyword can be also defined similarly as that of the person in (2),
bodyText ||| in the flowing sections, we will not discriminate them and
bodyText ||| uniformly represent the probability p(personn | ej) (correspond-
bodyText ||| ingly, the p(locationn | ej) and p(keywordn | ej)) as p(wn | ej), which
bodyText ||| denotes the probability that the word wn appears in the event ej
bodyText ||| On the other hand, the time of an event usually lasts a continuous
bodyText ||| duration. It is also observed, especially in the news domain, that
bodyText ||| the documents about an event usually increases at the beginning
bodyText ||| stage of the event and then decreases at the end. Therefore, in
bodyText ||| our approach, a Gaussian model N(uj, aj) is utilized to roughly
bodyText ||| represent the probability p(timei | ej), where uj and aj is the mean
bodyText ||| and standard deviation, respectively.
bodyText ||| To this end, in order to estimate the probability p(ej I xi), we need
bodyText ||| to estimate the parameters 6 = {p(wn | ej), uj, σj, 1!�j5K}, assuming
bodyText ||| K is the number of events (the selection of K is discussed in
bodyText ||| section 3.2). In our approach, the Maximum Likelihood is used to
bodyText ||| estimate the model parameters, as,
equation ||| θ* = argmaxθ log(p(X |θ)) =
equation ||| M	K
equation ||| =argmax θ ∑ log(∑ p(ej)p(xi | ej
equation ||| ia	j=1
equation ||| where X represents the corpus of the obtained documents; M and
equation ||| K are number of documents and events, respectively.
bodyText ||| Since it is difficult to derive a close formula to estimate the
bodyText ||| parameters, in our approach, an Expectation Maximization (EM)
bodyText ||| algorithm is applied to maximize the likelihood, by running E-step
bodyText ||| and M-step iteratively. A brief summary of these two steps is
bodyText ||| listed as follows, and more details can be found in [14].
listItem ||| •	In E-step, the posterior probability p(ej | xi) is estimated as:
equation ||| p(ej | xi)(t+1) =  p(xi | ej)(t)p(ej)(t)	(4)
equation ||| p( xi
equation ||| where the upper script (t) indicate the tth iteration.
listItem ||| •	In M-step, the model parameters are updated, as,
bodyText ||| where tf(i,n) is the term frequency of the word wn in the
bodyText ||| document xi and N is the corresponding vocabulary size. It
bodyText ||| is noted that, in (5), the Laplace smoothing [ 16] is applied to
bodyText ||| prevent zero probability for the infrequently occurring word.
bodyText ||| At last, the prior of each event is updated as:
equation ||| M
equation ||| ∑p (
equation ||| p(ej)(t+1) = i=1(8)
equation ||| M
bodyText ||| arg
bodyText ||| The algorithm can increase the log-likelihood consistently with
bodyText ||| the iterations; and then converge to a local maximum. Once the
bodyText ||| parameters are estimated, we can simply assign each document to
bodyText ||| an event, as following
equation ||| yi =argmaxj(p(ej |xi))	(9)
equation ||| where yi is the event label of the document xi.
equation ||| i=1
equation ||| M
equation ||| t+1)
equation ||| (
equation ||| (
equation ||| )
equation ||| (t
equation ||| u
equation ||| i=1
equation ||| ej
equation ||| +1)
equation ||| | xi
equation ||| (6)
equation ||| ∑p
equation ||| timei
equation ||| tf (i, n)
equation ||| p(wn | ej)(t+1) = 	Mi=1jN	(5)
equation ||| i=1	s=1
equation ||| 1+N+∑(p(e
equation |||  I x)	'
equation ||| ∑s))
equation ||| tf 0
equation ||| ,
equation ||| M
equation ||| uj
equation ||| σ2(t+1) =  i=1 	/7)
equation ||| j	M
equation ||| l
equation ||| (
equation ||| ∑p
equation ||| )
equation ||| |xi
equation ||| i
equation ||| ej
equation ||| =1
equation ||| ∑ p(ej | xi)(t+1) ⋅ (timei −
equation ||| t+1) 2
equation ||| )
equation ||| (
equation ||| t+1)
equation ||| M
equation ||| |θ))
equation ||| maxθ log(∏ p(xi
equation ||| (3)
equation ||| ,θ))
equation ||| ej
equation ||| | xi
equation ||| ) (t+1)
page ||| 747
bodyText ||| The advantage of this generative approach is that it not only
bodyText ||| considers the temporal continuity of an event, it also can deal with
bodyText ||| the issue that some events overlap in some time durations. In this
bodyText ||| case, the Gaussian model of the event time can also be overlapped
bodyText ||| through this data-driven parameter estimation. From this view,
bodyText ||| the event clustering is also like a Gaussian mixture model (GMM)
bodyText ||| estimation in the timeline.
subsectionHeader ||| 3.2 Determining the Number of Events
bodyText ||| In the above approach to event clustering, the event number K is
bodyText ||| assumed known (as shown in (3)-(8)). However, the event number
bodyText ||| is usually very difficult to be determined a priori. In our approach,
bodyText ||| an intuitive way is adopted to roughly estimate the event number
bodyText ||| based on the document distribution along with the timeline.
bodyText ||| As mentioned above, it is assumed that each document is caused
bodyText ||| by an event, and the document number of an event changes with
bodyText ||| the development of the event. According to this property, each
bodyText ||| peak (or the corresponding contour) of the document distribution
bodyText ||| curve might indicate one event [14], as the Fig. 2 shows. Thus, we
bodyText ||| can roughly estimate the event number by simply counting the
bodyText ||| peak number. However, the curve is quite noisy and there
bodyText ||| inevitably exist some noisy peaks in the curve. In order to avoid
bodyText ||| the noisy peaks, in our approach, only the salient peaks are
bodyText ||| assumed to be relevant to the event number.
bodyText ||| To detect the salient peaks, we first smooth the document curve
bodyText ||| with a half-Hamming (raised-cosine) window, and then remove
bodyText ||| the very small peaks with a threshold. Fig.2 illustrates a
bodyText ||| smoothed document distribution with the corresponding threshold,
bodyText ||| collected on the topic “US Election” in four months. In
bodyText ||| experiments, the threshold is adaptively set as Yd-σd/2, where Yd
bodyText ||| and ad are the mean and standard deviation of the curve,
bodyText ||| respectively.
bodyText ||| After the smoothing and tiny peaks removal, we further detect the
bodyText ||| valleys between every two contingent peaks. Thus, the range of
bodyText ||| an event (which is correlated to the corresponding peak) can be
bodyText ||| considered as the envelope in the two valleys. As shown in Fig2,
bodyText ||| the duration denoted by Li+Ri is a rough range of the event
bodyText ||| correlated to the peak Pi. Assuming an important event usually
bodyText ||| has more documents and has effects in a longer duration, the
bodyText ||| saliency of each peak is defined as,
equation ||| Si =( P )(Li +Ri) (10)
equation ||| Pavr Davr
bodyText ||| where Pi is the ith peak, Li and Ri is the duration from the ith peak
bodyText ||| to the previous and next valley; Pavr is the average peak value and
bodyText ||| Davr is average duration between two valleys in the curve. Si is the
bodyText ||| saliency value of the peak Pi. It could also be considered as the
bodyText ||| normalized area under peak Pi, and thus, it roughly represents the
bodyText ||| document number of the corresponding event.
bodyText ||| In our approach, the top K salient peaks are selected to determine
bodyText ||| the event number:
equation ||| K=argmaxk{∑;1Si/∑N1S ≤η}	(11)
equation ||| where S; is the sorted saliency value from large to small, N is
bodyText ||| total number of detected peaks and ii is a threshold. In our
bodyText ||| experiments, ii is set as 0.9, which roughly means that at least
bodyText ||| 90% documents will be kept in the further initialization of event
bodyText ||| clustering. This selection scheme is designed to guarantee there is
bodyText ||| no important information is missed in presentation. After the
bodyText ||| event number and initial clusters (the most salient peaks with their
bodyText ||| corresponding range) are selected, the event parameters could be
bodyText ||| initialized and then updated iteratively.
figure ||| 0 20 40 60 80 100 120
figureCaption ||| Fig.2 Peak saliency definition. It also illustrates the smoothed
figureCaption ||| document distribution (document number per day) with the
figureCaption ||| corresponding threshold for tiny peak removal. Each peak Pi is
figureCaption ||| assumed to be correlated with each event.
bodyText ||| It is noted that some technology such as Bayesian Information
bodyText ||| Criteria (BIC) or minimum description length (MDL) [17] could
bodyText ||| be used to estimate the optimal event number, by searching
bodyText ||| through a reasonable range of the event number to find the one
bodyText ||| which maximizes the likelihood in (3). However, these algo-
bodyText ||| rithms take long time, and it is usually not necessary to estimate
bodyText ||| the exact event number in our scenario of rich presentation.
bodyText ||| Actually, in our system, the most important point of event cluster-
bodyText ||| ing is that the clustered documents ‘really’ represent the same
bodyText ||| event, rather than the event number, as observed in the experi-
bodyText ||| ments. Moreover, in the step of synchronization between the
bodyText ||| music and storyboard (in the section 4.2), the number of presented
bodyText ||| events may be further refined, based on the user’s preference, in
bodyText ||| order to match the presentation duration with the music duration.
subsectionHeader ||| 3.3 Event Description
bodyText ||| After obtaining the events and the corresponding documents, we
bodyText ||| not only need a concise event summary, but also need to extract
bodyText ||| some representative media to describe each event.
subsubsectionHeader ||| 3.3.1 Event Summary
bodyText ||| A simple way to summarize an event is to choose some
bodyText ||| representative words on the persons, locations and keywords of
bodyText ||| the event. For example, for the event ej, the ‘leading actor’ could
bodyText ||| be chosen as the person with the maximum p(personn | ej), while
bodyText ||| the major location could be selected based on p(locationn | ej).
bodyText ||| However, such brief description might have a bad readability.
bodyText ||| Therefore, in order to increase the readability of the summary, in
bodyText ||| our system, we also provide an alterative way. That is, we choose
bodyText ||| a candidate document to represent an event. For example, the
bodyText ||| document with the highest p(xi| ej) is a good candidate represen-
bodyText ||| tative of the event ej. However, a document might be too long to
bodyText ||| be shown on the storyboard. Therefore, in our system, only the
bodyText ||| “title-brow” (the text between the news title and news body) of
bodyText ||| the document, which usually exists and is usually a good
bodyText ||| overview (summary) of the document based on our observation
bodyText ||| (especially true in our case of news document), is selected to
bodyText ||| describe the event.
figure ||| 20
figure ||| 15
figure ||| 10
figure ||| 5
figure ||| 0
figure ||| Peaks relevant to event
figure ||| P;-1	P;+1
figure ||| L;	R;
figure ||| P;
figure ||| #Doc
figure ||| Threshold
figure ||| '
figure ||| 748
figure ||| IV
figure ||| I
figure ||| III
figure ||| II
figureCaption ||| Fig. 3 The event template of the Storyboard, which illustrates (I) the representative media, (II)geographic information, (III) event summary,
figureCaption ||| and (IV) a film strip giving an overview of the events in the temporal order.
subsectionHeader ||| 3.3.2 Extracting Representative Media
bodyText ||| In the obtained documents describing an event, there are usually
bodyText ||| many illustrational images, with possible flashes and video clips.
bodyText ||| These media information is also a good representative of the
bodyText ||| corresponding event. However, since the obtained documents are
bodyText ||| directly crawled from the news websites, they usually contain
bodyText ||| many noisy multimedia resources, such as the advertisements.
bodyText ||| Moreover, there also possible exist some duplicate images in
bodyText ||| different documents describing the same event. Therefore, to
bodyText ||| extract the representative media from the documents, we need to
bodyText ||| remove noisy media and possible duplicate images. Before this,
bodyText ||| we also performed a pre-filtering to remove all the images smaller
bodyText ||| than 50 pixels in height or width.
listItem ||| •	Noisy Media Detection. In our approach, a simple but
listItem ||| efficient rule is used to remove the noisy media resources.
listItem ||| We find almost all advertisements are provided by other
listItem ||| agencies rather than these news websites themselves. That is,
listItem ||| the hosts of advertisement resources are from different
listItem ||| websites. Thus, in our approach, we extract the host names
listItem ||| from the URLs of all multimedia resources, and remove
listItem ||| those resources with different host name.
listItem ||| •	Duplicate Detection. A number of image signature schemes
bodyText ||| can be adopted here to accomplish duplicate detection. In
bodyText ||| our implementation, each image is converted into grayscale,
bodyText ||| and down-sampled to 8 × 8. That is, a 64-byte signature for
bodyText ||| each image is obtained. Then the Euclidean distance of the
bodyText ||| 64-byte signature are taken as the dissimilarity measure.
bodyText ||| Images have sufficiently small distance are considered as
bodyText ||| duplicates.
bodyText ||| Once removing the noisy resources and duplicate images, we
bodyText ||| simply select the 1-4 large images from the top representative
bodyText ||| documents (with the top largest p(xi|ej)), and take them as
bodyText ||| representative media of the corresponding event. The exact
bodyText ||| number of the selected images is dependent on the document
bodyText ||| number (i.e., the importance) of the event and the total image
bodyText ||| number the event has. It is noted that, in our current system, we
bodyText ||| only associates images with each event. However, other media
bodyText ||| like video and flashes can be chosen in a similar way.
sectionHeader ||| 4. RICH PRESENTATION GENERATION
bodyText ||| In the proposed system, the above obtained information, including
bodyText ||| event summary and representative media, are fused to generate a
bodyText ||| concise and informative storyboard, in order to richly present the
bodyText ||| target topic. In this section, we will first describe the storyboard
bodyText ||| generation for the target topic, by presenting each event with the
bodyText ||| multimodal information. Then, we present the approach to
bodyText ||| synchronizing the storyboard with an incidental music.
subsectionHeader ||| 4.1 Storyboard Generation
bodyText ||| In our approach, a storyboard of a target topic is generated by
bodyText ||| presenting each event of the topic slide by slide. To describe an
bodyText ||| event, we have obtained the corresponding information including
bodyText ||| the person, time, location, event summary and other relevant
bodyText ||| images. Therefore, to informatively present each event, we need
bodyText ||| first to design an event template (i.e., an interface) to integrate all
bodyText ||| the information.
bodyText ||| Fig. 3 illustrates the event template used in our proposed system,
bodyText ||| with an example event in the topic ‘US Election”. First, the
bodyText ||| template presents the representative images in the largest area
bodyText ||| (part I), since the pictures are more vivid than the words. As for
bodyText ||| each representative picture, the title and date of the document from
bodyText ||| which it is extracted is also illustrated. In the Fig.3, there are 4
bodyText ||| pictures extracted from 3 documents. Then, the corresponding
bodyText ||| event summaries of these three documents are presented (part III),
bodyText ||| where each paragraph refers to the summary of one document. If a
bodyText ||| user is interested in one document, he can click on the correspond-
bodyText ||| ing title to read more details. Moreover, the geographic informa-
bodyText ||| tion of the event is shown with a map in the top-left corner (part
bodyText ||| II), to give users a view of the event location. The map is obtained
bodyText ||| from “MapPoint Location” service [18], which can return a
page ||| 749
bodyText ||| corresponding map based on user’s location query. However, the
bodyText ||| mapping is usually difficult, especially when the event location is
bodyText ||| confusing so that the representative location is not accurately
bodyText ||| detected. For example, the event shown in the Fig 1 is mapped to
bodyText ||| Washington D.C. rather than New York where the republic
bodyText ||| convention is held, since Washington is the most frequently
bodyText ||| mentioned places in the documents. Finally, a film strip (part IV)
bodyText ||| is also presented, arranging each event in the temporal order,
bodyText ||| where each event is simply represented by a cluster of images,
bodyText ||| with the current event highlighted. It enables users to have a quick
bodyText ||| overview of the past and the future in the event sequence.
bodyText ||| By connecting various events slide by slide, we could get an
bodyText ||| informative storyboard regarding the target topic. In order to
bodyText ||| catch the development process of a topic, the events are ordered
bodyText ||| by their timestamps in the generated storyboard.
subsectionHeader ||| 4.2 Synchronizing with Music
bodyText ||| To make the storyboard more expressive and attractive, and to
bodyText ||| provide a more relaxing way to read information, in the proposed
bodyText ||| system, we will accompany the storyboard with an incidental
bodyText ||| music and align the transitions between event slides with the
bodyText ||| music beats, following the idea in music video generation [19][20].
bodyText ||| Sometimes, music could also provide extra information about the
bodyText ||| target topic. For example, when the target topic is a movie, the
bodyText ||| corresponding theme song could be chosen for the rich presenta-
bodyText ||| tion. In this sub-section, we will present our approach to music
bodyText ||| analysis and synchronization with the storyboard.
subsubsectionHeader ||| 4.2.1 Music Rhythm Analysis
bodyText ||| In the proposed system, we detect the onset sequences instead of
bodyText ||| the exact beat series to represent music rhythm. This is because
bodyText ||| the beat information is sometimes not obvious, especially in light
bodyText ||| music which is usually selected as incidental music. The strongest
bodyText ||| onset in a time window could be assumed as a “beat”. This is
bodyText ||| reasonable since there are some beat positions in a time window
bodyText ||| (for example, 5 seconds); thus, the most possible position of a beat
bodyText ||| is the position of the strongest onset.
bodyText ||| The process of onset estimation is illustrated in Fig. 4. After FFT
bodyText ||| is performed on each frame of 16ms-length, an octave-scale filter-
bodyText ||| bank is used to divide the frequency domain into six sub-bands,
bodyText ||| including [0, co0 /26), [co0 /26, co0 /25), ..., [co0 /22, co0 /2], where co0
bodyText ||| refers to the sampling rate.
figure ||| Onset Curve
figureCaption ||| Fig. 4 The process of onset sequence estimation
bodyText ||| After the amplitude envelope of each sub-band is extracted by
bodyText ||| using a half-Hamming window, a Canny operator is used for onset
bodyText ||| sequence detection by estimating its difference function,
equation ||| Di (n) = Ai (n) ⊗ C(n) (12)
bodyText ||| where Di(n) is the difference function in the ith sub-band, Ai(n) is
bodyText ||| the amplitude envelope of the ith sub-band, and C(n) is the Canny
bodyText ||| operator with a Gaussian kernel,
equation ||| C(n) = i e .2/2σ2 n∈
equation ||| σ 2 c c
bodyText ||| where Lc is the length of the Canny operator and a is used to
bodyText ||| control the operator’s shape, which are set as 12 and 4 in our
bodyText ||| implementation, respectively.
bodyText ||| Finally, the sum of the difference curves of these six sub-bands is
bodyText ||| used to extract onset sequence. Each peak is considered as an
bodyText ||| onset, and the peak value is considered as the onset strength.
bodyText ||| Based on the obtained onsets, an incidental music is further
bodyText ||| segmented into music sub-clips, where a strong onset is taken as
bodyText ||| the boundary of a music sub-clip. These music sub-clips are then
bodyText ||| used as the basic timeline for the synchronization in the next step.
bodyText ||| Thus, to satisfy the requirement that the event slide transitions of
bodyText ||| the storyboard should occur at the music beats, we just need to
bodyText ||| align the event slide boundaries and music sub-clip boundaries.
bodyText ||| To give a more pleasant perception, the music sub-clip should not
bodyText ||| be too short or too long, also it had better not always keep the
bodyText ||| same length. In our implementation, the length of music sub-clips
bodyText ||| is randomly selected in a range of [tmin, tmax] seconds. Thus, the
bodyText ||| music sub-clips can be extracted in the following way: given the
bodyText ||| previous boundary, the next boundary is selected as the strongest
bodyText ||| onset in the window which is [tmin, tmax] seconds away from the
bodyText ||| previous boundary. In the proposed system, users can manually
bodyText ||| specify the range of the length of the music sub-clip. The default
bodyText ||| range in the system is set as [12, 18] seconds, in order to let users
bodyText ||| have enough time to read all the information on each event slide.
subsubsectionHeader ||| 4.2.2 Alignment Scheme
bodyText ||| To synchronize the transitions between different event slides and
bodyText ||| the beats of the incidental music, as mentioned above, we actually
bodyText ||| need to align the slide boundaries and music sub-clip boundaries.
bodyText ||| To satisfy this requirement, a straightforward way is to set the
bodyText ||| length of each event slide be equal to the corresponding length of
bodyText ||| the sub-music clip.
bodyText ||| However, as Fig. 5 illustrates, the number of event slides is
bodyText ||| usually not equal to the number of music sub-clip. In this case, in
bodyText ||| our proposed system, we provide two schemes to solve this
bodyText ||| problem.
listItem ||| 1) Music Sub-clip Based. In this scheme, only the top N important
listItem ||| events of the target topic are adaptively chosen and used in the
listItem ||| rich presentation, where N is supposed as the number of music
listItem ||| sub-clip in the corresponding incidental music, as the Fig.5 shows.
listItem ||| Although a formal definition of event importance is usually hard
listItem ||| and subjective, in our approach, the importance score of an event
listItem ||| is simply measured by the number of documents reporting it,
listItem ||| assuming that the more important the event, the more the
listItem ||| corresponding documents. The assumption is quite similar as that
listItem ||| in the definition of (10).
figure ||| Acoustic Music Data
figure ||| FFT
figure ||| Difference curve
figure ||| Sub-Band 1
figure ||| Envelope
figure ||| Extractor
figure ||| ...	...	...
figure ||| .
figure ||| .
figure ||| .
figure ||| .
figure ||| .
figure ||| .
figure ||| Difference curve
figure ||| Sub-Band N
figure ||| Envelope
figure ||| Extractor
figure ||| ]
figure ||| (13)
page ||| 750
listItem ||| 2) Specified Event Number Based. In this scheme, users can
listItem ||| specify the number of the event he wants to learn. For example, a
listItem ||| user could choose to show the top 30 important events or all the
listItem ||| events. Thus, to accommodate all the events in the music duration,
listItem ||| we will repeat the incidental music if it is needed and then fade out
listItem ||| the music at the end.
bodyText ||| Fig. 5 Music and storyboard synchronization: a music sub-slip
bodyText ||| based scheme, that is, only the top important events are presented
bodyText ||| to match the number of music sub-clips.
subsubsectionHeader ||| 4.2.3 Rendering
bodyText ||| After the alignment between storyboard and incidental music, in
bodyText ||| our system, fifteen common transition effects, such as cross-fade,
bodyText ||| wipe and dissolve, are also randomly selected to connect the event
bodyText ||| slides, producing a better rich presentation in final rendering.
sectionHeader ||| 5. EVALUATIONS
bodyText ||| In this section, we evaluate the performance of the proposed
bodyText ||| approach to rich presentation and its key component, event
bodyText ||| clustering. In the experiments, we randomly select 8 topics of
bodyText ||| different types, including Earthquake, Halloween, Air Disaster,
bodyText ||| US Election, Nobel Prize, Britney Spears, David Beckham, and
bodyText ||| Harry Potter, from some hot news topics in the end of 2004 and
bodyText ||| beginning of 2005. Once the topic is selected, the topic name is
bodyText ||| used as a query and the relevant documents are collected from
bodyText ||| CNN, MSNBC and BBC. More details about the selected topics
bodyText ||| and the corresponding documents are shown in the Table 1, which
bodyText ||| lists the topic name, the time range of the collected documents,
bodyText ||| and the number of documents and its corresponding events.
tableCaption ||| Table 1. A list of testing topics in the rich presentation evaluations
table ||| No.	Topic	Time	#doc	#event
table ||| 1	Earthquake	1995-2004	976	17
table ||| 2	Halloween	1995-2004	762	9
table ||| 3	Air Disaster	1995-2004	210	13
table ||| 4	US Election	1995-2004	2486	—
table ||| 5	Britney Spears	2000-2004	1311	—
table ||| 6	Nobel Prize	1995-2004	186	—
table ||| 7	David Beckham	1995-2004	877	—
table ||| 8	Harry Potter	2000-2004	841	—
table ||| Total	——	——	7649	—
bodyText ||| It is noted that, in the table, only 3 topics have labeled events,
bodyText ||| while another 5 topics have not. This is because that, the labeling
bodyText ||| work of a topic is very subjective and usually hard for individuals
bodyText ||| to manually decide the event number of a given topic. Therefore,
bodyText ||| we only label the topics which are easily to be annotated based on
bodyText ||| the criterion in Topic Detection and Tracking (TDT) project [21].
bodyText ||| For example, Halloween is a topic which is reported once a year,
bodyText ||| thus, each year's documents can be regarded as an event; as for
bodyText ||| Earthquake and Air Disaster, their events lists could be found
bodyText ||| from corresponding official websites. In the annotation, we
bodyText ||| remove the events which do not have or have few (less than 4)
bodyText ||| relevant documents, and also remove the documents not belonging
bodyText ||| to any events.
bodyText ||| After parsing the obtained documents, for each topic, we usually
bodyText ||| can obtain 3.8 images per document in average. With further
bodyText ||| duplicate detection, only 1.6 images per document are remained.
bodyText ||| Moreover, from each document, we could also obtain about 3.0
bodyText ||| unique location entities and 2.8 unique name entities. Other words
bodyText ||| except of these entities are taken as keywords. Fig.6 shows a real
bodyText ||| representation of an example document with extracted entities in
bodyText ||| the XML format, from which the event clustering is performed.
figure ||| <URL>http://news.bbc.co.uk/1/hi/world/americas/4071845.stm </URL>
figure ||| <Abstract>The US battleground state of Ohio has certified the victory
figure ||| of President George W Bush's in last month's poll. </Abstract>
figure ||| <Date> 2004/12/6 </Date>
figure ||| <NLPRESULT>
figure ||| <LOCATION>
figure ||| <entity> Ohio </entity> <freq>4</freq>
figure ||| <entity> US </entity> <freq> 2 </freq>
figure ||| </LOCATION>
figure ||| <PERSON>
figure ||| <entity> Bush </entity> <freq> 3 </freq>
figure ||| <entity>David Cobb</entity> <freq>1</freq>
figure ||| ...
figure ||| </PERSON>
figure ||| ...
figure ||| <DATE>
figure ||| <entity> 6 December, 200</entity> <freq> 1 </freq>
figure ||| <entity> Friday </entity> <freq> 2 </freq>
figure ||| ...
figure ||| </DATE>
figure ||| <KEYWORDS>
figure ||| ...
figure ||| <entity> recount </entity> <freq>7</freq>
figure ||| <entity> elect </entity> <freq>3</freq>
figure ||| <entity> America </entity> <freq>3</freq>
figure ||| <entity> poll </entity> <freq>3</freq>
figure ||| ...
figure ||| </KEYWORDS>
figure ||| </NLPRESULT>
figureCaption ||| Fig. 6. XML representation of a document on “US Election” with
figureCaption ||| extracted entities
subsectionHeader ||| 5.1 Event Clustering
bodyText ||| As mentioned above, the evaluation of the approach to event
bodyText ||| clustering is evaluated on three topics, including Earthquake, Hal-
bodyText ||| loween, and Air Disaster, for which the corresponding event num-
bodyText ||| bers are determined and the documents are labeled using a similar
bodyText ||| method in the TDT project. However, in the proposed appraoch,
bodyText ||| we actually do not estimate the optimal event number, but use a
bodyText ||| much larger one. Therefore, in order to better evaluate the
bodyText ||| performance of the event clustering algorithm and compare with
bodyText ||| its counterpart, we use the event number in the ground truth to
bodyText ||| initialize the cluster number in the proposed clustering algorithm.
figure ||| Event
figure ||| Slide List
figure ||| Music
figure ||| Sub-Clip
figure ||| E1
figure ||| S1
figure ||| E2
figure ||| S2
figure ||| E3
figure ||| S3
figure ||| E4
figure ||| S4
figure ||| E5
figure ||| S5
figure ||| E6
figure ||| E7
figure ||| E8
page ||| 751
bodyText ||| In the experiments, K-means, which is another frequently used
bodyText ||| clustering algorithm (as well in TDT [22]), is adopted to compare
bodyText ||| with the proposed approach. The comparison results of two
bodyText ||| clustering approaches are illustrated in Table 2, with precision and
bodyText ||| recall for each topic.
tableCaption ||| Table 2. The performance comparison between our approach and
tableCaption ||| K-means on the event clustering
table ||| 	Precision		Recall
table ||| 	K-means	Ours	K-means	Ours
table ||| Earthquake	0.74	0.87	0.63	0.74
table ||| Halloween	0.88	0.93	0.72	0.81
table ||| Air Disaster	0.57	0.68	0.55	0.61
table ||| Average	0.73	0.83	0.63	0.72
bodyText ||| From Table 2, it can be seen that the results of our approach are
bodyText ||| significantly better than those of K-means, both on precision and
bodyText ||| recall. On the three testing topics, the average precision of our
bodyText ||| approach is up to 0.83 and the average recall achieves 0.72, which
bodyText ||| is 10% and 9% higher than those of K-means, respectively. By
bodyText ||| tracing the process of K-means, we find that K-means usually
bodyText ||| assigns documents far away from each other on the timeline into
bodyText ||| the same cluster, since the time information affects little in K-
bodyText ||| means. It also indicates the advantages of our approach with time
bodyText ||| modeling.
bodyText ||| The algorithms also show different performance on different kind
bodyText ||| topics. As for the “Air disaster”, its performance is not as good as
bodyText ||| that of the other two, since the features (words and time) of its
bodyText ||| events are more complicated and intertwined in the feature space.
bodyText ||| As for the topics (4-8 in Table I) which could not have an
bodyText ||| objective evaluation, the clustering performance on these topics
bodyText ||| could be indirectly reflected by the subjective evaluation of the
bodyText ||| rich presentation presented in section 5.2. This is because users
bodyText ||| will be more satisfied when the grouped documents shown in each
bodyText ||| event slide really belong to the same event; while users are not
bodyText ||| satisfied if the documents from different events are mixed in one
bodyText ||| event slide.
subsectionHeader ||| 5.2 Rich Presentation
bodyText ||| It is usually difficult to find a quantitative measure for rich
bodyText ||| presentation, since the assessment of the goodness of rich presen-
bodyText ||| tation is a strong subjective task. In this paper, we carry out a pre-
bodyText ||| liminary user study to evaluate the performance of the proposed
bodyText ||| rich presentation schemes.
bodyText ||| To indicate the performance of rich presentation, we design two
bodyText ||| measures in the experiments, including ‘informativeness’ and
bodyText ||| ‘enjoyablity’, following the criteria used in the work [7]. Here, the
bodyText ||| informativeness measures whether the subjects satisfy with the
bodyText ||| information obtained from the rich presentation; while enjoyablity
bodyText ||| indicates if users feel comfortable and enjoyable when they are
bodyText ||| reading the rich presentation. In evaluating the informativeness,
bodyText ||| we also provide the documents from which the rich presentation is
bodyText ||| generated. They are used as baseline, based on which the subjects
bodyText ||| can more easily evaluate if the important overview information
bodyText ||| contained in the documents is conveyed by the rich presentation.
bodyText ||| Moreover, in order to reveal the subjects’ opinion on the design of
bodyText ||| the storyboard template, like the one shown in Fig 3, we also ask
bodyText ||| the subjects to evaluate the ‘interface design’.
bodyText ||| In the user study, 10 volunteered subjects including 8 males and 2
bodyText ||| females are invited. The subjects are around 20-35 years old, have
bodyText ||| much experience on computer manipulation, and usually read
bodyText ||| news on web in their leisure time. We ask them to give a
bodyText ||| subjective score between 1 and 5 for each measure of the rich
bodyText ||| presentation of each testing topic (an exception is ‘interface
bodyText ||| design’, which is the same for each rich presentation). Here, the
bodyText ||| score ‘1’ to ‘5’ stands for unsatisfied (1), somewhat unsatisfied (2),
bodyText ||| acceptable (3), satisfied (4) and very satisfied (5), respectively.
bodyText ||| In experiments, we first check with the ‘interface design’ measure.
bodyText ||| We find 7 out of 10 subjects satisfy with the event template design
bodyText ||| and the left three also think it is acceptable. The average score is
bodyText ||| up to 3.9. An interesting observation is that, some subjects like
bodyText ||| the template design very much at the first glance, but they feel a
bodyText ||| little boring after they finish all the user study since every slide in
bodyText ||| the rich presentation of each topic has the same appearance. It
bodyText ||| hints us that we had better design different templates for different
bodyText ||| topics to make the rich presentation more attractive.
bodyText ||| As for the other two measures, we average the score across all the
bodyText ||| subjects to represent the performance for each topic, and list the
bodyText ||| detailed results in Table 3. It can be seen that the average score of
bodyText ||| both enjoyablity and informativeness achieves 3.7, which indicates
bodyText ||| that most subjects satisfy the provided overview information of the
bodyText ||| target topic, and they enjoy themselves when reading these rich
bodyText ||| presentations.
tableCaption ||| Table 3. The evaluation results of rich presentation on each topic
table ||| No.	Topic	Informative	Enjoyable
table ||| 1	Earthquake	4.3	3.2
table ||| 2	Halloween	3.6	4.0
table ||| 3	Air Disaster	4.0	3.4
table ||| 4	US Election	4.1	4.0
table ||| 5	Britney Spears	3.6	4.1
table ||| 6	Nobel Prize	3.3	3.4
table ||| 7	David Beckham	3.4	4.0
table ||| 8	Harry Potter	3.3	3.4
table ||| Average		3.7	3.7
bodyText ||| In the experiments, we find informativeness is highly depended on
bodyText ||| the correlation between the presented documents and the target
bodyText ||| topic. If the presented information is consistent with the topic,
bodyText ||| subjects usually give a high score for informativeness, such as
bodyText ||| those on Earthquake and US Election; otherwise, they will give a
bodyText ||| low score, like those on David Beckham and Nobel Prize. It
bodyText ||| indicates that it is quite important to provide users clean
bodyText ||| information of the target topic with less noise. However, in
bodyText ||| current system, the documents are crawled from web and
bodyText ||| inevitably contain many noises. It affects much on the perform-
bodyText ||| ance of informativeness in the current system. We need to consider
bodyText ||| how to prone the information of the target topic in the future
bodyText ||| works.
bodyText ||| We also find that the enjoyablity score is usually related with
bodyText ||| informativeness. If the subjects do not get enough information
bodyText ||| from the rich presentation, they will be not enjoyable as well, such
bodyText ||| as the topics of Nobel Prize and Harry Potter. Enjoyablity is also
bodyText ||| topic-related, the subjects usually feel unconformable when they
bodyText ||| are facing with miserable topics, such as Earthquake and Air
bodyText ||| Disaster, although their informativeness is quite high. On the
page ||| 752
bodyText ||| contrary, users give a high score for enjoyablity on the interesting
bodyText ||| topics, such as Britney Spears and David Beckham, although their
bodyText ||| informative score is not high. This is because that there are
bodyText ||| usually many funny and interesting pictures in the presentation of
bodyText ||| these topics. Another finding is that users usually fell unenjoyable
bodyText ||| if the images and summaries in one event slide are not consistent
bodyText ||| with each other. From this view, the high enjoyablity score in our
bodyText ||| experiments also indicates that our event clustering algorithm
bodyText ||| works promisingly
sectionHeader ||| 6. CONCLUSIONS
bodyText ||| To facilitate users to quickly grasp and go through the content of a
bodyText ||| semantic topic, in this paper, we have proposed a novel approach
bodyText ||| to rich presentation to generate a concise and informative
bodyText ||| storyboard for the target topic, with many relevant multimodal
bodyText ||| information including image, text, audio and video. In this
bodyText ||| approach, the related multimodal information of a given topic is
bodyText ||| first extracted from news databases. Then, the events are clustered,
bodyText ||| and the corresponding information, such as representative images,
bodyText ||| geographic information, and event summary, is obtained. The
bodyText ||| information is composed into an attractive storyboard which is
bodyText ||| finally synchronized with incidental music. A user study indicates
bodyText ||| that the presented system works well on our testing examples.
bodyText ||| There is still some room for improving the proposed approach.
bodyText ||| First, the proposed approach could be extended to other
bodyText ||| multimedia databases or more general websites. For example,
bodyText ||| some standard multimedia database like NIST TRECVID could
bodyText ||| provide a nice platform for the implementation and evaluation of
bodyText ||| event detection and rich presentation. Second, to integrate more
bodyText ||| relevant multimedia information (such as video clips and flashes)
bodyText ||| and more accurate information regarding the target topic is highly
bodyText ||| expected by users. Thus, more advanced information retrieval/
bodyText ||| extraction techniques and other multimedia analysis techniques are
bodyText ||| needed to be exploited and integrated, such as relevance ranking,
bodyText ||| mapping schemes, important or representative video clips
bodyText ||| detection and video clip summarization. We also need to design a
bodyText ||| much natural way to incorporate video clips in the event template.
bodyText ||| Third, we also consider designing various storyboard templates for
bodyText ||| different kind of topics. For example, each topic may be belonging
bodyText ||| to different clusters such as politics, sports and entertainments,
bodyText ||| each of which can have a representative template. Forth,
bodyText ||| appropriate user interaction will be added to further make the
bodyText ||| storyboard more interactive and easy to control. Finally, a
bodyText ||| thorough evaluation will be implemented to evaluate the effect of
bodyText ||| each component in the framework and storyboard template.
sectionHeader ||| 7. REFERENCES
reference ||| [1] A. Vailaya, M.A.T. Figueiredo, A. K. Jain, and H.-J. Zhang.
reference ||| “Image classification for content-based indexing”. IEEE
reference ||| Transactions on Image Processing, Vol. 10, Iss.1, 2001
reference ||| [2] F. J., M.-J. Li, H.-J. Zhang, and B. Zhang. “An effective
reference ||| region-based image retrieval framework”. Proc. ACM
reference ||| Multimedia’02, pp. 456-465, 2002
reference ||| [3] J. Platt “AutoAlbum: Clustering Digital Photographs using
reference ||| Probabilistic Model Merging” Proc. IEEE Workshop on
reference ||| Content-Based Access of Image and Video Libraries, pp. 96–
reference ||| 100, 2000.
reference ||| [4] A. Hanjalic, R. L. Lagendijk, J. Biemond, “Automated high-
reference ||| level movie segmentation for advanced video-retrieval
reference ||| systems”, IEEE Trans on Circuits and Systems For Video
reference ||| Technology, Vol. 9, No. 4, pp. 580-588, 1999.
reference ||| [5] J. Assfalg and et al, “Semantic annotation of soccer videos:
reference ||| automatic highlights identification," CVIU'03, vol. 92, pp.
reference ||| 285-305, 2003.
reference ||| [6] A. Ekin, A. M. Tekalp, and R. Mehrotra, "Automatic soccer
reference ||| video analysis and summarization," IEEE Trans. on Image
reference ||| Processing, 12(7), pp. 796-807, 2003.
reference ||| [7] Y. -F. Ma, L. Lu, H. -J. Zhang, and M.-J Li. “A User
reference ||| Attention Model for Video Summarization”. ACM
reference ||| Multimeida’02, pp. 533-542, 2002.
reference ||| [8] L. Xie, P. Xu, S.F. Chang, A. Divakaran, and H. Sun,
reference ||| "Structure analysis of soccer video with domain knowledge
reference ||| and hidden markov models," Pattern Recognition Letters,
reference ||| vol. 25(7), pp. 767-775, 2004.
reference ||| [9] L. Lu, H. Jiang, H. J. Zhang, “A Robust Audio Classification
reference ||| and Segmentation Method,” Proc. ACM Multimedia’01, pp.
reference ||| 203-211, 2001
reference ||| [10] R. Cai, L. Lu, H.-J. Zhang, and L.-H. Cai, “Highlight Sound
reference ||| Effects Detection in Audio Stream,” Proc. ICME’03 Vol.3,
reference ||| pp.37-40, 2003.
reference ||| [11] Y. Rui, A. Gupta, and A. Acero, “Automatically Extracting
reference ||| Highlights for TV Baseball Programs”, Proc. ACM Multi-
reference ||| media’00, pp. 105-115, 2000.
reference ||| [12] C. Snoek, and M. Worring. “Multimodal Video Indexing: A
reference ||| Review of the State-of-the-art”. Multimedia Tools and
reference ||| Applications, Vol. 25, No. 1 pp. 5 – 35, 2005
reference ||| [13] E.M. Voorhees, “Query expansion using lexical-semantic
reference ||| relations” Proc. ACM SIGIR Conference on Research and
reference ||| Development in Information Retrieval , pp 61 - 69, 1994
reference ||| [14] Z.-W. Li, M.-J. Li, and W.-Y. Ma. "A Probabilistic Model for
reference ||| Retrospective News Event Detection”, Proc. SIGIR
reference ||| Conference on Research and Development in Information
reference ||| Retrieval, 2005
reference ||| [15] D. M. Bikel, R. L. Schwartz, and R. M. Weischedel. “An
reference ||| Algorithm That Learns What’s in a Name”. Machine
reference ||| Learning, 34(1-3), 1999
reference ||| [16] K. Nigam, A. McCallum, S. Thrun, and T. Mitchell. “Text
reference ||| Classification from Labeled and Unlabeled Documents using
reference ||| EM”. Machine Learning, 39(2-3), 2000
reference ||| [17] T. Hastie, R. Tibshirani, and J. Friedman. “The Elements of
reference ||| Statistical Learning: Data Mining, Inference and Prediction”.
reference ||| Springer-Verlag, 2001
reference ||| [18] MapPoint Web Service http://www.microsoft.com/mappoint/
reference ||| products/ webservice/default.mspx
reference ||| [19] X.-S. Hua, L. Lu, H.-J. Zhang. "Automated Home Video
reference ||| Editing", Proc. ACM Multimedia’03, pp. 490-497, 2003
reference ||| [20] J. Foote, M. Cooper, and A. Girgensohn. “Creating Music
reference ||| Videos Using Automatic Media Analysis”. ACM
reference ||| Multimedia’02, pp.553-560, 2002.
reference ||| [21] Topic Detection and Tracking (TDT) Project: http://www.
reference ||| nist.gov/speech/tests/tdt/
reference ||| [22] J. Allan, R. Papka, and V. Lavrenko. “On-line New Event
reference ||| Detection and Tracking”. Proc. SIGIR Conference on
reference ||| Research and Development in Information Retrieval 98,
reference ||| pp.37-45, 1998
page ||| 753

title ||| Automatic Extraction of Titles from General Documents
title ||| using Machine Learning
author ||| Yunhua Hu1
affiliation ||| Computer Science Department
affiliation ||| Xi’an Jiaotong University
address ||| No 28, Xianning West Road
address ||| Xi'an, China, 710049
email ||| yunhuahu@mail.xjtu.edu.cn
author ||| Hang Li, Yunbo Cao
affiliation ||| Microsoft Research Asia
address ||| 5F Sigma Center,
address ||| No. 49 Zhichun Road, Haidian,
address ||| Beijing, China, 100080
email ||| {hangli,yucao}@microsoft.com
author ||| Dmitriy Meyerzon
affiliation ||| Microsoft Corporation
address ||| One Microsoft Way
address ||| Redmond, WA,
address ||| USA, 98052
email ||| dmitriym@microsoft.com
author ||| Qinghua Zheng
affiliation ||| Computer Science Department
affiliation ||| Xi’an Jiaotong University
address ||| No 28, Xianning West Road
address ||| Xi'an, China, 710049
email ||| qhzheng@mail.xjtu.edu.cn
sectionHeader ||| ABSTRACT
bodyText ||| In this paper, we propose a machine learning approach to title
bodyText ||| extraction from general documents. By general documents, we
bodyText ||| mean documents that can belong to any one of a number of
bodyText ||| specific genres, including presentations, book chapters, technical
bodyText ||| papers, brochures, reports, and letters. Previously, methods have
bodyText ||| been proposed mainly for title extraction from research papers. It
bodyText ||| has not been clear whether it could be possible to conduct
bodyText ||| automatic title extraction from general documents. As a case study,
bodyText ||| we consider extraction from Office including Word and
bodyText ||| PowerPoint. In our approach, we annotate titles in sample
bodyText ||| documents (for Word and PowerPoint respectively) and take them
bodyText ||| as training data, train machine learning models, and perform title
bodyText ||| extraction using the trained models. Our method is unique in that
bodyText ||| we mainly utilize formatting information such as font size as
bodyText ||| features in the models. It turns out that the use of formatting
bodyText ||| information can lead to quite accurate extraction from general
bodyText ||| documents. Precision and recall for title extraction from Word is
bodyText ||| 0.810 and 0.837 respectively, and precision and recall for title
bodyText ||| extraction from PowerPoint is 0.875 and 0.895 respectively in an
bodyText ||| experiment on intranet data. Other important new findings in this
bodyText ||| work include that we can train models in one domain and apply
bodyText ||| them to another domain, and more surprisingly we can even train
bodyText ||| models in one language and apply them to another language.
bodyText ||| Moreover, we can significantly improve search ranking results in
bodyText ||| document retrieval by using the extracted titles.
sectionHeader ||| Categories and Subject Descriptors
category ||| H.3.3 [Information Storage and Retrieval]: Information Search
category ||| and Retrieval - Search Process; H.4.1 [Information Systems
copyright ||| Permission to make digital or hard copies of all or part of this work for
copyright ||| personal or classroom use is granted without fee provided that copies are
copyright ||| not made or distributed for profit or commercial advantage and that copies
copyright ||| bear this notice and the full citation on the first page. To copy otherwise, or
copyright ||| republish, to post on servers or to redistribute to lists, requires prior specific
copyright ||| permission and/or a fee.
note ||| JCDL’05, June 7–11, 2005, Denver, Colorado, USA
copyright ||| Copyright 2005 ACM 1-58113-876-8/05/0006...$5.00.
copyright ||| Applications]: Office Automation - Word processing; D.2.8
copyright ||| [Software Engineering]: Metrics - complexity measures,
copyright ||| performance measures
sectionHeader ||| General Terms
keyword ||| Algorithms, Experimentation, Performance.
sectionHeader ||| Keywords
keyword ||| information extraction, metadata extraction, machine learning,
keyword ||| search
sectionHeader ||| 1. INTRODUCTION
bodyText ||| Metadata of documents is useful for many kinds of document
bodyText ||| processing such as search, browsing, and filtering. Ideally,
bodyText ||| metadata is defined by the authors of documents and is then used
bodyText ||| by various systems. However, people seldom define document
bodyText ||| metadata by themselves, even when they have convenient
bodyText ||| metadata definition tools [26]. Thus, how to automatically extract
bodyText ||| metadata from the bodies of documents turns out to be an
bodyText ||| important research issue.
bodyText ||| Methods for performing the task have been proposed. However,
bodyText ||| the focus was mainly on extraction from research papers. For
bodyText ||| instance, Han et al. [10] proposed a machine learning based
bodyText ||| method to conduct extraction from research papers. They
bodyText ||| formalized the problem as that of classification and employed
bodyText ||| Support Vector Machines as the classifier. They mainly used
bodyText ||| linguistic features in the model.
bodyText ||| In this paper, we consider metadata extraction from general
bodyText ||| documents. By general documents, we mean documents that may
bodyText ||| belong to any one of a number of specific genres. General
bodyText ||| documents are more widely available in digital libraries, intranets
bodyText ||| and the internet, and thus investigation on extraction from them is
footnote ||| 1 The work was conducted when the first author was visiting
footnote ||| Microsoft Research Asia.
page ||| 145
bodyText ||| sorely needed. Research papers usually have well-formed styles
bodyText ||| and noticeable characteristics. In contrast, the styles of general
bodyText ||| documents can vary greatly. It has not been clarified whether a
bodyText ||| machine learning based approach can work well for this task.
bodyText ||| There are many types of metadata: title, author, date of creation,
bodyText ||| etc. As a case study, we consider title extraction in this paper.
bodyText ||| General documents can be in many different file formats:
bodyText ||| Microsoft Office, PDF (PS), etc. As a case study, we consider
bodyText ||| extraction from Office including Word and PowerPoint.
bodyText ||| We take a machine learning approach. We annotate titles in
bodyText ||| sample documents (for Word and PowerPoint respectively) and
bodyText ||| take them as training data to train several types of models, and
bodyText ||| perform title extraction using any one type of the trained models.
bodyText ||| In the models, we mainly utilize formatting information such as
bodyText ||| font size as features. We employ the following models: Maximum
bodyText ||| Entropy Model, Perceptron with Uneven Margins, Maximum
bodyText ||| Entropy Markov Model, and Voted Perceptron.
bodyText ||| In this paper, we also investigate the following three problems,
bodyText ||| which did not seem to have been examined previously.
listItem ||| (1) Comparison between models: among the models above, which
listItem ||| model performs best for title extraction;
listItem ||| (2) Generality of model: whether it is possible to train a model on
listItem ||| one domain and apply it to another domain, and whether it is
listItem ||| possible to train a model in one language and apply it to another
listItem ||| language;
listItem ||| (3) Usefulness of extracted titles: whether extracted titles can
listItem ||| improve document processing such as search.
bodyText ||| Experimental results indicate that our approach works well for
bodyText ||| title extraction from general documents. Our method can
bodyText ||| significantly outperform the baselines: one that always uses the
bodyText ||| first lines as titles and the other that always uses the lines in the
bodyText ||| largest font sizes as titles. Precision and recall for title extraction
bodyText ||| from Word are 0.810 and 0.837 respectively, and precision and
bodyText ||| recall for title extraction from PowerPoint are 0.875 and 0.895
bodyText ||| respectively. It turns out that the use of format features is the key
bodyText ||| to successful title extraction.
listItem ||| (1) We have observed that Perceptron based models perform
listItem ||| better in terms of extraction accuracies. (2) We have empirically
listItem ||| verified that the models trained with our approach are generic in
listItem ||| the sense that they can be trained on one domain and applied to
listItem ||| another, and they can be trained in one language and applied to
listItem ||| another. (3) We have found that using the extracted titles we can
listItem ||| significantly improve precision of document retrieval (by 10%).
bodyText ||| We conclude that we can indeed conduct reliable title extraction
bodyText ||| from general documents and use the extracted results to improve
bodyText ||| real applications.
bodyText ||| The rest of the paper is organized as follows. In section 2, we
bodyText ||| introduce related work, and in section 3, we explain the
bodyText ||| motivation and problem setting of our work. In section 4, we
bodyText ||| describe our method of title extraction, and in section 5, we
bodyText ||| describe our method of document retrieval using extracted titles.
bodyText ||| Section 6 gives our experimental results. We make concluding
bodyText ||| remarks in section 7.
sectionHeader ||| 2. RELATED WORK
subsectionHeader ||| 2.1 Document Metadata Extraction
bodyText ||| Methods have been proposed for performing automatic metadata
bodyText ||| extraction from documents; however, the main focus was on
bodyText ||| extraction from research papers.
bodyText ||| The proposed methods fall into two categories: the rule based
bodyText ||| approach and the machine learning based approach.
bodyText ||| Giuffrida et al. [9], for instance, developed a rule-based system for
bodyText ||| automatically extracting metadata from research papers in
bodyText ||| Postscript. They used rules like “titles are usually located on the
bodyText ||| upper portions of the first pages and they are usually in the largest
bodyText ||| font sizes”. Liddy et al. [14] and Yilmazel el al. [23] performed
bodyText ||| metadata extraction from educational materials using rule-based
bodyText ||| natural language processing technologies. Mao et al. [16] also
bodyText ||| conducted automatic metadata extraction from research papers
bodyText ||| using rules on formatting information.
bodyText ||| The rule-based approach can achieve high performance. However,
bodyText ||| it also has disadvantages. It is less adaptive and robust when
bodyText ||| compared with the machine learning approach.
bodyText ||| Han et al. [10], for instance, conducted metadata extraction with
bodyText ||| the machine learning approach. They viewed the problem as that
bodyText ||| of classifying the lines in a document into the categories of
bodyText ||| metadata and proposed using Support Vector Machines as the
bodyText ||| classifier. They mainly used linguistic information as features.
bodyText ||| They reported high extraction accuracy from research papers in
bodyText ||| terms of precision and recall.
subsectionHeader ||| 2.2 Information Extraction
bodyText ||| Metadata extraction can be viewed as an application of
bodyText ||| information extraction, in which given a sequence of instances, we
bodyText ||| identify a subsequence that represents information in which we
bodyText ||| are interested. Hidden Markov Model [6], Maximum Entropy
bodyText ||| Model [1, 4], Maximum Entropy Markov Model [17], Support
bodyText ||| Vector Machines [3], Conditional Random Field [12], and Voted
bodyText ||| Perceptron [2] are widely used information extraction models.
bodyText ||| Information extraction has been applied, for instance, to part-of-
bodyText ||| speech tagging [20], named entity recognition [25] and table
bodyText ||| extraction [19].
subsectionHeader ||| 2.3 Search Using Title Information
bodyText ||| Title information is useful for document retrieval.
bodyText ||| In the system Citeseer, for instance, Giles et al. managed to
bodyText ||| extract titles from research papers and make use of the extracted
bodyText ||| titles in metadata search of papers [8].
bodyText ||| In web search, the title fields (i.e., file properties) and anchor texts
bodyText ||| of web pages (HTML documents) can be viewed as ‘titles’ of the
bodyText ||| pages [5]. Many search engines seem to utilize them for web page
bodyText ||| retrieval [7, 11, 18, 22]. Zhang et al., found that web pages with
bodyText ||| well-defined metadata are more easily retrieved than those without
bodyText ||| well-defined metadata [24].
bodyText ||| To the best of our knowledge, no research has been conducted on
bodyText ||| using extracted titles from general documents (e.g., Office
bodyText ||| documents) for search of the documents.
page ||| 146
sectionHeader ||| 3. MOTIVATION AND PROBLEM
sectionHeader ||| SETTING
bodyText ||| We consider the issue of automatically extracting titles from
bodyText ||| general documents.
bodyText ||| By general documents, we mean documents that belong to one of
bodyText ||| any number of specific genres. The documents can be
bodyText ||| presentations, books, book chapters, technical papers, brochures,
bodyText ||| reports, memos, specifications, letters, announcements, or resumes.
bodyText ||| General documents are more widely available in digital libraries,
bodyText ||| intranets, and internet, and thus investigation on title extraction
bodyText ||| from them is sorely needed.
bodyText ||| Figure 1 shows an estimate on distributions of file formats on
bodyText ||| intranet and internet [15]. Office and PDF are the main file
bodyText ||| formats on the intranet. Even on the internet, the documents in the
bodyText ||| formats are still not negligible, given its extremely large size. In
bodyText ||| this paper, without loss of generality, we take Office documents as
bodyText ||| an example.
figureCaption ||| Figure 1. Distributions of file formats in internet and intranet.
bodyText ||| For Office documents, users can define titles as file properties
bodyText ||| using a feature provided by Office. We found in an experiment,
bodyText ||| however, that users seldom use the feature and thus titles in file
bodyText ||| properties are usually very inaccurate. That is to say, titles in file
bodyText ||| properties are usually inconsistent with the ‘true’ titles in the file
bodyText ||| bodies that are created by the authors and are visible to readers.
bodyText ||| We collected 6,000 Word and 6,000 PowerPoint documents from
bodyText ||| an intranet and the internet and examined how many titles in the
bodyText ||| file properties are correct. We found that surprisingly the accuracy
bodyText ||| was only 0.265 (cf., Section 6.3 for details). A number of reasons
bodyText ||| can be considered. For example, if one creates a new file by
bodyText ||| copying an old file, then the file property of the new file will also
bodyText ||| be copied from the old file.
bodyText ||| In another experiment, we found that Google uses the titles in file
bodyText ||| properties of Office documents in search and browsing, but the
bodyText ||| titles are not very accurate. We created 50 queries to search Word
bodyText ||| and PowerPoint documents and examined the top 15 results of
bodyText ||| each query returned by Google. We found that nearly all the titles
bodyText ||| presented in the search results were from the file properties of the
bodyText ||| documents. However, only 0.272 of them were correct.
bodyText ||| Actually, ‘true’ titles usually exist at the beginnings of the bodies
bodyText ||| of documents. If we can accurately extract the titles from the
bodyText ||| bodies of documents, then we can exploit reliable title information
bodyText ||| in document processing. This is exactly the problem we address in
bodyText ||| this paper.
bodyText ||| More specifically, given a Word document, we are to extract the
bodyText ||| title from the top region of the first page. Given a PowerPoint
bodyText ||| document, we are to extract the title from the first slide. A title
bodyText ||| sometimes consists of a main title and one or two subtitles. We
bodyText ||| only consider extraction of the main title.
bodyText ||| As baselines for title extraction, we use that of always using the
bodyText ||| first lines as titles and that of always using the lines with largest
bodyText ||| font sizes as titles.
figureCaption ||| Figure 2. Title extraction from Word document.
figureCaption ||| Figure 3. Title extraction from PowerPoint document.
bodyText ||| Next, we define a ‘specification’ for human judgments in title data
bodyText ||| annotation. The annotated data will be used in training and testing
bodyText ||| of the title extraction methods.
bodyText ||| Summary of the specification: The title of a document should be
bodyText ||| identified on the basis of common sense, if there is no difficulty in
bodyText ||| the identification. However, there are many cases in which the
bodyText ||| identification is not easy. There are some rules defined in the
bodyText ||| specification that guide identification for such cases. The rules
bodyText ||| include “a title is usually in consecutive lines in the same format”,
bodyText ||| “a document can have no title”, “titles in images are not
bodyText ||| considered”, “a title should not contain words like ‘draft’,
page ||| 147
bodyText ||| ‘whitepaper’, etc”, “if it is difficult to determine which is the title,
bodyText ||| select the one in the largest font size”, and “if it is still difficult to
bodyText ||| determine which is the title, select the first candidate”. (The
bodyText ||| specification covers all the cases we have encountered in data
bodyText ||| annotation.)
bodyText ||| Figures 2 and 3 show examples of Office documents from which
bodyText ||| we conduct title extraction. In Figure 2, ‘Differences in Win32
bodyText ||| API Implementations among Windows Operating Systems’ is the
bodyText ||| title of the Word document. ‘Microsoft Windows’ on the top of
bodyText ||| this page is a picture and thus is ignored. In Figure 3, ‘Building
bodyText ||| Competitive Advantages through an Agile Infrastructure’ is the
bodyText ||| title of the PowerPoint document.
bodyText ||| We have developed a tool for annotation of titles by human
bodyText ||| annotators. Figure 4 shows a snapshot of the tool.
figureCaption ||| Figure 4. Title annotation tool.
sectionHeader ||| 4. TITLE EXTRACTION METHOD
sectionHeader ||| 4.1 Outline
bodyText ||| Title extraction based on machine learning consists of training and
bodyText ||| extraction. The same pre-processing step occurs before training
bodyText ||| and extraction.
bodyText ||| During pre-processing, from the top region of the first page of a
bodyText ||| Word document or the first slide of a PowerPoint document a
bodyText ||| number of units for processing are extracted. If a line (lines are
bodyText ||| separated by ‘return’ symbols) only has a single format, then the
bodyText ||| line will become a unit. If a line has several parts and each of
bodyText ||| them has its own format, then each part will become a unit. Each
bodyText ||| unit will be treated as an instance in learning. A unit contains not
bodyText ||| only content information (linguistic information) but also
bodyText ||| formatting information. The input to pre-processing is a document
bodyText ||| and the output of pre-processing is a sequence of units (instances).
bodyText ||| Figure 5 shows the units obtained from the document in Figure 2.
figureCaption ||| Figure 5. Example of units.
bodyText ||| In learning, the input is sequences of units where each sequence
bodyText ||| corresponds to a document. We take labeled units (labeled as
bodyText ||| title_begin, title_end, or other) in the sequences as training data
bodyText ||| and construct models for identifying whether a unit is title_begin
bodyText ||| title_end, or other. We employ four types of models: Perceptron,
bodyText ||| Maximum Entropy (ME), Perceptron Markov Model (PMM), and
bodyText ||| Maximum Entropy Markov Model (MEMM).
bodyText ||| In extraction, the input is a sequence of units from one document.
bodyText ||| We employ one type of model to identify whether a unit is
bodyText ||| title_begin, title_end, or other. We then extract units from the unit
bodyText ||| labeled with ‘title_begin’ to the unit labeled with ‘title_end’. The
bodyText ||| result is the extracted title of the document.
bodyText ||| The unique characteristic of our approach is that we mainly utilize
bodyText ||| formatting information for title extraction. Our assumption is that
bodyText ||| although general documents vary in styles, their formats have
bodyText ||| certain patterns and we can learn and utilize the patterns for title
bodyText ||| extraction. This is in contrast to the work by Han et al., in which
bodyText ||| only linguistic features are used for extraction from research
bodyText ||| papers.
subsectionHeader ||| 4.2 Models
bodyText ||| The four models actually can be considered in the same metadata
bodyText ||| extraction framework. That is why we apply them together to our
bodyText ||| current problem.
bodyText ||| Each input is a sequence of instances x1x2 L xk together with a
bodyText ||| sequence of labels y1 y2 L yk . xi and yi represents an instance
bodyText ||| and its label, respectively (i =1,2, L , k ). Recall that an instance
bodyText ||| here represents a unit. A label represents title_begin, title_end, or
bodyText ||| other. Here, k is the number of units in a document.
bodyText ||| In learning, we train a model which can be generally denoted as a
bodyText ||| conditional probability distribution P(Y1 L Yk | X1 L Xk) where
bodyText ||| Xi and Yi denote random variables taking instance xi and label
bodyText ||| yi as values, respectively ( i =1,2, L ,k).
figure ||| x11 x12 L x1k → y11y12 L y1k
figure ||| x21x22 L x2k → y21y22 L y2k
figure ||| L L
figure ||| xn1xn 2 L x1k → yn1yn2 L ynk
figure ||| Learning Tool
figure ||| xm1xm2 L xmk	Extraction Tool
figure ||| arg max P(ymLym k | xm1 L xmk
figureCaption ||| Figure 6. Metadata extraction model.
bodyText ||| We can make assumptions about the general model in order to
bodyText ||| make it simple enough for training.
bodyText ||| Conditional
bodyText ||| Distribution
equation ||| P(Y1L Yk | X1LXk)
equation ||| )
page ||| 148
bodyText ||| For example, we can assume that Y1 , ... , Yk are independent of
bodyText ||| each other given X 1 ,... ,X k . Thus, we have
equation ||| P(Y1 ... Yk|X1 ... Xk)
equation ||| =P ( Y 1 | X 1)... P(Yk | Xk)
bodyText ||| In this way, we decompose the model into a number of classifiers.
bodyText ||| We train the classifiers locally using the labeled data. As the
bodyText ||| classifier, we employ the Perceptron or Maximum Entropy model.
bodyText ||| We can also assume that the first order Markov property holds for
bodyText ||| Y1 , ... , Yk given X1 ,... ,Xk . Thus, we have
bodyText ||| Again, we obtain a number of classifiers. However, the classifiers
bodyText ||| are conditioned on the previous label. When we employ the
bodyText ||| Percepton or Maximum Entropy model as a classifier, the models
bodyText ||| become a Percepton Markov Model or Maximum Entropy Markov
bodyText ||| Model, respectively. That is to say, the two models are more
bodyText ||| precise.
bodyText ||| In extraction, given a new sequence of instances, we resort to one
bodyText ||| of the constructed models to assign a sequence of labels to the
bodyText ||| sequence of instances, i.e., perform extraction.
bodyText ||| For Perceptron and ME, we assign labels locally and combine the
bodyText ||| results globally later using heuristics. Specifically, we first
bodyText ||| identify the most likely title_begin. Then we find the most likely
bodyText ||| title _end within three units after the title _begin. Finally, we
bodyText ||| extract as a title the units between the title_begin and the title_end.
bodyText ||| For PMM and MEMM, we employ the Viterbi algorithm to find
bodyText ||| the globally optimal label sequence.
bodyText ||| In this paper, for Perceptron, we actually employ an improved
bodyText ||| variant of it, called Perceptron with Uneven Margin [13]. This
bodyText ||| version of Perceptron can work well especially when the number
bodyText ||| of positive instances and the number of negative instances differ
bodyText ||| greatly, which is exactly the case in our problem.
bodyText ||| We also employ an improved version of Perceptron Markov
bodyText ||| Model in which the Perceptron model is the so-called Voted
bodyText ||| Perceptron [2]. In addition, in training, the parameters of the
bodyText ||| model are updated globally rather than locally.
subsectionHeader ||| 4.3 Features
bodyText ||| There are two types of features: format features and linguistic
bodyText ||| features. We mainly use the former. The features are used for both
bodyText ||| the title-begin and the title-end classifiers.
subsubsectionHeader ||| 4.3.1 Format Features
listItem ||| Font Size: There are four binary features that represent the
listItem ||| normalized font size of the unit (recall that a unit has only one
listItem ||| type of font).
bodyText ||| If the font size of the unit is the largest in the document, then the
bodyText ||| first feature will be 1, otherwise 0. If the font size is the smallest
bodyText ||| in the document, then the fourth feature will be 1, otherwise 0. If
bodyText ||| the font size is above the average font size and not the largest in
bodyText ||| the document, then the second feature will be 1, otherwise 0. If the
bodyText ||| font size is below the average font size and not the smallest, the
bodyText ||| third feature will be 1, otherwise 0.
bodyText ||| It is necessary to conduct normalization on font sizes. For
bodyText ||| example, in one document the largest font size might be ‘12pt’,
bodyText ||| while in another the smallest one might be ‘18pt’.
listItem ||| Boldface: This binary feature represents whether or not the
listItem ||| current unit is in boldface.
listItem ||| Alignment: There are four binary features that respectively
listItem ||| represent the location of the current unit: ‘left’, ‘center’, ‘right’,
listItem ||| and ‘unknown alignment’.
bodyText ||| The following format features with respect to ‘context’ play an
bodyText ||| important role in title extraction.
listItem ||| Empty Neighboring Unit: There are two binary features that
listItem ||| represent, respectively, whether or not the previous unit and the
listItem ||| current unit are blank lines.
listItem ||| Font Size Change: There are two binary features that represent,
listItem ||| respectively, whether or not the font size of the previous unit and
listItem ||| the font size of the next unit differ from that of the current unit.
listItem ||| Alignment Change: There are two binary features that represent,
listItem ||| respectively, whether or not the alignment of the previous unit and
listItem ||| the alignment of the next unit differ from that of the current one.
listItem ||| Same Paragraph: There are two binary features that represent,
listItem ||| respectively, whether or not the previous unit and the next unit are
listItem ||| in the same paragraph as the current unit.
subsubsectionHeader ||| 4.3.2 Linguistic Features
bodyText ||| The linguistic features are based on key words.
listItem ||| Positive Word: This binary feature represents whether or not the
listItem ||| current unit begins with one of the positive words. The positive
listItem ||| words include ‘title:’, ‘subject:’, ‘subject line:’ For example, in
listItem ||| some documents the lines of titles and authors have the same
listItem ||| formats. However, if lines begin with one of the positive words,
listItem ||| then it is likely that they are title lines.
listItem ||| Negative Word: This binary feature represents whether or not the
listItem ||| current unit begins with one of the negative words. The negative
listItem ||| words include ‘To’, ‘By’, ‘created by’, ‘updated by’, etc.
bodyText ||| There are more negative words than positive words. The above
bodyText ||| linguistic features are language dependent.
listItem ||| Word Count: A title should not be too long. We heuristically
bodyText ||| create four intervals: [1, 2], [3, 6], [7, 9] and [9, ∞ ) and define one
bodyText ||| feature for each interval. If the number of words in a title falls into
bodyText ||| an interval, then the corresponding feature will be 1; otherwise 0.
listItem ||| Ending Character: This feature represents whether the unit ends
listItem ||| with ‘:’, ‘-’, or other special characters. A title usually does not
listItem ||| end with such a character.
sectionHeader ||| 5. DOCUMENT RETRIEVAL METHOD
bodyText ||| We describe our method of document retrieval using extracted
bodyText ||| titles.
bodyText ||| Typically, in information retrieval a document is split into a
bodyText ||| number of fields including body, title, and anchor text. A ranking
bodyText ||| function in search can use different weights for different fields of
equation ||| P (Y1... Yk | X1... Xk
equation ||| =X0... P(Yk | Yk,Xk)
equation ||| )
equation ||| P(Y1 |
page ||| 149
bodyText ||| the document. Also, titles are typically assigned high weights,
bodyText ||| indicating that they are important for document retrieval. As
bodyText ||| explained previously, our experiment has shown that a significant
bodyText ||| number of documents actually have incorrect titles in the file
bodyText ||| properties, and thus in addition of using them we use the extracted
bodyText ||| titles as one more field of the document. By doing this, we attempt
bodyText ||| to improve the overall precision.
bodyText ||| In this paper, we employ a modification of BM25 that allows field
bodyText ||| weighting [21]. As fields, we make use of body, title, extracted
bodyText ||| title and anchor. First, for each term in the query we count the
bodyText ||| term frequency in each field of the document; each field
bodyText ||| frequency is then weighted according to the corresponding weight
bodyText ||| parameter:
equation ||| wtf, =∑wftfe
equation ||| f
bodyText ||| Similarly, we compute the document length as a weighted sum of
bodyText ||| lengths of each field. Average document length in the corpus
bodyText ||| becomes the average of all weighted document lengths.
equation ||| wdl =∑wfdlf
equation ||| f
equation ||| w
equation ||| t k1 ((1−b)+b wdl )+wtf	n
equation ||| avwdl
sectionHeader ||| 6. EXPERIMENTAL RESULTS
bodyText ||| Inourexperiments we used
none ||| k1
none |||  =1.8, b = 0.75. Weightforcontent
none ||| was 1.0, title was 10.0, anchorwas 10.0, andextractedtitle was
none ||| 5.0.
subsectionHeader ||| 6.1 Data Sets and Evaluation Measures
bodyText ||| We usedtwo datasets inourexperiments.
bodyText ||| First, we downloadedandrandomly selected5,000 Word
bodyText ||| documents and5,000 PowerPointdocuments fr
bodyText ||| om an intranet of
bodyText ||| Microsoft. We call it MS hereafter.
bodyText ||| Second, we downloadedandrandomlyselected500 Wordand500
bodyText ||| PowerPointdocuments fromthe DotGov andDotComdomains on
bodyText ||| the
bodyText |||  internet,
bodyText |||  respectively.
figureCaption ||| Figure 7 shows the distributions ofthe genres ofthedocuments.
bodyText ||| We see thatthe documents are indeed
bodyText |||  ‘generaldocuments’
bodyText |||  as
bodyText |||  we
bodyText ||| define them.
bodyText ||| internet.
bodyText ||| d 500 PowerPoint documents
bodyText ||| in Chinese.
bodyText ||| Wemanuallylabeledthe titles ofall the documents, onthe basis
bodyText ||| ofourspecification.
bodyText ||| Notall the documents inthe two datasets have titles. Table 1
bodyText ||| shows the percentages ofthe documents having titles. Wesee that
bodyText ||| DotComandDotGov have more PowerPointdocuments with titles
bodyText ||| thanMS. This mightbebecausePowerPointdocuments published
bodyText ||| onthe
bodyText ||| internet
bodyText ||| aremore formal thanthose onthe
bodyText ||| intranet.
tableCaption ||| Table 1. The portion of documents with titles
bodyText ||| Inourexperiments, we conductedevaluations ontitle extractionin
bodyText ||| terms ofprecision, recall, andF-measure. The evaluation
bodyText ||| measures aredefinedas
bodyText |||  follows:
equation ||| Precision:	P = A/
equation |||  ( A
equation |||  + B )
equation ||| Recall:
equation ||| R = A / ( A + C )
equation ||| F-measure:
equation ||| F1
equation |||  = 2PR/
equation |||  ( P
equation |||  +
equation ||| R )
bodyText ||| Here, A, B, C, andD are numbers ofdocuments as
bodyText |||  those defined
bodyText ||| in Table 2.
tableCaption ||| Table 2. Contingence table with regard to title extraction
subsectionHeader ||| 6.2 Baselines
bodyText ||| Wetestthe accuracies ofthe two baselines describedinsection
bodyText ||| 4.2. Theyare denotedas
bodyText ||| ‘largest
bodyText ||| font
bodyText |||  size’
bodyText |||  an
bodyText ||| d ‘first line’
bodyText ||| respectively.
subsectionHeader ||| 6.3 Accuracy ofTitles in File Properties
bodyText ||| Weinvestigate howmanytitles inthe file properties ofthe
bodyText ||| documents arereliable. We viewthe titles annotatedbyhumans as
bodyText ||| true titles andtesthowmanytitles inthe fileproperties can
bodyText ||| approximatelymatch with the truetitles. We useEditDistance to
bodyText ||| conductthe approximate match. (Approximate match is onlyused
bodyText ||| inthis evaluation). This is becausesometimes humanannotated
bodyText ||| titles canbe slightlydifferentfromthe titles infile properties on
bodyText ||| the surface, e.g., containextraspaces).
bodyText ||| GivenstringA andstringB:
bodyText ||| if ( (D == 0) or ( D / ( La + Lb ) < θ ) ) then
bodyText ||| string
bodyText ||| A =
bodyText |||  string B
bodyText ||| D:	EditDistan
bodyText ||| ce between string A and string B
bodyText ||| La:	length of string A
bodyText ||| Lb:	length of string B
equation ||| e:	0.1
equation ||| BM25F = ∑ 	`	× log( N)
equation ||| tf, (k, 1)
table ||| Domain		MSDotComDotGovType
table ||| 		Word	75.7%	77.8%	75.6%
table ||| 	PowerPoint	82.1%	93.4%	96.4%
figureCaption ||| Figure 7. Distributions of document genres.
table ||| 	Is title	Is not title
table ||| Extracted	Third, adatasetinChinese was also downloadedfromthe	B
table ||| 	A
table ||| Itincludes 500 Worddocuments an	C	D
table ||| Not extracted
page ||| 150
tableCaption ||| Table 3. Accuracies of titles in file properties
table ||| File Type	Domain	Precision	Recall	F1
table ||| Word	MS	0.299	0.311	0.305
table ||| 	DotCom	0.210	0.214	0.212
table ||| 	DotGov	0.182	0.177	0.180
table ||| PowerPoint	MS	0.229	0.245	0.237
table ||| 	DotCom	0.185	0.186	0.186
table ||| 	DotGov	0.180	0.182	0.181
subsectionHeader ||| 6.4 Comparison with Baselines
bodyText ||| We conducted title extraction from the first data set (Word and
bodyText ||| PowerPoint in MS). As the model, we used Perceptron.
bodyText ||| We conduct 4-fold cross validation. Thus, all the results reported
bodyText ||| here are those averaged over 4 trials. Tables 4 and 5 show the
bodyText ||| results. We see that Perceptron significantly outperforms the
bodyText ||| baselines. In the evaluation, we use exact matching between the
bodyText ||| true titles annotated by humans and the extracted titles.
tableCaption ||| Table 4. Accuracies of title extraction with Word
table ||| 		Precision	Recall	F1
table ||| Model	Perceptron	0.810	0.837	0.823
table ||| Baselines	Largest font size	0.700	0.758	0.727
table ||| 	First line	0.707	0.767	0.736
tableCaption ||| Table 5. Accuracies of title extraction with PowerPoint
table ||| 		Precision	Recall	F1
table ||| Model	Perceptron	0.875	0. 895	0.885
table ||| Baselines	Largest font size	0.844	0.887	0.865
table ||| 	First line	0.639	0.671	0.655
bodyText ||| We see that the machine learning approach can achieve good
bodyText ||| performance in title extraction. For Word documents both
bodyText ||| precision and recall of the approach are 8 percent higher than
bodyText ||| those of the baselines. For PowerPoint both precision and recall of
bodyText ||| the approach are 2 percent higher than those of the baselines.
bodyText ||| We conduct significance tests. The results are shown in Table 6.
bodyText ||| Here, ‘Largest’ denotes the baseline of using the largest font size,
bodyText ||| ‘First’ denotes the baseline of using the first line. The results
bodyText ||| indicate that the improvements of machine learning over baselines
bodyText ||| are statistically significant (in the sense p-value < 0.05)
tableCaption ||| Table 6. Sign test results
table ||| Documents Type	Sign test between	p-value
table ||| Word	Perceptron vs. Largest	3.59e-26
table ||| 	Perceptron vs. First	7.12e-10
table ||| PowerPoint	Perceptron vs. Largest	0.010
table ||| 	Perceptron vs. First	5.13e-40
bodyText ||| We see, from the results, that the two baselines can work well for
bodyText ||| title extraction, suggesting that font size and position information
bodyText ||| are most useful features for title extraction. However, it is also
bodyText ||| obvious that using only these two features is not enough. There
bodyText ||| are cases in which all the lines have the same font size (i.e., the
bodyText ||| largest font size), or cases in which the lines with the largest font
bodyText ||| size only contain general descriptions like ‘Confidential’, ‘White
bodyText ||| paper’, etc. For those cases, the ‘largest font size’ method cannot
bodyText ||| work well. For similar reasons, the ‘first line’ method alone
bodyText ||| cannot work well, either. With the combination of different
bodyText ||| features (evidence in title judgment), Perceptron can outperform
bodyText ||| Largest and First.
bodyText ||| We investigate the performance of solely using linguistic features.
bodyText ||| We found that it does not work well. It seems that the format
bodyText ||| features play important roles and the linguistic features are
bodyText ||| supplements..
bodyText ||| We conducted an error analysis on the results of Perceptron. We
bodyText ||| found that the errors fell into three categories. (1) About one third
bodyText ||| of the errors were related to ‘hard cases’. In these documents, the
bodyText ||| layouts of the first pages were difficult to understand, even for
bodyText ||| humans. Figure 8 and 9 shows examples. (2) Nearly one fourth of
bodyText ||| the errors were from the documents which do not have true titles
bodyText ||| but only contain bullets. Since we conduct extraction from the top
bodyText ||| regions, it is difficult to get rid of these errors with the current
bodyText ||| approach. (3). Confusions between main titles and subtitles were
bodyText ||| another type of error. Since we only labeled the main titles as
bodyText ||| titles, the extractions of both titles were considered incorrect. This
bodyText ||| type of error does little harm to document processing like search,
bodyText ||| however.
subsectionHeader ||| 6.5 Comparison between Models
bodyText ||| To compare the performance of different machine learning models,
bodyText ||| we conducted another experiment. Again, we perform 4-fold cross
figureCaption ||| Figure 8. An example Word document.
figureCaption ||| Figure 9. An example PowerPoint document.
page ||| 151
bodyText ||| validation on the first data set (MS). Table 7, 8 shows the results
bodyText ||| of all the four models.
bodyText ||| It turns out that Perceptron and PMM perform the best, followed
bodyText ||| by MEMM, and ME performs the worst. In general, the
bodyText ||| Markovian models perform better than or as well as their classifier
bodyText ||| counterparts. This seems to be because the Markovian models are
bodyText ||| trained globally, while the classifiers are trained locally. The
bodyText ||| Perceptron based models perform better than the ME based
bodyText ||| counterparts. This seems to be because the Perceptron based
bodyText ||| models are created to make better classifications, while ME
bodyText ||| models are constructed for better prediction.
tableCaption ||| Table 7. Comparison between different learning models for
table ||| title extraction with Word
table ||| Model	Precision	Recall	F1
table ||| Perceptron	0.810	0.837	0.823
table ||| MEMM	0.797	0.824	0.810
table ||| PMM	0.827	0.823	0.825
table ||| ME	0.801	0.621	0.699
tableCaption ||| Table 8. Comparison between different learning models for
table ||| title extraction with PowerPoint
table ||| Model	Precision	Recall	F1
table ||| Perceptron	0.875	0. 895	0. 885
table ||| MEMM	0.841	0.861	0.851
table ||| PMM	0.873	0.896	0.885
table ||| ME	0.753	0.766	0.759
subsectionHeader ||| 6.6 Domain Adaptation
bodyText ||| We apply the model trained with the first data set (MS) to the
bodyText ||| second data set (DotCom and DotGov). Tables 9-12 show the
bodyText ||| results.
tableCaption ||| Table 9. Accuracies of title extraction with Word in DotGov
table ||| 		Precision	Recall	F1
table ||| Model	Perceptron	0.716	0.759	0.737
table ||| Baselines	Largest font size	0.549	0.619	0.582
table ||| 	First line	0.462	0.521	0.490
tableCaption ||| Table 10. Accuracies of title extraction with PowerPoint in
table ||| DotGov
table ||| 		Precision	Recall	F1
table ||| Model	Perceptron	0.900	0.906	0.903
table ||| Baselines	Largest font size	0.871	0.888	0.879
table ||| 	First line	0.554	0.564	0.559
tableCaption ||| Table 11. Accuracies of title extraction with Word in DotCom
table ||| 		Precisio	Recall	F1
table ||| 		n
table ||| Model	Perceptron	0.832	0.880	0.855
table ||| Baselines	Largest font size	0.676	0.753	0.712
table ||| 	First line	0.577	0.643	0.608
tableCaption ||| Table 12. Performance of PowerPoint document title
table ||| extraction in DotCom
table ||| 		Precisio	Recall	F1
table ||| 		n
table ||| Model	Perceptron	0.910	0.903	0.907
table ||| Baselines	Largest font size	0.864	0.886	0.875
table ||| 	First line	0.570	0.585	0.577
bodyText ||| From the results, we see that the models can be adapted to
bodyText ||| different domains well. There is almost no drop in accuracy. The
bodyText ||| results indicate that the patterns of title formats exist across
bodyText ||| different domains, and it is possible to construct a domain
bodyText ||| independent model by mainly using formatting information.
subsectionHeader ||| 6.7 Language Adaptation
bodyText ||| We apply the model trained with the data in English (MS) to the
bodyText ||| data set in Chinese.
bodyText ||| Tables 13-14 show the results.
tableCaption ||| Table 13. Accuracies of title extraction with Word in Chinese
table ||| 		Precision	Recall	F1
table ||| Model	Perceptron	0.817	0.805	0.811
table ||| Baselines	Largest font size	0.722	0.755	0.738
table ||| 	First line	0.743	0.777	0.760
tableCaption ||| Table 14. Accuracies of title extraction with PowerPoint in
tableCaption ||| Chinese
table ||| 		Precision	Recall	F1
table ||| Model	Perceptron	0.766	0.812	0.789
table ||| Baselines	Largest font size	0.753	0.813	0.782
table ||| 	First line	0.627	0.676	0.650
bodyText ||| We see that the models can be adapted to a different language.
bodyText ||| There are only small drops in accuracy. Obviously, the linguistic
bodyText ||| features do not work for Chinese, but the effect of not using them
bodyText ||| is negligible. The results indicate that the patterns of title formats
bodyText ||| exist across different languages.
bodyText ||| From the domain adaptation and language adaptation results, we
bodyText ||| conclude that the use of formatting information is the key to a
bodyText ||| successful extraction from general documents.
subsectionHeader ||| 6.8 Search with Extracted Titles
bodyText ||| We performed experiments on using title extraction for document
bodyText ||| retrieval. As a baseline, we employed BM25 without using
bodyText ||| extracted titles. The ranking mechanism was as described in
bodyText ||| Section 5. The weights were heuristically set. We did not conduct
bodyText ||| optimization on the weights.
bodyText ||| The evaluation was conducted on a corpus of 1.3 M documents
bodyText ||| crawled from the intranet of Microsoft using 100 evaluation
bodyText ||| queries obtained from this intranet’s search engine query logs. 50
bodyText ||| queries were from the most popular set, while 50 queries other
bodyText ||| were chosen randomly. Users were asked to provide judgments of
bodyText ||| the degree of document relevance from a scale of 1to 5 (1
bodyText ||| meaning detrimental, 2 – bad, 3 – fair, 4 – good and 5 – excellent).
page ||| 152
bodyText ||| Figure 10 shows the results. In the chart two sets of precision
bodyText ||| results were obtained by either considering good or excellent
bodyText ||| documents as relevant (left 3 bars with relevance threshold 0.5), or
bodyText ||| by considering only excellent documents as relevant (right 3 bars
bodyText ||| with relevance threshold 1.0)
figure ||| Name All
figureCaption ||| Figure 10. Search ranking results.
bodyText ||| Figure 10 shows different document retrieval results with different
bodyText ||| ranking functions in terms of precision @10, precision @5 and
bodyText ||| reciprocal rank:
listItem ||| •	Blue bar – BM25 including the fields body, title (file
listItem ||| property), and anchor text.
listItem ||| •	Purple bar – BM25 including the fields body, title (file
bodyText ||| property), anchor text, and extracted title.
bodyText ||| With the additional field of extracted title included in BM25 the
bodyText ||| precision @10 increased from 0.132 to 0.145, or by ~10%. Thus,
bodyText ||| it is safe to say that the use of extracted title can indeed improve
bodyText ||| the precision of document retrieval.
sectionHeader ||| 7. CONCLUSION
bodyText ||| In this paper, we have investigated the problem of automatically
bodyText ||| extracting titles from general documents. We have tried using a
bodyText ||| machine learning approach to address the problem.
bodyText ||| Previous work showed that the machine learning approach can
bodyText ||| work well for metadata extraction from research papers. In this
bodyText ||| paper, we showed that the approach can work for extraction from
bodyText ||| general documents as well. Our experimental results indicated that
bodyText ||| the machine learning approach can work significantly better than
bodyText ||| the baselines in title extraction from Office documents. Previous
bodyText ||| work on metadata extraction mainly used linguistic features in
bodyText ||| documents, while we mainly used formatting information. It
bodyText ||| appeared that using formatting information is a key for
bodyText ||| successfully conducting title extraction from general documents.
bodyText ||| We tried different machine learning models including Perceptron,
bodyText ||| Maximum Entropy, Maximum Entropy Markov Model, and Voted
bodyText ||| Perceptron. We found that the performance of the Perceptorn
bodyText ||| models was the best. We applied models constructed in one
bodyText ||| domain to another domain and applied models trained in one
bodyText ||| language to another language. We found that the accuracies did
bodyText ||| not drop substantially across different domains and across
bodyText ||| different languages, indicating that the models were generic. We
bodyText ||| also attempted to use the extracted titles in document retrieval. We
bodyText ||| observed a significant improvement in document ranking
bodyText ||| performance for search when using extracted title information. All
bodyText ||| the above investigations were not conducted in previous work, and
bodyText ||| through our investigations we verified the generality and the
bodyText ||| significance of the title extraction approach.
sectionHeader ||| 8. ACKNOWLEDGEMENTS
bodyText ||| We thank Chunyu Wei and Bojuan Zhao for their work on data
bodyText ||| annotation. We acknowledge Jinzhu Li for his assistance in
bodyText ||| conducting the experiments. We thank Ming Zhou, John Chen,
bodyText ||| Jun Xu, and the anonymous reviewers of JCDL’05 for their
bodyText ||| valuable comments on this paper.
sectionHeader ||| 9. REFERENCES
reference ||| [1] Berger, A. L., Della Pietra, S. A., and Della Pietra, V. J. A
reference ||| maximum entropy approach to natural language processing.
reference ||| Computational Linguistics, 22:39-71, 1996.
reference ||| [2] Collins, M. Discriminative training methods for hidden
reference ||| markov models: theory and experiments with perceptron
reference ||| algorithms. In Proceedings of Conference on Empirical
reference ||| Methods in Natural Language Processing, 1-8, 2002.
reference ||| [3] Cortes, C. and Vapnik, V. Support-vector networks. Machine
reference ||| Learning, 20:273-297, 1995.
reference ||| [4] Chieu, H. L. and Ng, H. T. A maximum entropy approach to
reference ||| information extraction from semi-structured and free text. In
reference ||| Proceedings of the Eighteenth National Conference on
reference ||| Artificial Intelligence, 768-791, 2002.
reference ||| [5] Evans, D. K., Klavans, J. L., and McKeown, K. R. Columbia
reference ||| newsblaster: multilingual news summarization on the Web.
reference ||| In Proceedings of Human Language Technology conference /
reference ||| North American chapter of the Association for
reference ||| Computational Linguistics annual meeting, 1-4, 2004.
reference ||| [6] Ghahramani, Z. and Jordan, M. I. Factorial hidden markov
reference ||| models. Machine Learning, 29:245-273, 1997.
reference ||| [7] Gheel, J. and Anderson, T. Data and metadata for finding and
reference ||| reminding, In Proceedings of the 1999 International
reference ||| Conference on Information Visualization, 446-451,1999.
reference ||| [8] Giles, C. L., Petinot, Y., Teregowda P. B., Han, H.,
reference ||| Lawrence, S., Rangaswamy, A., and Pal, N. eBizSearch: a
reference ||| niche search engine for e-Business. In Proceedings of the
reference ||| 26th Annual International ACM SIGIR Conference on
reference ||| Research and Development in Information Retrieval, 413-
reference ||| 414, 2003.
reference ||| [9] Giuffrida, G., Shek, E. C., and Yang, J. Knowledge-based
reference ||| metadata extraction from PostScript files. In Proceedings of
reference ||| the Fifth ACM Conference on Digital Libraries, 77-84, 2000.
reference ||| [ 10] Han, H., Giles, C. L., Manavoglu, E., Zha, H., Zhang, Z., and
reference ||| Fox, E. A. Automatic document metadata extraction using
reference ||| support vector machines. In Proceedings of the Third
reference ||| ACM/IEEE-CS Joint Conference on Digital Libraries, 37-48,
reference ||| 2003.
reference ||| [1 1 ] Kobayashi, M., and Takeda, K. Information retrieval on the
reference ||| Web. ACM Computing Surveys, 32:144-173, 2000.
reference ||| [ 12] Lafferty, J., McCallum, A., and Pereira, F. Conditional
reference ||| random fields: probabilistic models for segmenting and
figure ||| 0.45
figure ||| BM25 AnchorTitle, Body
figure ||| BM25 AnchorTitle, Body ExtractedTitle
figure ||| 0.4
figure ||| 0.35
figure ||| 0.3
figure ||| 0.25
figure ||| 0.2
figure ||| 0.15
figure ||| 0.1
figure ||| 0.05
figure ||| 0
figure ||| P@10	P@5	ReciprocalP@10	P@5	Reciprocal
figure ||| 0.5	1
figure ||| RelevanceThreshold Data
figure ||| Description
page ||| 153
reference ||| labeling sequence data. In Proceedings of the Eighteenth
reference ||| International Conference on Machine Learning, 282-289,
reference ||| 2001.
reference ||| [13] Li, Y., Zaragoza, H., Herbrich, R., Shawe-Taylor J., and
reference ||| Kandola, J. S. The perceptron algorithm with uneven margins.
reference ||| In Proceedings of the Nineteenth International Conference
reference ||| on Machine Learning, 379-386, 2002.
reference ||| [14] Liddy, E. D., Sutton, S., Allen, E., Harwell, S., Corieri, S.,
reference ||| Yilmazel, O., Ozgencil, N. E., Diekema, A., McCracken, N.,
reference ||| and Silverstein, J. Automatic Metadata generation &
reference ||| evaluation. In Proceedings of the 25th Annual International
reference ||| ACM SIGIR Conference on Research and Development in
reference ||| Information Retrieval, 401-402, 2002.
reference ||| [15] Littlefield, A. Effective enterprise information retrieval
reference ||| across new content formats. In Proceedings of the Seventh
reference ||| Search Engine Conference,
reference ||| http://www.infonortics.com/searchengines/sh02/02prog.html,
reference ||| 2002.
reference ||| [16] Mao, S., Kim, J. W., and Thoma, G. R. A dynamic feature
reference ||| generation system for automated metadata extraction in
reference ||| preservation of digital materials. In Proceedings of the First
reference ||| International Workshop on Document Image Analysis for
reference ||| Libraries, 225-232, 2004.
reference ||| [17] McCallum, A., Freitag, D., and Pereira, F. Maximum entropy
reference ||| markov models for information extraction and segmentation.
reference ||| In Proceedings of the Seventeenth International Conference
reference ||| on Machine Learning, 591-598, 2000.
reference ||| [ 18] Murphy, L. D. Digital document metadata in organizations:
reference ||| roles, analytical approaches, and future research directions.
reference ||| In Proceedings of the Thirty-First Annual Hawaii
reference ||| International Conference on System Sciences, 267-276, 1998.
reference ||| [19] Pinto, D., McCallum, A., Wei, X., and Croft, W. B. Table
reference ||| extraction using conditional random fields. In Proceedings of
reference ||| the 26th Annual International ACM SIGIR Conference on
reference ||| Research and Development in Information Retrieval, 235-
reference ||| 242, 2003.
reference ||| [20] Ratnaparkhi, A. Unsupervised statistical models for
reference ||| prepositional phrase attachment. In Proceedings of the
reference ||| Seventeenth International Conference on Computational
reference ||| Linguistics. 1079-1085, 1998.
reference ||| [21] Robertson, S., Zaragoza, H., and Taylor, M. Simple BM25
reference ||| extension to multiple weighted fields, In Proceedings of
reference ||| ACM Thirteenth Conference on Information and Knowledge
reference ||| Management, 42-49, 2004.
reference ||| [22] Yi, J. and Sundaresan, N. Metadata based Web mining for
reference ||| relevance, In Proceedings of the 2000 International
reference ||| Symposium on Database Engineering & Applications, 113-
reference ||| 121, 2000.
reference ||| [23] Yilmazel, O., Finneran, C. M., and Liddy, E. D. MetaExtract:
reference ||| An NLP system to automatically assign metadata. In
reference ||| Proceedings of the 2004 Joint ACM/IEEE Conference on
reference ||| Digital Libraries, 241-242, 2004.
reference ||| [24] Zhang, J. and Dimitroff, A. Internet search engines' response
reference ||| to metadata Dublin Core implementation. Journal of
reference ||| Information Science, 30:310-320, 2004.
reference ||| [25] Zhang, L., Pan, Y., and Zhang, T. Recognising and using
reference ||| named entities: focused named entity recognition using
reference ||| machine learning. In Proceedings of the 27th Annual
reference ||| International ACM SIGIR Conference on Research and
reference ||| Development in Information Retrieval, 281-288, 2004.
reference ||| [26] http://dublincore.org/groups/corporate/Seattle/
page ||| 154

title ||| A Dependability Perspective on Emerging Technologies
author ||| Lucian Prodan	Mihai Udrescu	Mircea Vladutiu
affiliation ||| Advanced Computing Systems and Architectures (ACSA) Laboratory,
affiliation ||| Computer Science and Engineering Department, “Politehnica” University of Timisoara,
address ||| 2 V.Parvan Blvd, 300223 Timisoara, Romania
note ||| www.acsa.upt.ro
address ||| +40-722-664779	+40-723-154989	+40-256-403258
email ||| lprodan@cs.upt.ro	mudrescu@cs.upt.ro	mvlad@cs.upt.ro
sectionHeader ||| ABSTRACT
bodyText ||| Emerging technologies are set to provide further provisions for
bodyText ||| computing in times when the limits of current technology of
bodyText ||| microelectronics become an ever closer presence. A technology
bodyText ||| roadmap document lists biologically-inspired computing and
bodyText ||| quantum computing as two emerging technology vectors for novel
bodyText ||| computing architectures [43]. But the potential benefits that will
bodyText ||| come from entering the nanoelectronics era and from exploring
bodyText ||| novel nanotechnologies are foreseen to come at the cost of
bodyText ||| increased sensitivity to influences from the surrounding
bodyText ||| environment. This paper elaborates on a dependability perspective
bodyText ||| over these two emerging technology vectors from a designer’s
bodyText ||| standpoint. Maintaining or increasing the dependability of
bodyText ||| unconventional computational processes is discussed in two
bodyText ||| different contexts: one of a bio-inspired computing architecture
bodyText ||| (the Embryonics project) and another of a quantum computational
bodyText ||| architecture (the QUERIST project).
sectionHeader ||| Categories and Subject Descriptors
category ||| B.8.1 [Performance and Reliability]: Reliability, Testing, and
category ||| Fault-Tolerance.
category ||| C.4 [Performance of Systems]: Fault-Tolerance, Reliability,
category ||| Availability, and Serviceability.
sectionHeader ||| General Terms
keyword ||| Design, Reliability, Theory.
sectionHeader ||| Keywords
keyword ||| Dependability, emerging technologies, evolvable hardware, bio-
keyword ||| inspired computing, bio-inspired digital design, Embryonics,
keyword ||| reliability, quantum computing, fault-tolerance assessment.
sectionHeader ||| 1. INTRODUCTION
bodyText ||| High-end computing has reached nearly every corner of our
bodyText ||| present day life, in a variety of forms taylored to accommodate
bodyText ||| either general purpose or specialized applications. Computers
copyright ||| Permission to make digital or hard copies of all or part of this work for
copyright ||| personal or classroom use is granted without fee provided that copies are
copyright ||| not made or distributed for profit or commercial advantage and that
copyright ||| copies bear this notice and the full citation on the first page. To copy
copyright ||| otherwise, or republish, to post on servers or to redistribute to lists,
copyright ||| requires prior specific permission and/or a fee.
note ||| CF’06, May 3–5, 2006, Ischia, Italy.
copyright ||| Copyright 2006 ACM 1-59593-302-6/06/0005...$5.00.
copyright ||| may be considerred as fine exponents of the present days’
copyright ||| technological wave – if not their finest, they certainly do count as
copyright ||| solid, indispensable support for the finest.
bodyText ||| From the very beginning of the computing advent, the main target
bodyText ||| was squeezing out any additional performance. The inception
bodyText ||| period was not always trouble-free, accurate computation results
bodyText ||| being required at an ever faster pace on a road that has become
bodyText ||| manifold: some applications do require computational speed as a
bodyText ||| top priority; others are set for the highest possible dependability,
bodyText ||| while still delivering sufficient performance levels.
bodyText ||| Several definitions for dependability have been proposed: “the
bodyText ||| ability of a system to avoid service failures that are more frequent
bodyText ||| or more severe than is acceptable” [2], or “the property of a
bodyText ||| computer system such that reliance can justifiably be placed on
bodyText ||| the service it delivers” [9][45]. Dependability is therefore a
bodyText ||| synthetic term specifying a qualitative system descriptor that can
bodyText ||| generally be quantified through a list of attributes including
bodyText ||| reliability, fault tolerance, availability, and others.
bodyText ||| In real world, a dependable system would have to operate
bodyText ||| normally over extended periods of time before experiencing any
bodyText ||| fail (reliability, availability) and to recover quickly from errors
bodyText ||| (fault tolerance, self-test and self-repair). The term “acceptable”
bodyText ||| has an essential meaning within the dependability’s definition,
bodyText ||| setting the upper limits of the damages that can be supported by
bodyText ||| the system while still remaining functional or computationally
bodyText ||| accurate. A dependability analysis should take into consideration
bodyText ||| if not quantitative figures for the acceptable damage limit, at least
bodyText ||| a qualitative parameter representation for its attributes.
bodyText ||| Dependable systems are therefore crucial for applications that
bodyText ||| prohibit or limit human interventions, such as long-term exposure
bodyText ||| to aggressive (or even hostile) environments. The best examples
bodyText ||| are long term operating machines as required by managing deep-
bodyText ||| underwater/nuclear activities and outer space exploration.
bodyText ||| There are three main concerns that should be posed through a
bodyText ||| system’s design in order to achieve high dependability [42]:
listItem ||| 1. Specifying the dependability requirements: selecting the
listItem ||| dependability requirements that have to be pursued in
listItem ||| building the computing system, based on known or assumed
listItem ||| goals for the part of the world that is directly affected by the
listItem ||| computing system;
listItem ||| 2. Designing and implementing the computing system so as to
listItem ||| achieve the dependability required. However, this step is hard
listItem ||| to implement since the system reliability cannot be satisfied
page ||| 187
bodyText ||| simply from careful design. Some techniques can be used to
bodyText ||| help to achieve this goal, such as using fault injection to
bodyText ||| evaluate the design process.
listItem ||| 3. Validating a system: gaining confidence that a certain
listItem ||| dependability requirement/goal has been attained.
bodyText ||| This paper will address these main concerns through an attempt to
bodyText ||| provide an in-depth view over modern computing directions and
bodyText ||| paradigms, which we consider to be representative for the efforts
bodyText ||| involved in improving overall dependability.
subsectionHeader ||| 1.1 Motivations
bodyText ||| We have listed some of the applications of dependable computing
bodyText ||| systems as linked to activities that take place in special
bodyText ||| environments, such as deep underwater or outer space. At a very
bodyText ||| first sight, these applications would appear specific enough to not
bodyText ||| encourage a specific design for dependability approach in
bodyText ||| computing. However, evidence suggest this is hardly the case; on
bodyText ||| the contrary, it is difficult to imagine a domain left unconquered
bodyText ||| by computer systems during times when industrial, transport,
bodyText ||| financial services and others do rely heavily on accurate computer
bodyText ||| operation at any given moment. If computer innacuracies could be
bodyText ||| more easily overlooked at home, professional environments
bodyText ||| cannot accept such missbehaviors.
bodyText ||| Yet the recent history of computing provides evidence that
bodyText ||| dependability is not a sine qua non feature. During their life
bodyText ||| cycle, electronic devices constantly suffer a number of influences
bodyText ||| that manifest predominantly over transient regimes, which in turn
bodyText ||| introduce a variety of errors unified in the literature under the
bodyText ||| name of transient faults, soft errors or single event upsets (SEUs).
bodyText ||| The rate electronic devices are affected with is known under the
bodyText ||| term of soft error rate or simply SER and is measured in fails per
bodyText ||| unit time. Because it relies on transient phenomena due to
bodyText ||| changing states and logical values, digital electronics makes up
bodyText ||| for a special category that is also affected by soft errors. No
bodyText ||| matter the name they are referred under, these errors affect the
bodyText ||| computing processes and are due to electromagnetic noise and/or
bodyText ||| external radiations rather than design or manufacturing flaws [28].
bodyText ||| One cause at the origin of soft fails affecting digital devices is
bodyText ||| known to be due to radioactive decay processes. Radioactive
bodyText ||| isotopes, widely used for a range of purposes, might contaminate
bodyText ||| semiconductor materials leading to soft errors; evidence is
bodyText ||| available throughout the literature, both by empirical observations
bodyText ||| and experimental results [20]. Consequently, cosmic rays,
bodyText ||| containing a broad range of energized atomic/subatomic particles
bodyText ||| may lead to the appearance of soft fails.
bodyText ||| Computers therefore are susceptive to soft errors, an issue that
bodyText ||| will potentially become essential with the advent of emerging
bodyText ||| technologies. As acknowledged by the International Technology
bodyText ||| Roadmap for Semiconductors (ITRS), issued at the end of 2004
bodyText ||| [43], the microelectronics industry faces a challenging task in
bodyText ||| going to and beyond 45nm scale in order to address “beyond
bodyText ||| CMOS” applications. Scaling down the technology will enable an
bodyText ||| extremely large number of devices to be integrated onto the same
bodyText ||| chip. However, the great challenge will be to ensure the new
bodyText ||| devices will be operational at this scale [6], since they will exhibit
bodyText ||| a sensitive behavior to soft fails. In order to address the negative
bodyText ||| effects brought by technology scaling, it is to be expected that
bodyText ||| significant control resources will need to be implemented [3].
bodyText ||| Another challenging aspect concerning emerging technologies is
bodyText ||| to match the newly developed device technologies with new
bodyText ||| system architectures, a synergistic/collaborative development of
bodyText ||| the two being seen as likely to be very rewarding. The potential of
bodyText ||| biologically-inspired and quantum computing architectures is
bodyText ||| acknowledged by the ITRS report on emerging technologies [43]
bodyText ||| (see Figure 1). This paper will investigate the relevance of soft
bodyText ||| fails and attempt to provide means of harnessing their negative
bodyText ||| effects on modern computing in the context of biologically-
bodyText ||| inspired and quantum computing architectures.
figureCaption ||| Figure 1: Bio-inspired and quantum computing are
bodyText ||| acknowledged as architectural technology vectors in emerging
bodyText ||| technologies [43]
subsectionHeader ||| 1.2 Paper Outline
bodyText ||| This paper is structured as follows. Section 2 will address the first
bodyText ||| main concern, that is, specifying and selecting dependability
bodyText ||| requirements that will have to be pursued when building a
bodyText ||| computational platform. Parameters that describe and quantify
bodyText ||| dependability attributes, such as reliability, will be introduced,
bodyText ||| with a highlight on their accepted models and their issues. A
bodyText ||| particular consideration will be given to the failure rate parameter,
bodyText ||| which is the basis of all reliability analyses.
bodyText ||| Section 3 will approach some of the means for design for
bodyText ||| dependability; it will therefore elaborate upon two emerging
bodyText ||| technology vectors, as seen by the ITRS report [43], which define
bodyText ||| two novel architectures, namely biologically-inspired (or bio-
bodyText ||| inspired) and quantum computing. We will introduce two projects
bodyText ||| and their corresponding architectures, called Embryonics (as a
bodyText ||| biologically-inspired computing platform) and QUERIST (as a
bodyText ||| quantum computing platform designed to allow and study error
bodyText ||| injection). These two architectures are representative for the
bodyText ||| coming age of nano-computing, where computational processes
bodyText ||| take place as encoded at the very inner core level of matter, be it
bodyText ||| semiconductor material (for nanoelectronics, targetted here by the
bodyText ||| Embryonics project) or atomic scale dynamics (for quantum
bodyText ||| computing, targetted here by the QUERIST project). This section
bodyText ||| will then introduce dependability aspects within bio-inspired
bodyText ||| computing (the Embryonics project being investigated in
bodyText ||| SubSection 3.1) and within quantum computing (the QUERIST
bodyText ||| project being investigated in SubSection 3.2).
bodyText ||| Finally, Section 4 will present the conclusions and prospects for
bodyText ||| designing emerging technology dependable computing systems,
bodyText ||| as we see them.
page ||| 188
sectionHeader ||| 2. DEPENDABILITY ATTRIBUTES
bodyText ||| An important dependability attribute for any given system lies in
bodyText ||| its capacity to operate reliably for a given time interval, knowing
bodyText ||| that normal operation was delivered at initial time [8]. Reliability
bodyText ||| functions are modelled as exponential functions of parameter A,
bodyText ||| which is the failure rate. The reliability of a system is the
bodyText ||| consequence of the reliability of all of its subsystems. The
bodyText ||| heterogeneity of the system leads to a difficult quantitative
bodyText ||| assessment of its overall reliability; moreover, estimating the
bodyText ||| reliability functions is further made difficult because formal
bodyText ||| rigour is not commercially available, this being kept under
bodyText ||| military mandate [44].
bodyText ||| The failure rate for a given system can be modelled as a function
bodyText ||| of the failure rates of its individual subsystems, suggestions being
bodyText ||| present in the MIL-HDBC-217 document, which is publicly
bodyText ||| available [44]. However, this document has been strongly
bodyText ||| criticized for its failure rate estimations based on the Arrhenius
bodyText ||| model, which relates the failure rate to the operating temperature:
bodyText ||| where K is a constant, KB is Boltzmann’s constant, T is the
bodyText ||| absolute temperature and E is the “activation energy” for the
bodyText ||| process [18]. Quantitative values for failure rates show significant
bodyText ||| differences between those predicted using MIL-HDBC-217 and
bodyText ||| those from testing real devices (see Figure 2). There are two
bodyText ||| conclusions that can be drawn from this:
listItem ||| 1. quantitative estimations for failure rate values are strongly
listItem ||| dependant on the quality of information used; unfortunately,
listItem ||| current reliable information about electronic devices is known
listItem ||| to be lacking [44];
listItem ||| 2. despite differences between predicted and real values, the
listItem ||| MIL-HDBC-217 methodology can be useful for qualitative
listItem ||| analyses in order to take decisions regarding sub-system parts
listItem ||| that should benefit from improved designs.
figureCaption ||| Figure 2. Predicted vs real failure rates plotted against
bodyText ||| temperature [18]
bodyText ||| So far the failure rate of digital devices has been considerred as
bodyText ||| due to internal causes. However, this is not always the case, soft
bodyText ||| fails being equally present due to the aggressive influences of the
bodyText ||| external environment, which also have to be modelled [22]. The
bodyText ||| external envirnment features highly dynamic changes in its
bodyText ||| parameters, which will eventually affect the normal operation of
bodyText ||| digital devices that lack sufficient protection or ability to adapt.
bodyText ||| Ideally, computing devices would behave in a consistent and
bodyText ||| accurate manner regardless of fluctuations in environmental
bodyText ||| parameters. This is either a consequence of soft error mitigation
bodyText ||| techniques or due to flexible hardware/software functionality that
bodyText ||| allow the system as a whole to adapt to environamental changes
bodyText ||| and tolerate induced faults.
bodyText ||| While certain soft error mitigation techniques are available, the
bodyText ||| technology scaling towards nanoelectronics affects their
bodyText ||| efficiency by integrating a larger number of devices per chip
bodyText ||| (which requires a larger amount of redundant/control logic or
bodyText ||| other measures), which feature, at the same time, smaller
bodyText ||| dimensions (which renders an electronic device much more
bodyText ||| senzitive to the influence of stray energetic particles that reach it
bodyText ||| as part of cosmic rays). Both aspects are involved in the
bodyText ||| development of the two emerging technology vectors mentioned
bodyText ||| in SubSection 1.1, although having slightly different motivations:
bodyText ||| while the nature of the quantum environment prohibits precise
bodyText ||| computation in the absence of fault tolerance techniques, such
bodyText ||| techniques are targetted by bio-inspired computing as means of
bodyText ||| improving the dependability of a computing platform.
subsectionHeader ||| 2.1 Bio-Inspired Computing
bodyText ||| If living beings may be considered to fulfill computational tasks,
bodyText ||| then Nature is the ultimate engineer: each of the living beings
bodyText ||| exhibit solutions that were successfully tested and refined in such
bodyText ||| ways human engineers will never afford. One reason is time: the
bodyText ||| testing period coinciding with the very existence of life itself.
bodyText ||| Another reason is variety and complexity: Nature has found and
bodyText ||| adapted a variety of solutions to address complex survivability
bodyText ||| issues in a dynamically changing environment. No matter how
bodyText ||| Nature approached the process of evolution, engineering could
bodyText ||| perhaps benefit most from drawing inspiration from its
bodyText ||| mechanisms rather from trying to develop particular techniques.
bodyText ||| Bio-inspired computing is not a new idea. John von Neumann was
bodyText ||| preoccupied to design a machine that could replicate itself and
bodyText ||| was quite interested in the study of how the behavior of the
bodyText ||| human brain could be implemented by a computer [13][14]. He
bodyText ||| also pioneered the field of dependable computing by studying the
bodyText ||| possibility of building reliable machines out of unreliable
bodyText ||| components [15]. Unfortunately, the dream of implementing his
bodyText ||| self-reproducing automata could not become true until the 1990s,
bodyText ||| when massively programmable logic opened the new era of
bodyText ||| reconfigurable computing.
bodyText ||| But when trying to adapt nature’s mechanisms in digital devices,
bodyText ||| it becomes most evident that biological organisms are rightfully
bodyText ||| the most intricate structures known to man. They continuously
bodyText ||| demonstrate a highly complex behavior due to massive, parallel
bodyText ||| cooperation between huge numbers of relatively simple elements,
bodyText ||| the cells. And considering uncountable variety of living beings,
bodyText ||| with a life span up to several hundreds (for the animal regnum) or
bodyText ||| even thousands (for the vegetal regnum) of years, it seems nature
bodyText ||| is the closest spring of inspiration for designing dependable, fault
bodyText ||| tolerant systems.
bodyText ||| Investigating the particularities of natural systems, a taxonomy of
bodyText ||| three categories of processes can be identified [32]:
listItem ||| 1. Phylogenetic processes constitute the first level of
listItem ||| organization of the living matter. They are concerned with the
listItem ||| temporal evolution of the genetic heritage of all individuals,
none ||| E
equation ||| λ= Ke KBT	(1)
equation ||| −
page ||| 189
bodyText ||| therefore mastering the evolution of all species. The
bodyText ||| phylogenetic processes rely on mechanisms such as
bodyText ||| recombination and mutation, which are essentially
bodyText ||| nondeterministic; the error rate ensures here nature’s
bodyText ||| diversity.
listItem ||| 2. Ontogenetic processes represent the second level of
listItem ||| organization of the living matter. They are also concerned
listItem ||| with the temporal evolution of the genetic heritage of, in this
listItem ||| case, a single, multicellular individual, therefore mastering an
listItem ||| individual’s development from the stage of a single cell, the
listItem ||| zygote, through succesive cellular division and specialization,
listItem ||| to the adult stage. These processes rely on deterministic
listItem ||| mechanisms; any error at this level results in malformations.
listItem ||| 3. Epigenetic processes represent the third level of organization
listItem ||| of the living matter. They are concerned with the integration
listItem ||| of interactions with the surrounding environment therefore
listItem ||| resulting in what we call learning systems.
bodyText ||| This taxonomy is important in that it provides a model called POE
bodyText ||| (from Phylogeny, Ontogeny and Epigenesis) that inspires the
bodyText ||| combination of processes in order to create novel bio-inspired
bodyText ||| hardware (see Figure 3). We believe this is also important from a
bodyText ||| dependability engineering perspective, for the following reasons:
listItem ||| 1. Phylogenetic processes were assimilated by modern
listItem ||| computing as evolutionary computation, including genetic
listItem ||| algorithms and genetic programming. The essence of any
listItem ||| genetic algorithm is the derivation of a solution space based
listItem ||| on recombination, crossover and mutation processes that
listItem ||| spawn a population of individuals, each encoding a possible
listItem ||| solution. One may consider that each such step, with the
listItem ||| exception of discovering the solution, is equivalent to a
listItem ||| process of error injection, which in turn leads to wandering
listItem ||| from the optimal solution (or class of solutions). However,
listItem ||| genetic algorithms prove to be successful despite this error
listItem ||| injection, the fitness function being responsible for the
listItem ||| successful quantification of the significance of the “error”.
listItem ||| Therefore genetic computation is intrinsicaly resilient to
listItem ||| faults and errors, largely due to the fact that they are part of
listItem ||| the very process that generates the solutions.
listItem ||| 2. Ontogenetic processes have been implemented in digital
listItem ||| hardware with modular and uniform architectures. Such an
listItem ||| architecture enables the implementation of mechanisms
listItem ||| similar to the cellular division and cellular differentiation that
listItem ||| take place in living beings [31]. These mechanisms bring the
listItem ||| advantage of distributed and hierarchical fault tolerance
listItem ||| strategies: the uniformity of the architecture also makes any
listItem ||| module to be universal, that is, to be able to take over the role
listItem ||| of any other damaged module.
listItem ||| 3. Epigenetic processes were assimilated by modern computing
listItem ||| mainly as artificial neural networks (or ANNs) as inspired by
listItem ||| the nervous system, and much less as inspired by the immune
listItem ||| or endocrine systems from superior multicellular living
listItem ||| beings. ANNs are known to have a generalization capacity,
listItem ||| that is, to respond well even if the input patterns are not part
listItem ||| of the patterns used during the learning phase. This means that
listItem ||| ANNs possess a certain ability to tolerante faults, whether
listItem ||| they manifest at the inputs or inside their intenal architecture.
bodyText ||| With the advent of field programmable logic (of which the most
bodyText ||| salient representative are the FPGAs) it is now possible to change
bodyText ||| hardware functionality through software, thus allowing
bodyText ||| information to govern matter in digital electronics. This is not
bodyText ||| dissimilar to what happens in nature: information coded in DNA
bodyText ||| affects the development of an organism. A special kind of such
bodyText ||| digital devices that change dynamically their behavior are known
bodyText ||| as evolvable or adaptive hardware; they are bio-inspired
bodyText ||| computing systems whose behaviors may change according to
bodyText ||| computational targets, or, if harsh or unknown environments are
bodyText ||| to be explored, for the purpose of maximizing dependability.
figureCaption ||| Figure 3. The POE model of bio-inspired systems [32]
subsectionHeader ||| 2.2 Quantum Computing
bodyText ||| Error detection and correction techniques are vital in quantum
bodyText ||| computing due to the destructive effect of the environment, which
bodyText ||| therefore acts as an omnipresent error generator. Error detection
bodyText ||| and correction must provide a safe recovery process within
bodyText ||| quantum computing processes through keeping error propagation
bodyText ||| under control. Without such dependability techniques there could
bodyText ||| be no realistic prospect of an operational quantum computational
bodyText ||| device [19].
bodyText ||| There are two main sources of errors: the first is due to the
bodyText ||| erroneous behavior of the quantum gate, producing the so-called
bodyText ||| processing errors; the second is due to the macroscopic
bodyText ||| environment that interacts with the quantum state, producing the
bodyText ||| storing and transmitting errors.
bodyText ||| The consistency of any quantum computation process can be
bodyText ||| destroyed by innacuracies and errors if the error probability in the
bodyText ||| basic components (qubits, quantum gates) excedes an accuracy
bodyText ||| threshold. This is a critical aspect since the microscopic quantum
bodyText ||| states are prone to frequent errors.
bodyText ||| The main error source is the decoherence effect [16]. The
bodyText ||| environment is constantly attempting to measure the sensitive
bodyText ||| quantum superposition state, a phenomenon that cannot be
bodyText ||| avoided technologically since it is not (yet) possible to isolate
bodyText ||| them perfectly. The superposition state will decay through
bodyText ||| measuring and will therefore become a projection of the state
bodyText ||| vector onto a basis vector (or eigenstate). The most insidious
bodyText ||| error, however, appears when decoherence affects the quantum
bodyText ||| amplitudes without destroying them; this is similar to small
bodyText ||| analog errors. Issues stated above are solved, on one hand,
bodyText ||| through intrinsic fault tolerance by technological implementation
bodyText ||| (topological interactions [1]) and, on the other hand, by error
bodyText ||| correcting techniques at the unitary (gate network) level. We will
bodyText ||| focus on the error detecting and correcting techniques, which are
bodyText ||| difficult to approach due to quantum constraints: the useful state
page ||| 190
bodyText ||| can neither be observed (otherwise it will decohere), nor can it be
bodyText ||| cloned.
subsubsectionHeader ||| 2.2.1 Background
bodyText ||| As expressed in bra-ket notation [16], the qubit is a normalized
bodyText ||| vector in some Hilbert space H2 , { 0 , 1 } being the orthonormal
bodyText ||| basis: ψ = a0 0 + a1 1 ( a0, a1 ∈ C are the so-called quantum
bodyText ||| amplitudes, representing the square root of the associated
bodyText ||| measurement probabilities for the eigenstates
bodyText ||| respectively, with a0 2 + a1 2 =1). Therefore, the qubit can be
bodyText ||| affected by 3 types of errors:
bodyText ||| Bit flip errors are somewhat similar to classical bit flip errors. For
bodyText ||| a single qubit things are exactly the same as in classical
bodyText ||| computation: 0 H 1 , 1 H 0 . For 2 or more qubits, flip errors
bodyText ||| affecting the state may modify it or leave it unchanged. For
bodyText ||| instance,	if we consider the so-called cat state
bodyText ||| ψ Cat = 2 ( 00 + 11 ) [19], and the first qubit is affected by a
bodyText ||| bit flip error, the resulting state will be yr Cat H 2 ( 10 + 01) .
bodyText ||| But, if both qubits are affected by bit flips, there will be no
bodyText ||| change in the state: V Cat H 2 ( 11 + 00 ) = ψ Cat
bodyText ||| Phase errors affect the phase of one of the qubit's amplitudes and
bodyText ||| is expressed as 0 H 0 , 1 H − 1 . This type of error is very
bodyText ||| dangerous, due to its propagation behavior but it only makes
bodyText ||| sense when dealing with superposition states. If we consider an
bodyText ||| equally weighted qubit superposition state and inject a phase
bodyText ||| error, this results in 2 ( 0 + 1 )H 2 ( 0 − 1 ) .
bodyText ||| There is a strict correspondence between bit flip and phase error
bodyText ||| types due to the way they map onto Hilbert spaces with the same
bodyText ||| dimension but different basis. The bit flip is an error from the
bodyText ||| { 0 , 1 } , whereas the phase error appears in the
bodyText ||| same space with basis r	0 + 1, �(0 − 1 )⎫⎬⎭ or{ +
bodyText ||| The space basis conversion, in this case, is made by applying the
bodyText ||| Hadamard transform; Figure 4 shows an example of transforming
bodyText ||| a bit flip error into a phase error (A, and vice versa (B.
bodyText ||| Small amplitude errors: amplitudes a0 and a1 of the quantum bit
bodyText ||| can be affected by small errors, similar to analog errors. Even if
bodyText ||| such an error does not destroy the superposition and conserves the
bodyText ||| value of the superposed states, small amplitude errors could
bodyText ||| accumulate over time, eventually ruining the computation. In
bodyText ||| order to avoid this situation, specific methodologies for digitizing
bodyText ||| small errors are used to reduce them to a non-fault or a bit-flip
bodyText ||| [19].
bodyText ||| Due to the quantum physics laws, fault tolerance techniques have
bodyText ||| to comply with the following computational constraints:
listItem ||| – The observation destroys the state. Since observation is
listItem ||| equivalent to measurement, this leads to destroying the
listItem ||| useful state superposition.
listItem ||| – Information copying is impossible. Quantum physics renders
listItem ||| the cloning of a quantum state impossible, meaning that a
listItem ||| quantum state cannot be copied correctly. Therefore
listItem ||| quantum error correction must address the following
listItem ||| problems:
bodyText ||| Non-destructive measurement. Despite the first constraint it is
bodyText ||| necessary to find a way to measure the encoded information
bodyText ||| without destroying it. Because the encoded state cannot be
bodyText ||| measured directly, one needs to properly prepare some scratch
bodyText ||| (ancilla) qubits, which can then be measured.
bodyText ||| Fault-tolerant recovery. Due to the high error rate in quantum
bodyText ||| computational devices, it is likely that the error recovery itself
bodyText ||| will be affected by errors. If the recovery process is not fault-
bodyText ||| tolerant, then any error coding becomes useless.
bodyText ||| Phase error backward propagation. If we consider the XOR gate
bodyText ||| from Figure 5(A, a flip error affecting the target qubit (b) will
bodyText ||| propagate backwards and also affect the source qubit. This is due
bodyText ||| to the gate network equivalence from Figure 5(B and the basis
bodyText ||| transformation described by Figure 4.
figureCaption ||| Figure 4. Correspondence between bit flip and phase errors
figureCaption ||| Figure 5. (A The backward propagation of a phase error for
bodyText ||| the XOR gate; (B Gate network equivalence
bodyText ||| In order to deal with the problems described the next strategies
bodyText ||| have to be followed:
bodyText ||| Digitizing small errors. The presence of small errors is not a
bodyText ||| major concern, as they can be digitized using a special technique
bodyText ||| based on measuring auxiliary (ancilla) qubits [19].
bodyText ||| Ancilla usage. Since qubit cloning is impossible, a majority
bodyText ||| voting strategy is difficult to implement. However, by using
bodyText ||| ancilla qubits, the eigenstate information can be duplicated inside
bodyText ||| the existing superposition, resulting in the entanglement of the
bodyText ||| ancilla with the useful data. Because any measurement performed
bodyText ||| on the ancilla could have repercussions on the useful qubits, the
bodyText ||| appropriate strategy will employ special coding for both data
bodyText ||| qubits and ancilla (data errors only will be copied onto the
bodyText ||| ancilla), followed by the computation of an error syndrome,
bodyText ||| which has to be obtained through measuring the ancilla (see
bodyText ||| Figure 6).
bodyText ||| Avoiding massive spreading of phase errors. As shown
bodyText ||| previously, a phase error on the target qubit will propagate on all
bodyText ||| source qubits. The solution is to use more ancilla qubits as targets,
bodyText ||| so that no ancilla qubit is used more than once.
none ||| 0 and 1
none ||| 	2
none ||| space with basis
page ||| 191
none ||| 1
figureCaption ||| Figure 6. Fault-tolerant procedure with ancilla qubits
bodyText ||| Ancilla and syndrome accuracy. Setting the ancilla code to some
bodyText ||| known quantum state could be an erroneous process. Computing
bodyText ||| the syndrome is also prone to errors. Hence, on one hand, one has
bodyText ||| to make sure that the ancilla qubits are in the right state by
bodyText ||| verifying and recovering them if needed; on the other hand, in
bodyText ||| order to have a reliable syndrome, it must be computed
bodyText ||| repeatedly.
bodyText ||| Error recovery. As the small errors can be digitized (therefore,
bodyText ||| they are either corrected or transformed into bit flip errors), the
bodyText ||| recovery must deal only with bit flip and phase errors. A state that
bodyText ||| needs to be recovered is described by:
bodyText ||| Correcting a bit flip error 1means applying the negation unitarytransformation UN = ux = ° Oj to the affected qubit. To
bodyText ||| correct phase and combined errors, the following unitary
bodyText ||| operators	will	have	to	be	applied	respectively:
equation ||| ⎡1	0 ⎤	⎡0	−i ⎤
equation ||| UZ=⎢0	−1], UY = UN⋅UZ	⎣i	.
equation ||| 			0 ⎥⎦
subsubsectionHeader ||| 2.2.2 Quantum Error Correcting Codes
bodyText ||| Quantum error coding and correcting (QECC) is performed with
bodyText ||| special coding techniques inspired from the classic Hamming
bodyText ||| codes. The classical error coding is adapted so that it becomes
bodyText ||| suitable for the quantum strategy, allowing only the ancilla qubits
bodyText ||| to be measured.
bodyText ||| The state-of-the-art in QECC is represented by the stabilizer
bodyText ||| encoding, a particular case being the Steane codes (the Shor codes
bodyText ||| may also be used [29]). Steane's 7-qubit code is a single error
bodyText ||| correcting code inspired from classical Hamming coding and can
bodyText ||| be adapted for ancilla coding as well. Therefore it cannot recover
bodyText ||| from two identical qubit faults, but it can recover from a bit flip a
bodyText ||| phase flip. The Steane 7-qubit coding of 0 and 1 consists of
bodyText ||| an equally weighted superposition of all the valid Hamming 7-bit
bodyText ||| words with an even and odd number of 1s, respectively:
equation ||| = 1
equation ||| S	3	odd⎞u0u1u2u3c0c1c2
equation ||| ⎜	⎟
equation ||| ⎝	⎠
equation ||| =1 1111111 + 1101000 + 1010001 + 1000110
equation ||| 232
equation ||| + 0110100 + 0100011 + 0011010 + 0001101
bodyText ||| Applying the Steane coding on an arbitrary given quantum state
equation ||| ψ = a0 0 +a1 1 transforms it into V S = a0 0 S + a1 1 S. This
bodyText ||| code was designed to correct bit-flip errors, but by changing the
bodyText ||| basis (through a Hadamard transform) the phase error transforms
bodyText ||| into a bit flip error, which can then be corrected:
subsubsectionHeader ||| 2.2.3 Fault Tolerance Methodologies
bodyText ||| Quantum error-correcting codes exist for r errors, r ∈ ICY, r ≥ 1.
bodyText ||| Therefore a non-correctable error occurs if a number of r +1
bodyText ||| errors occur simultaneously before the recovery process.
bodyText ||| If the probability of a quantum gate error or storage error in the
bodyText ||| time unit is of orderξ , then the probability of an error affecting
bodyText ||| the processed data block becomes of order �r+1 , which is
bodyText ||| negligible if r is sufficiently large. However, by increasing r the
bodyText ||| safe recovery also becomes more complex and hence prone to
bodyText ||| errors: it is possible that r +1 errors accumulate in the block
bodyText ||| before the recovery is performed.
bodyText ||| Considering the relationship between r and the number of
bodyText ||| computational steps required for computing the syndrome is
bodyText ||| polynomial of the order rp . It was proven that in order to reduce
bodyText ||| as much as possible the error probability r must be chosen so that
none ||| 1
none ||| −
bodyText ||| r — e 1K p [7][19]. By consequence, if attempting to execute N
bodyText ||| cycles Sof error correction without any r+1 errors accumulating
bodyText ||| before the recovery ends, then N — exp⎜ξp
none ||| ⎛ − 1
bodyText ||| . Therefore the
bodyText ||| accuracy degree will be of the form � —(logN)−p , which is
bodyText ||| better than the accuracy degree corresponding to the no-coding
bodyText ||| case, � — N-1. However, there exists a Nmax so that if N > Nmax
bodyText ||| then non-correctable error becomes likely, which limits the length
bodyText ||| of the recovery process. Given the extremely large number of
bodyText ||| gates employed by a quantum algorithm implementation, Nmax
bodyText ||| also has to be very large; for Shor's algorithm Nmax must be
bodyText ||| higher than 3⋅109 [30].
bodyText ||| As shown in Figure 7, the required accuracy degree approaches
bodyText ||| today's technological limits (tipically 10-3 for p=4) after N=105.
bodyText ||| For a fault tolerant encoding solution for Shor algorithm
bodyText ||| implementation this should have happened after N=109 [19][34].
bodyText ||| +	(2)	Additional fault tolerance must be employed in order to preserve
figure ||| ⎯⎯⎯→⎨error ⎧ ⎪ ⎪ ⎪ ⎪ ⎩
figure ||| a
figure ||| a1 0 + a0 1 for a flip error
figure ||| .
figure ||| a0 0 −a1 1 for a phase error
figure ||| a1 0 − a0 1 for both flip and phase errors
figure ||| 0 0 +a1 1 if no error occurs
figure ||| a00+a11
figure ||| = 1 0000000 + 0010111 + 0101110 + 0111001
figure ||| + 1001011 + 1011100 + 1100101 + 1110010
figure ||| 232
figure ||| (
figure ||| )
figure ||| 1
figure ||| =
figure ||| S	232	evelu0`2u3c01c2)
figure ||| 0
figure ||| u0u1u2u3c0c1c2
figure ||| +	(3)
figure ||| )
figure ||| 0 S =H⋅ 0S= 1
figure ||| 1 S =H⋅ 1 S = 1
figure ||| 2
figure ||| 2
figure ||| (0S+1S)
figure ||| (0S−1S)
none ||| (4)
bodyText ||| reliable quantum computation over an arbitrary number of
bodyText ||| computational steps. Concatenated coding represents one such
bodyText ||| technique, which improves the reliability by shaping the size of
page ||| 192
bodyText ||| the code blocks and the number of code levels. It is also resource
bodyText ||| demanding and vulnerable to correlated errors [19][37].
bodyText ||| Another approach, replacing the concatenated codes, is based on
bodyText ||| Reconfigurable Quantum Gate Arrays (RQGAs) [34][37], which
bodyText ||| are used for configuring ECC circuits based on stabilizer codes
bodyText ||| [7][33]. By using a quantum configuration register for the RQGA
bodyText ||| (i.e. a superposition of classical configurations), the
bodyText ||| reconfigurable circuit is brought to a state where it represents a
bodyText ||| simultaneous superposition of distinct ECC circuits. After
bodyText ||| measuring the configuration register, only one ECC circuit is
bodyText ||| selected and used; if k distinct ECC circuits were superposed and
bodyText ||| the gate error rate is � , then the overall gate error probability
bodyText ||| becomes �k (see Figure 8). As a result, the accuracy threshold
bodyText ||| value for the RQGA solution clearly dominates the technological
bodyText ||| accuracy limit, as shown in Figure 9 [37].
figureCaption ||| Figure 7. Accuracy plots: p=3 for xi1, p=4 for xi2, p=5 for xi3;
bodyText ||| xi4 for no-coding, ref is the reference accuracy (i.e. the
bodyText ||| accuracy allowed by today's state of the art technology)
figureCaption ||| Figure 8. A quantum configuration register acts as a
bodyText ||| superposition of k distinct circuits sharing the same input
bodyText ||| state and the same output qubits
sectionHeader ||| 3. DEPENDABLE SYSTEM DESIGN
bodyText ||| In order to model the erroneous behavior of a device of system it
bodyText ||| is necessary to understand the causality of phenomena concerned.
bodyText ||| A defect affecting a device from a physical point of view is called
bodyText ||| a fault, or a fail. Faults may be put in evidence through logical
bodyText ||| misbehavior, in which case they transform into errors. Finally,
bodyText ||| errors accumulating can lead to system failure [8]. The fault-
bodyText ||| error-failure causal chain is essential to developping techniques
bodyText ||| that reduce the risk of error occurrence, even in the presence of
bodyText ||| faults, in order to minimize the probability of a system failure,
bodyText ||| and can be architecture specific. We will elaborate next on
bodyText ||| techniques used by a bio-inspired and by a quantum computing
bodyText ||| platform.
figureCaption ||| Figure 9. Evolution of accuracy threshold value for RQHW
bodyText ||| stabilizer codes (xir); the technological accuracy limit (dim) is
bodyText ||| also provided for a relevant comparison
subsectionHeader ||| 3.1 The Embryonics Approach
bodyText ||| Several years before his untimely death John von Neumann began
bodyText ||| developping a theory of automata, which was to contain a
bodyText ||| systematic theory of mixed mathematical and logical forms,
bodyText ||| aimed to a better understanding of both natural systems and
bodyText ||| computers [14]. The essence of von Neumann’s message appears
bodyText ||| to entail the formula “genotype + ribotype = phenotype”. He
bodyText ||| provided the foundations of a self-replicating machine (the
bodyText ||| phenotype), consisting of its complete description (the genotype),
bodyText ||| which is interpreted by a ribosome (the ribotype).
bodyText ||| Embryonics (a contraction for embryonic electronics) is a long
bodyText ||| term research project launched by the Logic Systems Laboratory
bodyText ||| at the Swiss Federal Institute of Technology, Lausanne,
bodyText ||| Switzerland. Its aim is to explore the potential of biologically-
bodyText ||| inspired mechanisms by borrowing and adapting them from
bodyText ||| nature into digital devices for the purpose of endowing them with
bodyText ||| the remarkable robustness present in biological entities [39].
bodyText ||| Though perhaps fuzzy at a first glance, analogies between biology
bodyText ||| and electronics are presented in Table 1 [12][31].
bodyText ||| But if we consider that the function of a living cell is determined
bodyText ||| by the genome, and that a computer’s functionality is determined
bodyText ||| by the operating program, then the two worlds may be regarded as
bodyText ||| sharing a certain degree of similarity. Three fundamental features
bodyText ||| shared by living entities are required to be targetted by
bodyText ||| Embryonics in order to embody the formula “genotype + ribotype
bodyText ||| = phenotype” into digital hardware:
listItem ||| –multicellular organisms are made of a finite number of cells,
listItem ||| which in turn are made of a finite number of chemically
listItem ||| bonded molecules;
listItem ||| –each cell (beginning with the original cell, the zygote) may
listItem ||| generate one or several daughter cell(s) through a process
listItem ||| called cellular division; both the parent and the daughter
listItem ||| cell(s) share the same genetic information, called the genome;
listItem ||| –different types of cells may exist due to cellular
listItem ||| differentiation, a process through which only a part of the
listItem ||| genome is executed.
bodyText ||| These fundamental features led the Embryonics project to settle
bodyText ||| for an architectural hierarchy of four levels (see Figure 10). We
bodyText ||| will not delve very deep inside the Embryonics’phylosophy, as
bodyText ||| such details were broadly covered by literature [12][20][23][24]
bodyText ||| [25][40]; we will, however, introduce each of the four levels in
page ||| 193
bodyText ||| order to be able to see how this bio-inspired platform fits modern
bodyText ||| design for dependability efforts.
tableCaption ||| Table 1. Analogies present in Embryonics [12]
table ||| Biology	Electronics
table ||| Multicellular organism	Parallel computer systems
table ||| Cell	Processor
table ||| Molecule	FPGA Element
figureCaption ||| Figure 10. Structural hierarchy in Embryonics [12]
bodyText ||| The upmost level in Embryonics, bearing a certain similarity to
bodyText ||| what is found in nature, is the population level, composed of a
bodyText ||| number of organisms. One level down the hierarchy constitutes
bodyText ||| the organismic level, and corresponds to individual entities in a
bodyText ||| variety of functionalities and sizes. Each of the organisms may be
bodyText ||| further decomposed into smaller, simpler parts, called cells, which
bodyText ||| in turn may be decomposed in molecules. According to
bodyText ||| Embryonics, a biological organism corresponds in the world of
bodyText ||| digital systems to a complete computer, a biological cell is
bodyText ||| equivalent to a processor, and the smallest part in biology, the
bodyText ||| molecule, may be seen as the smallest, programmable element in
bodyText ||| digital electronics (see Table 1).
bodyText ||| An extremely valuable consequence of the Embryonics
bodyText ||| architecture is that each cell is "universal", containing a copy of
bodyText ||| the whole of the organism’s genetic material, the genome. This
bodyText ||| enables very flexible redundancy strategies, the living organisms
bodyText ||| being capable of self-repair (healing) or self-replication (cloning)
bodyText ||| [12]. Self-replication may be of great interest in the
bodyText ||| nanoelectronics era, where extremely large areas of
bodyText ||| programmable logic will probably render any centralized control
bodyText ||| very inefficient. Instead, the self-replication mechanism
bodyText ||| implemented in Embryonics will allow the initial colonization of
bodyText ||| the entire programmable array in a decentralized and distributed
bodyText ||| manner. Figure 11 presents an example of such colonization. At
bodyText ||| initial time the configuration bitstream (containing the genome)
bodyText ||| enters the bottom left corner of a programmable array and, at each
bodyText ||| clock cycle, the genome is pushed through and partitions the
bodyText ||| programmable space accordingly.
bodyText ||| From a dependability standpoint, the Embryonics hierarchical
bodyText ||| architecture offers incentives for an also hierarchical self-repair
bodyText ||| strategy. Because the target applications are those in which the
bodyText ||| failure frequency must be very low to be “acceptable”, two levels
bodyText ||| of self-repair are offered: at the molecular level (programmable
bodyText ||| logic is susceptible to soft fail occurrences) and at the cellular
bodyText ||| level (soft fails manifest at this level as soft errors).
bodyText ||| Let us consider an example of a simple cell made of 3 lines and 3
bodyText ||| columns of molecules, of which one column contains spare
bodyText ||| molecules. If a fault occurs inside an active cell, it can be repaired
bodyText ||| through transferring its functionality toward the appropriate spare
bodyText ||| molecule, which will become active (see Figure 12).
figureCaption ||| Figure 11. Space colonization in Embryonics [11]
figureCaption ||| Figure 12. Self-repair at the molecular level: faulty molecule
figureCaption ||| E is replaced by spare molecule H, which becomes active [39]
bodyText ||| The self-repair process at molecular level ensures the fault
bodyText ||| recovery as long as there are spare molecules left for repair.
bodyText ||| However, it is possible for a cell to experience a multiple error, in
bodyText ||| which case the self-repair mechanism at the molecular level can
bodyText ||| no longer reconfigure the inside of the cell successfully. If such a
bodyText ||| situation arises, then a second self-repair strategy is trigerred at a
bodyText ||| higher level. The cell will “die”, therefore trigerring the self-
bodyText ||| repair at the cellular level, the entire column containing the faulty
bodyText ||| cell (cell C in this example) being deactivated, its role being taken
bodyText ||| by the nearest spare column to the right (see Figure 13).
bodyText ||| A critique that could be addressed to the current Embryonics
bodyText ||| design would be its strategy of self-repair at the higher, cellular
bodyText ||| level: in case of a faulty cell, an entire column containing that cell
bodyText ||| will be deactivated, its role being transferred to the first available
bodyText ||| column of spares to the right (see Figure 13). There are two points
bodyText ||| in which this strategy could benefit:
page ||| 194
listItem ||| 1. Instead of deactivating a whole column of cells, it would be
listItem ||| more efficient to only deactivate the faulty cell only (see
listItem ||| Figure 14). The resources affected by the role transfer would
listItem ||| be greatly reduced (one cell versus an entire column),
listItem ||| coupled with the fact that particle flux generating soft fails is
listItem ||| unlikely to be homogeneous and isotrope. This means
listItem ||| regions assimilable more likely to cells rather than entire
listItem ||| column of cells would be more affected by soft fails, not to
listItem ||| mention that during genetic data transfer (required by taking
listItem ||| over the role of the faulty cell) there is a greater risk of
listItem ||| enduring a new soft fail (moving data is much more sensitive
listItem ||| to soft fails than static data) [5][10].
listItem ||| 2. Such a strategy would be consistent with that used for the
listItem ||| self-repair at the molecular level, which would simplify a
listItem ||| thorough reliability analysis. Concatenated coding would
listItem ||| also seem easier to be implemented and the strategy
listItem ||| consistency would mean that concatenated coding would not
listItem ||| be limited to a two-level hierarchy [20][21].
figureCaption ||| Figure 13. Molecular self-repair failure: the cell “dies”
figureCaption ||| (bottom), triggering the cellular self-repair (top) [39]
bodyText ||| We consider a cell of M lines and N columns, being composed of
bodyText ||| modules of M lines and n+s columns (for instance, the cell
bodyText ||| presented in Figure 12 consists of a single such module of two
bodyText ||| active columns and one spare column), of which s are spares. In
bodyText ||| order to meet certain reliability criteria, it is necessary to know
bodyText ||| what is the number s of spare columns of molecules that
bodyText ||| correspond to n columns of active molecules, that is, the
bodyText ||| horizontal dimensions for such a module. We will not provide a
bodyText ||| thorough reliability analysis, as this has been done previously
bodyText ||| [4][17][20][21]; instead, we will analyze the influences of the
bodyText ||| proposed consistent self-repair strategy at both molecular and
bodyText ||| cellular levels through the use of logic molecules. Therefore
bodyText ||| Equation (5) holds:
equation ||| k
equation ||| RModRow (t)=Prob{ no fails} (t) + ∑ Prob{ i fails} (t)
equation ||| i=1	(5)
equation ||| N=k(n+s)
bodyText ||| where RModRow(t) represents the reliability function for a row
bodyText ||| within a module. Then, considering the failure rate for one
bodyText ||| molecule λ, the probability of all molecules (both active and
bodyText ||| spare) to operate normally in a module’s row becomes:
equation ||| Prob{ no fails} (t) = e−"n+s)t	(6)
bodyText ||| The probability of a row enduring i fails in the active molecules
bodyText ||| part is the conditional probability of having n-i active molecules
bodyText ||| operating normally, while a number of s-i spare molecules are
bodyText ||| ready to activate (that is, they are not affected by errors
bodyText ||| themselves):
equation ||| Prob{ i fails} (t) = Prob{ i fails active} (t)
equation ||| ⋅Prob{i spares ok}(t)
equation ||| Prob{ i fails active} (t) = (n Je λ(n-i)t (1 − eλ(n-i)t)	(8)
equation ||| i	l
equation ||| Prob{ i spares ok} (t) = (k )e−λit (1 − a λ(k−i)t
equation ||| i
bodyText ||| Then the reliability function for an entire cell is the cummulated
bodyText ||| reliability functions for the total number of modules:
equation ||| RCell(t) = [RModRow(t)]MN`	(10)
figureCaption ||| Figure 14. Proposed reconfiguration strategy at the cellular
bodyText ||| level
bodyText ||| A self-repair strategy that conserves the consistency between the
bodyText ||| molecular and the cellular level would allow for a more
bodyText ||| straightforward reliability analysis. Basically, it would be
bodyText ||| sufficient to substitute dimension parameters in Equations (5)-
bodyText ||| (10) with those approapriate to the analysis of an organism
bodyText ||| instead of a cell. To illustrate this, we will consider an organism
bodyText ||| of M* lines and N* columns, being composed of modules of M*
bodyText ||| lines and n*+s* columns, of which s* are spares; we will also use
bodyText ||| the organism partitioning into modules, similar to the partitioning
bodyText ||| of cells used before. Therefore Equation (5) transforms into
bodyText ||| Equation (11):
equation ||| k
equation ||| RCellMR (t)=Prob*{nofails}(t)+∑Prob* { ifails} (t) i = 1	(11)
equation ||| N*=k*(n +s )
bodyText ||| where RCellMR (t) represents the reliability function for a row of
bodyText ||| cells within an organism module. In this case, the significance of
bodyText ||| the terms will be as follows:
equation ||| Prob {no fails} (t) = [RCell ( tj +s	(12)
equation ||| ⋅
equation ||| (7)
equation ||| (9)
page ||| 195
bodyText ||| While Equation (7) continues to hold under the form of Equation
bodyText ||| (13), the significance of its terms will change according to the
bodyText ||| dimensions at the cellular level:
equation ||| ⎛ ⎞ −
equation ||| Prob*{ifailsactive}(t)=⎜
equation |||  i
equation ||| (t)(1−R
equation ||| L
equation ||| ll(t
equation ||| ⎛ ⎞	−
equation ||| Prob*{isparesok}(t)=⎜k*
equation ||| J
equation ||| RCiell(t)(1−RCkelli(t))	(15) i
equation ||| t0, t1,..., tm−1 will be given by
equation ||| The outputs ofthe firstcycle, whichare also inputs forthe
equation ||| The used FTAMs are only valid if the relationship between the
bodyText ||| experimental ξsim and the assumed singular error rateξ is of the
equation ||| order gsim _ � 2 [19].
equation ||| ) )(14)
bodyText ||| Finally, similar to Equation(10), the reliabilityfunctionforan
bodyText ||| entire organism is the cummulated re
bodyText ||| liability functions for the
bodyText ||| total number of its modules:
equation ||| ROrg(t)=
equation |||  [
equation ||| RCellMR(t)
equation ||| ]
equation ||| MN
equation |||  �
equation ||| +
equation ||| s	(16)
bodyText ||| Equations (5) to (16) provide the basics forathorough reliability
bodyText ||| analysis for the proposed, uniformstrategy ofhierarchical
bodyText ||| reconfiguration, as opposedto the analysis providedby [21],
bodyText ||| whichspecifically targetted the currentEmbryonics architecture.
bodyText ||| Despite having settled the reliabilitymodel, bothanalyses are
bodyText ||| incomplete, inthatthe failure rate parameteris missing, which
bodyText ||| makes aprecise, quantitative dependability targetdifficultto
bodyText ||| meet. However, areliability analysis is still valuable from a
bodyText ||| qualitative pointofview, allowingadirectcomparison of
bodyText ||| differentsystems.
subsectionHeader ||| 3.2 The QUERISTApproach
bodyText ||| Inorderto deal with errors inducedby the constantinfluence of
bodyText ||| the external environmentuponcomputational processes, the
bodyText ||| following assumptions were made: errors appear randomly, are
bodyText ||| uncorrelated (neitherinspace, norintime), there are no storage
bodyText ||| errors, andthere are no leakage phenomenainvolved[19].
bodyText ||| Classical HDL-based faultinjectionmethodologies can be
bodyText ||| mappedto simulatingquantumcircuits withoutintervention
bodyText ||| providedthatthe new errorand faultmodels are takeninto
bodyText ||| account[35]. Ofcourse, efficiencycriteriarequire thatthey be
bodyText ||| adaptedto one ofthe available efficientsimulationframeworks
bodyText ||| [36][38][41]. QUERIST(from QUantum ERrorInjection
bodyText ||| Simulation Tool) is the name ofsucha project, fostering
bodyText ||| simulated faultinjectiontechniques inquantum circuits [34].
bodyText ||| Similarto classical computation, simulatedfaultinjection is used
bodyText ||| in orderto evaluate the employed FTAMS (FaultTolerance
bodyText ||| Algorithms andMethodologies) [26][27].
bodyText ||| Anoverview ofthe QUERISTprojectis presented in Figure 15.
bodyText ||| The three cycles ofinitialization, simulation, anddata
bodyText ||| computationare commonto bothclassical andquantum
bodyText ||| approaches. The firstcycle takes the quantumcircuitHDL
bodyText ||| description as aninput. Two abstractinputs are considered, the
bodyText ||| HDL model andthe assumederrormodel; the firstinfluences how
bodyText ||| the HDLdescription is presented, while the secondone dictates
bodyText ||| the testscenario by definingthe start/stop simulationstates (since
bodyText ||| qubits are equallyprone to error, all the signals mustbe
bodyText ||| observed). HDLmodelingofquantumcircuits inorderto attain
bodyText ||| effi
bodyText ||| cient simulation is discussed in [34][35][36][38].
page ||| 196
bodyText ||| secondcycle consists oftime diagrams forall qubits, from the
bodyText ||| startto the stop states. Useful information, extracted fromthe raw,
bodyText ||| bubble-bit-represented, qubittraces are comparedto correctqubit
bodyText ||| values, the resultbeingthe probabilistic accuracy thresholdvalue,
bodyText ||| inthe thirdcycle. The initialization andsimulation cycles depend
bodyText ||| on specific aspects ofquantum circuitsimulation [35]. The data
bodyText ||| processing cycle is independentfromthe specific simulation
bodyText ||| framework andis aimedatdeterminingthe accuracythresholdas
bodyText ||| the mainreliability measure thatalso defines the feasibility ofthe
bodyText ||| quantum circuitimplementations.
bodyText ||| Suppose that, atsimulationtime twe observe signals
bodyText ||| {s0,s1,...,sn}
bodyText |||  . In ouranalysis,
bodyText ||| si
bodyText |||  is the state observedduringnon-
bodyText ||| faulty simulation, so forthe same state ina faulty environmentwe
bodyText ||| will have the state
bodyText ||| si* .
bodyText ||| Forvalidationofthe quantum FTAMs, we needto compare
bodyText ||| si
bodyText ||| with
bodyText ||| si*.
bodyText |||  This can be done by using operator
bodyText |||  d
bodyText ||| if
bodyText ||| (si,s
bodyText ||| ;
bodyText ||| )
bodyText |||  . This
bodyText ||| mean
bodyText ||| s that the total number of overall state errors at simulation
bodyText ||| n − 1
bodyText ||| time tis
bodyText ||| . et=∑d
bodyText ||| if
bodyText ||| (si,s
bodyText ||| ;
bodyText ||| )The error rate on the overall observed
sectionHeader ||| 4. CONCLUSIONS
bodyText ||| This paper presented arguments in favor of two novel computing
bodyText ||| architectures for the purpose of addressing the challenges raised
bodyText ||| by the forthcoming nanoelectronics era. Distributed self-testing
bodyText ||| and self-repairing will probably become a must in the next years
bodyText ||| as centralized control logic is expected to become unable to
bodyText ||| harness the extremely large number of devices, all equally prone
bodyText ||| to errors, that will be integrated onto the same chip. Bio-inspired
bodyText ||| computing brings valuable techniques that explore the potential of
bodyText ||| massively parallel, distributed computation and fault-tolerance
bodyText ||| that will likely provide an essential help to jumpstart new
bodyText ||| nanoelectronic architectures. As one of the representatives of bio-
bodyText ||| inspired computing, the Embryonics project presents a
bodyText ||| hierarchical architecture that achieves fault tolerance through
bodyText ||| implementing an also hierarchical reconfiguration. A similar
bodyText ||| approach for maximizing fault tolerance is present in quantum
bodyText ||| computing, the QUERIST project; even if bio-inspired and
bodyText ||| quantum computing may seem dissimilar at a first glance, they
bodyText ||| both achieve fault tolerance by adapting the same techniques from
bodyText ||| classical computing and using essentially the same error model.
bodyText ||| Nanoelectronics will potentially change the way computing
bodyText ||| systems are designed, not only because of the sheer number of
bodyText ||| devices that will coexist onto the same chip, but also because of
bodyText ||| the sensitivity of these devices.
equation ||| Prob*
equation ||| { i fails} (t) = Prob* { i fails active} (t)
equation ||| ⋅
equation ||| ⋅ Prob* { i spares ok} (t)
equation ||| (13)
equation ||| i=0
figureCaption ||| simulation cycle, consistofatestscenario and an executable HDL
figureCaption ||| model withthe correspondingentanglementanalysis, dictatedby
figureCaption ||| the bubble-bitencoded quantum states [36][38]. The outputofthe
figureCaption ||| states at moments
equation ||| 1 m−1
equation ||| ξsim	∑ et •
equation ||| m
equation ||| j=0 �
figureCaption ||| Figure 15. An overview of the QUERIST project
bodyText ||| Therefore, if nanoelectronics is to be employed to build
bodyText ||| dependable computing machines (a certain contradiction
bodyText ||| notwithstanding), valuable expertise in design can be drawn from
bodyText ||| natural sciences. While biology provides countless examples of
bodyText ||| successfully implemented fault tolerance strategies, physics offers
bodyText ||| theoretical foundations, both of which were found to share
bodyText ||| common ground. It is perhaps a coincidence worth exploring in
bodyText ||| digital computing.
sectionHeader ||| 5. REFERENCES
reference ||| [1] Aharonov, D., Ben-Or, M. Fault Tolerant Quantum
reference ||| Computation with Constant Error. Proc. ACM 29th Ann.
reference ||| Symposium on Theory of Computing, El Paso, Texas, May
reference ||| 1997, pp. 176-188.
reference ||| [2] Avižienis, A., Laprie, J.C., Randell, B., Landwehr, C. Basic
reference ||| Concepts and Taxonomy of Dependable and Secure
reference ||| Computing. IEEE Transactions on Dependable and Secure
reference ||| Computing, 1, 1 (Jan-Mar 2004), 11-33.
reference ||| [3] Butts, M., DeHon, A., Golstein, S.C. Molecular Electronics:
reference ||| Devices, Systems and Tools for Gigagate, Gigabit Chips.
reference ||| Proc. Intl. Conference on CAD (ICCAD’02), 2002, pp. 433-
reference ||| 440.
reference ||| [4] Canham, R., Tyrrell, A. An Embryonic Array with Improved
reference ||| Efficiency and Fault Tolerance. Proc. IEEE NASA/DoD
reference ||| Conference on Evolvable Hardware, Chicago Il, 2003, 275-
reference ||| 282.
reference ||| [5] Gaisler, J. Evaluation of a 32-Bit Microprocessor with Built-
reference ||| In Concurrent Error Detection. Proc. 27th Annual Intl.
reference ||| Symposium on Fault-Tolerant Computing (FTCS-27), 1997,
reference ||| pp. 42-46.
reference ||| [6] Goldstein, S.C. The Challenges and Opportunities of
reference ||| Nanoelectronics. Proc. Government Microcircuit Applica-
reference ||| tions and Critical Technology Conference (GOMAC Tech -
reference ||| 04), Monterey, CA, March 2004.
reference ||| [7] Gottesman, D. Class of quantum error-correcting codes
reference ||| saturating the quantum Hamming bound. Phys. Rev. A 54,
reference ||| 1996, pp. 1862-1868.
reference ||| [8] Johnson, B.W. Design and Analysis of Fault-Tolerant
reference ||| Digital Systems. Addison-Wesley, 1989.
reference ||| [9] Laprie, J.-C. (Ed.). Dependability: Basic Concepts and
reference ||| Terminology. Dependable Computing and Fault-Tolerant
reference ||| Systems Series, Vol. 5, Springer-Verlag, Vienna, 1992.
reference ||| [10] Liden, P., Dahlgren, P., Johansson, R., Karlsson, J. On
reference ||| Latching Probability of Particle Induced Transients in
reference ||| Combinational Networks. Proc. Intl. Symposium on Fault-
reference ||| Tolerant Computing (FTCS-24), 1994, pp.340-349.
reference ||| [11] Mange, D., Sipper, M., Stauffer, A., Tempesti, G. Toward
reference ||| Robust Integrated Circuits: The Embryonics Approach. Proc.
reference ||| of the IEEE, vol. 88, No. 4, April 2000, pp. 516-541.
reference ||| [12] Mange, D. and Tomassini, M. eds. Bio -Inspired Computing
reference ||| Machines: Towards Novel Computational Architectures.
reference ||| Presses Polytechniques et Universitaires Romandes,
reference ||| Lausanne, Switzerland, 1998.
reference ||| [13] Von Neumann, J. The Computer and the Brain (2nd edition).
reference ||| Physical Science, 2000.
reference ||| [14] Von Neumann, J. The Theory of Self-Reproducing
reference ||| Automata. A. W. Burks, ed. University of Illinois Press,
reference ||| Urbana, IL, 1966.
reference ||| [15] Von Neumann, J. Probabilistic Logic and the Synthesis of
reference ||| Reliable Organisms from Unreliable Components. In C.E.
reference ||| Shannon, J. McCarthy (eds.) Automata Studies, Annals of
reference ||| Mathematical Studies 34, Princeton University Press, 1956,
reference ||| 43-98.
reference ||| [16] Nielsen, M.A., Chuang, I.L. Quantum Computation and
reference ||| Quantum Information. Cambridge University Press, 2000.
reference ||| [17] Ortega, C., Tyrrell, A. Reliability Analysis in Self-Repairing
reference ||| Embryonic Systems. Proc. 1st NASA/DoD Workshop on
reference ||| Evolvable Hardware, Pasadena CA, 1999, 120-128.
reference ||| [18] O’Connor, P.D.T. Practical Reliability Engineering. John
reference ||| Wiley & Sons, 4th edition, 2002.
reference ||| [19] Preskill, J. Fault Tolerant Quantum Computation. In H.K.
reference ||| Lo, S. Popescu and T.P. Spiller, eds. Introduction to
reference ||| Quantum Computation, World Scientific Publishing Co.,
reference ||| 1998.
page ||| 197
reference ||| [20] Prodan, L. Self-Repairing Memory Arrays Inspired by
reference ||| Biological Processes. Ph.D. Thesis, “Politehnica” University
reference ||| of Timisoara, Romania, October 14, 2005.
reference ||| [21] Prodan, L., Udrescu, M., Vladutiu, M. Survivability Analysis
reference ||| in Embryonics: A New Perspective. Proc. IEEE NASA/DoD
reference ||| Conference on Evolvable Hardware, Washington DC, 2005,
reference ||| 280-289.
reference ||| [22] Prodan, L., Udrescu, M., Vladutiu, M. Self-Repairing
reference ||| Embryonic Memory Arrays. Proc. IEEE NASA/DoD
reference ||| Conference on Evolvable Hardware, Seattle WA, 2004, 130-
reference ||| 137.
reference ||| [23] Prodan, L., Tempesti, G., Mange, D., and Stauffer, A.
reference ||| Embryonics: Electronic Stem Cells. Proc. Artificial Life VIII,
reference ||| The MIT Press, Cambridge MA, 2003, 101-105.
reference ||| [24] Prodan, L., Tempesti, G., Mange, D., and Stauffer, A.
reference ||| Embryonics: Artificial Cells Driven by Artificial DNA.
reference ||| Proc. 4th International Conference on Evolvable Systems
reference ||| (ICES2001), Tokyo, Japan, LNCS vol. 2210, Springer,
reference ||| Berlin, 2001, 100-111.
reference ||| [25] Prodan, L., Tempesti, G., Mange, D., and Stauffer, A.
reference ||| Biology Meets Electronics: The Path to a Bio-Inspired
reference ||| FPGA. In Proc. 3rd International Conference on Evolvable
reference ||| Systems (ICES2000), Edinburgh, Scotland, LNCS 1801,
reference ||| Springer, Berlin, 2000, 187-196.
reference ||| [26] Rimen, M., Ohlsson, J., Karlsson, J., Jenn, E., Arlat, J.
reference ||| Validation of fault tolerance by fault injection in VHDL
reference ||| simulation models. Rapport LAAS No. 92469, December
reference ||| 1992.
reference ||| [27] Rimen, M., Ohlsson, J., Karlsson, J., Jenn, E., Arlat, J.
reference ||| Design guidelines of a VHDL-based simulation tool for the
reference ||| validation of fault tolerance. Rapport LAAS No931 70, Esprit
reference ||| Basic Research Action No. 6362, May 1993.
reference ||| [28] Shivakumar, P., Kistler, M., Keckler, S.W., Burger, D.,
reference ||| Alvisi, L. Modelling the Effect of Technology Trends on the
reference ||| Soft Error Rate of Combinational Logic. Proc. Intl.
reference ||| Conference on Dependable Systems and Networks (DSN),
reference ||| June 2002, pp. 389-398.
reference ||| [29] Shor, P. Fault-tolerant quantum computation.
reference ||| arXiv.org:quant-ph/9605011, 1996.
reference ||| [30] Shor, P. Algorithms for Quantum Computation: Discrete
reference ||| Logarithms and Factoring. Proc. 35th Symp. on Foundations
reference ||| of Computer Science, 1994, pp. 124-134.
reference ||| [31] Sipper, M., Mange, D., Stauffer, A. Ontogenetic Hardware.
reference ||| BioSystems, 44, 3, 1997, 193-207.
reference ||| [32] Sipper, M., Sanchez, E., Mange, D., Tomassini, M., Perez-
reference ||| Uribe, A., Stauffer, A. A Phylogenetic, Ontogenetic and
reference ||| Epigenetic View of Bio-Inspired Hardware Systems. IEEE
reference ||| Transactions on Evolutionary Computation, 1, 1, April 1997,
reference ||| 83-97.
reference ||| [33] Steane, A. Multiple Particle Interference and Quantum Error
reference ||| Correction. Proc. Roy. Soc. Lond. A 452, 1996, pp. 2551.
reference ||| [34] Udrescu, M. Quantum Circuits Engineering: Efficient
reference ||| Simulation and Reconfigurable Quantum Hardware. Ph.D.
reference ||| Thesis, “Politehnica” University of Timisoara, Romania,
reference ||| November 25, 2005.
reference ||| [35] Udrescu, M., Prodan, L., Vladutiu, M. Simulated Fault
reference ||| Injection in Quantum Circuits with the Bubble Bit
reference ||| Technique. Proc. International Conference "Adaptive and
reference ||| Natural Computing Algorithms", pp. 276-279.
reference ||| [36] Udrescu, M., Prodan, L., Vladutiu, M. The Bubble Bit
reference ||| Technique as Improvement of HDL-Based Quantum Circuits
reference ||| Simulation. IEEE 38th Annual Simulation Symposium, San
reference ||| Diego CA, USA, 2005, pp. 217-224.
reference ||| [37] Udrescu, M., Prodan, L., Vladutiu, M. Improving Quantum
reference ||| Circuit Dependability with Reconfigurable Quantum Gate
reference ||| Arrays. 2nd ACM International Conference on Computing
reference ||| Frontiers, Ischia, Italy, 2005, pp. 133-144.
reference ||| [38] Udrescu, M., Prodan, L., Vladutiu, M. Using HDLs for
reference ||| describing quantum circuits: a framework for efficient
reference ||| quantum algorithm simulation. Proc. 1st ACM Conference
reference ||| on Computing Frontiers, Ischia, Italy, 2004, 96-110.
reference ||| [39] Tempesti, G. A Self-Repairing Multiplexer-Based FPGA
reference ||| Inspired by Biological Processes. Ph.D. Thesis No. 1827,
reference ||| Logic Systems Laboratory, The Swiss Federal Institute of
reference ||| Technology, Lausanne, 1998.
reference ||| [40] Tempesti, G., Mange, D., Petraglio, E., Stauffer, A., Thoma
reference ||| Y. Developmental Processes in Silicon: An Engineering
reference ||| Perspective. Proc. IEEE NASA/DoD Conference on
reference ||| Evolvable Hardware, Chicago Il, 2003, 265-274.
reference ||| [41] Viamontes, G., Markov, I., Hayes, J.P. High-performance
reference ||| QuIDD-based Simulation of Quantum Circuits. Proc. Design
reference ||| Autom. and Test in Europe (DATE), Paris, France, 2004, pp.
reference ||| 1354-1359.
reference ||| [42] Yu, Y., Johnson, B.W. A Perspective on the State of
reference ||| Research on Fault Injection Techniques. Technical Report
reference ||| UVA-CSCS-FIT-001, University of Virginia, May 20, 2002.
reference ||| [43] ***. ITRS – International Technology Roadmap for Semic-
reference ||| onductors, Emerging Research Devices, 2004, http://www.
reference ||| itrs.net/Common/2004Update/2004_05_ERD.pdf
reference ||| [44] ***. Society of Reliability Engineers, http://www.sre.org/
reference ||| pubs/
reference ||| [45] ***. http://www.dependability.org/wg10.4/
page ||| 198

title ||| A Distributed 3D Graphics Library
author ||| Blair MacIntyre and Steven Feiner1
affiliation ||| Department of Computer Science
affiliation ||| Columbia University
sectionHeader ||| Abstract
bodyText ||| We present Repo-3D, a general-purpose, object-oriented library for
bodyText ||| developing distributed, interactive 3D graphics applications across
bodyText ||| a range of heterogeneous workstations. Repo-3D is designed to
bodyText ||| make it easy for programmers to rapidly build prototypes using a
bodyText ||| familiar multi-threaded, object-oriented programming paradigm.
bodyText ||| All data sharing of both graphical and non-graphical data is done
bodyText ||| via general-purpose remote and replicated objects, presenting the
bodyText ||| illusion of a single distributed shared memory. Graphical objects
bodyText ||| are directly distributed, circumventing the “duplicate database”
bodyText ||| problem and allowing programmers to focus on the application
bodyText ||| details.
bodyText ||| Repo-3D is embedded in Repo, an interpreted, lexically-scoped,
bodyText ||| distributed programming language, allowing entire applications to
bodyText ||| be rapidly prototyped. We discuss Repo-3D’s design, and introduce
bodyText ||| the notion of local variations to the graphical objects, which allow
bodyText ||| local changes to be applied to shared graphical structures. Local
bodyText ||| variations are needed to support transient local changes, such as
bodyText ||| highlighting, and responsive local editing operations. Finally, we
bodyText ||| discuss how our approach could be applied using other program-
bodyText ||| ming languages, such as Java.
category ||| CR Categories and Subject Descriptors: D.1.3 [Program-
category ||| ming Techniques]: Concurrent Programming—Distributed Pro-
category ||| gramming; H.4.1 [Information Systems Applications]: Office
category ||| Automation—Groupware; I.3.2 [Computer Graphics]: Graphics
category ||| Systems—Distributed/network graphics; I.3.6 [Computer Graph-
category ||| ics]: Methodology and Techniques—Graphics data structures and
category ||| data types; I.3.7 [Computer Graphics]: Three-Dimensional
category ||| Graphics and Realism—Virtual reality.
keyword ||| Additional Keywords and Phrases: object-oriented graphics,
keyword ||| distributed shared memory, distributed virtual environments,
keyword ||| shared-data object model.
sectionHeader ||| 1 INTRODUCTION
bodyText ||| Traditionally, distributed graphics has referred to the architecture
bodyText ||| of a single graphical application whose components are distributed
bodyText ||| over multiple machines [14, 15, 19, 27] (Figure 1a). By taking
bodyText ||| advantage of the combined power of multiple machines, and the
bodyText ||| particular features of individual machines, otherwise impractical
bodyText ||| applications became feasible. However, as machines have grown
bodyText ||| more powerful and application domains such as Computer
footnote ||| 1. {bm,feiner}@cs.columbia.edu, http://www.cs.columbia.edu/graphics
figureCaption ||| Figure 1: Two meanings of distributed graphics: (a) a single logical
figureCaption ||| graphics system with distributed components, and (b) multiple dis-
figureCaption ||| tributed logical graphics systems. We use the second definition here.
bodyText ||| Supported Cooperative Work (CSCW) and Distributed Virtual
bodyText ||| Environments (DVEs) have been making the transition from
bodyText ||| research labs to commercial products, the term distributed graphics
bodyText ||| is increasingly used to refer to systems for distributing the shared
bodyText ||| graphical state of multi-display/multi-person, distributed, interac-
bodyText ||| tive applications (Figure 1b). This is the definition that we use here.
bodyText ||| While many excellent, high-level programming libraries are
bodyText ||| available for building stand-alone 3D applications (e.g. Inventor
bodyText ||| [35], Performer [29], Java 3D [33]), there are no similarly powerful
bodyText ||| and general libraries for building distributed 3D graphics applica-
bodyText ||| tions. All CSCW and DVE systems with which we are familiar
bodyText ||| (e.g., [1, 7, 11, 12, 16, 28, 30, 31, 32, 34, 37, 41]) use the following
bodyText ||| approach: A mechanism is provided for distributing application
bodyText ||| state (either a custom solution or one based on a general-purpose
bodyText ||| distributed programming environment, such as ISIS [4] or Obliq
bodyText ||| [8]), and the state of the graphical display is maintained separately
bodyText ||| in the local graphics library. Keeping these “dual databases” syn-
bodyText ||| chronized is a complex, tedious, and error-prone endeavor. In con-
bodyText ||| trast, some non-distributed libraries, such as Inventor [35], allow
bodyText ||| programmers to avoid this problem by using the graphical scene
bodyText ||| description to encode application state. Extending this “single data-
bodyText ||| base” model to a distributed 3D graphics library is the goal of our
bodyText ||| work on Repo-3D.
bodyText ||| Repo-3D is an object-oriented, high-level graphics package,
bodyText ||| derived from Obliq-3D [25]. Its 3D graphics facilities are similar to
bodyText ||| those of other modern high-level graphics libraries. However, the
bodyText ||| objects used to create the graphical scenes are directly distribut-
bodyText ||| able—from the programmer’s viewpoint, the objects reside in one
bodyText ||| large distributed shared memory (DSM) instead of in a single
bodyText ||| process. The underlying system replicates any of the fine-grained
bodyText ||| objects across as many processes as needed, with no additional
bodyText ||| effort on the part of the programmer. Updates to objects are
bodyText ||| automatically reflected in all replicas, with any required objects
bodyText ||| automatically distributed as needed. By integrating the replicated
bodyText ||| objects into the programming languages we use, distributed
bodyText ||| applications may be built using Repo-3D with little more difficulty
bodyText ||| than building applications in a single process.
bodyText ||| No matter how simple the construction of a distributed applica-
bodyText ||| tion may be, a number of differences between distributed and
bodyText ||| monolithic applications must be addressed. These include:
listItem ||| •	Distributed control. In a monolithic application, a single com-
listItem ||| ponent can oversee the application and coordinate activities
listItem ||| among the separate components by notifying them of changes
listItem ||| to the application state. This is not possible in a non-trivial dis-
listItem ||| tributed application. Therefore, we must provide mechanisms
listItem ||| for different components to be notified of changes to the
listItem ||| distributed state.
listItem ||| •	Interactivity. Updates to distributed state will be slower than
listItem ||| updates to local state, and the amount of data that can be
listItem ||| distributed is limited by network bandwidth. If we do not want
listItem ||| to sacrifice interactive speed, we must be able to perform some
listItem ||| operations locally. For example, an object could be dragged
listItem ||| locally with the mouse, with only a subset of the changes
listItem ||| applied to the replicated state.
listItem ||| •	Local variations. There are times when a shared graphical
listItem ||| scene may need to be modified locally. For example, a
listItem ||| programmer may want to highlight the object under one user’s
listItem ||| mouse pointer without affecting the scene graph viewed by
listItem ||| other users.
bodyText ||| Repo-3D addresses these problems in two ways. First, a
bodyText ||| programmer can associate a notification object with any replicated
bodyText ||| object. The notification object’s methods will be invoked when the
bodyText ||| replicated object is updated. This allows reactive programs to be
bodyText ||| built in a straightforward manner. To deal with the second and third
bodyText ||| problems, we introduce the notion of local variations to graphical
bodyText ||| objects. That is, we allow the properties of a graphical object to be
bodyText ||| modified locally, and parts of the scene graph to be locally added,
bodyText ||| removed, or replaced.
bodyText ||| In Section 2 we describe how we arrived at the solution presented
bodyText ||| here. Section 3 discusses related work, and Section 4 offers a
bodyText ||| detailed description of the underlying infrastructure that was used.
bodyText ||| The design of Repo-3D is presented in Section 5, followed by
bodyText ||| some examples and concluding remarks in Sections 6 and 7.
sectionHeader ||| 2 BACKGROUND
bodyText ||| Repo-3D was created as part of a project to support rapid prototyp-
bodyText ||| ing of distributed, interactive 3D graphical applications, with a
bodyText ||| particular focus on DVEs. Our fundamental belief is that by
bodyText ||| providing uniform high-level support for distributed programming
bodyText ||| in the languages and toolkits we use, prototyping and experiment-
bodyText ||| ing with distributed interactive applications can be (almost) as
bodyText ||| simple as multi-threaded programming in a single process. While
bodyText ||| care must be taken to deal with network delays and bandwidth
bodyText ||| limitations at some stage of the program design (the languages and
bodyText ||| toolkits ought to facilitate this), it should be possible to ignore such
bodyText ||| issues until they become a problem. Our view can be summarized
bodyText ||| by a quote attributed to Alan Kay, “Simple things should be
bodyText ||| simple; complex things should be possible.”
bodyText ||| This is especially true during the exploration and prototyping
bodyText ||| phase of application programming. If programmers are forced to
bodyText ||| expend significant effort building the data-distribution components
bodyText ||| of the application at an early stage, not only will less time be spent
bodyText ||| exploring different prototypes, but radical changes in direction will
bodyText ||| become difficult, and thus unlikely. For example, the implementa-
bodyText ||| tion effort could cause programs to get locked into using a commu-
bodyText ||| nication scheme that may eventually prove less than ideal, or even
bodyText ||| detrimental, to the program’s final design.
bodyText ||| Since we are using object-oriented languages, we also believe
bodyText ||| that data distribution should be tightly integrated with the
bodyText ||| language’s general-purpose objects. This lets the language’s type
bodyText ||| system and programming constructs reduce or eliminate errors in
bodyText ||| the use of the data-distribution system. Language-level integration
bodyText ||| also allows the system to exhibit a high degree of network data
bodyText ||| transparency, or the ability for the programmer to use remote and
bodyText ||| local data in a uniform manner. Without pervasive, structured,
bodyText ||| high-level data-distribution support integrated into our program-
bodyText ||| ming languages and libraries, there are applications that will never
bodyText ||| be built or explored, either because there is too much programming
bodyText ||| overhead to justify trying simple things (“simple things are not
bodyText ||| simple”), or because the added complexity of using relatively
bodyText ||| primitive tools causes the application to become intractable (“com-
bodyText ||| plex things are not possible”).
bodyText ||| Of the tools available for integrating distributed objects into
bodyText ||| programming languages, client-server data sharing is by far the
bodyText ||| most common approach, as exemplified by CORBA [26],
bodyText ||| Modula-3 Network Objects [5], and Java RMI [39]. Unfortunately,
bodyText ||| interactive graphical applications, such as virtual reality, require
bodyText ||| that the data used to refresh the display be local to the process
bodyText ||| doing the rendering or acceptable frame refresh rates will not be
bodyText ||| achieved. Therefore, pure client-server approaches are inappropri-
bodyText ||| ate because at least some of the shared data must be replicated.
bodyText ||| Furthermore, since the time delay of synchronous remote method
bodyText ||| calls is unsuitable for rapidly changing graphical applications,
bodyText ||| shared data should be updated asynchronously. Finally, when data
bodyText ||| is replicated, local access must still be fast.
bodyText ||| The most widely used protocols for replicated data consistency,
bodyText ||| and thus many of the toolkits (e.g., ISIS [4] and Visual-Obliq [3]),
bodyText ||| allow data updates to proceed unimpeded, but block threads read-
bodyText ||| ing local data until necessary updates arrive. The same reason we
bodyText ||| need replicated data in the first place—fast local read access to the
bodyText ||| data—makes these protocols unsuitable for direct replication of the
bodyText ||| graphical data. Of course, these protocols are fine for replicating
bodyText ||| application state that will then be synchronized with a parallel
bodyText ||| graphical scene description, but that is what we are explicitly try-
bodyText ||| ing to avoid. Fortunately, there are replicated data systems (e.g.,
bodyText ||| Orca [2] or COTERIE [24]) that provide replicated objects that are
bodyText ||| well suited to interactive applications, and it is upon the second of
bodyText ||| these systems that Repo-3D is built.
sectionHeader ||| 3 RELATED WORK
bodyText ||| There has been a significant amount of work that falls under the
bodyText ||| first, older definition of distributed graphics. A large number of
bodyText ||| systems, ranging from established commercial products (e.g., IBM
bodyText ||| Visualization Data Explorer [21]) to research systems (e.g.,
bodyText ||| PARADISE [19] and ATLAS [14]), have been created to distribute
bodyText ||| interactive graphical applications over a set of machines. However,
bodyText ||| the goal of these systems is to facilitate sharing of application data
bodyText ||| between processes, with one process doing the rendering. While
bodyText ||| some of these systems can be used to display graphics on more
bodyText ||| than one display, they were not designed to support high-level
bodyText ||| sharing of graphical scenes.
bodyText ||| Most high-level graphics libraries, such as UGA [40], Inventor
bodyText ||| [35] and Java 3D [33], do not provide any support for distribution.
bodyText ||| Others, such as Performer [29], provide support for distributing
bodyText ||| components of the 3D graphics rendering system across multiple
bodyText ||| processors, but do not support distribution across multiple
bodyText ||| machines. One notable exception is TBAG [13], a high-level
bodyText ||| constraint-based, declarative 3D graphics framework. Scenes in
bodyText ||| TBAG are defined using constrained relationships between time-
bodyText ||| varying functions. TBAG allows a set of processes to share a
bodyText ||| single, replicated constraint graph. When any process asserts or
bodyText ||| retracts a constraint, it is asserted or retracted in all processes.
bodyText ||| However, this means that all processes share the same scene, and
bodyText ||| that the system’s scalability is limited because all processes have a
bodyText ||| copy of (and must evaluate) all constraints, whether or not they are
bodyText ||| interested in them. There is also no support for local variations of
bodyText ||| the scene in different processes.
bodyText ||| Machiraju [22] investigated an approach similar in flavor to ours,
bodyText ||| but it was not aimed at the same fine-grained level of interactivity
bodyText ||| and was ultimately limited by the constraints of the implementa-
bodyText ||| tion platform (CORBA and C++). For example, CORBA objects
bodyText ||| are heavyweight and do not support replication, so much of their
bodyText ||| effort was spent developing techniques to support object migration
bodyText ||| and “fine-grained” object sharing. However, their fine-grained
bodyText ||| objects are coarser than ours, and, more importantly, they do not
bodyText ||| support the kind of lightweight, transparent replication we desire.
bodyText ||| A programmer must explicitly choose whether to replicate, move,
bodyText ||| or copy an object between processes when the action is to occur (as
bodyText ||| opposed to at object creation time). Replicated objects are indepen-
bodyText ||| dent new copies that can be modified and used to replace the origi-
bodyText ||| nal—simultaneous editing of objects, or real-time distribution of
bodyText ||| changes as they are made is not supported.
bodyText ||| Of greater significance is the growing interest for this sort of sys-
bodyText ||| tem in the Java and VRML communities. Java, like Modula-3, is
bodyText ||| much more suitable as an implementation language than C or C++
bodyText ||| because of its cross-platform compatibility and support for threads
bodyText ||| and garbage collection: Without the latter two language features,
bodyText ||| implementing complex, large-scale distributed applications is
bodyText ||| extremely difficult. Most of the current effort has been focused on
bodyText ||| using Java as a mechanism to facilitate multi-user VRML worlds
bodyText ||| (e.g., Open Communities [38]). Unfortunately, these efforts
bodyText ||| concentrate on the particulars of implementing shared virtual
bodyText ||| environments and fall short of providing a general-purpose shared
bodyText ||| graphics library. For example, the Open Communities work is
bodyText ||| being done on top of SPLINE [1], which supports only a single
bodyText ||| top-level world in the local scene database.
bodyText ||| Most DVEs [11, 12, 16, 31, 32] provide support for creating
bodyText ||| shared virtual environments, not general purpose interactive 3D
bodyText ||| graphics applications. They implement a higher level of abstrac-
bodyText ||| tion, providing support for rooms, objects, avatars, collision detec-
bodyText ||| tion, and other things needed in single, shared, immersive virtual
bodyText ||| environments. These systems provide neither general-purpose
bodyText ||| programming facilities nor the ability to work with 3D scenes at a
bodyText ||| level provided by libraries such as Obliq-3D or Inventor. Some use
bodyText ||| communication schemes that prevent them from scaling beyond a
bodyText ||| relatively small number of distributed processes, but for most the
bodyText ||| focus is explicitly on efficient communication. SIMNET [7], and
bodyText ||| the later NPSNet [41], are perhaps the best known large-scale
bodyText ||| distributed virtual-environment systems. They use a fixed, well-
bodyText ||| defined communication protocol designed to support a single,
bodyText ||| large-scale, shared, military virtual environment.
bodyText ||| The techniques for object sharing implemented in recent CSCW
bodyText ||| toolkits [28, 30, 34, 37] provide some of the features we need,
bodyText ||| particularly automatic replication of data to ease construction of
bodyText ||| distributed applications. However, none of these toolkits has
bodyText ||| integrated the distribution of data into its programming language’s
bodyText ||| object model as tightly as we desire. As a result, they do not pro-
bodyText ||| vide a high enough level of network data transparency or suffi-
bodyText ||| ciently strong consistency guarantees. In groupware applications,
bodyText ||| inconsistencies tend to arise when multiple users attempt to per-
bodyText ||| form conflicting actions: the results are usually obvious to the
bodyText ||| users and can be corrected using social protocols. This is not an
bodyText ||| acceptable solution for a general-purpose, distributed 3D graphics
bodyText ||| toolkit. Furthermore, none of these CSCW systems provides any
bodyText ||| support for asynchronous update notification, or is designed to
bodyText ||| support the kind of large-scale distribution we have in mind.
bodyText ||| Finally, while distributed games, such as Quake, have become
bodyText ||| very popular, they only distribute the minimum amount of applica-
bodyText ||| tion state necessary. They do not use (or provide) an abstract, high-
bodyText ||| level distributed 3D graphics system.
bodyText ||| Network
figureCaption ||| Figure 2: The architecture of Repo-3D. Aside from native graphics
figureCaption ||| libraries (X, Win32, OpenGL, Renderware) the Modula-3 runtime
figureCaption ||| shields most of the application from the OS. The Replicated Object
figureCaption ||| package uses an Event communication package and the Network
figureCaption ||| Object package. DistAnim-3D is implemented on top of a variety of
figureCaption ||| native graphics libraries and Replicated Objects. Repo exposes most of
figureCaption ||| the useful Modula-3 packages, as well as using Network Objects and
figureCaption ||| Replicated Objects to present a distributed shared memory model to
figureCaption ||| the programmer.
sectionHeader ||| 4 UNDERLYING INFRASTRUCTURE
bodyText ||| Our work was done in the Modula-3 programming language [18].
bodyText ||| We decided to use Modula-3 because of the language itself and the
bodyText ||| availability of a set of packages that provide a solid foundation for
bodyText ||| our infrastructure. Modula-3 is a descendant of Pascal that corrects
bodyText ||| many of its deficiencies, and heavily influenced the design of Java.
bodyText ||| In particular, Modula-3 retains strong type safety, while adding
bodyText ||| facilities for exception handling, concurrence object-oriented
bodyText ||| programming, and automatic garbage collection . One of its most
bodyText ||| important features for our work is that it gives us uniform access to
bodyText ||| these facilities across all architectures.
bodyText ||| Repo-3D relies on a number of Modula-3 libraries, as illustrated
bodyText ||| in Figure 2. Distributed data sharing is provided by two packages,
bodyText ||| the Network Object client-server object package [5], and the
bodyText ||| Replicated Object shared object package [24] (see Section 4.1).
bodyText ||| DistAnim-3D is derived from Anim-3D [25], a powerful, non-
bodyText ||| distributed, general-purpose 3D library originally designed for 3D
bodyText ||| algorithm animation (see Section 4.2). Finally, Repo itself is a
bodyText ||| direct descendant of Obliq [8], and uses the Replicated Object
bodyText ||| package to add replicated data to Obliq (see Section 4.3).
subsectionHeader ||| 4.1 Distributed Shared Memory
bodyText ||| Repo-3D’s data sharing mechanism is based on the Shared Data-
bodyText ||| Object Model of Distributed Shared Memory (DSM) [20]. DSM
bodyText ||| allows a network of computers to be programmed much like a mul-
bodyText ||| tiprocessor, since the programmer is presented with the familiar
bodyText ||| paradigm of a common shared memory. The Shared Data-Object
bodyText ||| Model of DSM is particularly well suited to our needs since it is a
bodyText ||| high-level approach that can be implemented efficiently at the
bodyText ||| application level. In this model, shared data is encapsulated in
bodyText ||| user-defined objects and can only be accessed through those
bodyText ||| objects’ method calls. The DSM address space is partitioned
bodyText ||| implicitly by the application programmer, with an object being the
bodyText ||| smallest unit of sharing. All shared data is fully network transpar-
footnote ||| 2. The Modula-3 compiler we used is available from Critical Mass, Inc. as
footnote ||| part of the Reactor programming environment. The compiler, and thus
footnote ||| our system, runs on all the operating systems we have available (plus
footnote ||| others): Solaris, IRIX, HP-UX, Linux, and Windows NT and 95.
figure ||| Repo-3D
figure ||| Modula-3 Runtime
figure ||| Operating System Services
figure ||| Repo
figure ||| Network Objects
figure ||| Replicated Objects
figure ||| Events
figure ||| DistAnim-3D
figure ||| Native
figure ||| Graphics
bodyText ||| ent because it is encapsulated within the programming language
bodyText ||| objects.
bodyText ||| Distribution of new objects between the processes is as simple as
bodyText ||| passing them back and forth as parameters to, or return values
bodyText ||| from, method calls—the underlying systems take care of the rest.3
bodyText ||| Objects are only distributed to new processes as necessary, and (in
bodyText ||| our system) are removed by the garbage collector when they are no
bodyText ||| longer referenced. Furthermore, distributed garbage collection is
bodyText ||| supported, so objects that are no longer referenced in any process
bodyText ||| are removed completely.
bodyText ||| There are three kinds of distributed object semantics in our DSM:
listItem ||| •	Simple objects correspond to normal data objects, and have no
listItem ||| special distributed semantics. When a simple object is copied
listItem ||| between processes, a new copy is created in the destination
listItem ||| process that has no implied relationship to the object in the
listItem ||| source process.
listItem ||| •	Remote objects have client-server distribution semantics. When
listItem ||| a remote object is copied between processes, all processes
listItem ||| except the one in which the object was created end up with a
listItem ||| proxy object that forwards method invocations across the
listItem ||| network to the original object.
listItem ||| •	Replicated objects have replicated distribution semantics.
listItem ||| When a replicated object is passed between processes, a new
listItem ||| replica is created in the destination process. If any replica is
listItem ||| changed, the change is reflected in all replicas.
bodyText ||| The Network Object package provides support for remote
bodyText ||| objects. It implements distributed garbage collection, exception
bodyText ||| propagation back to the calling site, and automatic marshalling and
bodyText ||| unmarshalling of method arguments and return values of virtually
bodyText ||| any data type between heterogeneous machine architectures. The
bodyText ||| package is similar to other remote method invocation (RMI) pack-
bodyText ||| ages developed later, such as the Java RMI library [39]. All method
bodyText ||| invocations are forwarded to the original object, where they are
bodyText ||| executed in the order they are received.
bodyText ||| The Replicated Object package supports replicated objects. Each
bodyText ||| process can call any method of an object it shares, just as it can
bodyText ||| with a simple or remote object. We will describe the Replicated
bodyText ||| Object package in more detail, as Repo-3D relies heavily on its
bodyText ||| design, and the design of a replicated object system is less straight-
bodyText ||| forward than a remote one. The model supported by the Replicated
bodyText ||| Object package follows two principles:
listItem ||| •	All operations on an instance of an object are atomic and
listItem ||| serializable. All operations are performed in the same order on
listItem ||| all copies of the object. If two methods are invoked simulta-
listItem ||| neously, the order of invocation is nondeterministic, just as if
listItem ||| two threads attempted to access the same memory location
listItem ||| simultaneously in a single process.
listItem ||| •	The above principle applies to operations on single objects.
listItem ||| Making sequences of operations atomic is up to the program-
listItem ||| mer.
bodyText ||| The implementation of the Replicated Object package is based
bodyText ||| on the approach used in the Orca distributed programming
bodyText ||| language [2]. A full replication scheme is used, where a single
bodyText ||| object is either fully replicated in a process or not present at all.
bodyText ||| Avoiding partial replication significantly simplifies the implemen-
bodyText ||| tation and the object model, and satisfies the primary rationale for
bodyText ||| replication: fast read-access to shared data. To maintain replication
bodyText ||| consistency an update scheme is used, where updates to the object
bodyText ||| are applied to all copies.
footnote ||| 3. An important detail is how the communication is bootstrapped. In the
footnote ||| case of the Network and Replicated Object packages, to pass a first
footnote ||| object between processes, one of them exports the object to a special
footnote ||| network object demon under some known name on some known
footnote ||| machine. The second process then retrieves the object.
bodyText ||| The method of deciding what is and is not an update is what
bodyText ||| makes the Orca approach particularly interesting and easy to
bodyText ||| implement. All methods are marked as either read or update meth-
bodyText ||| ods by the programmer who creates the object type. Read methods
bodyText ||| are assumed to not change the state of the object and are therefore
bodyText ||| applied immediately to the local object without violating consis-
bodyText ||| tency. Update methods are assumed to change the state. To distrib-
bodyText ||| ute updates, arguments to the update method are marshalled into a
bodyText ||| message and sent to all replicas. To ensure all updates are applied
bodyText ||| in the same order, the current implementation of the Replicated
bodyText ||| Object package designates a sequencer process for each object.
bodyText ||| There may be more than one sequencer in the system to avoid
bodyText ||| overloading one process with all the objects (in this case, each
bodyText ||| object has its updates managed by exactly one of the sequencers.)
bodyText ||| The sequencer is responsible for assigning a sequence number to
bodyText ||| each message before it is sent to all object replicas. The replicas
bodyText ||| then execute the incoming update messages in sequence. The pro-
bodyText ||| cess that initiated the update does not execute the update until it
bodyText ||| receives a message back from the sequencer and all updates with
bodyText ||| earlier sequence numbers have been executed.
bodyText ||| There are three very important reasons for choosing this
bodyText ||| approach. First, it is easy to implement on top of virtually any
bodyText ||| object-oriented language, using automatically generated object
bodyText ||| subtypes and method wrappers that communicate with a simple
bodyText ||| runtime system. We do this in our Modula-3 implementation, and it
bodyText ||| would be equally applicable to an implementation in C++ or Java.
bodyText ||| For example, the JSDT [36] data-sharing package in Java uses a
bodyText ||| similar approach.
bodyText ||| Second, the Replicated Object package does not pay attention to
bodyText ||| (or even care) when the internal data fields of an object change.
bodyText ||| This allows the programmer great flexibility in deciding exactly
bodyText ||| what constitutes an update or not, and what constitutes the shared
bodyText ||| state 4. For example, objects could have a combination of global
bodyText ||| and local state, and the methods that change the local state could
bodyText ||| be classified as read methods since they do not modify the global
bodyText ||| state. Alternatively, read methods could do some work locally and
bodyText ||| then call an update method to propagate the results, allowing time-
bodyText ||| consuming computation to be done once and the result distributed
bodyText ||| in a clean way. We took advantage of both of these techniques in
bodyText ||| implementing Repo-3D.
bodyText ||| Finally, the immediate distribution of update methods ensures
bodyText ||| that changes are distributed in a timely fashion, and suggests a
bodyText ||| straightforward solution to the asynchronous notification problem.
bodyText ||| The Replicated Object package generates a Notification Object
bodyText ||| type for each Replicated Object type. These new objects have
bodyText ||| methods corresponding to the update methods of their associated
bodyText ||| Replicated Object. The arguments to these methods are the same as
bodyText ||| the corresponding Replicated Object methods, plus an extra
bodyText ||| argument to hold the Replicated Object instance. These notifiers
bodyText ||| can be used by a programmer to receive notification of changes to
bodyText ||| a Replicated Object in a structured fashion. To react to updates to a
bodyText ||| Replicated Object instance, a programmer simply overrides the
bodyText ||| methods of the corresponding Notification Object with methods
bodyText ||| that react appropriately to those updates, and associates an instance
footnote ||| 4. Of course, it falls squarely on the shoulders of the programmer to
footnote ||| ensure that the methods provided always leave the object in a consistent
footnote ||| state. This is not significantly different than what needs to be done
footnote ||| when building a complex object that is simultaneously accessed by
footnote ||| multiple threads in a non-distributed system. For example, if a
footnote ||| programmer reads an array of numbers from inside the object and then
footnote ||| uses an update method to write a computed average back into the
footnote ||| object, the internal array may have changed before the average is
footnote ||| written, resulting in a classic inconsistency problem. In general,
footnote ||| methods that perform computations based on internal state (rather than
footnote ||| on the method arguments) are potentially problematic and need to be
footnote ||| considered carefully.
figure ||| RootGO
figure ||| ChoiceGroupGO
figure ||| OrthoCameraGO
figure ||| PerspCameraGO
figure ||| AmbientLightGO
figure ||| VectorLightGO
figure ||| PointLightGO
figure ||| SpotLightGO
figure ||| GO
figure ||| IndexedLineSetGO
figure ||| NonSurfaceGO
figure ||| Text2DGO
figure ||| PolygonGO
figure ||| BoxGO
figure ||| SphereGO
figure ||| CylinderGO
figure ||| DiskGO
figure ||| TorusGO
figure ||| QuadMeshGO
figure ||| IndexedPolygonSetGO
figureCaption ||| Figure 3: The Repo-3D GO class hierarchy. Most of the classes are
figureCaption ||| also in Obliq-3D; the italicized ones were added to Repo-3D.
figureCaption ||| Figure 4: The relationship between properties, names, values, and
figureCaption ||| behaviors. Each oval represents an object and arrows show contain-
figureCaption ||| ment.
bodyText ||| of it with the Replicated Object instance. Each time an update
bodyText ||| method of the Replicated Object is invoked, the corresponding
bodyText ||| method of the Notifier Object is also invoked. Notification Objects
bodyText ||| eliminate the need for object polling and enable a “data-driven”
bodyText ||| flow of control.
subsectionHeader ||| 4.2 Obliq-3D
bodyText ||| Obliq-3D is composed of Anim-3D, a 3D animation package
bodyText ||| written in Modula-3, and a set of wrappers that expose Anim-3D to
bodyText ||| the Obliq programming language (see Section 4.3). Anim-3D is
bodyText ||| based on three simple and powerful concepts: graphical objects for
bodyText ||| building graphical scenes, properties for specifying the behavior of
bodyText ||| the graphical objects, and input event callbacks to support interac-
bodyText ||| tive behavior. Anim-3D uses the damage-repair model: whenever a
bodyText ||| graphical object or property changes (is damaged), the image is
bodyText ||| repaired without programmer intervention.
bodyText ||| Graphical objects (GOs) represent all the logical entities in the
bodyText ||| graphical scene: geometry (e.g., lines, polygons, spheres, polygon
bodyText ||| sets, and text), lights and cameras of various sorts, and groups of
bodyText ||| other GOs. One special type of group, the RootGO, represents a
bodyText ||| window into which graphics are rendered. GOs can be grouped
bodyText ||| together in any valid directed acyclic graph (DAG). The GO class
bodyText ||| hierarchy is shown in Figure 3.
bodyText ||| A property is a defined by a name and a value. The name deter-
bodyText ||| mines which attribute is affected by the property, such as “Texture
bodyText ||| Mode” or “Box Corner1”. The value specifies how it is affected
bodyText ||| and is determined by its behavior, a time-variant function that
bodyText ||| takes the current animation time and returns a value. Properties,
bodyText ||| property values, and behaviors are all objects, and their relation-
bodyText ||| ships are shown in Figure 4. When a property is created, its name
bodyText ||| and value are fixed. However, values are mutable and their behav-
bodyText ||| ior may be changed at any time. There are four kinds of behaviors
bodyText ||| for each type of properties: constant (do not vary over time),
bodyText ||| synchronous (follow a programmed set of requests, such as “move
bodyText ||| from A to B starting at time t=1 and taking 2 seconds”), asynchro-
bodyText ||| nous (execute an arbitrary time-dependent function to compute the
bodyText ||| value) and dependent (asynchronous properties that depend on
bodyText ||| other properties). Synchronous properties are linked to animation
bodyText ||| handles and do not start satisfying their requests until the anima-
bodyText ||| tion handle is signalled. By linking multiple properties to the same
bodyText ||| handle, a set of property value changes can be synchronized.
bodyText ||| Associated with each GO g is a partial mapping of property
bodyText ||| names to values determined by the properties that have been asso-
bodyText ||| ciated with g. A property associated with g affects not only g but
bodyText ||| all the descendants of g that do not override the property. A single
bodyText ||| property may be associated with any number of GOs. It is perfectly
bodyText ||| legal to associate a property with a GO that is not affected by it; for
bodyText ||| example, attaching a “Surface Color” property to a GroupGO does
bodyText ||| not affect the group node itself, but could potentially affect the
bodyText ||| surface color of any GO contained in that group. A RootGO sets an
bodyText ||| initial default value for each named property.
bodyText ||| There are three types of input event callbacks in Anim-3D, corre-
bodyText ||| sponding to the three kinds of interactive events they handle:
bodyText ||| mouse callbacks (triggered by mouse button events), motion call-
bodyText ||| backs (triggered by mouse motion events) and keyboard callbacks
bodyText ||| (triggered by key press events). Each object has three callback
bodyText ||| stacks, and the interactive behavior of an object can be redefined
bodyText ||| by pushing a new callback onto the appropriate stack. Any event
bodyText ||| that occurs within a root window associated with a RootGO r will
bodyText ||| be delivered to the top handler on r’s callback stack. The handler
bodyText ||| could delegate the event to one of r’s children, or it may handle it
bodyText ||| itself, perhaps changing the graphical scene in some way.
bodyText ||| DistAnim-3D is a direct descendant of Anim-3D. In addition to
bodyText ||| the objects being distributed, it has many additional facilities that
bodyText ||| are needed for general-purpose 3D graphical applications, such as
bodyText ||| texture mapping, indexed line and polygon sets, choice groups,
bodyText ||| projection and transformation callbacks, and picking. Since
bodyText ||| DistAnim-3D is embedded in Repo instead of Obliq (see
bodyText ||| Section 4.3), the resulting library is called Repo-3D.
subsectionHeader ||| 4.3 Obliq and Repo
bodyText ||| Obliq [8] is a lexically-scoped, untyped, interpreted language for
bodyText ||| distributed object-oriented computation. It is implemented in, and
bodyText ||| tightly integrated with, Modula-3. An Obliq computation may
bodyText ||| involve multiple threads of control within an address space, multi-
bodyText ||| ple address spaces on a machine, heterogeneous machines over a
bodyText ||| local network, and multiple networks over the Internet. Obliq uses,
bodyText ||| and supports, the Modula-3 thread, exception, and garbage-collec-
bodyText ||| tion facilities. Its distributed-computation mechanism is based on
bodyText ||| Network Objects, allowing transparent support for multiple
bodyText ||| processes on heterogeneous machines. Objects are local to a site,
bodyText ||| while computations can roam over the network. Repo [23] is a
bodyText ||| descendant of Obliq that extends the Obliq object model to include
bodyText ||| replicated objects. Therefore, Repo objects have state that may be
bodyText ||| local to a site (as in Obliq) or replicated across multiple sites.
sectionHeader ||| 5 DESIGN OF REPO-3D
bodyText ||| Repo-3D’s design has two logical parts: the basic design and local
bodyText ||| variations. The basic design encompasses the changes to Obliq-3D
bodyText ||| to carry it into a distributed context, and additional enhancements
bodyText ||| that are not particular to distributed graphics (and are therefore not
bodyText ||| discussed here). Local variations are introduced to handle two
bodyText ||| issues mentioned in Section 1: transient local changes and respon-
bodyText ||| sive local editing.
figure ||| . . .
figure ||| Name
figure ||| Property
figure ||| Value	Behavior
figure ||| Request
figure ||| Request
figure ||| GroupGO
figure ||| CameraGO
figure ||| LightGO
figure ||| SurfaceGO
figure ||| LineGO
figure ||| MarkerGO
figure ||| TextGO
subsectionHeader ||| 5.1 Basic Repo-3D Design
bodyText ||| The Anim-3D scene-graph model is well suited for adaptation to a
bodyText ||| distributed environment. First, in Anim-3D, properties are attached
bodyText ||| to nodes, not inserted into the graph, and the property and child
bodyText ||| lists are unordered (i.e., the order in which properties are assigned
bodyText ||| to a node, or children are added to a group, does not affect the final
bodyText ||| result). In libraries that insert properties and nodes in the graph and
bodyText ||| execute the graph in a well-defined order (such as Inventor), the
bodyText ||| siblings of a node (or subtree) can affect the attributes of that node
bodyText ||| (or subtree). In Anim-3D, and similar libraries (such as Java 3D),
bodyText ||| properties are only inherited down the graph, so a node’s properties
bodyText ||| are a function of the node itself and its ancestors—its siblings do
bodyText ||| not affect it. Therefore, subtrees can be added to different scene
bodyText ||| graphs, perhaps in different processes, with predictable results.
bodyText ||| Second, the interface (both compiled Anim-3D and interpreted
bodyText ||| Obliq-3D) is programmatical and declarative. There is no “graphi-
bodyText ||| cal scene” file format per se: graphical scenes are created as the
bodyText ||| side effect of executing programs that explicitly create objects and
bodyText ||| manipulate them via the object methods. Thus, all graphical
bodyText ||| objects are stored as the Repo-3D programs that are executed to
bodyText ||| create them. This is significant, because by using the Replicated
bodyText ||| Object library described in Section 4.1 to make the graphical
bodyText ||| objects distributed, the “file format” (i.e., a Repo-3D program) is
bodyText ||| updated for free.
bodyText ||| Converting Anim-3D objects to Replicated Objects involved
bodyText ||| three choices: what objects to replicate, what methods update the
bodyText ||| object state, and what the global, replicated state of each object is.
bodyText ||| Since replicated objects have more overhead (e.g., method execu-
bodyText ||| tion time, memory usage, and latency when passed between
bodyText ||| processes), not every category of object in Repo-3D is replicated.
bodyText ||| We will consider each of the object categories described in
bodyText ||| Figure 4.2 in turn: graphical objects (GOs), properties (values,
bodyText ||| names, behaviors, animation handles) and callbacks. For each of
bodyText ||| these objects, the obvious methods are designated as update meth-
bodyText ||| ods, and, as discussed in Section 4. 1, the global state of each object
bodyText ||| is implicitly determined by those update methods. Therefore, we
bodyText ||| will not go into excessive detail about either the methods or the
bodyText ||| state. Finally, Repo-3D’s support for change notification will be
bodyText ||| discussed.
subsubsectionHeader ||| 5.1.1 Graphical Objects
bodyText ||| GOs are the most straightforward. There are currently twenty-one
bodyText ||| different types of GOs, and all but the RootGOs are replicated.
bodyText ||| Since RootGOs are associated with an onscreen window, they are
bodyText ||| not replicated—window creation remains an active decision of the
bodyText ||| local process. Furthermore, if replicated windows are needed, the
bodyText ||| general-purpose programming facilities of Repo can be used to
bodyText ||| support this in a relatively straightforward manner, outside the
bodyText ||| scope of Repo-3D. A GO’s state is comprised of the properties
bodyText ||| attached to the object, its name, and some other non-inherited
bodyText ||| property attributes.5 The methods that modify the property list are
bodyText ||| update methods. Group GOs also contain a set of child nodes, and
bodyText ||| have update methods that modify that set.
subsubsectionHeader ||| 5.1.2 Properties
bodyText ||| Properties are more complex. There are far more properties in a
bodyText ||| graphical scene than there are graphical objects, they change much
bodyText ||| more rapidly, and each property is constructed from a set of
bodyText ||| Modula-3 objects. There are currently 101 different properties of
footnote ||| 5. Some attributes of a GO, such as the arrays of Point3D properties that
footnote ||| define the vertices of a polygon set, are not attached to the object, but
footnote ||| are manipulated through method calls.
bodyText ||| seventeen different types in Repo-3D, and any of them can be
bodyText ||| attached to any GO. A typical GO would have anywhere from two
bodyText ||| or three (e.g., a BoxGO would have at least two properties to
bodyText ||| define its corners) to a dozen or more. And, each of these proper-
bodyText ||| ties could be complex: in the example in Section 6, a single
bodyText ||| synchronous property for a long animation could have hundreds of
bodyText ||| requests enqueued within it.
bodyText ||| Consider again the object structure illustrated in Figure 4. A
bodyText ||| property is defined by a name and a value, with the value being a
bodyText ||| container for a behavior. Only one of the Modula-3 objects is
bodyText ||| replicated, the property value. Property values serve as the repli-
bodyText ||| cated containers for property behaviors. To change a property, a
bodyText ||| new behavior is assigned to its value. The state of the value is the
bodyText ||| current behavior.
bodyText ||| Animation handles are also replicated. They tie groups of related
bodyText ||| synchronous properties together, and are the basis for the interac-
bodyText ||| tion in the example in Section 6. In Anim-3D, handles have one
bodyText ||| animate method, which starts an animation and blocks until it
bodyText ||| finishes. Since update methods are executed everywhere, and block
bodyText ||| access to the object while they are being executed, they should not
bodyText ||| take an extended period of time. In creating Repo-3D, the
bodyText ||| animate method was changed to call two new methods: an update
bodyText ||| method that starts the animation, and a non-update method that
bodyText ||| waits for the animation to finish. We also added methods to pause
bodyText ||| and resume an animation, to retrieve and change the current rela-
bodyText ||| tive time of an animation handle, and to stop an animation early.
bodyText ||| The state of an Animation handle is a boolean value that says if it is
bodyText ||| active or not, plus the start, end, and current time (if the handle is
bodyText ||| paused).
bodyText ||| Most of the Modula-3 objects that comprise a property are not
bodyText ||| replicated, for a variety of reasons:
listItem ||| •	Properties represent a permanent binding between a property
listItem ||| value and a name. Since they are immutable, they have no syn-
listItem ||| chronization requirements and can simply be copied between
listItem ||| processes.
listItem ||| •	Names represent simple constant identifiers, and are therefore
listItem ||| not replicated either.
listItem ||| •	Behaviors and requests are not replicated. While they can be
listItem ||| modified after being created, they are treated as immutable
listItem ||| data types for two reasons. First, the vast majority of behaviors,
listItem ||| even complex synchronous ones, are not changed once they
listItem ||| have been created and initialized. Thus, there is some justifica-
listItem ||| tion for classifying the method calls that modify them as part
listItem ||| of their initialization process. The second reason is practical
listItem ||| and much more significant. Once a scene has been created and
listItem ||| is being “used” by the application, the bulk of the time-critical
listItem ||| changes to it tend to be assignments of new behaviors to the
listItem ||| existing property values. For example, an object is moved by
listItem ||| assigning a new (often constant) behavior to its
listItem ||| GO _T rans fo rm property value. Therefore, the overall perfor-
listItem ||| mance of the system depends heavily on the performance of
listItem ||| property value behavior changes. By treating behaviors as
listItem ||| immutable objects, they can simply be copied between
listItem ||| processes without incurring the overhead of the replicated
listItem ||| object system.
subsubsectionHeader ||| 5.1.3 Input Callbacks
bodyText ||| In Repo-3D, input event callbacks are not replicated. As discussed
bodyText ||| in Section 4.2, input events are delivered to the callback stacks of a
bodyText ||| RootGO. Callbacks attached to any other object receive input
bodyText ||| events only if they are delivered to that object by the programmer,
bodyText ||| perhaps recursively from another input event callback (such as the
bodyText ||| one attached to the RootGO). Therefore, the interactive behavior of
bodyText ||| a root window is defined not only by the callbacks attached to its
bodyText ||| RootGO, but also by the set of callbacks associated with the graph
bodyText ||| rooted at that RootGO. Since the RootGOs are not replicated, the
figure ||| (a)	(b)
figure ||| (c) (d)
figureCaption ||| Figure 5: Simultaneous images from a session with the distributed CATHI animation viewer, running on four machines, showing an anima-
figureCaption ||| tion of an engine. (a) Plain animation viewer, running on Windows NT. (b) Overview window, running on Windows 95. (c) Animation viewer
figureCaption ||| with local animation meter, running on IRIX. (d) Animation viewer with local transparency to expose hidden parts, running on Solaris.
bodyText ||| callbacks that they delegate event handling to are not replicated
bodyText ||| either. If a programmer wants to associate callbacks with objects as
bodyText ||| they travel between processes, Repo’s general-purpose program-
bodyText ||| ming facilities can be used to accomplish this in a straightforward
bodyText ||| manner.
subsubsectionHeader ||| 5.1.4 Change Notification
bodyText ||| The final component of the basic design is support for notification
bodyText ||| of changes to distributed objects. For example, when an object’s
bodyText ||| position changes or a new child is added to a group, some of the
bodyText ||| processes containing replicas may wish to react in some way. For-
bodyText ||| tunately, as discussed in Section 4.1, the Replicated Object
bodyText ||| package automatically generates Notification Object types for all
bodyText ||| replicated object types, which provide exactly the required
bodyText ||| behavior. The Notification Objects for property values allow a
bodyText ||| programmer to be notified of changes to the behavior of a property,
bodyText ||| and the Notification Objects for the various GOs likewise allow
bodyText ||| notification of updates to them.
subsectionHeader ||| 5.2 Local Variations
bodyText ||| Repo-3D’s local variations solve a set of problems particular to the
bodyText ||| distributed context in which Repo-3D lives: maintaining interactiv-
bodyText ||| ity and supporting local modifications to the shared scene graph.
bodyText ||| If the graphical objects and their properties were always strictly
bodyText ||| replicated, programmers would have to create local variations by
bodyText ||| copying the objects to be modified, creating a set of Notification
bodyText ||| Objects on the original objects, the copies of those objects, and all
bodyText ||| their properties (to be notified when either change), and reflecting
bodyText ||| the appropriate changes between the instances. Unfortunately,
bodyText ||| while this process could be automated somewhat, it would still be
bodyText ||| extremely tedious and error prone. More seriously, the overhead of
bodyText ||| creating this vast array of objects and links between them would
bodyText ||| make this approach impractical for short transient changes, such as
bodyText ||| highlighting an object under the mouse.
bodyText ||| To overcome this problem, Repo-3D allows the two major
bodyText ||| elements of the shared state of the graphical object scene—the
bodyText ||| properties attached to a GO and the children of a group—to have
bodyText ||| local variations applied to them. (Local variations on property
bodyText ||| values or animation handles are not supported, although we are
bodyText ||| considering adding support for the latter.)
bodyText ||| Conceptually, local state is the state added to each object (the
bodyText ||| additions, deletions, and replacements to the properties or
bodyText ||| children) that is only accessible to the local copies and is not
bodyText ||| passed to remote processes when the object is copied to create a
bodyText ||| new replica. The existence of local state is possible because, as
bodyText ||| discussed in Section 4. 1, the shared state of a replicated object is
bodyText ||| implicitly defined by the methods that update it 6. Therefore, the
bodyText ||| new methods that manipulate the local variations are added to the
bodyText ||| GOs as non-update methods. Repo-3D combines both the global
bodyText ||| and local state when creating the graphical scene using the under-
bodyText ||| lying graphics package.
bodyText ||| As mentioned above, local variations come in two flavors:
listItem ||| •	Property variations. There are three methods to set, unset, and
listItem ||| get the global property list attached to a GO. We added the
listItem ||| following methods to manipulate local variations: add or
listItem ||| remove local properties (overriding the value normally used for
listItem ||| the object), hide or reveal properties (causing the property
listItem ||| value of the parent node to be inherited), and flush the set of
listItem ||| local variations (removing them in one step) or atomically
listItem ||| apply them to the global state of the object.
listItem ||| •	Child variations. There are five methods to add, remove,
listItem ||| replace, retrieve, and flush the set of children contained in a
listItem ||| group node. We added the following ones: add a local node,
listItem ||| remove a global node locally, replace a global node with some
listItem ||| other node locally, remove each of these local variations, flush
listItem ||| the local variations (remove them all in one step), and atomi-
listItem ||| cally apply the local variations to the global state.
bodyText ||| This set of local operations supports the problems local variations
bodyText ||| were designed to solve, although some possible enhancements are
bodyText ||| discussed in Section 7.
sectionHeader ||| 6 EXAMPLE: AN ANIMATION EXAMINER
bodyText ||| As an example of the ease of prototyping distributed applications
bodyText ||| with Repo-3D, we created a distributed animation examiner for the
bodyText ||| CATHI [6] animation generation system. CATHI generates short
bodyText ||| informational animation clips to explain the operation of technical
bodyText ||| devices. It generates full-featured animation scripts, including
bodyText ||| camera and object motion, color and opacity effects, and lighting
bodyText ||| setup.
bodyText ||| It was reasonably straightforward to modify CATHI to generate
bodyText ||| Repo-3D program files, in addition to the GeomView and Render-
bodyText ||| Man script files it already generated. The resulting output is a
bodyText ||| Repo-3D program that creates two scene DAGs: a camera graph
bodyText ||| and a scene graph. The objects in these DAGs have synchronous
bodyText ||| behaviors specified for their surface and transformation properties.
bodyText ||| An entire animation is enqueued in the requests of these behaviors,
bodyText ||| lasting anywhere from a few seconds to a few minutes.
bodyText ||| We built a distributed, multi-user examiner over the course of a
bodyText ||| weekend. The examiner allows multiple users to view the same
bodyText ||| animation while discussing it (e.g., via electronic chat or on the
bodyText ||| phone). Figure 5 shows images of the examiner running on four
footnote ||| 6. The local state is not copied when a replicated object is first passed to a
footnote ||| new process because the Repo-3D objects have custom serialization
footnote ||| routines (or Picklers, in Modula-3 parlance). These routines only pass
footnote ||| the global state, and initialize the local state on the receiving side to
footnote ||| reasonable default values corresponding to the empty local state.
bodyText ||| machines, each with a different view of the scene. The first step
bodyText ||| was to build a simple “loader” that reads the animation file, creates
bodyText ||| a window, adds the animation scene and camera to it, and exports
bodyText ||| the animation on the network, requiring less than a dozen lines of
bodyText ||| Repo-3D code. A “network” version, that imports the animation
bodyText ||| from the network instead of reading it from disk, replaced the lines
bodyText ||| of code to read and export the animation with a single line to
bodyText ||| import it. Figure 5(a) shows an animation being viewed by one of
bodyText ||| these clients.
bodyText ||| The examiner program is loaded by both these simple clients, and
bodyText ||| is about 450 lines long. The examiner supports:
listItem ||| •	Pausing and continuing the animation, and changing the
listItem ||| current animation time using the mouse. Since this is done by
listItem ||| operating on the shared animation handle, changes performed
listItem ||| by any viewer are seen by all. Because of the consistency guar-
listItem ||| antees, all users can freely attempt to change the time, and the
listItem ||| system will maintain all views consistently.
listItem ||| •	A second “overview” window (Figure 5(b)), where a new
listItem ||| camera watches the animation scene and camera from a distant
listItem ||| view. A local graphical child (representing a portion of the
listItem ||| animation camera’s frustum) was added to the shared anima-
listItem ||| tion camera group to let the attributes of the animation camera
listItem ||| be seen in the overview window.
listItem ||| •	A local animation meter (bottom of Figure 5(c)), that can be
listItem ||| added to any window by pressing a key, and which shows the
listItem ||| current time offset into the animation both graphically and
listItem ||| numerically. It was added in front of the camera in the anima-
listItem ||| tion viewer window, as a local child of a GO in the camera
listItem ||| graph, so that it would be fixed to the screen in the animation
listItem ||| viewer.
listItem ||| •	Local editing (Figure 5(d)), so that users can select objects and
listItem ||| make them transparent (to better see what was happening in the
listItem ||| animation) or hide them completely (useful on slow machines,
listItem ||| to speed up rendering). Assorted local feedback (highlighting
listItem ||| the object under the mouse and flashing the selected object)
listItem ||| was done with local property changes to the shared GOs in the
listItem ||| scene graph.
bodyText ||| Given the attention paid to the design of Repo-3D, it was not
bodyText ||| necessary to be overly concerned with the distributed behavior of
bodyText ||| the application (we spent no more than an hour or so). Most of that
bodyText ||| time was spent deciding if a given operation should be global or a
bodyText ||| local variation. The bulk of programming and debugging time was
bodyText ||| spent implementing application code. For example, in the overview
bodyText ||| window, the representation of the camera moves dynamically,
bodyText ||| based on the bounding values of the animation’s scene and camera
bodyText ||| graphs. In editing mode, the property that flashes the selected node
bodyText ||| bases its local color on the current global color (allowing a user
bodyText ||| who is editing while an animation is in progress to see any color
bodyText ||| changes to the selected node.)
sectionHeader ||| 7 CONCLUSIONS AND FUTURE WORK
bodyText ||| We have presented the rationale for, and design of, Repo-3D, a
bodyText ||| general-purpose, object-oriented library for developing distributed,
bodyText ||| interactive 3D graphics applications across a range of heteroge-
bodyText ||| neous workstations. By presenting the programmer with the
bodyText ||| illusion of a large shared memory, using the Shared Data-Object
bodyText ||| model of DSM, Repo-3D makes it easy for programmers to rapidly
bodyText ||| prototype distributed 3D graphics applications using a familiar
bodyText ||| object-oriented programming paradigm. Both graphical and
bodyText ||| general-purpose, non-graphical data can be shared, since Repo-3D
bodyText ||| is embedded in Repo, a general-purpose, lexically-scoped, distrib-
bodyText ||| uted programming language.
bodyText ||| Repo-3D is designed to directly support the distribution of graph-
bodyText ||| ical objects, circumventing the “duplicate database” problem and
bodyText ||| allowing programmers to concentrate on the application function-
bodyText ||| ality of a system, rather than its communication or synchronization
bodyText ||| components. We have introduced a number of issues that must be
bodyText ||| considered when building a distributed 3D graphics library, espe-
bodyText ||| cially concerning efficient and clean support for data distribution
bodyText ||| and local variations of shared graphical scenes, and discussed how
bodyText ||| Repo-3D addresses them.
bodyText ||| There are a number of ways in which Repo-3D could be
bodyText ||| improved. The most important is the way the library deals with
bodyText ||| time. By default, the library assumes all machines are running a
bodyText ||| time-synchronization rotocol, such as NTP, and uses an internal
bodyText ||| animation time offset�(instead of the system-specific time offset)
bodyText ||| because different OSs (e.g., NT vs. UNIX) start counting time at
bodyText ||| different dates. Hooks have been provided to allow a programmer
bodyText ||| to specify their own function to compute the “current” animation
bodyText ||| time offset within a process. Using this facility, it is possible to
bodyText ||| build inter-process time synchronization protocols (which we do),
bodyText ||| but this approach is not entirely satisfactory given our stated goal
bodyText ||| of relieving the programmer of such tedious chores. Future
bodyText ||| systems should integrate more advanced solutions, such as adjust-
bodyText ||| ing time values as they travel between machines, so that users of
bodyText ||| computers with unsynchronized clocks can collaborate8. This will
bodyText ||| become more important as mobile computers increase in popular-
bodyText ||| ity, as it may not be practical to keep their clocks synchronized.
bodyText ||| The specification of local variations in Repo-3D could benefit
bodyText ||| from adopting the notion of paths (as used in Java 3D and Inventor,
bodyText ||| for example). A path is an array of objects leading from the root of
bodyText ||| the graph to an object; when an object occurs in multiple places in
bodyText ||| one or more scene graphs, paths allow these instances to be differ-
bodyText ||| entiated. By specifying local variations using paths, nodes in the
bodyText ||| shared scene graphs could have variations within a process as well
bodyText ||| as between processes. One other limitation of Repo-3D, arising
bodyText ||| from our use of the Replicated Object package, is that there is no
bodyText ||| way to be notified when local variations are applied to an object.
bodyText ||| Recall that the methods of an automatically generated Notification
bodyText ||| Object correspond to the update methods of the corresponding
bodyText ||| Replicated Object. Since the methods that manipulate the local
bodyText ||| variations are non-update methods (i.e., they do not modify the
bodyText ||| replicated state), there are no corresponding methods for them in
bodyText ||| the Notification Objects. Of course, it would be relatively straight-
bodyText ||| forward to modify the Replicated Object package to support this,
bodyText ||| but we have not yet found a need for these notifiers.
bodyText ||| A more advanced replicated object system would also improve
bodyText ||| the library. Most importantly, support for different consistency
bodyText ||| semantics would be extremely useful. If we could specify
bodyText ||| semantics such as “all updates completely define the state of an
bodyText ||| object, and only the last update is of interest,” the efficiency of the
bodyText ||| distribution of property values would improve significantly; in this
bodyText ||| case, updates could be applied (or discarded) when they arrive,
bodyText ||| without waiting for all previous updates to be applied, and could be
bodyText ||| applied locally without waiting for the round trip to the sequencer.
bodyText ||| There are also times when it would be useful to have support for
bodyText ||| consistency across multiple objects, either using causal ordering
bodyText ||| (as provided by systems such as ISIS and Visual-Obliq), or some
bodyText ||| kind of transaction protocol to allow large groups of changes to be
bodyText ||| applied either as a unit, or not at all. It is not clear how one would
bodyText ||| provide these features with a replicated object system such as the
bodyText ||| one used here.
bodyText ||| While a library such as Repo-3D could be built using a variety of
bodyText ||| underlying platforms, the most likely one for future work is Java.
bodyText ||| Java shares many of the advantages of Modula-3 (e.g., threads and
bodyText ||| garbage collection are common across all architectures) and the
footnote ||| 7. Computed as an offset from January 1, 1997.
footnote ||| 8. Implementation details of the combination of Network and Replicated
footnote ||| Objects made it difficult for us to adopt a more advanced solution.
bodyText ||| packages needed to create a Repo-3D-like toolkit are beginning to
bodyText ||| appear. While Java does not yet have a replicated object system as
bodyText ||| powerful as the Replicated Object package, a package such as
bodyText ||| JSDT [36] (which focuses more on data communication than high-
bodyText ||| level object semantics) may be a good starting point. Work is also
bodyText ||| being done on interpreted, distributed programming languages on
bodyText ||| top of Java (e.g., Ambit [9]). Finally, Java 3D is very similar to
bodyText ||| Anim-3D, even though its design leans toward efficiency instead of
bodyText ||| generality when there are trade-offs to be made. For example, the
bodyText ||| designers chose to forgo Anim-3D’s general property inheritance
bodyText ||| mechanism because it imposes computational overhead. By com-
bodyText ||| bining packages such as Java 3D, JSDT, and Ambit, it should be
bodyText ||| possible to build a distributed graphics library such as Repo-3D in
bodyText ||| Java.
sectionHeader ||| Acknowledgments
bodyText ||| We would like to thank the reviewers for their helpful comments,
bodyText ||| as well as the many other people who have contributed to this
bodyText ||| project. Andreas Butz ported CATHI to use Repo-3D and helped
bodyText ||| with the examples and the video. Clifford Beshers participated in
bodyText ||| many lively discussions about the gamut of issues dealing with
bodyText ||| language-level support for 3D graphics. Tobias Höllerer and
bodyText ||| Steven Dossick took part in many other lively discussions. Xinshi
bodyText ||| Sha implemented many of the extensions to Obliq-3D that went
bodyText ||| into Repo-3D. Luca Cardelli and Marc Najork of DEC SRC
bodyText ||| created Obliq and Obliq-3D, and provided ongoing help and
bodyText ||| encouragement over the years that Repo and Repo-3D have been
bodyText ||| evolving.
bodyText ||| This research was funded in part by the Office of Naval Research
bodyText ||| under Contract N00014-97-1-0838 and the National Tele-Immer-
bodyText ||| sion Initiative, and by gifts of software from Critical Mass and
bodyText ||| Microsoft.
sectionHeader ||| References
reference ||| [1] D. B. Anderson, J. W. Barrus, J. H. Howard, C. Rich, C. Shen, and
reference ||| R. C. Waters. Building Multi-User Interactive Multimedia Environ-
reference ||| ments at MERL. Technical Report Research Report TR95-17, Mit-
reference ||| subishi Electric Research Laboratory, November 1995.
reference ||| [2] H. Bal, M. Kaashoek, and A. Tanenbaum. Orca: A Language for
reference ||| Parallel Programming of Distributed Systems. IEEE Transactions on
reference ||| Software Engineering, 18(3):190–205, March 1992.
reference ||| [3] K. Bharat and L. Cardelli. Migratory Applications. In ACM UIST '95,
reference ||| pages 133-142, November 1995.
reference ||| [4] K. P. Birman. The Process Group Approach to Reliable Distributed
reference ||| Computing. CACM, 36(12):36–53, Dec 1993.
reference ||| [5] A. Birrell, G. Nelson, S. Owicki, and E. Wobber. Network Objects.
reference ||| In Proc. 14th ACM Symp. on Operating Systems Principles, 1993.
reference ||| [6] A Butz, Animation with CATHI, In Proceedings ofAAAI/IAAI '97,
reference ||| pages 957–962, 1997.
reference ||| [7]	J. Calvin, A. Dickens, B. Gaines, P. Metzger, D. Miller, and
reference ||| D. Owen. The SIMNET Virtual World Architecture. In Proc. IEEE
reference ||| VRAIS ’93, pages 450–455, Sept 1993.
reference ||| [8] L. Cardelli. A Language with Distributed Scope. Computing Sys-
reference ||| tems, 8(1):27–59, Jan 1995.
reference ||| [9] L. Cardelli and A. Gordon. Mobile Ambients. In Foundations of
reference ||| Software Science and Computational Structures, Maurice Nivat
reference ||| (Ed.), LNCE 1378, Springer, 140–155. 1998.
reference ||| [10] R. Carey and G. Bell. The Annotated VRML 2.0 Reference Manual.
reference ||| Addison-Wesley, Reading, MA, 1997.
reference ||| [11] C. Carlsson and O. Hagsand. DIVE—A Multi-User Virtual Reality
reference ||| System. In Proc. IEEE VRAIS ’93, pages 394–400, Sept 1993.
reference ||| [12] C. F. Codella, R. Jalili, L. Koved, and J. B. Lewis. A Toolkit for
reference ||| Developing Multi-User, Distributed Virtual Environments. In Proc.
reference ||| IEEE VRAIS ’93, pages 401–407, Sept 1993.
reference ||| [13] C. Elliott, G. Schechter, R. Yeung and S. Abi-Ezzi. TBAG: A High
reference ||| Level Framework for Interactive, Animated 3D Graphics
reference ||| Applications, In Proc. ACM SIGGRAPH 94, pages 421–434, August,
reference ||| 1994.
reference ||| [14] M. Fairen and A. Vinacua, ATLAS, A Platform for Distributed
reference ||| Graphics Applications, In Proc. VI Eurographics Workshop on Pro-
reference ||| gramming Paradigms in Graphics, pages 91–102, September, 1997.
reference ||| [15] S. Feiner, B. MacIntyre, M. Haupt, and E. Solomon. Windows on the
reference ||| World: 2D Windows for 3D Augmented Reality. In Proc. ACM UIST
reference ||| ’93, pages 145–155, 1993.
reference ||| [16] T. A. Funkhouser. RING: A Client-Server System for Multi-User
reference ||| Virtual Environments. In Proc. 1995 ACM Symp. on Interactive 3D
reference ||| Graphics, pages 85–92, March 1995.
reference ||| [17] G. Grimsdale. dVS—Distributed Virtual Environment System. In
reference ||| Proc. Computer Graphics ’91 Conference, 1991.
reference ||| [18] S. P. Harbison. Modula-3. Prentice-Hall, 1992.
reference ||| [19] H.W. Holbrook, S.K. Singhal and D.R. Cheriton, Log-Based
reference ||| Receiver-Reliable Multicast for Distributed Interactive Simulation,
reference ||| Proc. ACM SIGCOMM ’95, pages 328–341, 1995.
reference ||| [20] W. Levelt, M. Kaashoek, H. Bal, and A. Tanenbaum. A Comparison
reference ||| of Two Paradigms for Distributed Shared Memory. Software
reference ||| Practice and Experience, 22(11):985–1010, Nov 1992.
reference ||| [21] B. Lucas. A Scientific Visualization Renderer. In Proc. IEEE
reference ||| Visualization '92, pp. 227-233, October 1992.
reference ||| [22] V. Machiraju, A Framework for Migrating Objects in Distributed
reference ||| Graphics Applications, Masters Thesis, University of Utah, Depart-
reference ||| ment of Computer Science, Salt Lake City, UT, June, 1997.
reference ||| [23] B. MacIntyre. Repo: Obliq with Replicated Objects. Programmers
reference ||| Guide and Reference Manual. Columbia University Computer
reference ||| Science Department Research Report CUCS-023-97, 1997.}
reference ||| [24] B. MacIntyre, and S. Feiner. Language-level Support for Exploratory
reference ||| Programming of Distributed Virtual Environments. In Proc. ACM
reference ||| UIST ’96, pages 83–94, Seattle, WA, November 6–8, 1996.
reference ||| [25] M. A. Najork and M. H. Brown. Obliq-3D: A High-level, Fast-turn-
reference ||| around 3D Animation System. IEEE Transactions on Visualization
reference ||| and Computer Graphics, 1(2):175–145, June 1995.
reference ||| [26] R. Ben-Natan. CORBA: A Guide to the Common Object Request
reference ||| Broker Architecture, McGraw Hill, 1995.
reference ||| [27] D. Phillips, M. Pique, C. Moler, J. Torborg, D. Greenberg. Distribut-
reference ||| ed Graphics: Where to Draw the Lines? Panel Transcript,
reference ||| SIGGRAPH 89, available at:
reference ||| http://www.siggraph.org:443/publications/panels/siggraphi89/
reference ||| [28] A. Prakash and H. S. Shim. DistView: Support for Building Efficient
reference ||| Collaborative Applications Using Replicated Objects. In Proc. ACM
reference ||| CSCW ’94, pages 153–162, October 1994.
reference ||| [29] J. Rohlf and J. Helman, IRIS Performer: A High Performance
reference ||| Multiprocessing Toolkit for Real-Time {3D} Graphics, In Proc.
reference ||| ACM SIGGRAPH 94, pages 381–394, 1994.
reference ||| [30] M. Roseman and S. Greenberg. Building Real-Time Groupware with
reference ||| GroupKit, a Groupware Toolkit. ACM Transactions on Computer-
reference ||| Human Interaction, 3(1):66–106, March 1996.
reference ||| [31] C. Shaw and M. Green. The MR Toolkit Peers Package and
reference ||| Experiment. In Proc. IEEE VRAIS ’93, pages 18–22, Sept 1993.
reference ||| [32] G. Singh, L. Serra, W. Png, A. Wong, and H. Ng. BrickNet: Sharing
reference ||| Object Behaviors on the Net. In Proc. IEEE VRAIS ’95, pages 19–25,
reference ||| 1995.
reference ||| [33] H. Sowizral, K. Rushforth, and M. Deering. The Java 3D API
reference ||| Specification, Addison-Wesley, Reading, MA, 1998.
reference ||| [34] M. Stefik, G. Foster, D. G. Bobrow, K. Kahn, S. Lanning, and
reference ||| L. Suchman. Beyond The Chalkboard: Computer Support for
reference ||| Collaboration and Problem Solving in Meetings. CACM, 30(1):32–
reference ||| 47, January 1987.
reference ||| [35] P. S. Strauss and R. Carey, An Object-Oriented 3D Graphics Toolkit,
reference ||| In Computer Graphics (Proc. ACM SIGGRAPH 92), pages 341–349,
reference ||| Aug, 1992.
reference ||| [36] Sun Microsystems, Inc. The Java Shared Data Toolkit, 1998.
reference ||| Unsupported software, available at:
reference ||| http://developer.javasoft.com/developer/earlyAccess/jsdt/
reference ||| [37] I. Tou, S. Berson, G. Estrin, Y. Eterovic, and E. Wu. Prototyping
reference ||| Synchronous Group Applications. IEEE Computer, 27(5):48–56,
reference ||| May 1994.
reference ||| [38] R. Waters and D. Anderson. The Java Open Community Version 0.9
reference ||| Application Program Interface. Feb, 1997. Available online at:
reference ||| http://www.merl.com/opencom/opencom-java-api.html
reference ||| [39] A. Wollrath, R. Riggs, and J. Waldo. A Distributed Object Model for
reference ||| the Java System, In Proc. USENIX COOTS ’96, pages 219–231, July
reference ||| 1996.
reference ||| [40] R. Zeleznik, D. Conner, M. Wloka, D. Aliaga, N. Huang,
reference ||| P. Hubbard, B. Knep, H. Kaufman, J. Hughes, and A. van Dam. An
reference ||| Object-oriented Framework for the Integration of Interactive
reference ||| Animation Techniques. In Computer Graphics (SIGGRAPH '91
reference ||| Proceedings), pages 105–112, July, 1991.
reference ||| [41 ] M. J. Zyda, D. R. Pratt, J. G. Monahan, and K. P. Wilson. NPSNET:
reference ||| Constructing a 3D Virtual World. In Proc. 1992 ACM Symp. on
reference ||| Interactive 3D Graphics, pages 147–156, Mar. 1992.

note ||| CHI 2008 Proceedings · Socio-Cultural Impact	April 5-10, 2008 · Florence, Italy
title ||| Ambient Social TV:
title ||| Drawing People into a Shared Experience
author ||| Gunnar Harboe, Crysta J. Metcalf, Frank Bentley,
author ||| Joe Tullio, Noel Massey, Guy Romano
affiliation ||| Motorola Labs
address ||| 1295 E. Algonquin Rd., Schaumburg, IL 60196
email ||| {gunnar.harboe, crysta.metcalf, f.bentley, joe.tullio, noel.massey, guy} @motorola.com
sectionHeader ||| ABSTRACT
bodyText ||| We examine how ambient displays can augment social
bodyText ||| television. Social TV 2 is an interactive television solution
bodyText ||| that incorporates two ambient displays to convey to
bodyText ||| participants an aggregate view of their friends’ current TV-
bodyText ||| watching status. Social TV 2 also allows users to see which
bodyText ||| television shows friends and family are watching and send
bodyText ||| lightweight messages from within the TV-viewing
bodyText ||| experience. Through a two-week field study we found the
bodyText ||| ambient displays to be an integral part of the experience.
bodyText ||| We present the results of our field study with a discussion
bodyText ||| of the implications for future social systems in the home.
sectionHeader ||| Author Keywords
keyword ||| Social television, interactive television, social presence
keyword ||| awareness, ambient displays, field trial
sectionHeader ||| ACM Classification Keywords
keyword ||| H5.m. Information interfaces and presentation (e.g., HCI):
keyword ||| Miscellaneous.
sectionHeader ||| INTRODUCTION
bodyText ||| Although Internet use is gaining importance, TV watching
bodyText ||| is still the primary recreational activity of American adults,
bodyText ||| accounting for half of all leisure time [7]. Although there is
bodyText ||| great social potential in TV watching as a shared activity
bodyText ||| and a topic for conversation [20], at least half of all people
bodyText ||| usually watch alone [10].
bodyText ||| Many technologies coming out of the interactive television
bodyText ||| (iTV) field, such as Video-On-Demand and Personal Video
bodyText ||| Recorders (PVRs), focus on providing personalization and
bodyText ||| greater individual control. They cater to viewers as isolated
bodyText ||| individuals, and fragment audiences further [16].
bodyText ||| However, in recent years ‘social television,’ the idea of
bodyText ||| using communication technology to connect TV viewers, in
bodyText ||| order to create remotely shared experiences around TV
copyright ||| Permission to make digital or hard copies of all or part of this work for
copyright ||| personal or classroom use is granted without fee provided that copies are
copyright ||| not made or distributed for profit or commercial advantage and that copies
copyright ||| bear this notice and the full citation on the first page. To copy otherwise,
copyright ||| or republish, to post on servers or to redistribute to lists, requires prior
copyright ||| specific permission and/or a fee.
note ||| CHI 2008, April 5–10, 2008, Florence, Italy.
copyright ||| Copyright 2008 ACM 978-1-60558-011-1/08/04...$5.00
bodyText ||| content, has received much attention. Proponents of this
bodyText ||| idea see television as a social experience capable of
bodyText ||| reinforcing bonds in strong-tie relationships. TV
bodyText ||| programming can provide the common, shared experience
bodyText ||| that serves as a basis for socialization, even for groups who
bodyText ||| are already fairly close [29]. Social television systems
bodyText ||| typically integrate some combination of text chat, voice
bodyText ||| chat or video chat with TV programming, and use presence
bodyText ||| to provide awareness of the status and context of other users
bodyText ||| of the system [5, 9, 15, 23]. These efforts tie into earlier
bodyText ||| CMC work on telepresence and co-viewing, but come at the
bodyText ||| design and research questions from a different angle.
bodyText ||| In previous work we noted that users of social television
bodyText ||| systems would benefit from features that indicate favorable
bodyText ||| times for shared viewing [15]. One solution is to use
bodyText ||| always-on ambient displays to let users be aware of when
bodyText ||| others are watching TV. From a research standpoint, we can
bodyText ||| then examine how this kind of awareness helps or
bodyText ||| encourages people to get in touch through their social
bodyText ||| televisions, and in particular, how it is used to initiate and
bodyText ||| escalate communication sessions. As no extended field
bodyText ||| trials of social television systems have been reported to
bodyText ||| date, these important issues remain largely unexplored.
bodyText ||| In this paper, we present results from a two-week field
bodyText ||| study of Social TV 2, an experimental social television
bodyText ||| system that incorporates an ambient display component to
bodyText ||| provide awareness of remote viewers. Two groups of five
bodyText ||| households participated, with the members of each group
bodyText ||| comprising an existing social circle. In addition to standard
bodyText ||| social television functionality, Social TV 2 incorporates
bodyText ||| ambient displays in order to keep users aware of the
bodyText ||| participation of their friends and family. We found that the
bodyText ||| ambient displays proved to be a defining component of the
bodyText ||| system. The displays were effective indicators of good
bodyText ||| times to use Social TV 2, increased participants’ awareness
bodyText ||| of others’ TV-viewing schedules, and encouraged
bodyText ||| participation in the system. This participation often began
bodyText ||| as a glance at the ambient display – a quick check on the
bodyText ||| status of a participant’s social network, but would
bodyText ||| frequently escalate to deeper or more extended
bodyText ||| communication. In this way, participants began treating TV
bodyText ||| watching as a fundamentally social activity. Thus, the
page ||| 1
note ||| CHI 2008 Proceedings · Soci-Cultural Impact	April 5-10, 2008 · Florence, Italy
figureCaption ||| Figure 1: The Social TV 2 system in use. The ambient
figureCaption ||| orb is visible in the upper left, above the television.
figureCaption ||| addition of ambient displays helped to fulfill the design
figureCaption ||| objectives of the system.
bodyText ||| In the following sections, we describe the design of our
bodyText ||| Social TV 2 prototype, which we then put in the context of
bodyText ||| existing work in both the social television and ambient
bodyText ||| display literature. We outline unanswered questions that led
bodyText ||| us to initiate this work and describe the mixed-method
bodyText ||| approach to our field study. We then present our results,
bodyText ||| describing how the ambient devices functioned as
bodyText ||| traditional presence displays and as components of a more
bodyText ||| complex communication system. Lastly, we show how
bodyText ||| these findings bear on other social applications in the home,
bodyText ||| and outline our future goals for social television research
bodyText ||| and design.
sectionHeader ||| SOCIAL TV 2
bodyText ||| Social TV 2 follows Social TV, the system previously
bodyText ||| described in Harboe et al. [15]. It is a prototype system that
bodyText ||| allows remotely located friends and family to experience
bodyText ||| some of the benefits of sitting next to one another on the
bodyText ||| couch and watching a TV program together (Figure 1). To
bodyText ||| provide this experience, we supplement typical TV
bodyText ||| functions with two additional features: TV presence
bodyText ||| information, and the ability to send and receive lightweight
bodyText ||| messages. The features were selected to specifically
bodyText ||| investigate people’s behaviors at the boundaries of the
bodyText ||| social television experience, as they begin and end their
bodyText ||| interactions, rather than the details of how they acted while
bodyText ||| fully engaged in the communication experience.
bodyText ||| The prototype is implemented as a PC application running
bodyText ||| on top of GBPVR1 media center software. The system uses
bodyText ||| on-screen displays to communicate which of the user’s
bodyText ||| friends or family (‘buddies’) are currently watching, what
bodyText ||| they are watching, and what they have watched in the past.
footnote ||| 1 http://www.gbpvr.com/
footnote ||| The laptop running the Social TV 2 software is connected
footnote ||| to a television, and all interaction with the system is
footnote ||| performed with a standard remote control. For our field
footnote ||| tests we chose to use a TiVo® remote that had several keys
footnote ||| relabeled to correspond to the features of our system.
subsectionHeader ||| TV Presence
bodyText ||| A key requirement for encouraging participation in social
bodyText ||| television is the ability to make users aware of when their
bodyText ||| friends and family are logged into the system and watching
bodyText ||| programs on TV. This information can be viewed from an
bodyText ||| on-screen buddy list (Figure 2). The deployed system has
bodyText ||| two presence states: ‘watching TV’ and ‘away’. The ‘away’
bodyText ||| state is intended to inform buddies that a user is not
bodyText ||| currently watching TV. It is set automatically when the TV
bodyText ||| is turned off or when no interactions with the system are
bodyText ||| detected for some time after a program has ended. Users
bodyText ||| can also disconnect from the social component of the
bodyText ||| system if they wish to watch TV in privacy, and will then
bodyText ||| appear to others to be ‘away.’ However, in this state many
bodyText ||| of the features of the system are disabled, preserving a ‘see
bodyText ||| and be seen’ information reciprocity.
bodyText ||| Users can change to the same program that their buddy is
bodyText ||| watching from the buddy list. Additionally, whenever the
bodyText ||| channel is changed, a list of buddies who are also watching
bodyText ||| that program is displayed as part of the transient channel
bodyText ||| information banner.
subsectionHeader ||| Ambient Devices
bodyText ||| While Social TV 2’s on-screen display provides presence
bodyText ||| awareness on the television, we wanted another means to
bodyText ||| convey this information when the TV wasn’t on, or when
bodyText ||| users were in a different room and unable to see the TV.
bodyText ||| We chose to use two separate displays capable of
bodyText ||| communicating information unobtrusively, visible from
bodyText ||| anywhere in a room, and which would fit in as household
bodyText ||| objects. The system has two different display devices to
bodyText ||| meet these needs (Figure 3).
figureCaption ||| Figure 2: The Social TV 2 on-screen buddy list.
page ||| 2
note ||| CHI 2008 Proceedings · Socio-Cultural Impact	April 5-10, 2008 · Florence, Italy
figureCaption ||| Figure 3: The orb and Chumby devices displaying a
figureCaption ||| purple color (more than one friend is watching TV).
bodyText ||| As our primary ambient display, we chose the Ambient
bodyText ||| Orb, a color changing lamp from Ambient Devices,2 and
bodyText ||| configured it to display the current number of buddies
bodyText ||| watching television. Different colors are used to indicate
bodyText ||| whether one (blue), more than one (purple), or no other
bodyText ||| buddies (yellow) are currently watching TV.
bodyText ||| The orb was connected via serial cable to our prototype,
bodyText ||| and therefore had to be placed close to the TV. As people
bodyText ||| often spend much of their time outside of the living room
bodyText ||| [1], we wanted to include a second display for times when
bodyText ||| users could not see the primary ambient display. The
bodyText ||| Chumby3 is a WiFi-enabled internet appliance with a 3.5"
bodyText ||| LCD color display Though we would have preferred to use
bodyText ||| a second orb, the Chumby provided faster updates and more
bodyText ||| reliable wireless reception than the orb’s pager-based
bodyText ||| network alternative. We wrote a Flash widget for the
bodyText ||| Chumby that follows the color of the living room orb in
bodyText ||| near-synchronization (within 15 seconds).
bodyText ||| Besides providing information about the number of buddies
bodyText ||| online, we wanted to use the displays to attract users to the
bodyText ||| system when a friend or family member invited them to
bodyText ||| watch a show with them. To signal this, we designed the
bodyText ||| displays to pulse slowly between the current color and
bodyText ||| black. We did not want the flashing to be too distracting,
bodyText ||| but wanted users to notice it so that they could come to their
bodyText ||| televisions if they desired.
subsectionHeader ||| Messaging
bodyText ||| We provided no voice or freeform text communication
bodyText ||| features. However, users can send ‘suggestions’ to invite a
bodyText ||| buddy to watch their current show together. If the buddy
bodyText ||| accepts the suggestion, the system automatically changes
bodyText ||| the channel to that program.
bodyText ||| When two or more buddies are watching the same program,
bodyText ||| the prototype allows them to send messages to each other.
bodyText ||| In the first round of this study, the system allowed only
bodyText ||| three expressions, in the form of graphical thumbs-up,
bodyText ||| thumbs-down, or ‘shout-out’ emoticons. After this
bodyText ||| deployment, we received feedback that our participants
bodyText ||| wanted to send a wider variety of messages. Therefore, for
footnote ||| 2 http://www.ambientdevices.com/
footnote ||| 3 http://www.chumby.com/
bodyText ||| the second group, we implemented a new feature that
bodyText ||| replaced the generic ‘shout-out’ message with
bodyText ||| approximately 20 pre-determined messages such as “How
bodyText ||| is this show?”, “This sucks!”, or “Call me”. A number of
bodyText ||| possible replies are available (“Good!”, “Bad!”, etc.), as
bodyText ||| well as the thumbs-up and thumbs-down emoticons.
sectionHeader ||| RELATED WORK
subsectionHeader ||| Social Television Systems and Studies
bodyText ||| The idea of communicating and sharing awareness through
bodyText ||| the television set has been explored by a number of
bodyText ||| different researchers. However, social television systems as
bodyText ||| yet remain confined to labs and limited trials. AmigoTV,
bodyText ||| described by Coppens et al. [9], was an early social
bodyText ||| television system that included presence, a buddy list,
bodyText ||| invitations, emoticons, and voice chat, but no facilities for
bodyText ||| indicating presence while offline. Telebuddies, by Luyten et
bodyText ||| al. [21], takes a different approach to the challenge of
bodyText ||| drawing users into the experience, using a friend-of-a-friend
bodyText ||| profile of interests and social relationships to match users
bodyText ||| with suitable communication partners. A more
bodyText ||| comprehensive review of social television systems can be
bodyText ||| found in Harboe et al. [14].
bodyText ||| Geerts [14] and Baillie et al. [2] conducted user studies of
bodyText ||| AmigoTV, both of them lab experiments comparing voice
bodyText ||| communication to other modalities. Weisz et al. [29] and
bodyText ||| Regan and Todd [24] examined groups or pairs of friends
bodyText ||| and strangers using text chat while watching videos or TV
bodyText ||| together. Similarly, Oehlberg et al. studied groups of
bodyText ||| friends and acquaintances watching television, both in
bodyText ||| collocated groups and connected via an audio link [23].
bodyText ||| Finally, In Harboe et al. we examined friends and family
bodyText ||| watching TV in a voice chat setting; this in the participants’
bodyText ||| homes rather than the lab [15].
bodyText ||| All these studies were based on single-session events. None
bodyText ||| of them looked at the process by which a shared viewing
bodyText ||| experience is initiated or how the systems are used over
bodyText ||| time. However, Boertjes has announced a prolonged in-
bodyText ||| home study of a social television system called ConnecTV
bodyText ||| [5], and we await those results with interest.
bodyText ||| Building on this existing work, we are extending the social
bodyText ||| television concept by including additional facilities for
bodyText ||| offline awareness of TV presence information. In addition,
bodyText ||| we are presenting results from the field that that throw light
bodyText ||| on the real-world use of television-based sociability, and
bodyText ||| which suggest design considerations for future social
bodyText ||| television systems.
subsectionHeader ||| Social Awareness Systems for the Home
bodyText ||| Hindus et al. created and evaluated a number of social and
bodyText ||| communication systems, with varying levels of media
bodyText ||| richness, for the home [18]. They note that consumers
bodyText ||| wanted devices with multiple communication modes.
bodyText ||| In the context of domestic video calling over the TV,
bodyText ||| Hemmeryckx-Deleersnijder and Thorne integrated an
page ||| 3
note ||| CHI 2008 Proceedings · Socio-Cultural Impact	April 5-10, 2008 · Florence, Italy
bodyText ||| awareness component that displayed images automatically
bodyText ||| captured from the environment [17]. In their scenario, they
bodyText ||| seek to provide background awareness and help negotiate
bodyText ||| conversation engagement.
bodyText ||| De Ruyter et al. compared different degrees of peripheral
bodyText ||| awareness of remote friends (displayed as video) while
bodyText ||| watching a shared TV program [27]. The system in their
bodyText ||| study only supported awareness while in a shared viewing
bodyText ||| session. Markopoulos et al. provide an overview of other
bodyText ||| awareness systems [22].
subsectionHeader ||| Evaluation of Ambient Displays
bodyText ||| While the ambient display literature contains a wealth of
bodyText ||| design examples, it contains few reports of field
bodyText ||| evaluations. CareNet [8], a combination ambient/interactive
bodyText ||| display for elder care, arrived at a number of useful findings
bodyText ||| for the design of effective ambient displays for the home.
bodyText ||| Rowan et al. showed how an ambient display can foster
bodyText ||| connectedness and promote communication between elders
bodyText ||| and their adult children [26]. In addition to these studies,
bodyText ||| other researchers have shown how ambient displays can
bodyText ||| maintain a sense of connectedness between friends and
bodyText ||| loved ones [12, 28]. The Whereabouts clock [6] shows how
bodyText ||| simple location and messaging capabilities can enhance
bodyText ||| connectedness and allow family members make inferences
bodyText ||| about each others’ activities using their existing knowledge
bodyText ||| of one another. In this work, we build on these findings to
bodyText ||| demonstrate how ambient displays can be designed into a
bodyText ||| larger social application to promote use of that system and
bodyText ||| fulfill its goals of strengthening social bonds.
sectionHeader ||| METHODS
bodyText ||| In the design of our field study, we were interested to see
bodyText ||| whether the ambient displays met our design goal of
bodyText ||| encouraging social television participation during those
bodyText ||| periods when a participant’s friends and family were also
bodyText ||| using the system, if it led to other forms of communication,
bodyText ||| and how it would ultimately affect the feelings of
bodyText ||| connectedness between our participants. Striving to
bodyText ||| understand these patterns of behavior is an essentially
bodyText ||| qualitative question, and our approach was largely
bodyText ||| exploratory. We ran two separate in-home trials. Five
bodyText ||| households were recruited for each trial, and each trial
bodyText ||| lasted 14 days.
subsectionHeader ||| Recruitment
bodyText ||| Participants were recruited using an independent recruiting
bodyText ||| agency that was instructed to find social groups in which
bodyText ||| the various household members were mutual friends, and
bodyText ||| all had strong ties with one another. The actual relationships
bodyText ||| between the recruited households varied (Figure 4). In both
bodyText ||| trials there was a central ‘hub’ (A1, B1), a person who
bodyText ||| knew and recruited all the other participants, but there were
bodyText ||| also at least two households who were more peripheral,
bodyText ||| without strong ties to the rest of the group. In both trials the
figureCaption ||| Figure 4: Social ties between households in our field
figureCaption ||| trials. Dashed lines represent acquaintances.
bodyText ||| central hub was a woman, and the four friends she recruited
bodyText ||| female. However, in each group some of the husbands
bodyText ||| knew each other, and in the second group two of the
bodyText ||| husbands were best friends.
bodyText ||| Group A, our first group, consisted of four couples living in
bodyText ||| their own households, two with (very young) children. The
bodyText ||| fifth participant was recently engaged, but still living with
bodyText ||| her parents and brother. Ages of the main participants
bodyText ||| ranged from 26 to 33. A2 and A5 are sisters, and A3 is the
bodyText ||| cousin of A1’s husband. A5 was not friends with anyone
bodyText ||| else in the study except her sister, and A3 and A4 knew
bodyText ||| each other only tangentially from having attended the same
bodyText ||| parties.
bodyText ||| In Group B, our second group, all five nuclear families
bodyText ||| were living in their own households, and all five households
bodyText ||| included teenage children. Ages of the main participants
bodyText ||| ranged from 46 to 53. B1 was very close friends with B2
bodyText ||| and B4, and knew B3 and B5 well. Again we had a pair of
bodyText ||| sisters: B4 and B5, but B2, B3, and B4 only see each other
bodyText ||| at the parties of mutual friends, and B5 did not remember
bodyText ||| ever meeting B2 and B3.
bodyText ||| While there were some husbands in both groups who knew
bodyText ||| each other well, and some of the teenage children in Group
bodyText ||| B knew each other, their relationships, for the most part,
bodyText ||| mirrored those of our female main participants. Thus, we
bodyText ||| had a number of different kinds of relationships represented
bodyText ||| in the two social groups, but neither group was uniformly
bodyText ||| tight-knit.
subsectionHeader ||| Deployment
bodyText ||| For each household, the Social TV 2 system was installed
bodyText ||| in the room participants reported as being the most common
bodyText ||| place for watching TV. As mentioned earlier, Groups A and
bodyText ||| B received slightly different versions of the software, as a
bodyText ||| result of an iterative design process on the basis of Group
bodyText ||| A’s feedback. Each household was given one orb and one
bodyText ||| Chumby. We asked participants to place the Chumby in any
bodyText ||| part of their home where they spent a significant amount of
bodyText ||| time or passed by frequently. Six participants put it in the
page ||| 4
note ||| CHI 2008 Proceedings · Soci-Cultural Impact	April 5-10, 2008 · Florence, Italy
bodyText ||| kitchen, two in a hallway, and one in a bedroom. The last
bodyText ||| Chumby malfunctioned and was not used. Participants were
bodyText ||| given a brief (20 minute) introduction to the system and its
bodyText ||| features, and a phone number for technical support that they
bodyText ||| could call at any time. We asked each participant to use the
bodyText ||| system the way they would if they were not in a study, and
bodyText ||| explained that they did not have to use every feature, or any
bodyText ||| feature, unless they wanted to. Other household members
bodyText ||| were also welcome to use the system, and generally did so.
subsectionHeader ||| Data Collection
bodyText ||| We used multiple methods for data collection, including
bodyText ||| interviews, usage logs, and voice mail diaries.
bodyText ||| There were three sets of semi-structured interviews for each
bodyText ||| household. The initial interview lasted about half an hour
bodyText ||| and was used to collect background information. In a phone
bodyText ||| interview after the first week, lasting between 15 and 30
bodyText ||| minutes, we gathered data about the participants’ use of and
bodyText ||| reactions to the prototype during the first week. And the
bodyText ||| final interview, lasting from an hour to an hour and half,
bodyText ||| was structured to collect more detailed information on a
bodyText ||| number of topics. Whenever possible, we asked other
bodyText ||| household members to participate in the interviews. We
bodyText ||| recorded a total of 22 hours of interview data, but much of
bodyText ||| the material falls outside the scope of this paper.
bodyText ||| We logged all interactions with the system, in order to
bodyText ||| document actual usage and to allow us to examine
bodyText ||| interesting incidents in detail later. The logs, then, provide
bodyText ||| support for some of the events described in the interviews.
bodyText ||| Cameras or sensors in the home would have been useful to
bodyText ||| put the system use in context, but we felt this would be too
bodyText ||| intrusive and technically complex for this study.
bodyText ||| Instead, voice mail diaries were used to collect information
bodyText ||| on behaviors we could neither log nor directly observe, and
bodyText ||| which we were afraid would be forgotten prior to the
bodyText ||| interviews. We devised questions about behaviors
bodyText ||| surrounding the ambient presence/awareness features,
bodyText ||| communications with other people in the study, and their
bodyText ||| reactions to, as well as use of, the various features. So that
bodyText ||| the questions would not influence our participants’ behavior
bodyText ||| in advance, the participants were given 14 sealed envelopes,
bodyText ||| one for each day of the study, each containing that day’s
bodyText ||| questions. Thus, participants had the questions in front of
bodyText ||| them as they provided their feedback. Participants left 3
bodyText ||| hours and 41 minutes of voice mail messages in total.
subsectionHeader ||| Analysis
bodyText ||| From the log data we extracted some basic measures of
bodyText ||| system use (Table 1). Given the small scale and non-
bodyText ||| experimental design of the study, we did not attempt further
bodyText ||| statistical treatment of the quantitative data.
bodyText ||| The bulk of the analysis was instead qualitative, using a
bodyText ||| variation of the affinity diagram method. We reviewed the
bodyText ||| interview and voice mail data, and extracted observations,
bodyText ||| statements (which we transcribed) and behavioral
table ||| Activity	A	B
table ||| TV watched, connected (hrs)	154.27	180.77
table ||| TV watched, disconnected (hrs)	21.81	0.34
table ||| Buddy list views	185	390
table ||| Joined show through buddy list	62	160
table ||| Emoticons sent	59	120
table ||| Canned messages sent	N/A	185
tableCaption ||| Table 1: Aggregate usage data by group.
bodyText ||| descriptions relating to ambient presence and awareness.
bodyText ||| These items were printed out as sticky notes.
bodyText ||| Then, working as a team, we put these items together into
bodyText ||| groups or categories, a process of “comparison, contrast,
bodyText ||| and integration” [19]. To efficiently organize the data we
bodyText ||| used an affinity-like post-it chart [4]. Here we followed
bodyText ||| Bernard: As the categories were identified we would “pull
bodyText ||| all the data (that is, exemplars) from those categories
bodyText ||| together and compare them, considering not only what
bodyText ||| [items belong] in each emerging category but also how the
bodyText ||| categories are linked together” [3]. The patterns that
bodyText ||| emerged from this analysis process form the basis of the
bodyText ||| results that follow.
sectionHeader ||| RESULTS
bodyText ||| Our analysis identified several themes around the effect and
bodyText ||| effectiveness of our ambient displays. We first discuss their
bodyText ||| basic ability to communicate presence information, and
bodyText ||| then go on to talk about how they functioned as part of the
bodyText ||| larger Social TV 2 system. Throughout, we use quotes from
bodyText ||| the interviews and voice mail diaries to illustrate each
bodyText ||| particular theme in our participants’ own words.
subsectionHeader ||| Effectiveness as Ambient Displays
bodyText ||| In considering how the ambient information interacted with
bodyText ||| the other components of the Social TV 2 system, the orb
bodyText ||| and Chumby would only be relevant if they actually
bodyText ||| functioned as ambient displays. Fortunately, they did.
subsubsectionHeader ||| Noticing and interpreting the displays
bodyText ||| Our participants saw and noticed the changing colors of the
bodyText ||| orb, and by and large understood what they signified. B3: “I
bodyText ||| notice when the color’s on, whether it’s purple or blue, I
bodyText ||| know that someone else is actually on the system.” In fact,
bodyText ||| several participants commented on the orb consistently
bodyText ||| drawing their attention. B 1 mentioned in the final interview
bodyText ||| that “every time I passed by, a thousand times a day, I
bodyText ||| would look to see what color it was.” Only one participant,
bodyText ||| B4, could not account for the meaning of the different
bodyText ||| colors. When asked if she knew what they signified, she
bodyText ||| answered: “[My daughter] does, I don’t.”
bodyText ||| The pulsing signal that the ambient devices sent when a
bodyText ||| suggestion was received was less widely understood. Many
page ||| 5
note ||| CHI 2008 Proceedings · Soci-Cultural Impact	April 5-10, 2008 · Florence, Italy
bodyText ||| participants confused pulsing with just changing colors. For
bodyText ||| example, B3 said “I’m not sure if it was pulsating or just
bodyText ||| changing purple to blue, to purple to blue [ ... ] I honestly
bodyText ||| don’t know...” This may partly have been a problem of
bodyText ||| terminology. More substantially, at least part of the reason
bodyText ||| for the confusion was that few participants saw the pulsing
bodyText ||| happen. Most invitations were sent to people who were
bodyText ||| already watching TV, and who accepted or declined them
bodyText ||| before they had a chance to notice the ambient devices
bodyText ||| pulsing. Another likely contributing factor was the subtlety
bodyText ||| of the signal: “I love the orb, but when it flashes, I wish it
bodyText ||| flashed a different color or did something crazy. I can’t tell
bodyText ||| when it’s flashing sometimes.” (A2)
bodyText ||| A number of participants reported that they were less aware
bodyText ||| of the Chumby than of the orb. As B3 said: “I think it's kind
bodyText ||| of a non-entity, the Chumby.” A few different factors
bodyText ||| appeared to contribute to this. In daylight, the Chumby’s
bodyText ||| small LCD screen was only clearly readable from certain
bodyText ||| angles, so participants were unable to see it from some
bodyText ||| areas of the room where it was installed. In a few
bodyText ||| households, the Chumby was redundant because
bodyText ||| participants could also see the orb from most places where
bodyText ||| they could see the Chumby. Finally, the Chumbies used
bodyText ||| were pre-production models prone to technical glitches and
bodyText ||| service interruptions, so for nearly all of the participants the
bodyText ||| Chumby did not work properly for parts of the study.
bodyText ||| Nevertheless, the Chumby played an important part of the
bodyText ||| experience for certain participants: For example, A1 told us
bodyText ||| “Since I had [the Chumby] in the kitchen it was just while I
bodyText ||| was cooking...it was like ‘oh, I wonder who’s on.’ ”
subsubsectionHeader ||| Placement
bodyText ||| As noted by others [8, 26], we found that the ambient
bodyText ||| displays needed to be located where they would frequently
bodyText ||| be seen. B1 mentioned, “The physical positioning in my
bodyText ||| house [for the Chumby] was the perfect spot, because I
bodyText ||| spend most of my day in the kitchen when I’m home.” In
bodyText ||| two households, participants chose locations for the
bodyText ||| Chumby where they rarely spent time or passed by. “The
bodyText ||| orb was a lot more helpful than the Chumby. [ ... ] Because
bodyText ||| we’re down here more.” (B2) A5 did not regard the
bodyText ||| displays as particularly useful. This may have been the
bodyText ||| result of physical context, as both were put in her brother’s
bodyText ||| bedroom. When we asked her if she ever saw the orb go
bodyText ||| purple when she wasn’t watching TV, she replied “Uh, no,
bodyText ||| because if I was in that room, I knew I’m gonna be
bodyText ||| watching TV.”
subsubsectionHeader ||| Acceptability of form factor
bodyText ||| The majority of our participants liked the form factor of the
bodyText ||| displays. We received numerous comments such as “I love
bodyText ||| the orb” (B5), and “I like the orb, I like the Chumby... the
bodyText ||| colors and the blinking” (A2). A3 and A4 both called the
bodyText ||| orb “cool” and B4 said it was “neat.” Even when the
bodyText ||| novelty of the system wore off and some participants were
bodyText ||| saying that interacting with the on-screen application was a
bodyText ||| “chore” (B5), their enjoyment of the orb continued to the
bodyText ||| end. It should be noted that the acceptance wasn’t universal;
bodyText ||| A1’s husband complained that the orb did not go with their
bodyText ||| décor, but “if it was a little bit smaller I think it would look
bodyText ||| fine.”
subsectionHeader ||| Drawing Users into Communication
bodyText ||| Although the ambient devices provided effective social
bodyText ||| presence, our participants felt that the orb and Chumby
bodyText ||| would not be useful by themselves without the rest of the
bodyText ||| information the Social TV 2 system provided. “It would be
bodyText ||| pretty, but I couldn’t see what people were doing,” said A3.
bodyText ||| B1 commented that “There’d be no reason to have an orb
bodyText ||| and then I can’t turn it on and see who it’s connected to.”
bodyText ||| A2 thought that without the additional information of who
bodyText ||| was watching, and what they were watching, “it would be a
bodyText ||| tease.” Balancing this, several of our participants said that
bodyText ||| at times they were just interested in learning that a friend
bodyText ||| was at home and available, not specifically whether he or
bodyText ||| she was watching television.
bodyText ||| We saw further evidence that the ambient information did
bodyText ||| help to involve them in the social television experience.
bodyText ||| Many of our participants told us of occasions when they
bodyText ||| turned on the TV because the orb indicated that others were
bodyText ||| watching. For example, A2 told us “as soon as I come into
bodyText ||| the house or I wake up or come into the room, that’s the
bodyText ||| first thing. It draws my attention, and the first thing I do is
bodyText ||| turn on the TV.” In a voice mail, A3 told us that the orb
bodyText ||| “has made me a little bit more aware, makes me want to,
bodyText ||| when it does change colors, to see which of my buddies are
bodyText ||| on.”
bodyText ||| In some cases the participants switched on the TV just to
bodyText ||| see who was there, then turned it off. However, more often
bodyText ||| they would contact or be contacted by one of their friends,
bodyText ||| or simply go on watching the TV show. A2 told us that she
bodyText ||| would turn on the TV “just to see who’s on, and then most
bodyText ||| of the time we would all end up watching the same thing.”
bodyText ||| This usually involved exchanging lightweight messages:
bodyText ||| “Find out what other people are watching, flip to what
bodyText ||| they’re watching, and then talking to some of the people to
bodyText ||| throw comments out.” (B3)
bodyText ||| In a number of cases, the people who described watching
bodyText ||| TV with their buddies and messaging them were people
bodyText ||| who were doing similar things prior to the study. For
bodyText ||| example, the sisters A2 and A5 told us that they often
bodyText ||| watched TV shows together, and A2 mentioned receiving a
bodyText ||| text message from her sister while they were both watching
bodyText ||| the season finale of Gilmore Girls. Regarding our system,
bodyText ||| she said: “The first thing I do is see what my buddies are
bodyText ||| watching, and then I tend to sometimes watch what they’re
bodyText ||| watching and then give suggestions or thumbs up or down
bodyText ||| depending on how I feel toward their program.”
bodyText ||| Interestingly, people who used to watch TV with others
bodyText ||| remotely found themselves doing so again once the Social
bodyText ||| TV 2 system was in their homes. B 1 told us how, years ago,
bodyText ||| she and her close friend B2 would “watch Saturday Night
page ||| 6
note ||| CHI 2008 Proceedings · Socio-Cultural Impact	April 5-10, 2008 · Florence, Italy
table ||| 8:01:48 PM B5 watching TV, B1 turns TV on
table ||| 8:06:24 PM B5 joins B1 at Desperate Housewives
table ||| 8:07:00 PM B 1: “How are you?”
table ||| 8:08:38 PM B5: “Good!”
table ||| 8:09:05 PM B1: t, [thumbs-up]
table ||| 8:09:18 PM B5: t, [thumbs-up]
table ||| 8:10:20 PM B5: “I really like this!”
table ||| 8:17:26 PM B1: “Call me!”
tableCaption ||| Table 2: Sample interaction sequence from logs.
bodyText ||| Live together,” while they talked on the phone. However,
bodyText ||| they haven’t done anything like that since their children
bodyText ||| were little. Until they participated in this study:
construct ||| “I noticed the orb was blue, so I knew somebody had their
construct ||| television on, and sure enough, it was [B2’s household].
construct ||| And I knew that her husband’s at work and her kids were at
construct ||| school, so I deduced it was [B2]. And so without even
construct ||| saying ‘Who’s there?’ I immediately went to her channel,
construct ||| which was Oprah, and I sent her a thumbs-up. And then
construct ||| she thumbs-upped me, and then two seconds later I said [to
construct ||| myself], ‘This is dumb!’ And then [I called her, and] we
construct ||| had a whole conversation.”
bodyText ||| In this story, we can see that the ambient display serves to
bodyText ||| initially draw the participant into an interaction which then
bodyText ||| becomes progressively deeper, culminating in a direct voice
bodyText ||| conversation. This is a pattern we can see repeated with
bodyText ||| different variations in the logs (Table 2).
bodyText ||| It should be pointed out that although turning the TV on in
bodyText ||| response to the orb was one of the most commonly reported
bodyText ||| behavior patterns in our study, some participants did not
bodyText ||| have a desire to turn on the television and dig deeper into
bodyText ||| the presence information. B3 said: “[The orb is] kind of
bodyText ||| interesting, but once again, what do I care if somebody is
bodyText ||| watching TV?”
bodyText ||| Other participants were curious, but had little interest in
bodyText ||| talking about it. B2’s husband said he would “turn it on just
bodyText ||| to see what they’re watching, and then probably send them
bodyText ||| a message saying that ‘it sucks’ or something.” To put this
bodyText ||| in context, he rarely socializes around TV content anyway;
bodyText ||| although B1’s husband is his best friend, he has only once
bodyText ||| been over there to watch TV, for a Super Bowl party.
subsectionHeader ||| Meeting the Goal of Connectedness
bodyText ||| Our participants reported that when they saw the ambient
bodyText ||| colors, they found themselves thinking about the fact that
bodyText ||| others were watching TV. In some cases this translated into
bodyText ||| a feeling that they could “know what’s going on,” (B2’s
bodyText ||| husband) with others in the study. Said A3: “I still think the
bodyText ||| orb is kinda the coolest part of the whole thing because it’s
bodyText ||| really neat to see it change color and then know that
bodyText ||| something is going on on the other end to cause it to do
bodyText ||| that.” The husband of A1 said: “Even before I turned on the
bodyText ||| TV, I knew that someone was on there.” B1 put it this way:
bodyText ||| “I liked the different colors, I liked coming in the house and
bodyText ||| saying ‘oh, someone’s home watching TV too now.’ I don’t
bodyText ||| know, it was like a friendly feeling, like someone else is
bodyText ||| home and I’m not the only one home tonight.”
bodyText ||| While B1 knew all the other participants in her trial, that
bodyText ||| was not true for the others. Participants on the periphery of
bodyText ||| the group could only imagine what it would be like to use
bodyText ||| the system with people closer to them. For example B5,
bodyText ||| who expressed dismay with the system overall, said “it’s a
bodyText ||| love connection. You have feelings for these people and
bodyText ||| you care more. My parents could be blue, my sisters could
bodyText ||| be pink, orange, green.” While B3 did not find the orb
bodyText ||| useful during the study, when she was asked if she would
bodyText ||| be more interested if the orb was telling her about different
bodyText ||| people, she answered:
construct ||| “Oh, yeah, yeah, yeah. Probably. If it’s somebody I was
construct ||| closer to. [ ... ] It’s almost like a communication light
construct ||| bulb. You know what I mean? Like the fire bell goes off,
construct ||| and ‘Ding, ding, ding!’ If I saw that, I’d be ‘Hmm, Dad’s
construct ||| watching,’ or, I feel like ‘Hmm, I’m connecting with
construct ||| somebody.’ It sounds so stupid, but maybe you’re
construct ||| connecting with somebody.”
subsectionHeader ||| Inference and Learning about Presence
bodyText ||| Despite the fact that our ambient displays only showed
bodyText ||| three colors, our participants were able to combine the
bodyText ||| information conveyed with previous social knowledge in
bodyText ||| order to draw rich inferences about the other people in the
bodyText ||| study. In some cases it inspired them to leaps of
bodyText ||| imagination, like when B2’s husband saw the orb turn blue
bodyText ||| when someone turned the TV on at 2 am: “I just figured
bodyText ||| somebody was watching, maybe fell asleep on the couch,
bodyText ||| maybe some guy got thrown out of the bedroom for the
bodyText ||| night.” At other times the speculations were more mundane,
bodyText ||| as when B 1 looked at the orb one morning: “The orb was
bodyText ||| yellow and no one was on, so I'm assuming everyone was
bodyText ||| already at work.” This statement also exemplifies another
bodyText ||| use our participants found for the ambient information:
bodyText ||| Whether or not someone was watching TV was used as a
bodyText ||| proxy for whether they were home. Naturally, the presence
bodyText ||| information in the buddy list was a helpful supplement to
bodyText ||| the ambient devices for this purpose. A5 put it this way:
bodyText ||| “It’d be interesting when I’d be on at night, like ‘Oh, let me
bodyText ||| see if she’s on. Is she watching TV, is she home, is she
bodyText ||| out?’ So that was one way to know, ‘Yeah, she’s home,
bodyText ||| she’s watching TV.’ ”
bodyText ||| We saw evidence that over the course of the study, our
bodyText ||| participants learned more about each other’s viewing habits,
bodyText ||| and used that knowledge to interpret the ambient signals
bodyText ||| with more confidence, guessing who might be on at any
bodyText ||| given time. Most of our participants knew little about the
bodyText ||| TV viewing habits of the rest of their group before the
bodyText ||| study commenced. To take just one example, A1 was only
bodyText ||| able to make general guesses about her friends’ viewing
bodyText ||| habits when the study started. At the end, on the other hand,
bodyText ||| she told us: “Yeah, I think as the two weeks progressed I
bodyText ||| kinda had a feel; like on Fridays I know [A4] works from
page ||| 7
note ||| CHI 2008 Proceedings · Soci-Cultural Impact	April 5-10, 2008 · Florence, Italy
bodyText ||| home so, like, this past Friday the light was blue, and I was
bodyText ||| like ‘the only person who’s going to be watching TV right
bodyText ||| now is her.’ So I kinda got a feel. Late night would be [A5],
bodyText ||| daytime would be [A3] because of the kids.”
bodyText ||| By allowing participants to leverage their existing
bodyText ||| knowledge of one another to learn more detail about their
bodyText ||| viewing habits, the ambient information conveyed by Social
bodyText ||| TV 2 became more powerful. Participants were soon able to
bodyText ||| use the orb to glean (with some degree of uncertainty)
bodyText ||| information that they had initially needed to look up in the
bodyText ||| buddy list. One indication of the meaning that our
bodyText ||| participants attributed to the ambient devices’ output is the
bodyText ||| power the displays had to puzzle them. When B1 sat down
bodyText ||| to watch TV on a rainy evening, she noted to her surprise
bodyText ||| that no one else was logged on: “The oddest thing, it’s a
bodyText ||| nice night to be in... and not one person is on Social TV
bodyText ||| tonight!”
bodyText ||| Presence seemed to lead to an expectation that someone
bodyText ||| who was watching TV was available for interaction.
bodyText ||| Unfortunately, our participants were often disappointed. B2
bodyText ||| told us in a voice mail: “We’ve not really heard back from
bodyText ||| people, the orb is blue, I don’t know if they’re getting them
bodyText ||| or if they’re just not sending back or what the problem is.”
bodyText ||| In the phone interview she said that when people weren’t
bodyText ||| responding, perhaps “they just wanted to watch their show,
bodyText ||| and they were ignoring you.” B1 said that when she notices
bodyText ||| the orb turning blue or purple and turns on the TV, she felt
bodyText ||| like “they’re on for a few minutes, we say hello, and then
bodyText ||| someone turns it off or they have to go.”
sectionHeader ||| DISCUSSION
subsectionHeader ||| An Integral Component of Social TV 2
bodyText ||| If we consider the ambient devices in isolation, they appear
bodyText ||| as fairly ordinary displays for peripheral presence
bodyText ||| awareness. And indeed, the results show that they
bodyText ||| successfully functioned as such. This, along with the fact
bodyText ||| that the orb, at least, was on the whole so well liked, goes
bodyText ||| some way towards validating our design, but it is not by
bodyText ||| itself a particularly novel finding. Far more interesting are
bodyText ||| the ways in which the ambient devices and the other Social
bodyText ||| TV 2 features interacted. Our findings reveal and hint at a
bodyText ||| number of interesting behaviors emerging, and these are
bodyText ||| particularly relevant to the design and understanding of
bodyText ||| future social systems in the home.
bodyText ||| Our system was designed so that the ambient devices only
bodyText ||| worked while the Social TV 2 client remained connected to
bodyText ||| the network. And as we have noted, people, in general,
bodyText ||| liked the ambient lights, both because of the information
bodyText ||| they provided and for the aesthetic appeal. Although the
bodyText ||| design of our study didn’t allow us to conclusively test this,
bodyText ||| it does seem to indicate that the ambient devices would
bodyText ||| therefore encourage people to stay logged on, and serve as a
bodyText ||| reminder, if they ever do leave, to return as soon as
bodyText ||| possible, thereby ensuring the presence conduit remains
bodyText ||| open.
bodyText ||| The orb and the Chumby were effective at conveying when
bodyText ||| other people were watching TV, and this allowed our
bodyText ||| participants to be aware of others’ availability even when
bodyText ||| their own TV sets were turned off and they were engaged in
bodyText ||| other activities. In this way, it reduced the risk of an
bodyText ||| opportunity for interaction going by unnoticed.
bodyText ||| Together, these effects expand the interface between the
bodyText ||| system and the environment. For one thing, the chances of
bodyText ||| making contact are greatly increased. Also, the social
bodyText ||| television experience is no longer something that only takes
bodyText ||| place during the time you are actually watching TV. The
bodyText ||| ambient devices keep users engaged with the system while
bodyText ||| they go about other activities, thereby creating an ‘out-of-
bodyText ||| the-box’ social experience.
subsectionHeader ||| Multiple Levels of Engagement
bodyText ||| Our findings indicate that while it extended the social
bodyText ||| experience beyond the TV, the awareness provided by the
bodyText ||| ambient displays also helped draw our participants into the
bodyText ||| television experience and encourage them to use the
bodyText ||| system. This result supports previous efforts to use
bodyText ||| peripheral social awareness to lower the barriers to
bodyText ||| communication [17, 11].
bodyText ||| We can generalize the steps reported by our users (and
bodyText ||| corroborated by the logs): the participants become aware of
bodyText ||| their friends’ availability through the ambient devices, turn
bodyText ||| on their TV (thereby themselves showing up as available to
bodyText ||| the other participants), look at their buddy list, and either
bodyText ||| join what one of their friends were watching or suggest that
bodyText ||| their friend join them. Once they were viewing together,
bodyText ||| they would usually send messages or emoticons, and
bodyText ||| sometimes this would culminate with a phone call. From
bodyText ||| this idealized flow, we can define different stages of
bodyText ||| interaction (Table 3). This can be viewed as an extension of
bodyText ||| Eggen et al.’s three interaction states [13].
bodyText ||| We can see that as we move down the levels, the user
bodyText ||| becomes progressively more engaged with the experience,
bodyText ||| going from peripheral presence awareness to immersive
bodyText ||| participation through a number of intermediate levels. Part
bodyText ||| of the reason for this is that at each stage, the user has
bodyText ||| access to more detailed information. This is similar to a
bodyText ||| “ramping interface” model of information design and
bodyText ||| interaction [25], and allows users to drill down to the level
bodyText ||| they are interested in. In particular, each step provides more
bodyText ||| specific presence and richer contextual awareness. The
bodyText ||| ambient device provides only aggregate presence, and only
bodyText ||| conveys that a TV is on. The buddy list shows presence per
bodyText ||| household, and what they are watching. By watching the
bodyText ||| same thing, common ground is established, and by
bodyText ||| communicating it is possible to identify the other person at
bodyText ||| an individual level. However, the most interesting thing to
bodyText ||| note may be that as users become more deeply engaged,
bodyText ||| they also become increasingly present to, and eventually
bodyText ||| connected to, their buddies.
page ||| 8
note ||| CHI 2008 Proceedings · Soci-Cultural Impact	April 5-10, 2008 · Florence, Italy
table ||| Interaction	Information	Presence specificity	Context detail	What others experience	Degree of
table ||| 	amount				participation
table ||| Noticing ambient display	Bite	Aggregate buddy list (+inferences)	TV is on/off	No presence info	Peripheral awareness
table ||| 					Full involvement
table ||| Viewing buddy list	Snack	Aggregate household (+inferences)	The program(s) being watched	TV is on/watching program
table ||| Co-viewing program			Shared viewing context (common ground)	Sharing the viewing experience
table ||| Exchanging lightweight messages	Meal	Aggregate	Reactions to show, responses to	In contact, communicating
table ||| 		household or individual	messages
table ||| Talking on the phone	Feast	Individual	Two-way audio stream	Rich conversation
tableCaption ||| Table 3: Different stages of interaction with the system, along with some notable characteristics.
bodyText ||| Users can move freely between the various interaction
bodyText ||| levels, as their needs and interest dictate. However, each
bodyText ||| stage provides impulses that encourage deeper engagement,
bodyText ||| playing on such traits as curiosity and desire to express
bodyText ||| opinions, and guides users towards the ultimate state of live
bodyText ||| conversation, which here takes the form of phone calls.
subsectionHeader ||| Improving the Quality of Time Spent Watching TV
bodyText ||| We see that the ambient information is intimately bound up
bodyText ||| with the social functionality available on the TV. Although
bodyText ||| our participants found the ambient data interesting in the
bodyText ||| context of the Social TV 2 system, the information would
bodyText ||| be nearly meaningless on its own; “a tease.” If the ambient
bodyText ||| displays extend the social television experience outside of
bodyText ||| the TV set, the other features help users interpret the
bodyText ||| ambient signals and provide the information with a purpose.
bodyText ||| They make it actionable.
bodyText ||| Furthermore, as social presence information is made
bodyText ||| actionable through the TV, turning on the TV becomes
bodyText ||| redefined as a social act: “Even before I turned on the TV, I
bodyText ||| knew that someone was on there.” Because the ambient
bodyText ||| devices provide users with at least peripheral awareness of
bodyText ||| their buddies’ presence information, there is now an
bodyText ||| unavoidable social dimension to pressing that button, such
bodyText ||| as expectations of availability. And even if users should be
bodyText ||| oblivious, turning on the TV affects their buddies’ ambient
bodyText ||| displays and presence view, making them aware. We saw
bodyText ||| this social consideration give rise to new behaviors such as
bodyText ||| turning on the TV when the ambient devices showed other
bodyText ||| people online.
bodyText ||| The methods of our study do not allow us to say with
bodyText ||| confidence whether Social TV 2 caused our participants to
bodyText ||| watch more TV, or keep their TV on more. For that, a
bodyText ||| control condition would be required. Certainly some of our
bodyText ||| findings suggest that it might be the case. However, in light
bodyText ||| of the above, direct comparisons may not be particularly
bodyText ||| meaningful. To watch Social TV 2 is not merely to
bodyText ||| consume entertainment, but to engage in communication
bodyText ||| with friends and family that can bring you closer together,
bodyText ||| reaffirm social ties, and let you get to know each other
bodyText ||| better. The ambient displays provide a first point of contact
bodyText ||| for TV-based conversations, and help establish a social
bodyText ||| mindset around the very notion of television.
bodyText ||| This insight suggests that different systems could use
bodyText ||| ambient displays to emphasize specific features, by
bodyText ||| preparing the user’s frame of mind in advance of their
bodyText ||| active interactions.
sectionHeader ||| CONCLUSIONS
bodyText ||| In this paper we have presented results from testing a social
bodyText ||| television system with an ambient component for social
bodyText ||| presence. On the whole, our participants liked the idea of
bodyText ||| having the TV watching activities of their social groups
bodyText ||| represented in ambient displays. Presence information was
bodyText ||| understood and used as a proxy for who was home and
bodyText ||| available. More importantly, it worked to support the
bodyText ||| experience of communicating through the television.
bodyText ||| Most social television research to date has focused on what
bodyText ||| happens once people are engaged in a social television
bodyText ||| experience. There has been little research into how such
bodyText ||| sessions would be initiated, and how they can be made to fit
bodyText ||| into the context of everyday activities. Our study addresses
bodyText ||| these issues: Designs based on ambient displays offer a
bodyText ||| credible answer, and our field study showed one such
bodyText ||| design to perform well in practice. Since the same concerns
bodyText ||| are relevant to a wide class of other in-home social systems,
bodyText ||| this finding holds more general interest.
sectionHeader ||| FUTURE WORK
bodyText ||| One of the most interesting questions raised by this study is
bodyText ||| how the addition of social awareness will affect pre-existing
bodyText ||| patterns of behavior around TV viewing. The effect is
bodyText ||| profound, and some simple examples are clearly evident in
bodyText ||| the data. However, we suspect that the altered social
bodyText ||| dynamic of TV viewing could have far more complex and
bodyText ||| subtle effects, especially as the presence awareness
bodyText ||| increases the visibility of TV viewing habits to oneself and
page ||| 9
note ||| CHI 2008 Proceedings · Soci-Cultural Impact	April 5-10, 2008 · Florence, Italy
bodyText ||| others. Understanding these changes in perception and
bodyText ||| behavior is a rich area for further research.
bodyText ||| While our data collection provided a great deal of
bodyText ||| qualitative information on how participants used Social TV
bodyText ||| 2, we have no data on when participants were home, when
bodyText ||| they were in a room from which they could observe the
bodyText ||| ambient indicators, or who was using the system at any
bodyText ||| particular moment in time. This limits our ability to
bodyText ||| interpret the log data. In upcoming studies we plan to
bodyText ||| include a control condition, to provide a baseline against
bodyText ||| which changes in behavior can be detected.
bodyText ||| We continue to iterate on the design of the Social TV
bodyText ||| prototype. Given the tendency of our participants to seek
bodyText ||| progressively deeper engagement and richer
bodyText ||| communication, we have now integrated support for voice
bodyText ||| and text chatting, and are currently preparing another field
bodyText ||| trial with these features included. We are also considering
bodyText ||| other form factors for the ambient devices, and changing
bodyText ||| the kinds of information these devices display. However,
bodyText ||| one change we are not going to make is eliminating the
bodyText ||| ambient information. Our findings spoke clearly to us about
bodyText ||| the attractive nature of ambient awareness, and we intend to
bodyText ||| keep using this feature to promote TV-based sociability.
sectionHeader ||| ACKNOWLEDGMENTS
bodyText ||| We thank Ambient Devices, Inc. and Chumby Industries for
bodyText ||| providing the ambient devices, and Seonyoung Park and
bodyText ||| Elaine Huang for their contributions to the study and paper.
sectionHeader ||| REFERENCES
reference ||| 1. Aipperspach, R., Rattenbury, T., Woodruff, A., Canny, J.
reference ||| (2006) A Quantitative Method for Revealing and
reference ||| Comparing Places in the Home. Proc. Ubicomp 2006.
reference ||| 2. Baillie, L., Fröhlich, P., Schatz, R. (2007) Exploring Social
reference ||| TV. In Proc. ITI 2007: 215–220.
reference ||| 3. Bernard, H.R. (1998) Handbook of Methods in Cultural
reference ||| Anthropology. Walnut Creek, CA : Altamira Press.
reference ||| 4. Beyer, H., & Holtzblatt, K. (1998). Contextual design:
reference ||| Defining customer-centered systems. San Francisco, CA :
reference ||| Morgan Kaufmann Publishers.
reference ||| 5. Boertjes, E. (2007) ConnecTV: Share the Experience. In
reference ||| EuroITV 2007 Adj. Proc.
reference ||| 6. Brown, B., Taylor, A., Izadi, S., Sellen, A., Kaye, J. (2007)
reference ||| Locating Family Values: A Field Trial of the Whereabouts
reference ||| Clock. In Proc. Ubicomp 2007.
reference ||| 7. Bureau of Labor Statistics (2006) American Time Use
reference ||| Survey. ftp://ftp.bls.gov/pub/news.release/atus.txt
reference ||| 8. Consolvo, S., Roessler, P., Shelton, B.E. (2004) The
reference ||| CareNet Display: Lessons Learned from an In Home
reference ||| Evaluation of an Ambient Display. Proc. Ubicomp 2004.
reference ||| 9. Coppens, T., Trappeniers, L. Godon, M. (2004).
reference ||| AmigoTV: towards a social TV experience. In Proc.
reference ||| EuroITV 2004.
reference ||| 10. Crispell, D. (1997) “TV soloists – Statistics on number of
reference ||| television sets owned in households from SRI Consulting’s
reference ||| Media Futures Program”, American Demographics, May
reference ||| 1997.
reference ||| 11. DeGuzman, E.S., Yau, M., Gagliano, A., Park, A., Dey,
reference ||| A.K. (2004) Exploring the design and use of peripheral
reference ||| displays of awareness information. CHI 04 Ext. Abstracts.
reference ||| 12. Dey, A.K. and DeGuzman, E.S. (2006) From Awareness to
reference ||| Connectedness: The Design and Deployment of Presence
reference ||| Displays. In Proc. CHI ’06: 899–908.
reference ||| 13. Eggen, B., Rozendaal, M., Schimmel, O. (2003) Home
reference ||| Radio: Extending the Home Experience beyond the
reference ||| Physical Boundaries of the House. In Proc. HOIT 2003.
reference ||| 14. Geerts, D. (2006) Comparing voice chat and text chat in a
reference ||| communication tool for interactive television. In Proc.
reference ||| NordiCHI 2006: 461–464.
reference ||| 15. Harboe, G., Massey, N., Metcalf, C.J., Wheatley, D.,
reference ||| Romano, G. (2008) The Uses of Social Television. In
reference ||| Comput. Entertain. 6, 1 (Jan 2008).
reference ||| 16. Harrison, C. and Amento, B. (2007) CollaboraTV –
reference ||| Making TV Social Again. In EuroITV 2007 Adj. Proc.
reference ||| 17. Hemmeryckx-Deleersnijder, B. and Thorne, J.M. (2007)
reference ||| Awareness and Conversational Context Sharing to Enrich
reference ||| TV Based Communication, In Proc. EuroITV 2007: 1–10.
reference ||| 18. Hindus, D., Mainwaring, S.D., Leduc, N., Hagström, A.E.,
reference ||| Bayley, O. (2001) Casablanca: Designing Social
reference ||| Communication Devices for the Home. In Proc. CHI ’01.
reference ||| 19. LeCompte, M. and Schensul, J. (1999) Designing and
reference ||| Conducting Ethnographic Research. Walnut Creek, CA :
reference ||| Altamira Press.
reference ||| 20. Lull, J. (1990). Inside family viewing: Ethnographic
reference ||| research on television's audiences. London: Routledge.
reference ||| 21. Luyten, K., Thys, K., Huypens, S., Coninx, K. (2006)
reference ||| Telebuddies: Social Stitching with Interactive Television.
reference ||| In CHI 2006 Extended Abstracts.
reference ||| 22. Markopoulos, P., de Ruyter, B., Mackay, W.E. (2005)
reference ||| Awareness Systems: Known Results, Theory, Concepts
reference ||| and Future Challenges. CHI 05 Ext. Abstracts.
reference ||| 23. Oehlberg, L., Ducheneaut, N., Thornton, J. D., Moore, R.
reference ||| J., Nickell, E. (2006). Social TV: Designing for
reference ||| Distributed, Sociable Television Viewing. In Proc.
reference ||| EuroITV 2006: 25–26.
reference ||| 24. Regan, T. and Todd, I. (2004) Media Center Buddies:
reference ||| Instant Messaging around a Media Center. In Proc.
reference ||| NordiCHI 2004: 141–144.
reference ||| 25. Rhodes, B. and Maes, P. (2000) Just-in-time information
reference ||| retrieval agents. IBM Systems Journal 39(3–4).
reference ||| 26. Rowan, J. and Mynatt, E. D. (2005) Digital Family Portrait
reference ||| Field Trial: Support for Aging in Place. In Proc. CHI ’05:
reference ||| 521–530.
reference ||| 27. de Ruyter, B., Huijnen, C., Markopoulos, P., IJsselstein,
reference ||| W. (2003) Creating social presence through peripheral
reference ||| awareness. In Proc. HCI International 2003.
reference ||| 28. Vetere et al. (2005) Mediating Intimacy: Designing
reference ||| Technologies to Support Strong-Tie Relationships. In
reference ||| Proc. CHI ’05: 471–480.
reference ||| 29. Weisz, J. D., Kiesler, S., Zhang, H., Ren, Y., Kraut, R. E.,
reference ||| Konstan, J. A. (2007) Watching together: integrating text
reference ||| chat with video. In Proc. CHI ’07: 877–886.
page ||| 10

note ||| CHI 2008 Proceedings · Help Me Search	April 5-10, 2008 · Florence, Italy
title ||| Conversation Pivots and Double Pivots
author ||| Daniel Xiaodan Zhou, Nathan Oostendorp, Michael Hess, Paul Resnick
affiliation ||| CommunityLab*
affiliation ||| University of Michigan School of Information
address ||| Ann Arbor, MI 48109
email ||| {mrzhou, oostendo, mlhess, presnick}@umich.edu
sectionHeader ||| ABSTRACT
bodyText ||| Many sites on the web offer collaborative databases that
bodyText ||| catalog items such as bands, events, products, or software
bodyText ||| modules. Conversation pivots allow readers to navigate
bodyText ||| from pages about these items to conversations about them
bodyText ||| on the same site or elsewhere on the Internet. Double pivots
bodyText ||| allow readers to navigate from item pages to pages about
bodyText ||| other items mentioned in the same conversations. Using
bodyText ||| text mining techniques specific to the collection it is
bodyText ||| possible to find references to collected items in online
bodyText ||| conversations. We implemented conversation pivots for the
bodyText ||| CPAN archive of Perl modules, and for Drupal.org, the
bodyText ||| reference site for the Drupal content management system.
sectionHeader ||| Author Keywords
keyword ||| Online Discussion, Conversation, Recommender, Pivot,
keyword ||| Drupal, Perlmonks
sectionHeader ||| ACM Classification Keywords
category ||| H5.4 Hypertext/Hypermedia Navigation. H5.2. User
category ||| Interfaces
sectionHeader ||| INTRODUCTION
bodyText ||| Many websites maintain collections of pages about people,
bodyText ||| places, and things. These item pages typically include
bodyText ||| structured data. The sites also frequently include online
bodyText ||| forums, with an abundant and unstructured repository of
bodyText ||| user-contributed data about the same items. Drenner et al
bodyText ||| [1] describe these areas as “item-land” and “forum-land”,
bodyText ||| and describe how the site MovieLens was able to cross-link
bodyText ||| them. Movie item pages have links to conversation threads
bodyText ||| mentioning the movies and conversation pages link to the
bodyText ||| referenced movie pages.
bodyText ||| More generally, item-land describes a large variety of
bodyText ||| online collections:
copyright ||| Permission to make digital or hard copies of all or part of this work for
copyright ||| personal or classroom use is granted without fee provided that copies are
copyright ||| not made or distributed for profit or commercial advantage and that copies
copyright ||| bear this notice and the full citation on the first page. To copy otherwise,
copyright ||| or republish, to post on servers or to redistribute to lists, requires prior
copyright ||| specific permission and/or a fee.
note ||| CHI 2008, April 5–10, 2008, Florence, Italy.
copyright ||| Copyright 2008 ACM 978-1-60558-011-1/08/04...$5.00
listItem ||| •	Musician profiles on MySpace.com or Last.fm
listItem ||| •	Concert or other event listing in a public calendar
listItem ||| •	Wikipedia entries for people, places, or things
listItem ||| •	Product pages (e.g., on Amazon.com)
listItem ||| •	Software module pages on a repository such as PEAR
listItem ||| or CPAN
bodyText ||| It is easy to imagine how bridges between “item-land” and
bodyText ||| “forum-land” could be very useful in these contexts,
bodyText ||| especially when “forum-land” might be separate from the
bodyText ||| item collection (i.e., on a separate website.)
bodyText ||| While previous work has explored the connections in the
bodyText ||| case of movie items, we explore them in the case of item
bodyText ||| pages that describe software modules. We explain how the
bodyText ||| unique features of software modules and conversation
bodyText ||| threads can be used in inferring links between them. We
bodyText ||| also show how these links can be used not only to help
bodyText ||| navigate from software modules to related conversation but
bodyText ||| also from software modules to related modules.
sectionHeader ||| CONVERSATION PIVOTS
bodyText ||| Links between items and forums are instances of a more
bodyText ||| general class of navigation aids that we call pivots. A pivot
bodyText ||| enables navigation from an object to a set of other objects
bodyText ||| that share some attribute in common. Perhaps the most
bodyText ||| familiar instantiation of the pivot concept is the ability, at
bodyText ||| sites such as del.icio.us and Flickr and many individual
bodyText ||| blogs, to click on a “tag” in order to move from one page or
bodyText ||| photo to a set of others that have been classified with the
bodyText ||| same tag. Many other pivots are possible. For example, a
bodyText ||| pivot can allow navigation from a message to other
bodyText ||| messages by the same author, or from an event
bodyText ||| announcement to other events at the same venue, or other
bodyText ||| events at the same time, or other events featuring the same
bodyText ||| speaker.1
footnote ||| * CommunityLab is a collaborative project of the University of
footnote ||| Minnesota, University of Michigan, and Carnegie Mellon
footnote ||| University. http://www.communitylab.org/
footnote ||| 1 We borrow this usage of the term pivot from spreadsheet
footnote ||| pivot tables and from the description of features of the Ning
footnote ||| platform for building social applications. [2]
page ||| 1009
note ||| CHI 2008 Proceedings · Help Me Search	April 5-10, 2008 · Florence, Italy
table ||| 		Messages
table ||| 		T4	T2	T3	T4a	T4b
table ||| 	S1	0	1	0	1	0
table ||| 	S2	1	0	1	0	0
table ||| 	S3	1	0	1	0	1
tableCaption ||| Table 1. A matrix representing the pivot from software
tableCaption ||| modules to conversation messages that reference them.
tableCaption ||| Target messages T4a and T4b are from the same thread.
bodyText ||| More formally, we define a pivot as a function that maps
bodyText ||| from source items to subsets of a set of target items. The
bodyText ||| pivots can be represented as a matrix P, with one row for
bodyText ||| each source item and one column for each target item. Each
bodyText ||| cell in the matrix indicates whether the source and target are
bodyText ||| related (i.e., share a “common attribute”).
bodyText ||| In the case of conversation pivots for software modules, the
bodyText ||| source items are pages describing software modules and the
bodyText ||| targets are messages. A cell’s value encodes whether the
bodyText ||| message mentions the software module. For example, as
bodyText ||| shown in Table 1, message T3 refers to the software
bodyText ||| module that page S1 describes but not the modules
bodyText ||| described by pages S2 and S3.
bodyText ||| Depending on the application, it may be useful to
bodyText ||| automatically display on a source page a pivot block with
bodyText ||| links to a few targets. In other applications, users may need
bodyText ||| to explicitly request that related targets be displayed. This is
bodyText ||| common, for example, in tagging interfaces, where a user
bodyText ||| has to click on a tag before the set of related items is
bodyText ||| displayed. In either case, if too many target items are
bodyText ||| related to a single source, it is helpful to order them based
bodyText ||| on which are likely to be most useful when navigating from
bodyText ||| that source item. To accommodate that, a cell in the pivot
bodyText ||| matrix can contain a similarity or relevance score based on
bodyText ||| frequency or prominence of the reference, rather than just a
bodyText ||| binary indicator of a reference to the source item.
bodyText ||| We have implemented, but not yet publicly released
bodyText ||| conversation pivot blocks for two popular software
bodyText ||| platforms, Drupal and CPAN. On the Drupal.org website,
bodyText ||| there is a page for each of the hundreds of available add-on
bodyText ||| modules. The Related Discussion block, on the top right in
bodyText ||| Figure 1, will add links to related conversations that occur
bodyText ||| in the Drupal forums, elsewhere on the site. Each link is to
bodyText ||| an entire thread, scrolled to the first message in the thread
bodyText ||| that references the module.
bodyText ||| For the programming language Perl, there are thousands of
bodyText ||| software libraries, also referred to as modules, that
bodyText ||| programmers can download from a site called CPAN. Each
bodyText ||| module gets its own page on CPAN, with information about
bodyText ||| its history and status and a link to download the actual code.
bodyText ||| We have focused on an experimental mirror site called
bodyText ||| AnnoCPAN that displays user annotations on the module
bodyText ||| pages. The CPAN and AnnoCPAN sites do not host
figureCaption ||| Figure 1. The Drupal.org website with (A) pivot to
figureCaption ||| related conversations and (B) double-pivot to other
bodyText ||| conversations about Perl or Perl modules. One popular
bodyText ||| venue for such conversations is a website called Perlmonks.
bodyText ||| We have implemented a conversation pivot block for
bodyText ||| AnnoCPAN that shows links to related conversation threads
bodyText ||| on the Perlmonks website, as shown in Figure 2.
bodyText ||| We exploit the structure and chronology of conversation
bodyText ||| threads to help determine which messages are most
bodyText ||| important. Among messages that reference a software
bodyText ||| module, conversations that are longer and more recent are
bodyText ||| more likely to be useful to display in a pivot block.
bodyText ||| Although each link in a pivot block points to a particular
bodyText ||| message in a thread, we compute the message’s importance
bodyText ||| based on features of the entire thread. Our initial
bodyText ||| implementation simply computes a timestamp based on the
bodyText ||| time of the most recent message posted in the thread.
bodyText ||| Among messages that reference the source item, those
bodyText ||| whose threads have more recent activity are shown first.
bodyText ||| Without the conversation pivot blocks, people could use a
bodyText ||| search engine to seek forum references to particular
bodyText ||| software modules. This would require significant user
bodyText ||| effort. Moreover, we are able to tune our search algorithm
bodyText ||| to take advantage of the structure of software module pages
bodyText ||| and conversation threads, in a way that would be difficult
bodyText ||| for users to simulate if they had to construct their own
bodyText ||| search queries.
subsectionHeader ||| Double Pivots
bodyText ||| Any pivot matrix relating source items to subsets of target
bodyText ||| items can be used to generate another pivot matrix relating
bodyText ||| the source items back to subsets of those same source items.
bodyText ||| For example, from the page for a software module, we can
bodyText ||| display a pivot block of other related software modules, as
bodyText ||| shown in the “Related Modules” blocks in Figures 1 and 2.
bodyText ||| This can help users identify complementary modules and
figure ||| A
figure ||| B
page ||| 1010
note ||| CHI 2008 Proceedings · Help Me Search	April 5-10, 2008 · Florence, Italy
bodyText ||| especially substitutes that may be preferable to the current
bodyText ||| module.
bodyText ||| Conceptually, the double pivot block automatically follows
bodyText ||| the pivot to related conversation threads and then pivots
bodyText ||| again to a set of modules that are also referenced by those
bodyText ||| threads. Such a process would be tedious, however, for
bodyText ||| users to perform manually. By automatically aggregating
bodyText ||| the other module references from the set of messages that
bodyText ||| reference the current module, the body of contributing
bodyText ||| content is much larger than just the few messages that can
bodyText ||| be displayed to a user on a page.
bodyText ||| The double-pivot technique is closely related to the
bodyText ||| technique of item-item collaborative filtering [3], where
bodyText ||| two items are related if they are highly rated (or purchased)
bodyText ||| by the same people. It is also analogous to co-citation
bodyText ||| analysis in bibliometrics, where two papers are related if
bodyText ||| they are cited in the same other paper [4].
bodyText ||| In computing conversation double pivots, we first collapse
bodyText ||| messages into threads. Column T4a in Table 1 is a message
bodyText ||| that might have said something like, “Module S 1 doesn’t
bodyText ||| quite do what I need. Anyone have suggestions?” T4b is a
bodyText ||| reply suggesting module S3 as an alternative. Other users,
bodyText ||| when visiting the page for module S1, might then benefit
bodyText ||| from a double pivot link to S3, even though no single
bodyText ||| message mentions both S1 and S3. Thus, we treat two
bodyText ||| modules as related if they are referenced in the same thread.
bodyText ||| Table 2 illustrates the double pivot matrix resulting from
bodyText ||| the original matrix from Table 1. It indicates that S1 and S2
bodyText ||| are never referenced in the same thread, but S2 and S3 are
bodyText ||| both referenced in two different threads, and S1 and S3 in
bodyText ||| one thread. Thus, the double pivot block for the page about
bodyText ||| S2 would include a link to S3 but not to S1.
bodyText ||| More sophisticated implementations of the double pivot
bodyText ||| would account for the overall popularity of source items.
bodyText ||| For example, when two modules that are rarely referenced
bodyText ||| are referenced in the same thread, it is a stronger indicator
bodyText ||| that the two are related than when the same outcome occurs
bodyText ||| for a pair of frequently referenced modules.
table ||| 		Software Module
table ||| 		S1	S2	S3
table ||| 	S1	2	0	1
table ||| 	S2	0	2	2
table ||| 	S3	1	2	3
tableCaption ||| Table 2. Module by Module Associations from a double pivot
sectionHeader ||| DETECTING CONVERSATION SUBJECTS
bodyText ||| The pivot matrix is constructed by examining the potential
bodyText ||| target threads to see which source items they reference. One
bodyText ||| possibility would be to rely on message authors to explicitly
bodyText ||| link to source items rather than using natural language to
bodyText ||| identify them. Tools such as auto-complete could simplify
bodyText ||| this task for message authors. Even so, it seems unwise to
bodyText ||| depend on authors to do this, since the primary beneficiaries
bodyText ||| would not be the authors or even the readers of the
bodyText ||| messages, but unknown and unseen future visitors to
bodyText ||| module pages.
bodyText ||| Instead, a software program can automatically infer
bodyText ||| references to items as they are naturally expressed in
bodyText ||| messages, albeit with some error. The errors will be
bodyText ||| reduced to the extent that authors refer to items using
bodyText ||| distinctive canonical identifiers, such as ISBN numbers. For
bodyText ||| example, the PHOAKS project mined Usenet for references
bodyText ||| to web pages, where the natural way to refer to a site in
bodyText ||| conversation was to put in a complete URL [5].
bodyText ||| Two factors make it practical to automatically mine
bodyText ||| conversations for software module references. The first is a
bodyText ||| high tolerance for errors of omission: detecting even a small
bodyText ||| fraction of the actual references to software modules may
bodyText ||| be sufficient to generate useful pivot and double-pivot
bodyText ||| blocks for navigation. The second factor is that there are
bodyText ||| regularities in module names and in patterns of reference to
bodyText ||| them that can be exploited when creating a reference index.
bodyText ||| Some software systems employ a naming system that
bodyText ||| allows exact string matching on module titles to perform
bodyText ||| well. Perl modules follow a hierarchical naming convention
bodyText ||| with “::” as a separator found rarely in normal conversation.
bodyText ||| If the text string “Time::ParseDate” appears in a message,
bodyText ||| the author almost certainly meant to refer to the Perl
bodyText ||| module of that name, so that exact matching on module
bodyText ||| titles will have high precision. Moreover, a social norm has
bodyText ||| emerged so that an author who wants to refer to that module
bodyText ||| will typically use that text string to refer to it, rather than a
bodyText ||| shorter alias such as ParseDate. Thus, exact text matching
bodyText ||| will retrieve the correct references with high recall as well,
bodyText ||| although it will occasionally miss matches due to
bodyText ||| misspellings.
figure ||| A
figure ||| B
figureCaption ||| Figure 2. CPAN with a (A) conversation pivot to
figureCaption ||| Perlmonks.org, and a (B) double-pivot to related modules
page ||| 1011
note ||| CHI 2008 Proceedings · Help Me Search	April 5-10, 2008 · Florence, Italy
bodyText ||| In mining Perlmonks conversations, we used the exact
bodyText ||| matching on module titles technique. Of 550,679 total
bodyText ||| comments that had been posted on the Perlmonks site, 16%
bodyText ||| contained module references. Some messages contained
bodyText ||| long lists of modules; it seemed unlikely that a user
bodyText ||| examining any particular module would find it useful to
bodyText ||| navigate to a message containing a long list that happened
bodyText ||| to contain the source module, so we discarded those
bodyText ||| messages. Even after discarding 35 outliers that referenced
bodyText ||| more than ten modules each, 41% of the 4,548 total CPAN
bodyText ||| modules were cited on Perlmonks, and those had a median
bodyText ||| of 5 references.
bodyText ||| Based on those detected module references, excluding 35
bodyText ||| outliers, we computed the double pivot matrix. Of the 1,884
bodyText ||| modules that were cited at all, 1,702 had at least one other
bodyText ||| module co-cited in the same conversation. Of these, the
bodyText ||| median number of “related modules” was 6.
bodyText ||| String matching on titles can be extended to include
bodyText ||| searching for distinctive aliases. For example, most authors
bodyText ||| refer to the Drupal module titled “Content Construction Kit
bodyText ||| (CCK)” as “CCK” rather than using the full title. Even if it
bodyText ||| is unrealistic to expect all message authors to tag all their
bodyText ||| references to modules, it may be quite reasonable to expect
bodyText ||| the authors of the module pages to identify aliases that are
bodyText ||| frequently used in conversation. The authors of those pages,
bodyText ||| typically the people responsible for maintaining the
bodyText ||| software modules, have both the knowledge of commonly
bodyText ||| used aliases and the incentive to enter them in to the
bodyText ||| system, in order to help users find what others are saying
bodyText ||| about the modules.
bodyText ||| String matching on titles can also be narrowed to handle
bodyText ||| situations where it would yield too many false positives.
bodyText ||| Some software systems use module titles that are
bodyText ||| potentially ambiguous. For example, Drupal modules
bodyText ||| generally use common words such as “Event” or “Upload”
bodyText ||| for titles. Simple text matching on these titles would yield
bodyText ||| many false positives, conversation messages that use these
bodyText ||| words but not in reference to the software modules. Real
bodyText ||| references to the Upload module, however, frequently
bodyText ||| contain the word “module” in close proximity to the word
bodyText ||| “Upload”. Thus, a matching algorithm that searches for the
bodyText ||| title adjacent to the magic word “module” will likely
bodyText ||| generate many fewer false positives, though possibly
bodyText ||| missing more correct references.
bodyText ||| We used this method to find module references in the
bodyText ||| Drupal.org conversation forums. Of 292,139 messages,
bodyText ||| 47,794 contained at least one module reference. After
bodyText ||| discarding 21 outliers that each referred to more than ten
bodyText ||| modules, 915 of the 1,590 modules were cited in at least
bodyText ||| one message and those had a median of 6 references.
bodyText ||| Based on those detected module references, we computed
bodyText ||| the double pivot matrix. Of the 915 modules that were cited
bodyText ||| at all, 747 had at least one other module co-cited in the
bodyText ||| same conversation. Of these, the median number of “related
bodyText ||| modules” was 6.
sectionHeader ||| CONCLUSIONS AND FUTURE RESEARCH
bodyText ||| The results from our implementations with Drupal.org and
bodyText ||| AnnoCPAN/Perlmonks lead us to believe that conversation
bodyText ||| pivots and double pivots hold a great deal of promise for
bodyText ||| making online collections more useful for users. By
bodyText ||| automatically mining forum data for item references and
bodyText ||| generating recommendations of other modules we provide
bodyText ||| users with a shortcut through time-intensive manual search.
bodyText ||| The vision of the semantic web [6] is that information for
bodyText ||| human consumption will also be tagged in a way that
bodyText ||| computers can process in useful ways. When semantic
bodyText ||| markup is not available, however, it may be possible to
bodyText ||| infer it imperfectly, but well enough to enable particular
bodyText ||| kinds of processing. We have developed techniques for
bodyText ||| detecting references to software modules in online
bodyText ||| conversations that are sufficient to enable the creation of
bodyText ||| navigation aids in the form of conversation pivots and
bodyText ||| double pivots. The techniques may be extensible to creating
bodyText ||| conversation pivots for other types of items.
sectionHeader ||| ACKNOWLEDGEMENTS
bodyText ||| This material is based upon work supported by the National
bodyText ||| Science Foundation under Grant Nos. 0308006 and
bodyText ||| 0325837. We wish to thank the administrators of
bodyText ||| Drupal.org and Perlmonks.org for allowing us access to
bodyText ||| their data sets and to Ivan Tubert-Brohman for allowing us
bodyText ||| to add the pivot feature to the AnnoCPAN site.
sectionHeader ||| REFERENCES
reference ||| 1. Drenner, S., Harper, M., Frankowski, D., Riedl, J., and
reference ||| Terveen, L. Insert movie reference here: a system to
reference ||| bridge conversation and item-oriented web sites. In
reference ||| Proceedings of the SIGCHI Conference on Human
reference ||| Factors in Computing Systems CHI '06 (2006)
reference ||| 2. Ning Platform Pivots Feature. http://blog.ning.com/
reference ||| 2005/11/new_on_the_ning_pivot.html
reference ||| 3. Linden, G., Smith, B., York, J. Amazon.com
reference ||| recommendations: item-to-item collaborative filtering,
reference ||| Internet Computing, IEEE, 7, 1 (2003), 76-80.
reference ||| 4. Small, H. Co-citation in the scientific literature: A new
reference ||| measure of the relationship between two documents.
reference ||| Journal of the American Society for Information
reference ||| Science, vol. 24, 4 (1973), 265 – 269.
reference ||| 5. Terveen, L., Hill, W., Amento, B., McDonald, D., and
reference ||| Creter, J. PHOAKS: a system for sharing
reference ||| recommendations. Communications of the ACM. 40, 3
reference ||| (1997), 59 – 62.
reference ||| 6. Berners-Lee, T., Hendler, J., and Lassila,O.,The
reference ||| semantic web. Scientific American. 284 (2001), 5, 34.
page ||| 1012

note ||| CHI 2008 Proceedings · Online Social Networks	April 5-10, 2008 · Florence, Italy
title ||| Harvesting with SONAR - The Value of Aggregating Social
title ||| Network Information
author ||| Ido Guy, Michal Jacovi, Elad Shahar,
author ||| Noga Meshulam, Vladimir Soroka
affiliation ||| IBM Haifa Research Lab
address ||| Mt. Carmel, Haifa 31905, Israel
email ||| {ido, jacovi, elads, noga, vladi} @il.ibm.com
sectionHeader ||| ABSTRACT
bodyText ||| Web 2.0 gives people a substantial role in content and
bodyText ||| metadata creation. New interpersonal connections are
bodyText ||| formed and existing connections become evident. This
bodyText ||| newly created social network (SN) spans across multiple
bodyText ||| services and aggregating it could bring great value. In this
bodyText ||| work we present SONAR, an API for gathering and sharing
bodyText ||| SN information. We give a detailed description of SONAR,
bodyText ||| demonstrate its potential value through user scenarios, and
bodyText ||| show results from experiments we conducted with a
bodyText ||| SONAR-based social networking application within our
bodyText ||| organizational intranet. These suggest that aggregating SN
bodyText ||| information across diverse data sources enriches the SN
bodyText ||| picture and makes it more complete and useful for the end
bodyText ||| user.
sectionHeader ||| Author Keywords
keyword ||| Social networks, SN, social network analysis, SNA,
keyword ||| aggregation.
sectionHeader ||| ACM Classification Keywords
category ||| H.5.3 Group and Organizational Interfaces – Computer-
category ||| supported cooperative work
sectionHeader ||| INTRODUCTION
bodyText ||| Social software – software that has people as its focal point
bodyText ||| – is the core of Web 2.0. From blogs and wikis through
bodyText ||| recommender systems to social bookmarking and personal
bodyText ||| network systems – social applications proliferate. In
bodyText ||| continuation to its dominance on the internet, social
bodyText ||| software has recently emerged in organizations, as a mean
bodyText ||| of connecting employees in a better way and enhancing
bodyText ||| knowledge management and expertise location. Blogging
bodyText ||| systems [14], social bookmarking [19], and people tagging
copyright ||| Permission to make digital or hard copies of all or part of this work for
copyright ||| personal or classroom use is granted without fee provided that copies are
copyright ||| not made or distributed for profit or commercial advantage and that copies
copyright ||| bear this notice and the full citation on the first page. To copy otherwise,
copyright ||| or republish, to post on servers or to redistribute to lists, requires prior
copyright ||| specific permission and/or a fee.
note ||| CHI 2008, April 5–10, 2008, Florence, Italy.
copyright ||| Copyright 2008 ACM 978-1-60558-011-1/08/04...$5.00.
author ||| Stephen Farrell
affiliation ||| IBM Almaden Research Center
address ||| 650 Harry Road, San Jose, California
email ||| sfarrell@almaden.ibm.com
bodyText ||| [7], are examples of social applications that became part of
bodyText ||| organizations’ intranets in the purpose of promoting intra-
bodyText ||| organizational interaction.
bodyText ||| Many of these social applications expose interesting
bodyText ||| information about people’s relationships. For example, by
bodyText ||| analysing blog commenters, or bookmarking similarities,
bodyText ||| connections among people can become evident. By
bodyText ||| extracting this information and aggregating it across
bodyText ||| multiple sources, a comprehensive and often intriguing
bodyText ||| picture of individual and organizational social networks
bodyText ||| may be revealed.
bodyText ||| Potential sources of social information are very diverse.
bodyText ||| Different users make use of different tools, and social
bodyText ||| information is scattered among many services and
bodyText ||| applications. As these applications rarely interoperate, each
bodyText ||| is typically only aware of its own social data and cannot
bodyText ||| benefit from other applications’ data.
bodyText ||| The diversity of sources of social networking data also
bodyText ||| brings a variety of semantics to interpersonal connections.
bodyText ||| While some of these semantics are straightforward and
bodyText ||| derived from the nature of the connection (brother, close
bodyText ||| friend, manager, etc.), others are more complex. Many
bodyText ||| researchers recognized that people are connected through
bodyText ||| artifacts. For example, many studies have investigated
bodyText ||| networks where two people are connected if they have co-
bodyText ||| authored a paper [22]. Newer examples of artifacts that
bodyText ||| connect people include email messages [3,28], and web
bodyText ||| pages [14]. Affiliation networks [29] present people’s
bodyText ||| connections through groups in which they co-participate,
bodyText ||| such as a board of directors, or a movie cast [22]. The
bodyText ||| above examples imply that aggregating social network data
bodyText ||| presents the challenge of creating a single framework,
bodyText ||| general yet informative, to fit all types of connections.
bodyText ||| To address the above challenges, we introduce SONAR
bodyText ||| (Social Networks Architecture) – an API for sharing social
bodyText ||| network data and aggregating it across applications to show
bodyText ||| who is related to whom and how. Applications
bodyText ||| implementing the SONAR API (SONAR providers) should
bodyText ||| provide internal information about how strongly people are
bodyText ||| connected and by what means. SONAR clients can use the
bodyText ||| SONAR API to access data from a single provider that
bodyText ||| implements the API. However, the more compelling case is
page ||| 1017
note ||| CHI 2008 Proceedings · Online Social Networks	April 5-10, 2008 · Florence, Italy
bodyText ||| where an intermediate component, an aggregator, is used
bodyText ||| by clients, with the very same SONAR API, to consolidate
bodyText ||| the data from different providers. This way, one can choose
bodyText ||| multiple providers and assign an appropriate weight to each
bodyText ||| of them. It is expected that federating more data providers
bodyText ||| will make the resulting answers to queries more complete.
bodyText ||| Clients of SONAR may vary from expertise miners,
bodyText ||| through network visualizers, to user interface widgets.
bodyText ||| SONAR answers questions such as “who does this person
bodyText ||| communicate with most?”, “what are all the artifacts co-
bodyText ||| authored by these two individuals?”, “whom should I invite
bodyText ||| to a brainstorm on a certain topic?”
bodyText ||| SONAR includes two types of data sources: personal
bodyText ||| (private) and public. Personal sources, such as email and
bodyText ||| instant messaging (IM), are only available to their owner
bodyText ||| and reflect the owner’s personal, or egocentric, social
bodyText ||| network (i.e., all nodes in the network are directly related to
bodyText ||| the owner). Public data sources, such as blogs and
bodyText ||| organizational charts, are available to all users and reflect
bodyText ||| their extended, or sociocentric, network. SONAR maintains
bodyText ||| the privacy model of its data sources: only those users who
bodyText ||| have access to a certain piece of data by the original
bodyText ||| provider will have access to the social information extracted
bodyText ||| from this data by SONAR.
bodyText ||| As of now, we implemented the SONAR API for over ten
bodyText ||| sources, public and personal, within the IBM intranet.
bodyText ||| SONAR’s ultimate goal is to be widely used by social
bodyText ||| networking and Web 2.0 services on the internet and to
bodyText ||| define a standard, analogous to RSS [11]. SONAR is based
bodyText ||| on the REST design pattern [9] and uses standard data
bodyText ||| formats such as Atom [23] and JSON [13].
bodyText ||| When used for creating a sociocentric view of a social
bodyText ||| network, SONAR is based solely on public sources. Any
bodyText ||| user may use this view to examine publicly visible
bodyText ||| connections within any group of people. When used for
bodyText ||| creating an egocentric view of a user’s network, SONAR
bodyText ||| also makes use of the user’s personal sources. Enriching the
bodyText ||| egocentric network, as reflected in personal sources, with
bodyText ||| information from public sources, opens up new
bodyText ||| opportunities for learning about one’s extended network
bodyText ||| (i.e., one’s connections and their connections with others).
bodyText ||| Consider, for example, Alice who seeks a social connection
bodyText ||| to Cindy. Cindy may not appear at all in Alice’s egocentric
bodyText ||| network based on personal sources. However, examining
bodyText ||| the extended network, Alice may discover that Bob – who
bodyText ||| appears on her egocentric network by her personal data – is
bodyText ||| related to Cindy according to public sources. Alice will then
bodyText ||| be able to discover a social path to Cindy through Bob,
bodyText ||| based on aggregation of her personal and public sources.
bodyText ||| In order to verify the fundamental concepts on which
bodyText ||| SONAR relies, namely aggregation and the usage of public
bodyText ||| sources, we conducted three experiments. The first
bodyText ||| experiment examines different social networks derived
bodyText ||| from four of SONAR’s implemented public data sources.
bodyText ||| The second experiment involves a user study in which over
bodyText ||| a hundred users evaluated different buddylists derived from
bodyText ||| 24 different combinations of SONAR public as well as
bodyText ||| personal data sources. For the third experiment we
bodyText ||| interviewed 12 users about their usage of a SONAR UI and
bodyText ||| their thoughts on the different buddylists. The experiments
bodyText ||| examine the diversity of the public data sources, their value
bodyText ||| to the user, and whether they add value over personal data
bodyText ||| sources. Finally, we checked whether there exists an ideal
bodyText ||| weighting scheme of the sources, which may serve as the
bodyText ||| system’s default, and followed users as they were
bodyText ||| composing their own ideal weighting scheme.
bodyText ||| We note that the experiments in this paper examine
bodyText ||| buddylists and social networks generally, while, in practice,
bodyText ||| different semantics may yield different social networks. For
bodyText ||| example, the network consisting of users’ friends may be
bodyText ||| different from the network of people with whom users
bodyText ||| communicate most frequently, which may be different from
bodyText ||| the network of individuals with whom users share similar
bodyText ||| interests.
bodyText ||| The rest of the paper is organized as follows. The next
bodyText ||| section surveys related work, followed by a more detailed
bodyText ||| description of SONAR and typical usage scenarios. We
bodyText ||| then describe our hypotheses, research method, and results.
bodyText ||| The final section discusses conclusions and future work.
sectionHeader ||| RELATED WORK
bodyText ||| The formal discipline that studies interpersonal connections
bodyText ||| is called social network analysis (SNA) [29]. A social
bodyText ||| network (SN) is a graph that represents social entities and
bodyText ||| relationships between them. SNs have often been studied
bodyText ||| through the use of social science tools such as surveys and
bodyText ||| interviews, which require a great deal of human labor. The
bodyText ||| evolution of the Web, which is often referred to as Web 2.0
bodyText ||| [24], has introduced new possibilities for SN research.
subsectionHeader ||| Gathering SN Data from Computer Applications
bodyText ||| There are several popular SN services on the Web, which
bodyText ||| help to connect friends and business acquaintances1. These
bodyText ||| services define an explicit SN. Users directly specify who
bodyText ||| their friends are and often manually state the nature of the
bodyText ||| connection. The manual nature of these networks is perhaps
bodyText ||| their main disadvantage. Only part of the user’s actual SN
bodyText ||| will be registered in any such application, and since
bodyText ||| explicitly entering social data is tedious, even users who are
bodyText ||| registered are likely to have incomplete information about
bodyText ||| their network. These applications are useful for SONAR,
bodyText ||| providing very accurate, even if partial, social connections.
bodyText ||| The wealth of information in computer databases and
bodyText ||| applications is a good source for automatically obtaining
bodyText ||| various kinds of SN data without burdening users with the
bodyText ||| manual management of their network. For example,
bodyText ||| Wellman views computer networks as SNs and surveys
bodyText ||| how computer networks reflect and affect traditional SNs
footnote ||| 1 {myspace, facebook, linkedin, orkut, friendster}.com
page ||| 1018
note ||| CHI 2008 Proceedings · Online Social Networks	April 5-10, 2008 · Florence, Italy
bodyText ||| [30]. In addition, data mining can discover subtle details of
bodyText ||| a relationship that a person may not be able to provide
bodyText ||| accurately. For example, the rate of email communication
bodyText ||| can be used to estimate the strength of social ties [19].
bodyText ||| Email is commonly used to extract SNs. Extraction of the
bodyText ||| sociocentric SN from email logs has been demonstrated in
bodyText ||| [28] in order to automatically identify communities. Other
bodyText ||| tools, such as ContactMap [19] and Personal Map [8],
bodyText ||| analyze emails to extract the user’s egocentric SN. Email is
bodyText ||| one of the important sources for SONAR, but it is definitely
bodyText ||| not the only one. SONAR’s philosophy states that there is
bodyText ||| much important social information outside the inbox.
bodyText ||| Another common source for SN information is the Web.
bodyText ||| Adamic et al. [1] describe techniques for mining links and
bodyText ||| text of homepages to predict social relationships. The
bodyText ||| strength of a connection between two people can be
bodyText ||| estimated by querying a search engine with their names and
bodyText ||| checking for web pages where they co-occur [14,17]. Since
bodyText ||| various data sources such as papers, organizational charts,
bodyText ||| and net-news archives are available on the internet or
bodyText ||| intranet, they too could be mined by web searching [14].
bodyText ||| SN extraction has been conducted on many other sources,
bodyText ||| including Usenet data [27] and Instant Messaging logs [25].
subsectionHeader ||| Public vs. Personal Data Sources
bodyText ||| Sociocentric network approaches may encounter difficulties
bodyText ||| using personal data sources due to privacy concerns. For
bodyText ||| example, mining email, even when results are displayed in
bodyText ||| aggregated forms, might expose private information [14].
bodyText ||| One solution is to limit data mining to public sources. For
bodyText ||| example, Aleman-Meza et al. [2] chose to aggregate only
bodyText ||| publicly available SN data due to privacy concerns.
bodyText ||| However, ignoring private information may exclude
bodyText ||| important data. An alternative solution is to have users opt-
bodyText ||| in to explicitly give permission to make certain private
bodyText ||| information public. For example, Smarr [26] suggests
bodyText ||| requiring users to opt-in to publish their information to a
bodyText ||| public Friend of a Friend (FOAF) file [10]. However, opt-in
bodyText ||| requires action and motivation on the part of users – so
bodyText ||| those publishing their FOAF files will cover only a small
bodyText ||| percentage of organization members.
bodyText ||| SONAR can aggregate both private and public sources,
bodyText ||| without exposing private data to other people, or requiring
bodyText ||| users to opt-in.
subsectionHeader ||| Aggregating SN Data from Different Sources
bodyText ||| No single archive or tool captures all our social relations
bodyText ||| with others. Aggregating SN data from several sources may
bodyText ||| improve the completeness of constructed SNs. For example,
bodyText ||| the ContactMap developers plan to extend their email
bodyText ||| mining tool to use sources such as voice mail and phone
bodyText ||| logs due to user complaints on the absence of phone-based
bodyText ||| contacts [19].
bodyText ||| Several tools combine different sources to generate better
bodyText ||| SNs. In [5], an email database is used to extract people
bodyText ||| names and email addresses – these are then searched on the
bodyText ||| Web, to extract keywords and to find additional related
bodyText ||| people for which the search is recursively applied. Web
bodyText ||| mining, face-to-face communication, and manually entering
bodyText ||| one’s SN are combined in [12] to construct the SN in a
bodyText ||| Japanese conference.
bodyText ||| A basic problem of aggregation is deciding on the
bodyText ||| algorithm to be used for combining data from various
bodyText ||| sources. A simple approach is to compute the aggregation
bodyText ||| as a linear combination of the individual sources. Cai et al.
bodyText ||| [4] propose a method for learning the optimal linear
bodyText ||| combination given input from the user that describes the
bodyText ||| user’s expectation. However, this method requires the user
bodyText ||| to specify the query in ways which may prove to be
bodyText ||| complex. Matsuo et al. [16] extract and integrate SNs from
bodyText ||| several different sources. They provide a rough sketch for
bodyText ||| integrating the networks into a single one by using a linear
bodyText ||| combination of the different networks. Our research tests
bodyText ||| whether there is a weighting scheme which is appropriate to
bodyText ||| most users, for a specific scenario.
subsectionHeader ||| Evaluation of Social Network Quality
bodyText ||| A common approach for validating an automatically
bodyText ||| constructed SN is to ask the people in the network about its
bodyText ||| correctness, usually by questionnaires that require rating
bodyText ||| various aspects of the SNs and/or providing open-ended
bodyText ||| feedback [8,19,28].
bodyText ||| Another possible approach used in SNA is to compare the
bodyText ||| automatically constructed network to external data. For
bodyText ||| example, Aleman-Meza et al. [2] detect conflict of interests
bodyText ||| between paper authors and referees by integrating data from
bodyText ||| several SNs. Their evaluation included comparison to data
bodyText ||| from an external source: a different existing system for
bodyText ||| detecting conflict of interest. The problem with this method
bodyText ||| of evaluation is that it is possible only if there exists a
bodyText ||| relevant external source, which can be used for comparison.
bodyText ||| This paper includes three types of evaluation. In the
bodyText ||| absence of an external source to compare to when
bodyText ||| evaluating an aggregated network, our first evaluation
bodyText ||| compares the networks obtained from individual sources to
bodyText ||| the other sources, to measure their uniqueness. The second
bodyText ||| evaluation is a user evaluation, where we evaluate and
bodyText ||| compare numerous linear combinations of different sources.
bodyText ||| The third evaluation employs interviews in order to receive
bodyText ||| user feedback on individual sources and their aggregation.
sectionHeader ||| SONAR IN DETAIL
bodyText ||| The purpose of the SONAR API is to provide open
bodyText ||| interfaces to SN data, “locked up” in a multitude of
bodyText ||| systems. SONAR specifies a way to share weighted SNs as
bodyText ||| relation lists. Clients may retrieve information about how
bodyText ||| people are connected based on different parameters. Like
bodyText ||| RSS, our goal is to make a read-only interface, simple to
bodyText ||| implement by the provider and consume by the client.
page ||| 1019
note ||| CHI 2008 Proceedings · Online Social Networks	April 5-10, 2008 · Florence, Italy
bodyText ||| The first premise behind the SONAR API is that it is
bodyText ||| necessary to present the strength of ties between people. In
bodyText ||| contrast to APIs for specific SN applications like Facebook
bodyText ||| [6], SONAR does not model any specific semantics of the
bodyText ||| underlying system like “friending” or “communities”.
bodyText ||| Instead, it asks providers to boil down these semantics into
bodyText ||| floating point numbers between 0 and 1. SONAR
bodyText ||| aggregators combine results from multiple systems using a
bodyText ||| simple weighted average. This approach enables diverse
bodyText ||| applications from instant messaging clients through
bodyText ||| publication databases to SN sites to provide data supporting
bodyText ||| an aggregated view of relationships among people. SONAR
bodyText ||| clients are oblivious to the types of relations – when
bodyText ||| querying for strength of a relationship, all that the client
bodyText ||| sees is people and the weight of their associations.
bodyText ||| Users of aggregated SN data frequently want to understand
bodyText ||| how people are connected, or why a connection is stronger
bodyText ||| than another. To support this need, SONAR allows queries
bodyText ||| for evidence. Evidence is essentially a time-ordered log of
bodyText ||| entries, originating from each of the providers. It may
bodyText ||| include comments posted by one user in the other user’s
bodyText ||| blog, email messages or chat transcripts between them, or
bodyText ||| web sites that they both bookmarked. According to our
bodyText ||| privacy model, users do not have access to any private
bodyText ||| material of other people through this interface—it just
bodyText ||| organizes information they already had access to before.
subsectionHeader ||| SONAR API Specification
bodyText ||| We have implemented SONAR as a REST API. The API
bodyText ||| has four methods. The first three are fetching weighted
bodyText ||| people relationships, while the fourth provides evidence for
bodyText ||| connections. The methods are summarized in Table 1.
subsectionHeader ||| SONAR Aggregator
bodyText ||| SONAR is designed to enable an aggregator component
bodyText ||| that merges results from multiple providers. Like an HTTP
bodyText ||| proxy, the aggregator protocol is in most ways identical to
bodyText ||| the protocol for interacting with a SONAR provider. In fact,
bodyText ||| clients communicate with aggregators the exact same way
bodyText ||| they do with primary providers – through the SONAR API.
bodyText ||| The aggregator is configured to connect to one or more
bodyText ||| providers. When a request is received, the aggregator
bodyText ||| forwards it to each provider. It then processes the results by
bodyText ||| computing a weighted average and returns the result to the
bodyText ||| user. The original results from the different sources remain
bodyText ||| transparent to the user.
table ||| Name	Parameters*	Output
table ||| Strength	source (user) , target (user)	Float (0.0 to 1.0)
table ||| Relations	user(s), limit, offset	<list of people>
table ||| Network	user(s), degrees, threshold	<graph of people>
table ||| Evidence	users(s), limit, offset	<list of entries>
tableCaption ||| Table 1. SONAR API methods*
footnote ||| * All methods also accept parameters since and until. Since limits results to
footnote ||| those after the given date, until limits to those before the given date.
subsectionHeader ||| SONAR Providers
bodyText ||| We have implemented SONAR providers of over ten
bodyText ||| sources in our organizational intranet. The following four
bodyText ||| systems, which serve as public sources, were used in our
bodyText ||| experiments: BlogCentral (IBM’s corporate blogging
bodyText ||| system [14]), Fringe, for people tagging and friending [7],
bodyText ||| Dogear, for social bookmarking [19], and the IBM
bodyText ||| organizational chart.
bodyText ||| For the blog system, social relations are derived from the
bodyText ||| comments made to one’s blog. This information is an
bodyText ||| indication of the people who leave a trace in a blog, which
bodyText ||| is likely to imply that the author is aware of them. Fringe
bodyText ||| supports extraction of social information of both friending
bodyText ||| and tagging. Friending is a reciprocal action: one person
bodyText ||| invites the other to be friends and they are defined friends
bodyText ||| only if the invitation is accepted. Tagging people is one
bodyText ||| sided, yet indicates some level of connection. The SONAR
bodyText ||| provider that extracts SNs from Dogear is based on
bodyText ||| bookmark similarity information. The connections returned
bodyText ||| by this provider are those of people who bookmark the
bodyText ||| same pages. From the organizational chart we extracted, for
bodyText ||| each user, the user’s manager as well as the user’s direct
bodyText ||| peers - all employees who have the same manager.
bodyText ||| We have implemented several client-side SONAR
bodyText ||| providers that have access to the user’s private data. The
bodyText ||| experiments in this paper use two of these – email and chat
bodyText ||| transcripts. The outcome of these providers is only visible
bodyText ||| to the owner, visualizing an egocentric map of connections,
bodyText ||| but not revealing any private information to others.
bodyText ||| For the email information, our client requests the user’s
bodyText ||| password and then crawls the mailbox and collects details
bodyText ||| of people the user corresponds with. The chat information is
bodyText ||| easily accessible to our SONAR client, as the client is
bodyText ||| implemented as a plugin of Lotus Sametime, IBM’s chat
bodyText ||| system. We extract social information from the history of
bodyText ||| chat transcripts, as these indicate the people a person
bodyText ||| actually chats with.
subsectionHeader ||| SONAR Usage Scenarios
bodyText ||| To demonstrate the potential usage of the SONAR API, we
bodyText ||| created SonarBuddies – a plugin for Lotus Sametime. The
bodyText ||| plugin presents an alternative buddylist, which consists of
bodyText ||| the people most strongly related to the user, ordered by
bodyText ||| their strength of connection (see Figure 1(a)).
bodyText ||| Additional features include showing related people to any
bodyText ||| buddy on the list, the connection points (evidence) with a
bodyText ||| buddy (Figure 1(b)), and people who are connected to both
bodyText ||| the user and a buddy (Figure 1(c)).
bodyText ||| The SonarBuddies extension has a preference page in which
bodyText ||| the user may choose the relative weight of each data source,
bodyText ||| the number of buddies to display, and the number of days in
bodyText ||| history to consider. When adjusting the preferences, the
bodyText ||| user may see a preview of the buddylist. This enables fine-
bodyText ||| tuning the selection of weights (see Figure 2).
page ||| 1020
note ||| CHI 2008 Proceedings · Online Social Networks	April 5-10, 2008 · Florence, Italy
figureCaption ||| Figure 1. SONARBuddies UI
bodyText ||| SonarBuddies is just one example of a potential SONAR
bodyText ||| client. Below, are a few examples of more advanced
bodyText ||| scenarios that SONAR may support:
listItem ||| •	Expertise location (e.g., [14,18,31]) – SONAR, integrated
listItem ||| with search, may be used for scenarios of expertise location,
listItem ||| such as the basic “who knows about <topic>?”, but also
listItem ||| “who do I know that knows about <topic>?”, and the related
listItem ||| “who do I mostly communicate with about <topic>?”
listItem ||| •	Automatic completion of names (e.g., [21]) and groups–
listItem ||| completing a single string to a name may sort alternatives by
listItem ||| strength of social ties and relevance to the context. Moreover,
listItem ||| the completion of a whole group can be supported - e.g., if
listItem ||| one participates in a project of 10 people, typing the names of
listItem ||| 3 of them may automatically be completed to the entire
listItem ||| group. This may also be useful for resolving “who's missing
listItem ||| from the mail I’m about to send?”
listItem ||| •	Finding social paths to someone who is not directly related
listItem ||| to the user (e.g., [15])
listItem ||| •	Enhancing SN services by recommending people to connect
listItem ||| to based on other evidence and by enriching information
listItem ||| about existing friends: connection strength, evidence, and
listItem ||| temporal characteristics of relationships
sectionHeader ||| SONAR EXPERIMENTS
bodyText ||| SonarBuddies has been made available for download at the
bodyText ||| IBM intranet and over 1800 users downloaded and used it.
bodyText ||| SonarBuddies is mainly an egocentric application and it
bodyText ||| could be assumed that its success is due to heavy usage of
bodyText ||| private data sources by the users. However, from the usage
bodyText ||| data it is evident that public sources are explored. We
bodyText ||| envision the SONAR API as being heavily used by
bodyText ||| sociocentric applications and thus the interest in public data
bodyText ||| sources was encouraging.
bodyText ||| This section states our hypotheses, describes our
bodyText ||| experiments, and discusses the results.
subsectionHeader ||| Hypotheses
subsubsectionHeader ||| Public Data Sources
bodyText ||| The first group of hypotheses focuses on public data
bodyText ||| sources and their influence on the users’ SN. Public data
bodyText ||| sources are different in nature, ranging from social
bodyText ||| bookmarking systems to blogs and therefore we assume:
listItem ||| (1) Public data sources provide diverse SN information.
bodyText ||| There is no single public data source that holds all SN
bodyText ||| information, and each public source makes a
bodyText ||| significant contribution to the overall SN information.
bodyText ||| Moreover, as part of the user activities are performed
bodyText ||| “outside the mailbox”, the public sources provide valuable
bodyText ||| SN information which is not reflected in private sources.
bodyText ||| We thus raise the following 2 hypotheses:
listItem ||| (2) Public data sources provide SN information that is
listItem ||| valuable to the user.
listItem ||| (3) Public data sources enrich egocentric SN information.
listItem ||| By combining private sources with public sources, one
listItem ||| can potentially get a more complete picture of the SN.
subsubsectionHeader ||| Data Source Aggregation
bodyText ||| An additional hypothesis focuses on aggregation of SN
bodyText ||| information. A key concept behind SONAR is the ability to
bodyText ||| consolidate social information from multiple data sources,
bodyText ||| assuming that there is real value in such aggregation. The
bodyText ||| following hypothesis is explored:
listItem ||| (4) Aggregated SN information is of greater value to users
listItem ||| than information that originates from any single source.
bodyText ||| A SONAR client based on this hypothesis would need to
bodyText ||| use some weight combination in order to aggregate the
bodyText ||| different sources. While the user may have control over the
bodyText ||| weights, a SONAR client should have a default weight
bodyText ||| combination that would be reasonably good for all users for
bodyText ||| the most common scenario (such as finding the people the
bodyText ||| user communicates with the most). During our experiments,
bodyText ||| we wish to study the following hypothesis:
listItem ||| (5) For a basic scenario, there exists a weighting scheme
listItem ||| by which an aggregation of data sources most
listItem ||| reasonably represents most users’ SN.
bodyText ||| If this hypothesis is correct, our experiments may reveal the
bodyText ||| weighting scheme that we should use as default.
bodyText ||| Finally, an even more valuable aggregation of SNs can be
bodyText ||| achieved if users would share some of their private SN with
bodyText ||| others. While people are hesitant to share their private
bodyText ||| information, they may agree to share the buddylists created
bodyText ||| based on it, and thus allow a sociocentric view that is
bodyText ||| enhanced by private information. We hypothesize:
listItem ||| (6) People would be willing to share the buddylists created
listItem ||| based on their private sources
subsectionHeader ||| Research Method
bodyText ||| In order to examine our hypotheses, we conducted three
bodyText ||| experiments on SN information collected by SONAR.
subsubsectionHeader ||| Experiment 1: Information from Public Sources
bodyText ||| For the first experiment we gathered information from the
bodyText ||| four public sources. Our goal was to compare the lists of
bodyText ||| connected people from the different sources (hypothesis
bodyText ||| (1)) and show that no source covers the others and may thus
bodyText ||| serve as a single source of information (hypothesis (4)). The
bodyText ||| collaboration tools in IBM, like many Web 2.0 services on
page ||| 1021
note ||| CHI 2008 Proceedings · Online Social Networks	April 5-10, 2008 · Florence, Italy
bodyText ||| the internet, are still in their diffusion phase and are not yet
bodyText ||| used by all. However, they are gaining momentum and have
bodyText ||| become quite prevalent. As we wanted to compare all
bodyText ||| sources, we decided to focus on users who use all of the
bodyText ||| chosen data sources. While such users are not a statistical
bodyText ||| sample, we refer to them as the early adopters of the
bodyText ||| technologies, and use their figures as a reflection of the
bodyText ||| potential of SN information that may be extracted from
bodyText ||| public sources as Web 2.0 technologies become ubiquitous
bodyText ||| [24].
bodyText ||| We started by locating the top 1000 heavy users of each of
bodyText ||| the tools (BlogCentral, Fringe, and Dogear). For blogs, we
bodyText ||| defined heavy users as those who received most comments
bodyText ||| in their blog. For Fringe we took the 1000 users with the
bodyText ||| largest lists of connections. For Dogear, the 1000 people
bodyText ||| with most bookmarks. Once we had these three lists, we
bodyText ||| took their union and received a list of 1761 users. We then
bodyText ||| obtained results from the different SONAR providers for all
bodyText ||| 1761 users, and examined those users who had a nonempty
bodyText ||| result in all four sources (the fourth source being the
bodyText ||| organizational chart). We ended up with a list of 273 such
bodyText ||| users. For every one of the four public sources and every
bodyText ||| one of the 273 users, we calculated the number of unique
bodyText ||| contributions of this source over the union of all other three
bodyText ||| sources.
subsubsectionHeader ||| Experiment 2: Online Questionnaire for Ranking Buddylists
bodyText ||| For the second experiment we implemented a dedicated
bodyText ||| plugin for Lotus Sametime. The plugin was easy to install
bodyText ||| and presented a questionnaire containing three sets of up to
bodyText ||| eight buddylists that were aggregated from the different
bodyText ||| sources and tailored specifically for the user. The user could
bodyText ||| not tell what the sources of the different lists had been.
bodyText ||| Before starting the experiment, we asked the user to
bodyText ||| imagine setting up an “ideal” buddylist for communication
bodyText ||| inside IBM. By this request, we framed the experiment to a
bodyText ||| basic scenario. The user was then asked to rank the
bodyText ||| buddylists by how close they were to representing the ideal
bodyText ||| buddylist. The scale for ranking was 1-4 (where “1” is
bodyText ||| good, and “4” is bad). In addition, we asked the user to
bodyText ||| mark a single buddylist as the “best” buddylist – relative to
bodyText ||| the other lists in that set.
bodyText ||| The first set of up to eight buddylists was composed solely
bodyText ||| from public sources. Our goal with this set was to examine
bodyText ||| the value of extracting SN information from public sources
bodyText ||| (hypothesis (2)), and to compare the quality of lists created
bodyText ||| by aggregation of different sources vs. the quality of lists
bodyText ||| created from a single source. The weight combinations of
bodyText ||| sources used in this set are displayed in the leftmost
bodyText ||| columns of Table 2 (1-8). We use the term “up to eight
bodyText ||| lists”, since if two different combinations created two
bodyText ||| identical lists (in both content and order), we only presented
bodyText ||| them once. If the user voted “best” for a list that was
bodyText ||| created from more than one combination, we added a vote
bodyText ||| to all these combinations.
bodyText ||| The second set of buddylists was also focused on public
bodyText ||| sources. The goal with this set was to learn whether a
bodyText ||| specific weight combination is preferred by most users and
bodyText ||| may serve as a default (hypothesis (5)). The weight
bodyText ||| combinations of sources used in this set are displayed in the
bodyText ||| rightmost columns of Table 2 (9-16).
bodyText ||| The last set of buddylists introduced information gathered
bodyText ||| from the user’s private sources. The goal of this set was to
bodyText ||| examine the value of information public sources add over
bodyText ||| private sources (hypothesis (3)), as well as to study the
bodyText ||| effect aggregation has on the lists (hypothesis (4)) –
bodyText ||| aggregation of private sources, and aggregation of a mix of
bodyText ||| private and public sources. The weight combinations of
bodyText ||| sources used in this set are displayed in Table 5 (17-24).
bodyText ||| Our plugin reported the user ranking of the buddylists to a
bodyText ||| dedicated server that produced a report with all results. The
bodyText ||| results visible to us did not contain any private information
bodyText ||| nor could we see the buddylists, we only examined the
bodyText ||| ranks (1-4) and the vote for best list in each set.
subsubsectionHeader ||| Experiment 3: Sliders UI for Personal Weight Combination
bodyText ||| A set of interviews we conducted, helped us examine
bodyText ||| hypotheses (2), (4), and (6), as well as hypothesis (5). It
bodyText ||| also gave us some insight about how people perceive their
bodyText ||| SN and what they feel about our UI.
bodyText ||| The preferences-page of the SONAR plugin allows
bodyText ||| modifying the weight combination of different sources with
bodyText ||| sliders and simultaneously seeing a preview of the buddylist
bodyText ||| created from this combination. The user interface of this
bodyText ||| feature is shown in Figure 2.
table ||| 	1	2	3	4	5	6	7	8	9	10	11	12	13	14	15	16
table ||| bookmarking	1.0				0.5		0.1	0.25	0.1	0.3	0.3	0.3	0.1	0.1	0.4	0.5
table ||| people tagging		1.0			0.5		0.2	0.25	0.3	0.1	0.3	0.3	0.2	0.1	0.3	0.3
table ||| blogs			1.0			0.5	0.3	0.25	0.3	0.3	0.1	0.3	0.3	0.3	0.2	0.1
table ||| org-chart				1.0		0.5	0.4	0.25	0.3	0.3	0.3	0.1	0.4	0.5	0.1	0.1
table ||| average score
table ||| # of “best” votes	0	23	1	63	6	57	58	46	70	48	46	47	63	61	46	43
table ||| # of score “1”	0	12	0	18	5	14	17	9	20	4	6	9	20	20	7	6
tableCaption ||| Table 2. Weight combinations and results of the public sources in the first two sets of buddylists
page ||| 1022
note ||| CHI 2008 Proceedings · Online Social Networks	April 5-10, 2008 · Florence, Italy
figureCaption ||| Figure 2. Weight combination user interface
bodyText ||| We conducted personal interviews with 12 of the users who
bodyText ||| took part in experiment 2, in order to learn about their
bodyText ||| experience with the sliders and follow their line of thought
bodyText ||| while they are examining the different buddylists. Each
bodyText ||| interviewee was asked to first reset all sliders and start with
bodyText ||| an empty list. In order to examine hypotheses (2) and (4),
bodyText ||| each slider was moved separately, to compare the lists
bodyText ||| based on single sources to an ideal list (as in the framed
bodyText ||| scenario of experiment 2). Once all sources were examined,
bodyText ||| the interviewees were asked to fiddle with the sliders in
bodyText ||| order to compose a list that is closest to their ideal list. We
bodyText ||| retrieved the selected weight combinations from our logs
bodyText ||| and examined them in order to validate hypothesis (5).
bodyText ||| Finally, we posed the question about sharing the buddylists
bodyText ||| based on private sources (hypothesis (6)). The question is a
bodyText ||| multiple choice question: to share automatically vs. share
bodyText ||| after manual editing; to share with anyone, or only with
bodyText ||| friends, or only with a specific individual.
subsectionHeader ||| Experimental Results
subsubsectionHeader ||| Results of Experiment 1
bodyText ||| In this experiment we examined the 273 users who had a
bodyText ||| nonempty result in all four public sources. For each of the
bodyText ||| four public sources and each of the 273 users, we calculated
bodyText ||| the number of connections extracted from the source, and
bodyText ||| the number of unique contributions of this source over the
bodyText ||| union of all other three sources. The averages of these
bodyText ||| figures appear in Table 3.
bodyText ||| Examining the average numbers of unique contributions is
bodyText ||| interesting. One would assume that the commonalities of
bodyText ||| the lists from the different sources would be large; that a
bodyText ||| person would mostly friend with peers from the
bodyText ||| organizational group; that a person’s friends would be the
bodyText ||| ones commenting in the blogging system; and even that
bodyText ||| working in the same group would imply similar interests
bodyText ||| and thus bookmarking the same web pages. However, our
bodyText ||| org chart		friending		blogs		bookmarks
table ||| #	>	#	>	#	>	#	>
table ||| 15.73	13.91	24.64	20.27	8.57	5.74	423.1	417.7
tableCaption ||| Table 3. Results of experiment 1: average number of
tableCaption ||| connections (#) and unique contributions (>)
table ||| contribution	org chart	friending	blogs	bookmarks
table ||| full list	107	76	83	55
table ||| 	(39.2%)	(27.8%)	(30.4%)	(20.1%)
table ||| nothing	41 0	22 0 (8.1%)	370	00
table ||| 	(4.0%)		(13.6/0)	(0.0%)
tableCaption ||| Table 4. Unique contribution over all other sources
bodyText ||| results reveal a different picture. It seems that for each and
bodyText ||| every source, the average number of unique contributions
bodyText ||| over the other three sources is quite close to the average
bodyText ||| number of connections, implying that the information
bodyText ||| extracted from the different sources is indeed diverse.
bodyText ||| Table 4 shows two statistics of the unique contributions of
bodyText ||| the different sources over all other sources. The first row in
bodyText ||| the table shows the number of people for whom the source
bodyText ||| contributed its full list – meaning that the lists from other
bodyText ||| sources had no intersection with this source. For instance,
bodyText ||| for 107 of the people (39.19%) – the lists of blog
bodyText ||| commenters, tagging friends, or similar bookmarkers did
bodyText ||| not contain anyone from their organizational group. As can
bodyText ||| be seen on Table 4, these numbers are rather large – 76 for
bodyText ||| Fringe, 83 for BlogCentral, and 55 for Dogear – indicating
bodyText ||| the diversity of the sources. There was not even a single
bodyText ||| person, for whom a single source covered all other sources,
bodyText ||| proving that aggregation creates a broader picture than any
bodyText ||| single source. The second row in the table shows the
bodyText ||| number of people for whom a source contributed nothing
bodyText ||| over the other lists. These figures indicate cases in which a
bodyText ||| single source may be dismissed, as the other three sources
bodyText ||| cover the information it provides. As may be seen on the
bodyText ||| table, these figures are rather small: up to 37, for
bodyText ||| BlogCentral, and as low as 0 for Dogear.
bodyText ||| For 33 out of the 273 people examined (12.08%), there was
bodyText ||| no intersection between any of the sources – each of their
bodyText ||| public sources provided a completely different list.
bodyText ||| The results of this experiment validate hypothesis (1) and
bodyText ||| support hypothesis (4), showing the diversity of information
bodyText ||| from public sources, that no single source holds all SN
bodyText ||| information, and thus that aggregation is likely to be of
bodyText ||| greater value than information from any single source.
subsubsectionHeader ||| Results of Experiments 2 and 3
bodyText ||| Our questionnaire plugin collected information from 116
bodyText ||| users who responded to all three stages of the experiment.
bodyText ||| Out of the 116 users, 65 are from the US and Canada, 49
bodyText ||| are from Europe and the Middle East, and two are from
bodyText ||| Asia Pacific. 73 of the users who responded are using
bodyText ||| Fringe, 29 are bloggers, and 62 use Dogear. We believe
bodyText ||| these users represent a wide range of IBM employees and
bodyText ||| are thus a good test bed for our hypotheses. In addition,
bodyText ||| results collected from the in depth interviews with 12 users
bodyText ||| strengthen some of our hypotheses.
bodyText ||| The bottom part of Table 2 shows the results of the first two
bodyText ||| sets of buddylists. On the first step, shown on the bottom
bodyText ||| left of the table, the list that got the most “best” votes (63)
bodyText ||| is the one based on a single source: the organizational chart.
page ||| 1023
note ||| CHI 2008 Proceedings · Online Social Networks	April 5-10, 2008 · Florence, Italy
bodyText ||| The average score of this list is 2.36 (on a scale of 1=good,
bodyText ||| 4=bad). The list that got the best average score is the one
bodyText ||| based on aggregation of all four sources by weight
bodyText ||| combination 7 on Table 2. The average score of this list is
bodyText ||| 2.34 and its number of “best” votes is 58. Over 40% of the
bodyText ||| users (48) got in this aggregated list an identical list to the
bodyText ||| one based on the organizational chart. As the score of the
bodyText ||| aggregated list is better, we may conclude that when the
bodyText ||| lists were not identical, the aggregated list received better
bodyText ||| scores. Finally, note that in Table 2, the total number of
bodyText ||| “best” votes given to aggregations (i.e., combinations 5
bodyText ||| through 8) was significantly higher than the combined
bodyText ||| number of “best” votes for all single sources (1 through 4).
bodyText ||| We consider the above findings as supporting hypothesis
bodyText ||| (4) – the value of aggregation.
bodyText ||| The results of the second step are shown on the bottom
bodyText ||| right of Table 2. All lists of this step received scores that
bodyText ||| are higher than 2 but lower than 3, and all lists received
bodyText ||| quite a few “best” votes (over 40). It appears that no
bodyText ||| optimal weighting scheme exists that may serve a good
bodyText ||| default for most users. We were therefore unable to prove
bodyText ||| our hypothesis (5). While conducting the interviews during
bodyText ||| experiment 3, we had another chance to see how different
bodyText ||| people prefer different sources. For example, when
bodyText ||| examining the list from Fringe, one of the users said:
bodyText ||| “Completely off. Only 7 people, out of them only 3 are
bodyText ||| familiar” while another said: “Accurate, very accurate
bodyText ||| actually. [ ...] that would be my ideal buddylist”.
bodyText ||| The results of the third step are shown on the bottom of
bodyText ||| Table 5. In this step we compared lists from private sources
bodyText ||| with lists from public sources and with lists based on a mix
bodyText ||| of private and public sources. For this step our plugin
bodyText ||| requested access to users’ private data. Only 55 users
bodyText ||| granted us access to their private data. We therefore based
bodyText ||| our analysis on the responses of these 55 users only.
bodyText ||| As can be expected, the lists based on private sources
bodyText ||| received better average scores (1.62-1.76) than those based
bodyText ||| solely on public sources. The list with most “best” votes
bodyText ||| (17) on is the list based on the (private) chat system.
table ||| 	17	18	19	20	21	22	23	24
table ||| Bookmarking	0.25		0.16	0.1	0.2			0.1
table ||| people tagging	0.25		0.16	0.1	0.2			0.1
table ||| blogs	0.25		0.16	0.1	0.2			0.1
table ||| org-chart	0.25		0.16	0.1	0.2			0.1
table ||| email		0.5	0.16	0.3	0.1	1.0		0.4
table ||| chat		0.5	0.16	0.3	0.1		1.0	0.2
table ||| average score
table ||| # of “best” votes	0	12	2	9	0	10	17	9
table ||| # of score “1”	3	30	6	23	4	25	26	23
tableCaption ||| Table 5. Weight combinations and results of public and
tableCaption ||| private sources in the third set of buddylists
bodyText ||| However, 17 votes are only 30.9%, indicating that no list
bodyText ||| significantly outvoted the others. The list with best average
bodyText ||| score (1.62) is the list based on combination 18 in Table 5
bodyText ||| (email and chat), supporting the value of aggregating
bodyText ||| information (private in this case) – hypothesis (4). Yet
bodyText ||| another supporting point for hypothesis (4) was received
bodyText ||| during the interviews, when no single user had chosen a list
bodyText ||| based solely on one source. This observation is less strong,
bodyText ||| since the experiment setting encouraged people to play with
bodyText ||| aggregations, yet they clearly had a choice to disable all
bodyText ||| other sources and stay with one, but did not.
bodyText ||| Table 2 and Table 5 also show the number of times each of
bodyText ||| the buddylists in this experiment received score 1. List 18
bodyText ||| (email and chat) received score 1 for the largest number of
bodyText ||| times – over 54% of the people granted it a perfect score.
bodyText ||| Other lists which obtained many high scores are list 20 (mix
bodyText ||| of public and private), list 22 (email), list 23 (chat), and list
bodyText ||| 24 (anther mix of public and private). It is obvious from the
bodyText ||| table that lists based on private sources receive score 1
bodyText ||| more often, as expected. The value of public sources is
bodyText ||| evident from the bottom line of Table 2: the lists based
bodyText ||| solely on public sources received a perfect score a
bodyText ||| considerable amount of times, supporting hypothesis (2). In
bodyText ||| experiment 3, seven of 11 used some combination of public
bodyText ||| and private data sources (the twelfth user had no access to
bodyText ||| private data) and two of them even preferred the public
bodyText ||| sources slightly over private ones (see Table 6).
bodyText ||| Two of the combinations that mixed all six sources (number
bodyText ||| 20 and number 24 in Table 5) received 9 “best” votes each.
bodyText ||| Examining our results reveals that each such vote was given
bodyText ||| by a different user, implying that for 18 people, they created
bodyText ||| a buddylist that is preferred over the buddylists based solely
bodyText ||| on private sources. Both these lists received an average
bodyText ||| score of 1.75, which is identical to the average score of the
bodyText ||| list based on chat, and they both received a perfect score 23
bodyText ||| times. This implies that for quite a few people the mix with
bodyText ||| public sources creates buddylists of high quality. Together
bodyText ||| with the fact that in experiment 3 most users chose to
bodyText ||| combine private with public data, we conclude that
bodyText ||| hypothesis (3) is true - information from public sources
bodyText ||| may provide a more complete picture of one’s SN.
bodyText ||| Finally, Experiment 3 revealed what people think about
bodyText ||| sharing lists coming from their private data sources (see
bodyText ||| Table 6). Most of the people (10) said that they will be
table ||| 	1	2	3	4	5	6	7	8	9	10	11	12
table ||| prv	85	00	100	48	63	100	100	100	69	48	54	54
table ||| pub	15	100	00	52	37	00	00	00	31	52	46	46
table ||| shr	2	3	2	2	2	3	2	2	3	3	1	0
tableCaption ||| Table 6. Experiment 3 results*
footnote ||| * First row shows percentage of private sources, second row percentage of
footnote ||| public sources, third row – sharing list preference (3 – automatically with
footnote ||| anyone, 2- after editing with anyone, 1 – after editing with friends, 0 – will
footnote ||| not share)
page ||| 1024
note ||| CHI 2008 Proceedings · Online Social Networks	April 5-10, 2008 · Florence, Italy
bodyText ||| willing to share their lists with anyone. Seven stated that
bodyText ||| they would want to edit first. “I am worried that SONAR
bodyText ||| results are not accurate enough and would like to [ ...]
bodyText ||| make sure the people who see the lists get good lists”, said
bodyText ||| one user. Another user said, at first, “[I am] worried about
bodyText ||| what my buddies would say about me sharing their names”,
bodyText ||| but, after thinking about it he decided that it was harmless
bodyText ||| enough and said he would share his lists. Four users showed
bodyText ||| great openness by declaring that they would share their list
bodyText ||| automatically, without any editing, with anyone. Only one
bodyText ||| user said that he will not share his lists with anyone. One of
bodyText ||| the users summarized these results nicely: “... I think it
bodyText ||| should always be left up to the individual as there are
bodyText ||| dangerous things about SN. [but]... within a company, you
bodyText ||| have to realize you are probably not going to be that
bodyText ||| private”. All in all, hypothesis (6) is supported to a high
bodyText ||| extent. Our results suggest that there is a good chance
bodyText ||| people will be willing to share their private-based
bodyText ||| buddylists after applying some editing to it.
subsubsectionHeader ||| Discussion
bodyText ||| Our experiments show that information from public sources
bodyText ||| is very diverse and no single source may provide all SN
bodyText ||| information. While some sources provide communication
bodyText ||| data, others provide similarity data. While reacting to lists
bodyText ||| generated from Dogear, users said: “Far from ideal list”,
bodyText ||| “Over 50% are strangers”. But another user, while
bodyText ||| discussing her usage of SNs described: “if my goal was to
bodyText ||| search for expertise, then I would lean it heavily towards
bodyText ||| social bookmarking and blogs”. It suggests that diverse
bodyText ||| sources can become valuable for diverse tasks. It also
bodyText ||| explains why our hope to locate an optimal default
bodyText ||| combination of weights for aggregation was not fulfilled -
bodyText ||| different users with different views and different needs may
bodyText ||| require different combinations of the sources.
bodyText ||| The information extracted from public sources is shown to
bodyText ||| be of value, and while private sources provide better
bodyText ||| information, public sources do contribute additional
bodyText ||| information and create a more complete picture of SNs. The
bodyText ||| value of aggregation is proven both by the diversity of
bodyText ||| public sources and by user votes for aggregated lists.
bodyText ||| We saw in our interviews that aggregation and collection of
bodyText ||| SN information becomes crucial in global organizations.
bodyText ||| While analyzing the organizational chart data source one of
bodyText ||| the users noted: “It just looks at people within my world,
bodyText ||| and I deal with a lot of people outside of my function, if you
bodyText ||| will”. Another user commented: “Names that were missing
bodyText ||| on email appear now. Top person on ideal list does not
bodyText ||| appear here”. It shows that no single data source is
bodyText ||| sufficient for creating one’s ideal buddylist and thus
bodyText ||| demonstrates the value of aggregation.
sectionHeader ||| CONCLUSIONS AND FUTURE WORK
bodyText ||| In this paper, we present the motivation and challenge for
bodyText ||| aggregating SN information from multiple data sources. We
bodyText ||| describe SONAR, an API for exposing relations embedded
bodyText ||| in numerous applications or services. SONAR allows
bodyText ||| building weighted networks with evidence for each
bodyText ||| connection, showing how strongly people are connected.
bodyText ||| SONAR was implemented for various sources, public and
bodyText ||| personal, within IBM, and demonstrated through a plugin
bodyText ||| for Lotus Sametime: SONARBuddies.
bodyText ||| Our experiments indicate that aggregation produces a more
bodyText ||| comprehensive SN. Information coming from public data
bodyText ||| sources is shown to be relevant and diverse. Public sources
bodyText ||| mainly represent new emerging social technologies on the
bodyText ||| Web. We believe that people’s involvement in these
bodyText ||| technologies will continue to grow, while new technologies
bodyText ||| appear. Hence, more quality social information will be
bodyText ||| available for frameworks like SONAR. For some users,
bodyText ||| public sources make a significant contribution over private
bodyText ||| ones, which may have been considered the predominant
bodyText ||| sources. It is extremely interesting to continue examining
bodyText ||| the potential of public sources to actually replace SN
bodyText ||| information currently extracted from private sources, and
bodyText ||| thus relieving privacy issues.
bodyText ||| This paper focuses on general SNs. In practice, there are
bodyText ||| different types of SNs, which reflect different semantics of
bodyText ||| connections, like friendship, interpersonal communication,
bodyText ||| or similarity. Such networks tend to be semantically
bodyText ||| different even for the same user. Shared bookmarks, for
bodyText ||| instance, reflect similarity between users rather than a direct
bodyText ||| connection. The scenario used in our experiments asked the
bodyText ||| users to rank buddylists, typically used for communication.
bodyText ||| It was natural that Dogear, which exposes similarity,
bodyText ||| received low scores by our users. One could think of
bodyText ||| different scenarios, such as finding potential people for a
bodyText ||| community on a specific topic, where this similarity
bodyText ||| network would be a perfect networking tool. It would be
bodyText ||| interesting to identify different scenarios and examine the
bodyText ||| contribution of different sources to them.
bodyText ||| Another interesting direction is deriving contextual
bodyText ||| networks – networks that are related to a specific context or
bodyText ||| term. For example, the list of people with whom one
bodyText ||| communicates most frequently about Java, is likely to be
bodyText ||| different from the list of people with whom one
bodyText ||| communicates mostly about SN analysis.
bodyText ||| Our plans for future work on the SONAR API include
bodyText ||| extending it to support different types of relations (e.g.,
bodyText ||| familiarity vs. similarity). We also plan to allow a
bodyText ||| specification of a search term to support contextual queries
bodyText ||| such as: “who is most related to <person> w.r.t. <topic>?”
bodyText ||| These extensions would allow us to further explore the
bodyText ||| variety of SNs, the differences and relations among them,
bodyText ||| the value they bring to users, and the patterns of their usage.
sectionHeader ||| ACKNOWLEDGEMENTS
bodyText ||| We would like to acknowledge all those who installed
bodyText ||| SONARBuddies and provided us with feedback about its
bodyText ||| usage. We are especially grateful to those who participated
bodyText ||| in our experiments and interviews. We thank James Snell
page ||| 1025
note ||| CHI 2008 Proceedings · Online Social Networks	April 5-10, 2008 · Florence, Italy
bodyText ||| for providing us data about the usage of BlogCentral, and
bodyText ||| Jonathan Feinberg for data about Dogear. Sigalit Ur and
bodyText ||| Inbal Ronen participated in numerous discussions and
bodyText ||| provided enlightening comments, we are indebted to them.
sectionHeader ||| REFERENCES
reference ||| 1. Adamic, L. A., and Adar, E. Friends and neighbors on
reference ||| the Web, Social Networks, 25, 3 (2003), 211-230.
reference ||| 2. Aleman-Meza, B., Nagarajan, M., Ramakrishnan, C.,
reference ||| Sheth, A., Arpinar, I., Ding, L., Kolari, P., Josi, A., and
reference ||| Finin, T. Semantic analytics on social networks:
reference ||| Experiences in addressing the problem of conflict of
reference ||| interest detection. Proc. WWW '06, ACM Press (2006),
reference ||| 407-416.
reference ||| 3. Bar-Yossef, Z., Guy, I., Lempel, R., Maarek, Y. S., and
reference ||| Soroka, V. Cluster ranking with an application to
reference ||| mining mailbox networks. Proc. ICDM '06, IEEE
reference ||| Computer Society (2006), 63-74.
reference ||| 4. Cai, D., Shao, Z., He, X., Yan, X., and Han, J. Mining
reference ||| hidden community in heterogeneous social networks. In
reference ||| Proc. of the 3rd International Workshop on Link
reference ||| Discovery (LinkKDD 2005),ACM Press (2005), 58 – 65.
reference ||| 5. Culotta, A., Bekkerman, R., and McCallum, A.
reference ||| Extracting social networks and contact information from
reference ||| email and the Web. First Conference on Email and Anti-
reference ||| Spam (CEAS 2004) (2004).
reference ||| 6. Facebook Developers – Documentation.
reference ||| http://developers.facebook.com/documentation.php .
reference ||| 7. Farrell, S., and Lau, T. Fringe Contacts: People-Tagging
reference ||| for the Enterprise. Workshop on Collaborative Web
reference ||| Tagging, WWW’06, (2006).
reference ||| 8. Farnham, S., Portnoy, W., Turski, A., Cheng, L., and
reference ||| Vronay, D. Personal Map: Automatically modeling the
reference ||| user’s online social network. Proc. INTERACT’03, IOS
reference ||| Press (2003), 567-574.
reference ||| 9. Fielding, R.T. Architectural styles and the design of
reference ||| network-based software architectures. PhD thesis,
reference ||| University of California, Irvine, CA, (2000).
reference ||| 10. Friend of a Friend (FOAF) project.
reference ||| http://www.foaf-project.org/ .
reference ||| 11. HammerSley, B. Content Syndication with RSS, (2003).
reference ||| 12. Hope, T., Nishimura, T., and Takeda, H. An integrated
reference ||| method for social network extraction. Proc. WWW ’06,
reference ||| ACM Press (2006), 845-846.
reference ||| 13. Introducing JSON. http://www.json.org/ .
reference ||| 14. Jackson, A., Yates, J., Orlikowski, W. “Corporate
reference ||| Blogging: Building community through persistent
reference ||| digital talk”. Proc. 40th Annual Hawaii International
reference ||| Conference on System Sciences HICSS'07, (2007), p. 80
reference ||| 15. Kautz, H., Selman, B., and Shah., M. ReferralWeb:
reference ||| Combining social networks and collaborative filtering.
reference ||| Communications of the ACM 40, 3 (1997), 63-65.
reference ||| 16. Matsuo, Y., Hamasaki, M. et al. Spinning multiple
reference ||| social networks for semantic Web. Proc. AAAI '06
reference ||| (2006).
reference ||| 17. Matsuo, Y., Mori, J., Hamasaki, M., Takeda, H.,
reference ||| Nishimura, T., Hasida, K., and Ishizuka, M.
reference ||| POLYPHONET: An advanced social network extraction
reference ||| system. Proc. WWW ‘06, ACM Press (2006), 397-406.
reference ||| 18. McDonald D.W. and Ackerman M.S. Expertise
reference ||| recommender: a flexible recommendation system and
reference ||| architecture. Proc. CSCW’00, (2000), 231–240.
reference ||| 19. Millen, D.R., Feinberg, J., and Kerr, B. Dogear: Social
reference ||| Bookmarking in the Enterprise. Proc. CHI 2006, (2006),
reference ||| 111-120.
reference ||| 20. Nardi, B.A., Whittaker, S., Issacs, E., Creech, M.,
reference ||| Johnson, J., and Hainsworth, J. Integrating
reference ||| communication and information through contact map.
reference ||| Communications of the ACM 45, 4 (2002) 89-95.
reference ||| 21. Neustaedter, C., Brush, A., Smith, M., and Fisher, D.
reference ||| The social network and relationship finder: Social
reference ||| sorting for email triage. Proc. CEAS 2005.
reference ||| 22. Newman, M. E. J. Scientific collaboration networks,
reference ||| part I. Network construction and fundamental results.
reference ||| Physical Review E, 64, 016131, (2001).
reference ||| 23. Nottingham, M., and Sayre, R. RFC 4287 – The Atom
reference ||| Syndication Format (Proposed Standard).
reference ||| http://tools.ietf.org/html/rfc4287
reference ||| 24. O'Reilly, T. What is Web 2.0.
reference ||| http://www.oreillynet.com/go/web2 .
reference ||| 25. Resig, J., Dawara, S., Homan, C. M., and Teredesai, A.
reference ||| Extracting social networks from instant messaging
reference ||| populations, Proc. of the 7th ACM SIGKDD Workshop
reference ||| on Link KDD, (2004).
reference ||| 26. Smarr, J. Technical and privacy challenges for
reference ||| integrating FOAF into existing applications. In the 1st
reference ||| Workshop on Friend of a Friend, Social Networking and
reference ||| the Semantic Web, (2004).
reference ||| 27. Smith, M. Invisible crowds in cyberspace: Measuring
reference ||| and mapping the social structure of Usenet. In Smith,
reference ||| M., and Kollock, P. Eds., Communities in Cyberspace.
reference ||| Routledge Press, (1999).
reference ||| 28. Tyler, J.R., Wilkinson, D.M., and Huberman, B.A.
reference ||| Email as spectroscopy: Automated discovery of
reference ||| community structure within organizations. In
reference ||| Communities and Technologies, Huysman, M., Wenger,
reference ||| E., and V. Wulf, Eds. (2003), 81-96.
reference ||| 29. Wasserman, S., and Faust, K. Social Network Analysis.
reference ||| (1994).
reference ||| 30. Wellman, B. Computer networks as social networks.
reference ||| Science 293 (2001) 2031-2034.
reference ||| 31. Zhang, J., Ackerman M.S. Searching for expertise in
reference ||| social networks: a simulation of potential strategies.
reference ||| Proc. GROUP 2005, ACM Press (2005), 71-80.
page ||| 1026

note ||| CHI 2008 Proceedings · Online Social Networks	April 5-10, 2008 · Florence, Italy
title ||| ‘Looking at’, ‘Looking up’ or ‘Keeping up with’ People?
title ||| Motives and Uses of Facebook
author ||| Adam N. Joinson
affiliation ||| School of Management
affiliation ||| University of Bath
address ||| Bath
address ||| United Kingdom
address ||| BA2 7AA
email ||| A.Joinson@Bath.ac.uk
sectionHeader ||| ABSTRACT
bodyText ||| This paper investigates the uses of social networking site
bodyText ||| Facebook, and the gratifications users derive from those
bodyText ||| uses. In the first study, 137 users generated words or
bodyText ||| phrases to describe how they used Facebook, and what they
bodyText ||| enjoyed about their use. These phrases were coded into 46
bodyText ||| items which were completed by 241 Facebook users in
bodyText ||| Study 2. Factor analysis identified seven unique uses and
bodyText ||| gratifications: social connection, shared identities, content,
bodyText ||| social investigation, social network surfing and status
bodyText ||| updating. User demographics, site visit patterns and the use
bodyText ||| of privacy settings were associated with different uses and
bodyText ||| gratifications.
sectionHeader ||| Author Keywords
keyword ||| Social networking sites, uses and gratifications, motivation
sectionHeader ||| ACM Classification Keywords
category ||| H1. Models and Principles: User/Machine Systems; H5.m.
category ||| Information interfaces and presentation: Miscellaneous.
sectionHeader ||| INTRODUCTION
bodyText ||| Social networking sites such as MySpace, LinkedIn and
bodyText ||| Facebook have become hugely popular in the last few
bodyText ||| years. In July 2007, social networking sites occupied five of
bodyText ||| the top fifteen visited websites according to Alexa.com. On
bodyText ||| July 10, 2007, Facebook.com reported signing up its 30
bodyText ||| millionth user, with a year on year increase in unique users
bodyText ||| of 89% [12]. In the UK, use of Facebook increased by
bodyText ||| 500% between November 2006 and May 2007 [19].
bodyText ||| MySpace is reported (although disputed [10]) to have over
bodyText ||| 100 million users [4].
copyright ||| Permission to make digital or hard copies of all or part of this work for
copyright ||| personal or classroom use is granted without fee provided that copies are
copyright ||| not made or distributed for profit or commercial advantage and that
copyright ||| copies bear this notice and the full citation on the first page. To copy
copyright ||| otherwise, or republish, to post on servers or to redistribute to lists,
copyright ||| requires prior specific permission and/or a fee.
note ||| CHI 2008, April 5–10, 2008, Florence, Italy.
copyright ||| Copyright 2008 ACM 978-1-60558-011-1/08/04...$5.00.
bodyText ||| Social networking sites typically provide users with a
bodyText ||| profile space, facilities for uploading content (e.g. photos,
bodyText ||| music), messaging in various forms and the ability to make
bodyText ||| connections to other people. These connections (or
bodyText ||| ‘friends’) are the core functionality of a social network site
bodyText ||| [5, 6] although most also provide opportunities for
bodyText ||| communication, the forming of groups, hosting of content
bodyText ||| and small applications.
bodyText ||| Given the growth of social networking sites, it is perhaps
bodyText ||| unsurprising that their use has garnered media attention,
bodyText ||| including the seemingly now obligatory scare stories
bodyText ||| involving predatory child sex offenders [20], identity theft
bodyText ||| [1], workplace usage levels [9] and even addiction [8].
bodyText ||| In many recent cases, this coverage has focused on
bodyText ||| Facebook.com, which was originally restricted to users with
bodyText ||| an ‘.edu’ e-mail address. In September 2006, Facebook
bodyText ||| opened registration to non-college based users. This change
bodyText ||| led to rapid growth in the number of users, as well as
bodyText ||| almost viral growth within non-educational organizations.
bodyText ||| For instance, the British Broadcasting Corporation (BBC)
bodyText ||| network (which requires a BBC email address) has circa
bodyText ||| 10,000 members, approximately 50% of employees [21].
bodyText ||| Since May 2007, Facebook has also allowed the
bodyText ||| development and implementation of third-party applications
bodyText ||| (see dev.facebook.com).
bodyText ||| Before opening to non-academic (and non-US-based) users,
bodyText ||| Facebook.com was peculiar amongst social networking
bodyText ||| sites since many of the social networks its users built were
bodyText ||| based on offline, geographically confined groups (e.g. a
bodyText ||| campus). Termed ‘networks’ by the site (which have
bodyText ||| recently expanded to include non-university based
bodyText ||| geographic areas and workplaces), this reflection of the
bodyText ||| offline community in the online environment may have led
bodyText ||| to unique forms of use amongst users [17].
subsectionHeader ||| User motivation and social networking sites
bodyText ||| Social networks serve a number of functions in offline life –
bodyText ||| for instance, providing social and emotional support,
bodyText ||| information resources and ties to other people [25]. Similar
bodyText ||| kinds of social networks have been identified in online
page ||| 1027
note ||| CHI 2008 Proceedings · Online Social Networks	April 5-10, 2008 · Florence, Italy
bodyText ||| communities [7, 25], with users turning online for both
bodyText ||| emotional support and as an information resource (e.g. via a
bodyText ||| mailing list). In both cases, an online social network may
bodyText ||| provide users with social capital [7].
bodyText ||| Online social networking sites may also serve a number of
bodyText ||| other purposes [5, 16]. Lampe et al. [16] draw a distinction
bodyText ||| between the use of Facebook for ‘social searching’ –
bodyText ||| finding out information about offline contacts, and ‘social
bodyText ||| browsing’ – the use of the site to develop new connections,
bodyText ||| sometimes with the aim of offline interaction. A survey of
bodyText ||| over 2,000 students, found evidence that the primary use of
bodyText ||| Facebook was for ‘social searching’ – that is, using
bodyText ||| Facebook to find out more about people who they have met
bodyText ||| offline, or who they attend class or share a dormitory with
bodyText ||| [16]. The use of Facebook for ‘social browsing’, for
bodyText ||| instance, to meet someone via the site with the intention of
bodyText ||| a later offline meeting, or to attend an event organized
bodyText ||| online, scored relatively low amongst their sample. The
bodyText ||| main use reported by the sample studied by Lampe et al.
bodyText ||| [16, see also 7] was to, “keep in touch with an old friend or
bodyText ||| someone I knew from high school”, an activity that while
bodyText ||| expressing the offline aspects of social searching, also
bodyText ||| suggests a social capital function for Facebook. Golder et
bodyText ||| al. [11] report that while the vast majority of messages are
bodyText ||| sent to friends (90.6%), a large proportion (41.6%) is sent
bodyText ||| to friends outside of one’s local network. This suggests that
bodyText ||| messaging is used to maintain and build social ties across
bodyText ||| distances. In comparison, ‘pokes’ (a form of content-free
bodyText ||| messaging) were primarily exchanged within a network /
bodyText ||| school (98.3% of all pokes were within a network). Golder
bodyText ||| et al. [11] argue that friendship ties require little effort or
bodyText ||| investment to maintain, while messaging with
bodyText ||| geographically distant friends is used to build social capital
bodyText ||| [7].
bodyText ||| According to Lampe et al. [16], social networking sites like
bodyText ||| Facebook may also serve a surveillance function, allowing
bodyText ||| users to “track the actions, beliefs and interests of the larger
bodyText ||| groups to which they belong” (p. 167). The surveillance and
bodyText ||| ‘social search’ functions of Facebook may, in part, explain
bodyText ||| why so many Facebook users leave their privacy settings
bodyText ||| relatively open [13]. If ‘social searching’ is a public good,
bodyText ||| then reciprocity rules would dictate that by enabling a
bodyText ||| degree of surveillance of oneself, one would should also be
bodyText ||| able to engage in reciprocal surveillance of others. For
bodyText ||| instance, Gross and Acquisti [13] report that only 1.2% of
bodyText ||| users changed the default ‘search’ privacy setting, and less
bodyText ||| than 1/2% of users changed the default ‘profile visibility’
bodyText ||| privacy settings.
bodyText ||| Enabling Facebook users who are not currently linked as
bodyText ||| friends to view personal aspects of one’s profile may also
bodyText ||| be a strategy to increase the size of one’s social network. In
bodyText ||| support of this view, [17] report that users completion of
bodyText ||| profile fields that share a common referent (e.g. class,
bodyText ||| hometown) is positively associated with more friends,
bodyText ||| perhaps because such information encourages the
bodyText ||| development of ties based on shared experiences. Profile
bodyText ||| elements that focused on individual likes and dislikes did
bodyText ||| not have an association with the number of friends.
bodyText ||| As noted earlier, Facebook.com has undergone radical
bodyText ||| change over the last twelve months. By moving outside of
bodyText ||| the US-academic environment and embracing users
bodyText ||| globally and outside of academia, it has not only changed
bodyText ||| the profile of its users, but also the potential motivations for
bodyText ||| their use. While tightly controlled, geographically bounded
bodyText ||| networks based on university affiliation still exist, they are
bodyText ||| dwarfed by networks based outside of academia – for
bodyText ||| instance, as of September 2007, the ‘London’ network has
bodyText ||| over 1 million members, New York over 355,000 and
bodyText ||| Toronto over 800,000. The present paper examines the
bodyText ||| motivations of Facebook users using a ‘uses and
bodyText ||| gratifications’ framework.
bodyText ||| Uses and gratifications refer to the ‘how and why’ of media
bodyText ||| use [23]. Specifically, ‘uses and gratifications’ refer to the
bodyText ||| motivations of specific uses, and the satisfaction people
bodyText ||| gain from such use. These gratifications can be divided into
bodyText ||| those based on the content of the media (content
bodyText ||| gratifications) and those based on the actual experience of
bodyText ||| using the media (process gratifications). Typically, content
bodyText ||| gratifications are held to be related to the repeated use of a
bodyText ||| media [18] which for the designers of such systems relates
bodyText ||| to a site’s ‘stickiness’. However, the Internet, and social
bodyText ||| networking sites in particular, also provide communication
bodyText ||| and interaction, unlike many ‘old media’ (e.g. television).
bodyText ||| This led Stafford et al. [23] to propose a third form of
bodyText ||| gratification arising from Internet use: as a social
bodyText ||| environment.
bodyText ||| In the present study, the usual two stage approach to
bodyText ||| studying uses and gratification is adopted [3]. In Study 1,
bodyText ||| Facebook users are asked to generate lists of words or
bodyText ||| phrases that describe their uses and gratifications in an
bodyText ||| exploratory way. In Study 2, these terms are subjected to
bodyText ||| factor analysis in order to form grouped profiles of specific
bodyText ||| uses and gratifications.
sectionHeader ||| STUDY 1: EXPLORATORY STAGE
subsectionHeader ||| Participants
bodyText ||| Participants were 137 Facebook users who responded to a
bodyText ||| request to complete a short online study. The sample
bodyText ||| comprised 53 males and 88 females (Mean age = 26.3
bodyText ||| years). Participants were recruited through a number of
bodyText ||| different methods: postings to the ‘wall’ of three network
bodyText ||| homepages on Facebook (two universities, one regional), a
bodyText ||| paid flyer shown 10,000 times across all networks, and
bodyText ||| links on academic survey websites. The survey was open
bodyText ||| during the first two weeks of July 2007.
subsectionHeader ||| Materials
bodyText ||| The online survey comprised a series of basic demographic
bodyText ||| questions (e.g. age, gender, occupation, location), alongside
bodyText ||| some measures of use of Facebook (time spent on site each
bodyText ||| week, number of friends linked on site, history of use).
page ||| 1028
note ||| CHI 2008 Proceedings · Online Social Networks	April 5-10, 2008 · Florence, Italy
bodyText ||| Following this, participants were asked to respond to the
bodyText ||| following questions adapted from [23] using free text entry:
listItem ||| •	What is the first thing that comes to mind when
listItem ||| you think about what you enjoy most when using
listItem ||| Facebook?
listItem ||| •	What other words describe what you enjoy about
listItem ||| using Facebook?
listItem ||| •	Using single, easy-to-understand terms, what do
listItem ||| you use Facebook for?
listItem ||| •	What uses of Facebook are most important to you?
subsectionHeader ||| Results
bodyText ||| Two raters clustered the descriptive items and phrases
bodyText ||| developed by Facebook users in response to the first
bodyText ||| question. The raters worked collaboratively to develop the
bodyText ||| clusters, and were instructed to ‘identify responses that are
bodyText ||| related’. The author then discussed the themes with the
bodyText ||| raters, and named them accordingly. The main themes
bodyText ||| identified are outlined in Table 1.
table ||| Theme (sample user generated items)	Number
table ||| 	of
table ||| 	mentions
table ||| ‘Keeping in touch’	52
table ||| Contacting friends who are away from home Chatting to people I otherwise would have lost contact with
table ||| Passive contact, social surveillance Virtual people-watching.	19
table ||| ‘Re-acquiring lost contacts’	15
table ||| Reconnecting with people I’ve lost contact with
table ||| Finding people you haven't seen for a while
table ||| ‘Communication’ Being poked	15
table ||| Private messages Writing on walls
table ||| Photographs	11
table ||| Tagged in picture Posting pictures Sharing pictures
table ||| Design related Ease of use	4
table ||| Perpetual contact	4
table ||| Seeing what people have put as their 'status' The continuous updates
table ||| Seeing what my friends have been up to today
table ||| ‘Making new contacts’ Talking to singles	5
table ||| Getting new friends
table ||| Joining groups
tableCaption ||| Table 1: Frequency of mentions (Question 1)
bodyText ||| In keeping with previous research [e.g. 16], the use of
bodyText ||| Facebook to ‘keep in touch’ received the largest number of
bodyText ||| mentions, with the use of the site to make new contacts
bodyText ||| receiving a small number of mentions.
sectionHeader ||| STUDY 2: IDENTIFYING USES AND GRATIFICATIONS
subsectionHeader ||| Item generation
bodyText ||| A sample of items from each use and gratification proposed
bodyText ||| by users was extracted from the exploratory list developed
bodyText ||| in Study 1. Participants’ responses to items 2–4 were
bodyText ||| examined, and any occurrences of other uses or
bodyText ||| gratifications not mentioned in response to the first item
bodyText ||| were added to the list. This led to a total of 46 items. Where
bodyText ||| possible, the item was taken word for word from participant
bodyText ||| responses to Study 1.
subsectionHeader ||| Participants
bodyText ||| Participants were 241 Facebook users recruited using the
bodyText ||| same methods outlined in Study 1. In addition, e-mails were
bodyText ||| sent to selected mailing lists with a request for participation
bodyText ||| (e.g. AIR-L). Participants were 80 males (33.2%) and 161
bodyText ||| (66.8%) females (mean age = 25.97 years (SD = 9.30, range
bodyText ||| 15-66 years old). The majority of the sample were full time
bodyText ||| students (n = 151, 62.7%), 6.6% (n = 16) were part-time
bodyText ||| students and worked part- or full-time (or had carer
bodyText ||| responsibilities), and 30.7% were in full-time work and not
bodyText ||| studying (n = 78). The study was open during the final
bodyText ||| week in July, and throughout August.
subsectionHeader ||| Measures
bodyText ||| The same demographic and Facebook use measures
bodyText ||| described in Study 1 were used in Study 2. Participants also
bodyText ||| completed an item related to their use of Facebook privacy
bodyText ||| settings, specifically if they had changed the default
bodyText ||| settings, and if so, the degree to which they had made them
bodyText ||| more private or more open.
bodyText ||| Participants were finally asked to rate, using a 7-point
bodyText ||| Likert scale, the 46 uses and gratifications derived from
bodyText ||| Study 1 using the metric, “How important are the following
bodyText ||| uses of Facebook to you personally?’ The scale was
bodyText ||| anchored at 1 (very unimportant) and 7 (very important).
subsectionHeader ||| Results
bodyText ||| Participants had an average of 124 friends linked to their
bodyText ||| Facebook profile (Range 1-1000, Median = 85, SD =
bodyText ||| 129.97). Around half of the participants had been registered
bodyText ||| on the site for less than six months (6.3% for less than one
bodyText ||| month, 9.6% for between one and two months and 29.2%
bodyText ||| for between two and six months). The remaining
bodyText ||| participants had been signed up for between six months and
bodyText ||| a year (21.7%), more than one year, but less than two
bodyText ||| (21.7%) or for more than two years (10.8%). The majority
bodyText ||| of participants visited the site either daily (38.8%) or more
bodyText ||| than once a day (27.5%). Almost a quarter visited Facebook
bodyText ||| several times a week (22.5%), with 6.7% visiting once a
bodyText ||| week on average, and 4.2% visiting less than once a week.
page ||| 1029
note ||| CHI 2008 Proceedings · Online Social Networks	April 5-10, 2008 · Florence, Italy
bodyText ||| Amongst all respondents, the most common responses for
bodyText ||| the time spent on the site each week were between 1 and 2
bodyText ||| hours (33.3%) and between 2 and 5 hours (32.5%). A
bodyText ||| relatively small proportion of users claimed to spend either
bodyText ||| less than 1 hour a week (16.9%) or between 5 and 10 hours
bodyText ||| (11.0%) on the site. The proportion of users claiming more
bodyText ||| than 10 hours Facebook use per week was small (5.4%).
bodyText ||| Unlike previous research [13], the majority of users claimed
bodyText ||| to have changed the default privacy settings in Facebook,
bodyText ||| with 25.6% (n = 61) reporting making their profile
bodyText ||| ‘somewhat’ more private, 21% (n = 50) ‘much more’
bodyText ||| private and 10.9% (n = 26) making it ‘as private as
bodyText ||| possible. A smaller group claimed to have made their
bodyText ||| profile either more ‘open’ (9.2%, n = 22) or ‘as open to
bodyText ||| others as possible (9.2%, n = 22). The number of people
bodyText ||| making no changes to their profile (23.5%, n = 56) was
bodyText ||| substantially lower than that reported in previous studies
bodyText ||| [ 14].
bodyText ||| The most important uses of Facebook tended to be related
bodyText ||| to the ‘social searching’ and surveillance functions (see
bodyText ||| Tables 2-8), identified by [16]. Specifically, the use of the
bodyText ||| site to learn about old friends and maintain or re-connect
bodyText ||| relations scored consistently highly. This pattern repeats
bodyText ||| previous findings from student samples [7, 16].
bodyText ||| To investigate the nature of the various uses and
bodyText ||| gratifications of Facebook in more depth, exploratory factor
bodyText ||| analysis was conducted. The initial factor analysis (varimax
bodyText ||| rotation) yielded 9 components with eigenvalues over 1,
bodyText ||| explaining 64.8% of the variance. Examination of the scree
bodyText ||| plot and unique loadings suggested that seven components
bodyText ||| (explaining 59% of the variance) should be retained for
bodyText ||| further analysis. Only four items did not load on any of the
bodyText ||| factors: one was related to privacy settings, two about use
bodyText ||| of the ‘poke’ facility and one about leaving messages on the
bodyText ||| ‘wall’.
sectionHeader ||| INTERPRETATION OF FACTORS AND SCALE
sectionHeader ||| DEVELOPMENT
bodyText ||| To aid further analysis, scales were developed from each
bodyText ||| factor. As a preliminary check, score distributions on each
bodyText ||| item were examined to ensure that none suffered from
bodyText ||| restricted range (i.e., the full range of response options was
bodyText ||| being used). This was the case for all items. Items were
bodyText ||| identified as markers of each factor based on the commonly
bodyText ||| used benchmark of a loading greater than .5. Items that had
bodyText ||| significant loadings on other factors were discounted as
bodyText ||| marker items [22].
bodyText ||| Application of these criteria led to identification of eight
bodyText ||| marker items for Factor 1, three for Factors 2, four for
bodyText ||| Factor 3, four each for Factor 4 and 5, and three each for
bodyText ||| Factor 6 and 7.
bodyText ||| Factor 1 (Table 2) contains items predominantly concerned
bodyText ||| with ‘keeping in touch’ (the most often mentioned use of
bodyText ||| Facebook in Study 1, and by [16]). The items have a clear
bodyText ||| focus on re-connecting with lost contacts and maintaining
bodyText ||| contact with existing friends. Some of the items loading on
bodyText ||| this factor also clearly relate to the ‘surveillance’ function
bodyText ||| identified by [16], for instance, ‘Finding out what old
bodyText ||| friends are doing now”. Others are more closely related to
bodyText ||| the creation or maintenance of ‘weak ties’ (e.g.
bodyText ||| “Maintaining relationships with people you may not get to
bodyText ||| see very often”). Because of the combination of
bodyText ||| surveillance and social capital functions, this factor and
bodyText ||| related scale is labeled ‘social connection’. Two items
bodyText ||| loaded on this factor, but did not meet the criteria for factor
bodyText ||| purity: ‘Reading messages on your wall’ and ‘Seeing how
bodyText ||| old acquaintances look’).
table ||| Factor 1: Social connection (Cronbach’s Alpha = .89)	Item Mean (SD)	Loading
table ||| Finding out what old friends are doing now	5.08 (1.71)	.753
table ||| Reconnecting with people you’ve lost contact with	5.29 (1.79)	.783
table ||| Connecting with people you otherwise would have lost contact with	5.53 (1.61)	.842
table ||| Receiving a friend request	4.86 (1.68)	.601
table ||| Finding people you haven’t seen for a while	5.41 (1.66)	.850
table ||| Maintaining relationships with people you may not get to see very often	5.71 (1.56)	.764
table ||| Contacting friends who are away from home	5.46 (1.83)	.522
tableCaption ||| Table 2: Items and loading (Factor 1)
bodyText ||| The second factor is comprised of three items related to the
bodyText ||| joining of groups, organization of events and meeting of
bodyText ||| ‘like-minded people’ (see Table 3). These activities are akin
bodyText ||| to ‘social browsing’ identified by Lampe et al.; although
bodyText ||| there is no reason to assume that they are necessarily
bodyText ||| motivated by a desire to meet offline eventually. It also
bodyText ||| contains related to the discovery of new music and new
bodyText ||| groups via friends. As such, it seems to represent a ‘shared
bodyText ||| identities’ function. Two items (‘Seeing what kinds of
bodyText ||| networks and special interest groups your friends have’ and
bodyText ||| ‘Learning about new music’) loaded on the factor, but did
bodyText ||| not meet the factor purity criteria.
table ||| Factor 2: Shared identities (Cronbach’s alpha .74)	Item Mean (SD)	Loading
table ||| Organizing or joining events	3.42 (1.82)	.699
table ||| Joining groups	3.52 (1.63)	.727
table ||| Communication with likeminded people	3.82 (1.76)	.638
tableCaption ||| Table 3: Items and loading (Factor 2)
page ||| 1030
note ||| CHI 2008 Proceedings · Online Social Networks	April 5-10, 2008 · Florence, Italy
bodyText ||| The third factor is related to the posting and viewing of
bodyText ||| photographs (see Table 4), although many of the items also
bodyText ||| had loadings in the .3 region on the first factor. This
bodyText ||| suggests that these activities within Facebook may fulfill a
bodyText ||| number of gratifications. Specifically, the social uses of
bodyText ||| photographs (e.g. sharing, tagging) may also play an
bodyText ||| important role in ‘social connection’. However, by forming
bodyText ||| a unique factor, they may also be a content gratification in
bodyText ||| their own right.
table ||| Factor 3: Photographs (Cronbach’s alpha =.89)	Item Mean (SD)	Loading
table ||| Viewing photos	5.03 (1.72)	.609
table ||| Being tagged in photos	4.24 (1.90)	.668
table ||| Tagging photos	3.96 (1.89)	.734
table ||| Sharing / posting photographs	4.58 (1.89)	.701
tableCaption ||| Table 4: Items and loading (Factor 3)
bodyText ||| Factor four contains items related to content within
bodyText ||| Facebook – for instance, applications and quizzes (see
bodyText ||| Table 5). This relates to the usual ‘content gratification’
bodyText ||| identified in previous media research. It is worthwhile
bodyText ||| noting that while these items form a unique factor, the mean
bodyText ||| scores are relatively low. A single item (‘Looking at posted
bodyText ||| items’) loaded on the factor, but did not meet factor purity
bodyText ||| criteria.
table ||| Factor 4: Content (Cronbach’s alpha = .74)	Item Mean (SD)	Loading
table ||| Applications within Facebook	2.85 (1.65)	.826
table ||| Playing games	1.86 (1.40)	.559
table ||| Discovering apps because you see friends have added them	2.64 (1.58)	.756
table ||| Quizzes	1.85 1.30)	.638
tableCaption ||| Table 5: Items and loading (Factor 4)
bodyText ||| Factor five contains items akin to both social searching and
bodyText ||| social browsing identified by Lampe et al [16]. The items
bodyText ||| comprising this factor cover both the use of Facebook to
bodyText ||| meet or view new people and to find out more about people
bodyText ||| who are met offline (see Table 6).
table ||| Factor 5: Social investigation (Cronbach’s alpha =.75)	Item Mean (SD)	Loading
table ||| Virtual people watching	3.31 (1.90)	.574
table ||| Using advanced search to look for specific types of people	2.56 (1.70)	.508
table ||| Meeting new people	2.91 (1.83)	.509
table ||| Stalking other people	2.13 (1.71)	.755
tableCaption ||| Table 6: Items and loading (Factor 5)
bodyText ||| One item (‘Looking up the profile of people you meet
bodyText ||| offline’) loaded on the factor but did not meet the purity
bodyText ||| criteria. The items do share a targeted investigation of
bodyText ||| others, however. As such, the factor is termed ‘social
bodyText ||| investigation’.
bodyText ||| Factor six comprises items related to a unique affordance of
bodyText ||| social networking sites – the ability to view other people’s
bodyText ||| social networks and friends (see Table 7). This ability to
bodyText ||| find out more about one’s acquaintances through their
bodyText ||| social networks forms another important surveillance
bodyText ||| function, and may also be a method for increasing the size
bodyText ||| of one’s own social network. This specific use is termed
bodyText ||| ‘Social network surfing’ here to signify the ability of users
bodyText ||| to move from one person to another via friend links,
bodyText ||| although it may also relate closely to a ‘process
bodyText ||| gratification’.
table ||| Factor 6: Social network surfing (Cronbach’s alpha =.79)	Item Mean (SD)	Loading
table ||| Looking at the profiles of people you don’t know	2.48 (1.53)	.719
table ||| Viewing other people’s friends	3.34 (1.74)	.785
table ||| Browsing your friends’ friends	3.89 (1.65)	.724
tableCaption ||| Table 7: Items and loading (Factor 6)
bodyText ||| The final factor comprises items related to the newsfeed
bodyText ||| and status updates within Facebook. The newsfeed provides
bodyText ||| updates on both ‘friends’ status, alongside recent activity
bodyText ||| (e.g. the addition or removal of applications, changes in
bodyText ||| relationship status, addition of ‘friends’). Given the outcry
bodyText ||| when the newsfeed was introduced [2], the relative high
bodyText ||| scores for this use suggest an increasing degree of
bodyText ||| acceptance. Interestingly, a gratification (‘to keep up with
bodyText ||| the latest gossip’) also loaded on this factor (although only
bodyText ||| at the .4 level), suggesting a clear motivation for viewing
bodyText ||| the newsfeed.
table ||| Factor 7: Status updates (Cronbach’s alpha = .71)	Item Mean (SD)	Loading
table ||| Updating your own status	3.85 (1.77)	.568
table ||| The news feed	3.79 (1.83)	.531
table ||| Seeing what people have put as their status	3.84 (1.79)	.698
tableCaption ||| Table 8: Items and loading (Factor 7)
tableCaption ||| The pattern of loadings and internal reliability (Cronbach
tableCaption ||| alpha scores) suggests that the seven factors should be
tableCaption ||| considered suitable for use in further analysis, on the
tableCaption ||| assumption that they are interpretable. Scales were
tableCaption ||| developed for each factor by creating the mean score across
tableCaption ||| the marker items.
page ||| 1031
note ||| CHI 2008 Proceedings · Online Social Networks	April 5-10, 2008 · Florence, Italy
subsectionHeader ||| Inter-relations of uses and gratifications
bodyText ||| Despite the fact that these factors arise from an orthogonal
bodyText ||| rotation and are separable in terms of item loadings, they
bodyText ||| are correlated (see Table 9).
bodyText ||| The Spearman correlations between the factors suggest that
bodyText ||| the uses and gratifications identified are related, in some
bodyText ||| cases relatively strongly.
table ||| Shared Identities	.24**	1
table ||| Photographs	.62**	.32**	1
table ||| Content	.03	.31**	.06	1
table ||| Social investigation	.37**	.43**	.42**	.37**	1
table ||| Social network surfing	.28**	.33**	.29**	.29**	.54**	1
table ||| Status updates	.30**	.49**	.34**	.34**	.38**	.28**
tableCaption ||| Table 9: Spearman correlations between scales (n = 241)
subsectionHeader ||| User demographics and uses and gratifications
bodyText ||| A MANOVA test found a significant difference between
bodyText ||| males and females on their scores across the seven uses and
bodyText ||| gratifications scales (F (7, 233) = 2.662, p < 0.02). Further
bodyText ||| analysis of the between-subjects effects on the dependent
bodyText ||| variables showed that scores were significantly different on
bodyText ||| the first factor – ‘social connection’ (F (1, 239) = 16.16,
bodyText ||| p<0.001, η2= .063), with females scoring higher on the
bodyText ||| scale (M = 5.40, SD = 1.22) compared to males (M = 4.70,
bodyText ||| SD = 1.37), on the third factor - ‘photographs’ (F (1, 239) =
bodyText ||| 8.95, p<0.01, 112= .036), with females again scoring higher
bodyText ||| on the scale (M = 4.67, SD = 1.61) compared to males (M =
bodyText ||| 4.02, SD = 1.51). There was a marginally significant
bodyText ||| difference across the seventh factor – ‘status updates’ (F (1,
bodyText ||| 239) = 3.26, p=.072, r)2= .0 13), with females scoring higher
bodyText ||| on the scale (M = 3.94, SD = 1.40) compared to males (M =
bodyText ||| 3.58, SD = 1.47).
bodyText ||| A one-way between subjects ANOVA found a significant
bodyText ||| effect of gender on profile privacy settings (F (1, 236) =
bodyText ||| 12.29, p < .01), with females more likely to report making
bodyText ||| their profile more private (Mean = 4.83, SD = 1.60)
bodyText ||| compared to males (Mean = 4.01, SD = 1.86)
bodyText ||| A further MANOVA test was conducted to compare
bodyText ||| responses to the items in light of occupational status (i.e.
bodyText ||| full-time student, full-time employed, part-time
bodyText ||| student/employed). Given the relatively low number of
bodyText ||| people working part-time / studying part-time, this group
bodyText ||| was excluded from the analysis. The results showed a
bodyText ||| significant overall effect of occupational status on uses and
bodyText ||| gratifications of Facebook (F (7, 217) = 4.93, p < .001),
bodyText ||| with significant effects for Factor 1 (social connection – F
bodyText ||| (1, 223) = 7.3 1, p<.01), Factor 2 (shared identities – F (1,
bodyText ||| 223) = 4.90, p<.05), and Factor 3 (photographs – F (1, 223)
bodyText ||| = 7.85, p< .01).
bodyText ||| Full-time students scored higher on social connection and
bodyText ||| photographs, and lower on shared identities, compared to
bodyText ||| those in full-time work (Factor 1 Mean = 5.38 (SD = 1.16)
bodyText ||| for students, Mean = 4.89 (SD = 1.45) for full-time
bodyText ||| employment; Factor 2 Mean = 3.47 (SD = 1.37) for
bodyText ||| students, Mean = 3.90 (SD = 1.40) for full-time
bodyText ||| employment; Factor 3 Mean = 4.71 (SD = 1.53) for
bodyText ||| students, Mean = 4.09 (SD = 1.57) for full-time
bodyText ||| employment).
bodyText ||| Age also correlated negatively with their scores on social
bodyText ||| connection (rs(225) = -.27, p<.001), and photographs (rs(225) =
bodyText ||| -.32, p<.001), with younger respondents scoring higher on
bodyText ||| both scales. Age did not correlate with the other factor-
bodyText ||| derived scales.
bodyText ||| Age also correlated with the length of time users had been
bodyText ||| registered on Facebook (rs(241) = -.17, p<0.01), the regularity
bodyText ||| with which they visited the site (rs(241) = -.18, p<.01), the
bodyText ||| number of hours they used the site in a week (rs(241) = -.22,
bodyText ||| p<.01) and the number of friends they had linked to their
bodyText ||| profile (rs(219) = -.37, p<.001). In all cases, a younger user
bodyText ||| was associated with higher usage levels, and a greater
bodyText ||| number of ‘friends’.
bodyText ||| Age was also negatively correlated with the use of privacy
bodyText ||| settings (rs(238) = -.17, p<.01), such that younger users report
bodyText ||| that they were more likely to have increased the privacy of
bodyText ||| their profile. In part this may be due to the higher number
bodyText ||| of friends amongst younger users.
subsectionHeader ||| Predicting Facebook use
bodyText ||| A number of earlier researchers have predicted that certain
bodyText ||| uses and gratifications of Facebook may be associated with
bodyText ||| greater use of the site. For instance, [17] note that
bodyText ||| completion of certain profile elements is associated with a
bodyText ||| greater number of ‘friends’, while the findings of [16])
bodyText ||| suggest that the use of Facebook for social searching and
bodyText ||| surveillance motivates use.
bodyText ||| To examine possible motivators for use of Facebook, a
bodyText ||| series of multiple regression equations were calculated
bodyText ||| using scores on the seven factor-based scales to predict both
bodyText ||| the frequency of visits to the site and the time spent on
bodyText ||| Facebook during an average week. Age, occupation and
bodyText ||| gender were also entered as covariates (part-time excluded).
bodyText ||| The results of the regression analyses to predict the
bodyText ||| frequency of site use are shown in Table 10. The overall
bodyText ||| model was significant (F (10, 213) = 4.77, p<0.001, R2 =
bodyText ||| .15).
bodyText ||| A second regression equation examined the same variables
bodyText ||| predicting the amount of time spent on the site (see Table
page ||| 1032
note ||| CHI 2008 Proceedings · Online Social Networks	April 5-10, 2008 · Florence, Italy
bodyText ||| 11). Again, the overall model was significant (F (10, 210) =
bodyText ||| 3.85, p<0.001, R2 = .12).
table ||| Variable	J6	t	Sig
table ||| Sex	.179	2.638	.009
table ||| Age	.126	1.479	.141
table ||| Occupation	.036	.430	.667
table ||| F1 – ‘social connection’	-.055	-.619	.536
table ||| F2 - ‘shared identities’	.015	.200	.842
table ||| F3 – ‘photographs’	-.208	-2.295	.023
table ||| F4 – ‘content gratifications’	.032	.455	.649
table ||| F5 – ‘social investigation’	.156	1.819	.070
table ||| F6 – ‘social network surfing’	-.043	-.561	.576
table ||| F7 – ‘status updates’	-.296	-3.848	.000
tableCaption ||| Table 10: Predicting frequency of visits to Facebook
bodyText ||| The regression equations show a differential pattern of uses
bodyText ||| and gratifications motivating frequency of visits to the site,
bodyText ||| and the time spent on the site. Gender (females visit more
bodyText ||| frequently) and scores on the ‘photographs’ and ‘status
bodyText ||| updates’ factors predict the frequency of visits to the site.
bodyText ||| Higher scores on both scales predicted more frequent visits.
bodyText ||| There was a marginally significant effect of ‘social
bodyText ||| investigation’ (higher scores related to less frequent visits).
bodyText ||| However, participants age (younger spend more time) and
bodyText ||| scores on the content gratification scale predict the actual
bodyText ||| number of hours spent online. This suggests that
bodyText ||| surveillance gratifications motivate repeat visits, but that
bodyText ||| content gratifications motivate people to spend longer on
bodyText ||| the site when they do visit.
table ||| Variable	J6	t	Sig
table ||| Sex	-.031	-.440	.660
table ||| Age	-.265	-3.029	.003
table ||| Occupation	.058	.669	.504
table ||| F1 – ‘social connection’	-.090	-.983	.327
table ||| F2 - ‘shared identities’	.011	.145	.885
table ||| F3 – ‘photographs’	.134	1.442	.151
table ||| F4 – ‘content gratifications’	.213	2.962	.003
table ||| F5 – ‘social investigation’	-.040	-.448	.655
table ||| F6 – ‘social network surfing’	.117	1.481	.140
table ||| F7 – ‘status updates’	.086	1.092	.276
tableCaption ||| Table 11: Predicting time spent (hours) on Facebook
bodyText ||| A final regression equation was calculated to predict the
bodyText ||| number of ‘friends’ users reported on Facebook (see Table
bodyText ||| 12). Given that the number of friends should be related to
bodyText ||| the length of time users had been registered on Facebook,
bodyText ||| and the intensity of their use, the usage measures (length of
bodyText ||| time, frequency of visit, time spent on site) were entered
bodyText ||| alongside the remaining variables.
bodyText ||| The overall model was significant (F (15, 196) = 8.48, p <
bodyText ||| .001, R2 = .31).
bodyText ||| As might be expected, age was associated with the number
bodyText ||| of ‘friends’ (younger have more ‘friends’), as was the
bodyText ||| amount of time users had been registered on the site and the
bodyText ||| frequency of their site visits (longer time registered, and
bodyText ||| more frequent visits, associated with more friends).
bodyText ||| Interestingly, scores on the ‘social connection’ scale were
bodyText ||| not associated with ‘friend’ numbers, while scores on the
bodyText ||| ‘content gratification’ scale were negatively associated with
bodyText ||| the number of ‘friends’ (i.e. higher scores associated with
bodyText ||| smaller number of ‘friends’). Scores on the ‘social
bodyText ||| investigation’ scale were positively associated with the
bodyText ||| number of friends, while scores on the ‘photographs’ scale
bodyText ||| were marginally significantly associated with an increased
bodyText ||| number of friends.
table ||| Variable	J6	T	Sig
table ||| Sex	.036	.584	.560
table ||| Age	-.213	-2.936	.004
table ||| Occupation	-.041	-.584	.560
table ||| Time registered on site	.289	4.725	.000
table ||| Frequency of visit	-.184	-2.805	.006
table ||| Time spent on site	.062	.909	.364
table ||| F1 – ‘social connection’	-.081	-.978	.329
table ||| F2 - ‘shared identities’	.090	1.286	.200
table ||| F3 – ‘photographs’	.138	1.610	.109
table ||| F4 – ‘content gratifications’	-.139	-2.058	.041
table ||| F5 – ‘social investigation’	.169	2.123	.035
table ||| F6 – ‘social network surfing’	-.048	-.679	.498
table ||| F7 – ‘status updates’	-.047	-.641	.523
tableCaption ||| Table 12: Predicting number of ‘friends’ on Facebook
subsectionHeader ||| Use of Facebook Privacy Settings and meeting new
subsectionHeader ||| people
bodyText ||| A final set of analyses were conducted to examine the
bodyText ||| relationship between specific uses and respondents’
bodyText ||| reported privacy profile settings. The privacy settings of
bodyText ||| users were grouped, according to their responses, into those
bodyText ||| who reported making their profile less private (n=44), those
page ||| 1033
note ||| CHI 2008 Proceedings · Online Social Networks	April 5-10, 2008 · Florence, Italy
bodyText ||| who reported leaving it at the default setting (n = 56), and
bodyText ||| those who reported making it more private (n = 137). In the
bodyText ||| main, privacy settings in Facebook allow users to hide their
bodyText ||| profile from people who are neither listed as ‘friends’ or
bodyText ||| members of the user’s own network. However, if the
bodyText ||| motive for using Facebook is to meet new people, then such
bodyText ||| privacy settings would be somewhat counter productive. To
bodyText ||| test this proposition, a MANOVA was conducted with
bodyText ||| privacy settings as the independent variable, and the
bodyText ||| responses to items related to meeting new people set as the
bodyText ||| dependent variables. The results showed a significant link
bodyText ||| between privacy settings and the responses to the items (F
bodyText ||| (8, 454) = 2.11, p < .05). Analysis of the between subjects
bodyText ||| effects found no difference in responses to the ‘joining
bodyText ||| groups’ or ‘joining events’ items and privacy settings (ps >
bodyText ||| .3), but a significant effect of reported privacy settings on
bodyText ||| responses to the item ‘meeting new people’ (F (2, 229) =
bodyText ||| 4.16, p < .02), and a marginally significant effect on the
bodyText ||| item ‘using advanced search to look for specific types of
bodyText ||| people’ (F (2, 229) = 2.48, p = .08). The means for the
bodyText ||| ‘meeting new people’ item across the three privacy groups
bodyText ||| are shown in Figure 1.
figureCaption ||| Figure 1: Scores on ‘meeting new people’ by privacy
figureCaption ||| settings
bodyText ||| These results suggest that for users wishing to use
bodyText ||| Facebook to meet new people, the privacy settings may be
bodyText ||| set at too stringent a level. Further analyses confirmed no
bodyText ||| links between the social connection scales and privacy
bodyText ||| settings, suggesting that a primary motivation for making
bodyText ||| one’s profile less private is the desire to meet new people.
sectionHeader ||| DISCUSSION
bodyText ||| Social networking sites pose a number of challenges for
bodyText ||| HCI researchers and practitioners. First, the actual uses and
bodyText ||| gratifications of such sites are not well understood. The
bodyText ||| present paper presents the first study of a social networking
bodyText ||| site using a ‘uses and gratifications’ framework, and also
bodyText ||| provides an empirically developed measurement tool for
bodyText ||| future research.
bodyText ||| Second, previous research that has been conducted has
bodyText ||| tended to focus on campus-based use of Facebook [e.g. 7,
bodyText ||| 13, 6, 11, 17], which may limit the generalizability of any
bodyText ||| findings. However, the results of the present research
bodyText ||| support many of the conclusions of earlier research
bodyText ||| conducted on student populations. For instance, the
bodyText ||| distinction previously drawn between ‘social searching’ and
bodyText ||| ‘social browsing’ uses of Facebook [16] was similarly
bodyText ||| evident in the present research. Moreover, in keeping with
bodyText ||| prior student-users research [e.g. 7, 16], the use of
bodyText ||| Facebook to ‘keep in touch’ was the most commonly
bodyText ||| mentioned term in Study 1, and formed a large proportion
bodyText ||| of the items comprising the first factor in Study 2.
bodyText ||| However, the adoption of a uses and gratifications approach
bodyText ||| enables us to begin to probe in more depth the exact nature
bodyText ||| of ‘keeping in touch’ as both a use and a gratification. The
bodyText ||| results of the present study suggest that ‘keeping in touch’
bodyText ||| comprises two main functions. The first is a surveillance
bodyText ||| function as identified by Lampe and colleagues [16].
bodyText ||| Facebook is used to see what old contacts and friends are
bodyText ||| ‘up to’, how they look and how they behave. In keeping
bodyText ||| with this use, there is evidence that Facebook profiles serve
bodyText ||| an important self-presentation tool [26]. Associated with
bodyText ||| this use is the social capital building gratification, where
bodyText ||| Facebook is used to build, invest in and maintain ties with
bodyText ||| distant friends and contacts [7, 11].
bodyText ||| The ‘social search’ and ‘social browsing’ uses of Facebook
bodyText ||| identified by Lampe and colleagues [16] were closely
bodyText ||| related in the present study. The use of Facebook to search
bodyText ||| for new people loaded on the same factor as the use of
bodyText ||| Facebook to research offline contacts. This ‘virtual people
bodyText ||| watching’ was represented in both Factors 5 and 6, with the
bodyText ||| important distinction that Factor 6 relied primarily on
bodyText ||| ‘friend of friend’ connections, while Factor 5 represented
bodyText ||| targeted investigation of people met offline, or searched for.
bodyText ||| Symptomatic of this distinction is the difference between
bodyText ||| ‘looking up’ (Factor 5) and ‘looking at’ (Factor 6) people.
bodyText ||| In the present study, only social investigation was
bodyText ||| associated with a higher number of ‘friends’, not social
bodyText ||| network browsing.
bodyText ||| Interestingly, an increased score on the content gratification
bodyText ||| scale was negatively related to the number of ‘friends’
bodyText ||| reported to be linked to one’s profile. This perhaps suggests
bodyText ||| a sub-set of users gain gratification through the use of
bodyText ||| applications within Facebook, rather than through the
bodyText ||| accrual of ‘friends’. However, many of the applications
bodyText ||| available in Facebook are social in nature (e.g. scrabble
bodyText ||| games, ways to rate friends). But, at present these
bodyText ||| applications tend to rely on existing contacts, rather than the
bodyText ||| accrual of new ‘friends’. As such, they may serve to
bodyText ||| strengthen social ties, rather than acting to increase the
bodyText ||| overall size of a social network. Thus, investment of time
bodyText ||| and effort in social applications within Facebook may be
bodyText ||| akin to messaging between friends [11] – it solidifies ties,
bodyText ||| rather than creating new links.
bodyText ||| Users responses on the scales created from the factors also
bodyText ||| predicted their pattern of use of the site. In keeping with
figure ||| 4
figure ||| 3.5
figure ||| 3
figure ||| 2.5
figure ||| 2
figure ||| 1.5
figure ||| 1
figure ||| 0.5
figure ||| 0
figure ||| Less private	Default	More private
page ||| 1034
note ||| CHI 2008 Proceedings · Online Social Networks	April 5-10, 2008 · Florence, Italy
bodyText ||| earlier work on traditional media, content gratification
bodyText ||| predicted the amount of time spent on the site. However,
bodyText ||| the use of the site for social investigation, viewing and
bodyText ||| posting photographs and viewing status updates predicted
bodyText ||| the frequency of visits. It would seem from the present data
bodyText ||| that ‘keeping in touch’ may in actuality refer to ‘checking
bodyText ||| up on regularly’, while the ‘stickiness’ of the site (in terms
bodyText ||| of time spent on it) depends on use of the content and
bodyText ||| applications. This insight is clearly important for designers
bodyText ||| of social networking sites and associated content. If repeat
bodyText ||| visits are motivated by different uses and gratifications than
bodyText ||| the amount of time spent on the site, it is important to
bodyText ||| design content gratification alongside the ability to build
bodyText ||| and maintain social connections. It also suggests that the
bodyText ||| furor caused by the introduction of the newsfeed [2] has
bodyText ||| subsided, and been replaced by its new role as a ‘killer
bodyText ||| app’, at least in terms of repeat visits to the site. In many
bodyText ||| ways, this use of Facebook reflects the desire for ‘perpetual
bodyText ||| contact’ [15], and previously supplied by standalone
bodyText ||| services like Twitter [24]. While the social implications of
bodyText ||| this interest in perpetual contact and updates on ‘friends’
bodyText ||| are beyond the remit of the present paper, it is worth noting
bodyText ||| that an increased awareness of others’ actions has
bodyText ||| potentially important implications for how we relate to
bodyText ||| others, and understand ourselves.
subsectionHeader ||| Design Implications
bodyText ||| The designers of social networking sites should consider the
bodyText ||| varied uses and gratifications reported by users, and need to
bodyText ||| recognize that not all users have the same uses of a social
bodyText ||| networking site, nor derive the same gratifications from
bodyText ||| their use. For instance, there are clear distinctions between
bodyText ||| the use of Facebook to maintain and re-create connections
bodyText ||| with friends, its use as a surveillance tool and for content
bodyText ||| delivery. There were also differences in reported uses by
bodyText ||| age, gender and occupational status. It may be that different
bodyText ||| demographic groups are motivated to use social networking
bodyText ||| sites for different purposes, with social connectivity and
bodyText ||| perpetual contact motivating younger (and female) users
bodyText ||| more than older (and male) users.
bodyText ||| The differing goals for the use of Facebook are reflected not
bodyText ||| only in usage patterns, but also in users’ privacy settings.
bodyText ||| People who have made their privacy settings more
bodyText ||| permissive are more likely to want to meet new people
bodyText ||| (they also score higher on the content gratifications scale).
bodyText ||| This is a designed aspect of the system – in both cases, to
bodyText ||| fulfill one’s goal often requires a more permissive approach
bodyText ||| to profile privacy. Many of the applications are social in
bodyText ||| nature (e.g. comparing oneself with others, asking questions
bodyText ||| to ‘friends’, viewing people from one’s neighborhood), and
bodyText ||| often circumvent elements of the default privacy settings.
bodyText ||| Similarly, if the goal is to meet new people, making one’s
bodyText ||| profile more open than by default allows others pursuing
bodyText ||| the same gratification to view your profile, and presumably
bodyText ||| increases the chances of an interaction. For these users, the
bodyText ||| profile within Facebook is likely to become a key self-
bodyText ||| presentation tool, rather than simply a way to ‘keep in
bodyText ||| touch’ with others [6, 26].
subsectionHeader ||| Limitations and Further research
bodyText ||| The present research is a ‘snap shot’ of Facebook users, and
bodyText ||| further work should consider the possibility of researching
bodyText ||| the development of use over time. In particular, it would be
bodyText ||| of interest to see how people’s uses and gratifications of
bodyText ||| Facebook develop, and if the frequency of visit is motivated
bodyText ||| by ‘perpetual contact’ over time. There is, for instance,
bodyText ||| considerable research in the field of habit formation that
bodyText ||| could inform the study of social network site use. HCI
bodyText ||| research should also consider ways in which the desire to
bodyText ||| meet new people, and to allow oneself to be viewed by
bodyText ||| strangers, can be accommodated in a privacy-protecting
bodyText ||| manner [14]. At present, Facebook has reasonably nuanced
bodyText ||| privacy controls. From the results of the present research, it
bodyText ||| would seem that users are changing the default privacy
bodyText ||| settings in a motivated manner. However, the present study
bodyText ||| only collected reported privacy settings. It would be
bodyText ||| prudent to complete research that actually examined
bodyText ||| settings via automated querying of the site [e.g. 13], or by
bodyText ||| studying a corpus of actual interactions [e.g. 11].
bodyText ||| It should also be noted that the nature of the sampling
bodyText ||| method, and the self-selection of respondents, may have
bodyText ||| influenced the pattern of responses and overall levels of
bodyText ||| activity. Future research may wish to study a wider group
bodyText ||| of participants, or attempt to identify patterns of usage
bodyText ||| amongst non-respondents compared to respondents
sectionHeader ||| CONCLUSIONS
bodyText ||| Users derive a variety of uses and gratifications from social
bodyText ||| networking sites, including traditional content gratification
bodyText ||| alongside building social capital, communication,
bodyText ||| surveillance and social networking surfing. The different
bodyText ||| uses and gratifications relate differentially to patterns of
bodyText ||| usage, with social connection gratifications tending to lead
bodyText ||| to increased frequency of use, and content gratifications to
bodyText ||| increased time spent on the site. The variety of uses to
bodyText ||| which Facebook is put by its users identifies particular
bodyText ||| challenges for the designers of such sites. For instance, a
bodyText ||| default privacy setting may be too restrictive for users
bodyText ||| seeking to meet new people, or who wish to allow new
bodyText ||| people to discover them.
bodyText ||| Since user’s desire to engage in surveillance of their peers
bodyText ||| also motivates the frequency of site visit, this also poses a
bodyText ||| unique challenge in balancing user’s privacy concerns and
bodyText ||| controls with a key raison d’être of social networking sites
bodyText ||| like Facebook. At present, Facebook allows users to
bodyText ||| manage their ‘feed’, removing ‘stories’ as they wish. This
bodyText ||| solution not only provides a degree of privacy control to
bodyText ||| users, but it also enables users to engage with the site as a
bodyText ||| self-presentation tool [26] at numerous levels – not only via
bodyText ||| their profile and network, but also through their activity
bodyText ||| (and the removal of specific ‘stories’). As perpetual contact
bodyText ||| continues to develop, designers will need to face the
page ||| 1035
note ||| CHI 2008 Proceedings · Online Social Networks	April 5-10, 2008 · Florence, Italy
bodyText ||| challenges of providing continual feeds between users, and
bodyText ||| the desire of users to control their self-representation via
bodyText ||| such sites.
sectionHeader ||| ACKNOWLEDGEMENTS
bodyText ||| Jeff Hancock, Mina Vasalou, Pam Briggs and Martin
bodyText ||| Weller are thanked for their advice and comments on an
bodyText ||| earlier draft of this paper, as are three anonymous reviewers
bodyText ||| and the associate chair.
sectionHeader ||| REFERENCES
reference ||| 1. BBC News. Web Networkers at risk of fraud. 27 July
reference ||| 2007. http://news.bbc.co.uk/1/hi/uk/6910826.stm
reference ||| 2. Boyd, D. Facebook's Privacy Trainwreck: Exposure,
reference ||| Invasion, and Social Convergence. Convergence 14, 1
reference ||| (2008).
reference ||| 3. Churchill, G. A paradigm for development of better
reference ||| measures of marketing constructs. Journal of Marketing
reference ||| Research, 16 (1979), 64-73.
reference ||| 4. Cashmore, P. MySpace hits 100 Million Accounts.
reference ||| Mashable Social Networking News, (2006). Available
reference ||| at: http://mashable.com/2006/08/09/myspace-hits-100-
reference ||| million-accounts/
reference ||| 5. Donath, J. and Boyd, D. Public displays of connection".
reference ||| BT Technology Journal, 2, 4 (2004), 71-82.
reference ||| 6. Ellison, N., Heino, R. and Gibbs, J. Managing
reference ||| Impressions Online: Self-Presentation Processes in the
reference ||| Online Dating Environment. Journal of Computer-
reference ||| Mediated Communication, 11, 2 (2006).
reference ||| 7. Ellison, N., Steinfield, C. and Lampe, C. Spatially
reference ||| Bounded Online Social Networks and Social Capital:
reference ||| The Role of Facebook. Paper presented at the annual
reference ||| meeting of the International Communication
reference ||| Association, Dresden, June 2006.
reference ||| 8. Facebook Addiction.
reference ||| http://www.facebookaddiction.com/
reference ||| 9. Flavelle, D. Worries follow rise of Facebook:
reference ||| Employers not happy with time spent on site. Toronto
reference ||| Star, May 04, 2007. Available at:
reference ||| http://www.thestar.com/Business/article/210313
reference ||| 10. ForeverGeek. Debunking the MySpace Myth of 100
reference ||| Million Users.
reference ||| http://forevergeek.com/articles/debunking_the_myspace
reference ||| _myth_of_100_million_users.php
reference ||| 11. Golder, S. A., Wilkinson, D. and Huberman, B.A.
reference ||| Rhythms of Social Interaction: Messaging within a
reference ||| Massive Online Network 3rd International Conference
reference ||| on Communities and Technologies, (2007).
reference ||| 12. Gonzalez, N. Facebook users up 89% over last year;
reference ||| Demographic shift (2007).
reference ||| http://www.techcrunch.com/2007/07/06/facebook-users-
reference ||| up-89-over-last-year-demographic-shift/
reference ||| 13. Gross, R. and Acquisti, A. Information Revelation and
reference ||| Privacy in Online Social Networks. In Workshop on
reference ||| Privacy in the Electronic Society, ACM Press (2005).
reference ||| 14. Joinson, A.N. & Paine, C.B. Self-Disclosure, Privacy
reference ||| and the Internet. In A.N Joinson, K.Y.A McKenna, T.
reference ||| Postmes and U-D. Reips (Eds). Oxford Handbook of
reference ||| Internet Psychology (pp. 237-252). Oxford University
reference ||| Press (2007).
reference ||| 15. Katz, J.E., and Aakhus, M.A. (Eds.). Perpetual contact:
reference ||| mobile communication, private talk, public
reference ||| performance. New York: Cambridge University Press
reference ||| (2002).
reference ||| 16. Lampe, C., Ellison, N. and Steinfield, C. A Face(book)
reference ||| in the Crowd: Social Searching vs. Social Browsing. In
reference ||| proceedings of ACM Special Interest Group on
reference ||| Computer-Supported Cooperative Work, ACM Press
reference ||| (2006), 167 – 170.
reference ||| 17. Lampe, C., Ellison, N. and Steinfield, C. A Familiar
reference ||| Face(book): Profile Elements as Signals in an Online
reference ||| Social Network. In Proc. CHI 2007, ACM Press (2007),
reference ||| 435-444.
reference ||| 18. McGuire, W.J. Psychological motives and
reference ||| communication gratification (pp. 167-196). In J.Blunder
reference ||| & E. Katz (Eds.), The uses of mass communications:
reference ||| Current perspectives on gratifications research. Beverly
reference ||| Hills, CA: Sage (1974).
reference ||| 19. Nielsen//NetRatings. Facebook and Bebo: The assault
reference ||| on MySpace. Available from: http://www.nielsen-
reference ||| netratings.com/pr/pr_070628_UK.pdf
reference ||| 20. Rawstorne, T. How paedophiles prey on MySpace
reference ||| children. Daily Mail (UK), 21 July 2006. Available at:
reference ||| http://www.dailymail.co.uk/pages/live/femail/article.ht
reference ||| ml?in_article_id=397026&in_page_id=1879
reference ||| 21. http://sambrook.typepad.com/sacredfacts/2007/06/faceb
reference ||| ook.html
reference ||| 22. Saucier, G. Mini-markers: A brief version of Goldberg’s
reference ||| unipolar big-five markers. Journal of Personality
reference ||| Assessment, 63, (1994), 506–516.
reference ||| 23. Stafford, T.F., Stafford, M.R., & Schkade, L.L.
reference ||| Determining uses and gratifications for the internet.
reference ||| Decision Sciences, 35, (2004), 259–288.
reference ||| 24. Twitter. http://www.twitter.com
reference ||| 25. Wellman B and Gulia M. The network basis of social
reference ||| support: A network is more than the sum of its ties, in
reference ||| Wellman B (Ed): ‘Networks in the Global Village’,
reference ||| Boulder, CO, Westview Press (1999).
reference ||| 26. Walther, J.B., Van Der Heide, B., Kim, S-Y.,
reference ||| Westerman, D., Tong, S.T. The role of friends’
reference ||| appearance and behavior on evaluations of individuals
reference ||| on Facebook: Are we known by the company we keep?
reference ||| Human Communication Research, (in press).
page ||| 1036

note ||| CHI 2008 Proceedings · Am I Safe	April 5-10, 2008 · Florence, Italy
title ||| Sesame: Informing User Security Decisions
title ||| with System Visualization
author ||| Jennifer Stoll, Craig S Tashman, W. Keith Edwards, Kyle Spafford
affiliation ||| Georgia Institute of Technology, School of Interactive Computing
address ||| Atlanta, Georgia 30332
email ||| jstoll@gatech.edu, {craig, keith, kyle}@cc.gatech.edu
sectionHeader ||| ABSTRACT
bodyText ||| Non-expert users face a dilemma when making security
bodyText ||| decisions. Their security often cannot be fully automated
bodyText ||| for them, yet they generally lack both the motivation and
bodyText ||| technical knowledge to make informed security decisions
bodyText ||| on their own. To help users with this dilemma, we present a
bodyText ||| novel security user interface called Sesame. Sesame uses a
bodyText ||| concrete, spatial extension of the desktop metaphor to
bodyText ||| provide users with the security-related, visualized system-
bodyText ||| level information they need to make more informed deci-
bodyText ||| sions. It also provides users with actionable controls to
bodyText ||| affect a system's security state. Sesame graphically facili-
bodyText ||| tates users' comprehension in making these decisions, and
bodyText ||| in doing so helps to lower the bar for motivating them to
bodyText ||| participate in the security of their system. In a controlled
bodyText ||| study, users with Sesame were found to make fewer errors
bodyText ||| than a control group which suggests that our novel security
bodyText ||| interface is a viable alternative approach to helping users
bodyText ||| with their dilemma.
keyword ||| Author Keywords: Security usability, security interface
keyword ||| design, system visualization
category ||| ACM Classification: H.5.2 User Interfaces, User-centered
category ||| design; K.6.5 Management of Computing and Information
category ||| Systems: Security and Protection
sectionHeader ||| INTRODUCTION
bodyText ||| “AVG Update downloader is trying to access the Internet”
bodyText ||| “The firewall has blocked Internet access to your computer
bodyText ||| [FTP] from 192.168.0.105 [TCP Port 57796, Flags: S]”
bodyText ||| “[Your] AntiSpyware has detected that the Windows Net-
bodyText ||| BIOS Messenger Service is currently running. (This service
bodyText ||| should not be confused with the peer-to-peer Windows
bodyText ||| Messenger service, or MSN Messenger service which are
bodyText ||| used for Internet Chat). Beginning with Windows XP
bodyText ||| Service Pack 2, the Windows NetBIOS Messenger service...
bodyText ||| ...What would you like to do?”
copyright ||| Permission to make digital or hard copies of all or part of this work for
copyright ||| personal or classroom use is granted without fee provided that copies are
copyright ||| not made or distributed for profit or commercial advantage and that copies
copyright ||| bear this notice and the full citation on the first page. To copy otherwise,
copyright ||| or republish, to post on servers or to redistribute to lists, requires prior
copyright ||| specific permission and/or a fee.
note ||| CHI 2008, April 5–10, 2008, Florence, Italy.
copyright ||| Copyright 2008 ACM 978-1-60558-011-1/08/04...$5.00.
bodyText ||| The above are examples of actual alerts [15] that users are
bodyText ||| given from their anti-virus, anti-spyware and firewall tools.
bodyText ||| While some alerts are purely informational, most require
bodyText ||| users to make a decision. The choices they face are often
bodyText ||| “Always”, “This one time” or “Never,” posing the quandary
bodyText ||| of whether to suffer through even more messages or perform
bodyText ||| an action that may be irreversible. Further, the information
bodyText ||| given to help users make these decisions is often highly
bodyText ||| technical or vague (e.g., “Destination IP: 192.168.0.1:
bodyText ||| DNS” or “This program has changed since the last time it
bodyText ||| ran!”). Even when tools have a “More Info” button to
bodyText ||| provide access to more detailed information, that information
bodyText ||| is often confusing as well.
bodyText ||| How do users cope with such security decisions? Some turn
bodyText ||| to online research in an attempt to comprehend the alerts.
bodyText ||| This strategy is evident in the multitude of online forums
bodyText ||| where users ask questions, sharing their collective wisdom
bodyText ||| about such decisions (e.g., antionline.com or fo-
bodyText ||| rumz.tomshardware.com). In contrast, some cope by simply
bodyText ||| ignoring pop-ups or warnings from their security tools [20].
bodyText ||| In fact some security books even advise users to turn off the
bodyText ||| annoying alerts; for example, one self-help security book
bodyText ||| quips, “the [stop alerts] button should say Shut Up, You are
bodyText ||| Driving Me Crazy” [15].
bodyText ||| Simply put, users are asked to make decisions about things
bodyText ||| they do not understand, based on information that is difficult
bodyText ||| to comprehend. The poor decision making that (expectedly)
bodyText ||| is an outcome of this can result in dire consequences [18],
bodyText ||| including phishing attacks, bot infestations, and various
bodyText ||| forms of malware
bodyText ||| End-user security decisions present a troubling dilemma. On
bodyText ||| the one hand, because users must be involved in deciding
bodyText ||| how to balance security risks against the work they want to
bodyText ||| accomplish, many of these decisions are impossible to
bodyText ||| effectively automate [2, 3, 4, 5, 6] (e.g., as in the case of
bodyText ||| personal firewalls). On the other hand, the users who must
bodyText ||| make these decisions are generally uninterested in security as
bodyText ||| an end in itself [18] and, as noted, often have little useful
bodyText ||| information to help them make good decisions [4, 16].
bodyText ||| Further, most of these decisions require a level of technical
bodyText ||| knowledge not possessed by most end-users. The key ques-
bodyText ||| tion this paper then explores is: since users must make
bodyText ||| security decisions (in particular, ones requiring system-level
bodyText ||| knowledge), how can we help them understand their system
bodyText ||| well enough to make better-informed security choices?
page ||| 1045
note ||| CHI 2008 Proceedings · Am I Safe	April 5-10, 2008 · Florence, Italy
figureCaption ||| Figure 1: The Sesame ‘Behind-the-Scenes’ View running on a live system
bodyText ||| We explore this issue of informed security decision making
bodyText ||| through Sesame, an interactive, visual, firewall-like tool
bodyText ||| designed to assist non-experts in making better informed
bodyText ||| security decisions. Sesame addresses threats similar to those
bodyText ||| of consumer firewalls, but uses a visual, direct manipulation
bodyText ||| interface that exposes system-level information in a meaning-
bodyText ||| ful, comprehensible way. To this end, Sesame provides users
bodyText ||| a ‘behind-the-scenes’ view of their computer, integrating
bodyText ||| existing elements of the desktop UI (such as windows) with
bodyText ||| previously hidden systems-level components (such as the
bodyText ||| processes that own those windows, the network connections
bodyText ||| those processes are making, and so forth). Essentially, the
bodyText ||| desktop metaphor is extended to convey system-level con-
bodyText ||| cepts in terms of their relationship to familiar desktop-level
bodyText ||| abstractions. We conjecture that this view can help to inform
bodyText ||| user security decisions and, by lowering barriers to this
bodyText ||| information, may help to motivate them as well [18].
bodyText ||| Our initial study results suggest that this behind-the-scenes
bodyText ||| view of their system’s underlying architecture seems to help
bodyText ||| users make better security decisions involving system-level
bodyText ||| knowledge. In the sections that follow, we briefly survey
bodyText ||| current research and commercial security tools. We then
bodyText ||| describe the design of the Sesame UI and present the results
bodyText ||| of our user study. We conclude with a discussion of our
bodyText ||| study results and implications for future work.
sectionHeader ||| RELATED WORK
bodyText ||| While there are many security tools available, few are
bodyText ||| designed specifically to support end-users in their security
bodyText ||| decision making process. However, of the tools available for
bodyText ||| security decision making, many can be grouped into two
bodyText ||| categories: those for expert users and those for non-experts.
subsectionHeader ||| Experts
bodyText ||| Visualization tools: The majority of prior research focuses on
bodyText ||| visualization-based approaches intended for the expert user.
bodyText ||| While inappropriate for non-experts, they do illustrate types
bodyText ||| of information that experts find useful in order to detect
bodyText ||| security problems and make informed decisions with regard
bodyText ||| to security. For example, many of these tools support moni-
bodyText ||| toring of network connections; these include Rumint, IDS
bodyText ||| Rainstorm, VisAlert [7], and others that provide experts with
bodyText ||| a variety of useful network data representations [1]. How-
bodyText ||| ever, these tools are highly technical and complex
bodyText ||| (presenting data at the level of individual packets), and do
bodyText ||| not integrate with, or build on, existing metaphors of the
bodyText ||| desktop GUI.
bodyText ||| Text-based tools: Another set of very common tools provides
bodyText ||| extensive system behavior and status information in a text-
bodyText ||| based approach. Although these systems often ship on
bodyText ||| consumer computing platforms, they are generally intended
bodyText ||| for knowledgeable users or even system- or network-
bodyText ||| administrators. These include tools like ProcessExplorer,
bodyText ||| tcpview, and Windows Task Manager [22]. Again, these
bodyText ||| tools present system-level information useful in making
bodyText ||| informed security decisions. However, they convey informa-
bodyText ||| tion in a piecemeal fashion (different tools for different
bodyText ||| information), leaving users to assimilate and make sense of
bodyText ||| it; and the textual presentation neither supports visual meta-
bodyText ||| phors nor integrates with the existing and well-known
bodyText ||| features of the desktop UI.
subsectionHeader ||| Non-Experts
bodyText ||| In contrast to the wealth of tools available for network and
bodyText ||| security professionals, research in the area of supporting
page ||| 1046
note ||| CHI 2008 Proceedings · Am I Safe	April 5-10, 2008 · Florence, Italy
bodyText ||| security decision making for end users remains nascent [4,
bodyText ||| 18]. Discussed below are two classes of such tools.
bodyText ||| Tools for specific activities: Some tools for non-experts
bodyText ||| provide support only for security decisions that relate to a
bodyText ||| specific user activity, e.g., browsing, searching, making
bodyText ||| online transactions, sharing files, and so forth [2, 3, 21]. For
bodyText ||| example, Web Wallet [19] can be used to ensure that a user’s
bodyText ||| information will be sent to the desired site rather than to a
bodyText ||| spoof. While these tools help support security decisions in
bodyText ||| the context of a specific activity, they do not address the
bodyText ||| range of ‘system level’ security situations that are independ-
bodyText ||| ent of what the user is doing. Consequently, security
bodyText ||| decisions which do not map to a specific activity are largely
bodyText ||| overlooked by these tools. For example, a spyware or bot
bodyText ||| infection can severely endanger a user’s privacy and security
bodyText ||| regardless of what actions the user is performing [13,9].
bodyText ||| Further, since different tools are employed for different
bodyText ||| activities, the level of security, as well as the user interface,
bodyText ||| can easily be inconsistent. This is not to say that security
bodyText ||| tools are only effective if they support all security decisions
bodyText ||| across all activities, but rather that activity-specific tools are
bodyText ||| not a complete answer to end-user security.
bodyText ||| Tools for specific threats: Other tools provide support for
bodyText ||| user decisions based on specific types of threats such as anti-
bodyText ||| phishing toolbars, anti-virus, -adware, and –spyware sys-
bodyText ||| tems. These tools tend to be based on heuristics or black lists
bodyText ||| and will only provide protection for against attacks matching
bodyText ||| their heuristics or that are on their lists. Users must con-
bodyText ||| stantly update these tools in order for them to be effective;
bodyText ||| and the way in which they alert users to problems is also
bodyText ||| problematic, as evidence shows that users often find the
bodyText ||| information in these alerts to be difficult to understand and so
bodyText ||| ignore them [20, 4].
bodyText ||| Consumer firewalls are perhaps the most common types of
bodyText ||| security software that involves explicit user decision-making.
bodyText ||| These systems protect against a range of network-based
bodyText ||| attacks, such as worms that exploit software vulnerabilities.
bodyText ||| These systems are not task-specific, but present system-level
bodyText ||| information in a way that is often undecipherable to users
bodyText ||| (e.g., describing connection attempts in terms of process
bodyText ||| names, IP addresses, and port numbers). Users therefore
bodyText ||| have little actionable information on which to base security
bodyText ||| decisions when faced with firewall popups.
bodyText ||| Thus, there are few systems that attempt to provide users
bodyText ||| with a framework for making security decisions that are not
bodyText ||| tied directly to a specific activity, but instead help with
bodyText ||| overall system security. Our goal with Sesame is to fill this
bodyText ||| void; to provide general, firewall-like security (not, for
bodyText ||| example, detecting of malware at the point of installation),
bodyText ||| while helping users to make informed decisions. We focused
bodyText ||| specifically on handling common classes of attacks where
bodyText ||| user action is necessary to determine the correct course of
bodyText ||| action. These include situations where there is no universally
bodyText ||| correct action, but rather a tradeoff between security and
bodyText ||| convenience that the user must consider, or situations where
bodyText ||| the correct action is dependent on context outside of the
bodyText ||| system. Thus, unlike current firewalls—which convey
bodyText ||| systems-related information textually, using low-level
bodyText ||| technical details—Sesame provides a holistic graphical
bodyText ||| representation of security-related system information in a
bodyText ||| way designed to be understandable by end-users. Sesame
bodyText ||| also provides a means for exploration of the underlying
bodyText ||| system, allowing it be used for a greater range of purposes
bodyText ||| than traditional consumer firewalls.
sectionHeader ||| DESIGN PROCESS
bodyText ||| In this section we discuss our iterative design process and
bodyText ||| choice of the representational paradigm for Sesame.
subsectionHeader ||| Representational Paradigm
bodyText ||| Our overarching goal with Sesame is to convey a visual
bodyText ||| model that allows security-related system information to be
bodyText ||| meaningfully interpreted by the user. To do so, we chose a
bodyText ||| direct manipulation, model-world paradigm, as this is known
bodyText ||| to have significant benefits for learnability [8]. Within this
bodyText ||| interface we sought to 1) show how important but unfamiliar
bodyText ||| abstractions (e.g., processes and networks) relate to abstrac-
bodyText ||| tions that are familiar and meaningful to users (e.g., windows
bodyText ||| and real-world places); and 2) provide users with actionable
bodyText ||| controls that enable them to affect their security state using
bodyText ||| the information given.
bodyText ||| We believed a spatial, direct-manipulation interface would
bodyText ||| yield a number of important benefits, the first of which is to
bodyText ||| leverage existing knowledge. Our target, non-expert user
bodyText ||| already typically interacts with the computer through the
bodyText ||| spatial metaphor of the desktop GUI, which allows us to
bodyText ||| leverage that experience to convey other, more complex
bodyText ||| relationships via a similar spatial GUI. More subtly though,
bodyText ||| desktop objects are familiar and meaningful to users; by
bodyText ||| employing an interface that is metaphorically compatible
bodyText ||| with the desktop, it should be easier to represent relationships
bodyText ||| between esoteric security abstractions and the familiar
bodyText ||| windows and things found on the desktop. The second
bodyText ||| reason to use a visual representation is speed. The human
bodyText ||| visual system has an enormous facility for the rapid assess-
bodyText ||| ment of visual scenes [ 14]. By presenting data in this way, as
bodyText ||| opposed to a more verbose text-based approach, we hope to
bodyText ||| minimize the time users need to assess their security situation
bodyText ||| in any particular instance—thereby reducing one of the
bodyText ||| known barriers to user motivation for understanding security
bodyText ||| [18].
subsectionHeader ||| Information Content
bodyText ||| Portraying all low-level information about the state of the
bodyText ||| user’s system would not only potentially be overwhelming,
bodyText ||| but also likely unnecessary for protection against the classes
bodyText ||| of threats we are targeting. Thus, we do not attempt to depict
bodyText ||| all possible system information, but focus instead on a
bodyText ||| smaller subset selected through an analysis of whether the
bodyText ||| information is both practically accessible and relevant in
bodyText ||| addressing the common types of security threats we are
bodyText ||| targeting (spyware, phishing, and bot infections).
page ||| 1047
note ||| CHI 2008 Proceedings · Am I Safe	April 5-10, 2008 · Florence, Italy
bodyText ||| Thus, the information we depict includes:
listItem ||| •	Process characteristics, including depictions of which
listItem ||| windows are associated with a given process, average and
listItem ||| current CPU usage, putative vendor, whether that vendor
listItem ||| can be confirmed, and process installation date;
listItem ||| •	Network characteristics, including incoming and outgoing
listItem ||| connections;
listItem ||| •	Remote systems, including domain, putative owning
listItem ||| organization, and putative geographical location.
bodyText ||| Although far from comprehensive, the above data set pro-
bodyText ||| vides enough information to identify and potentially mitigate
bodyText ||| many variants of the three types of attacks on which we
bodyText ||| focus. Spyware, for example, could be identified by routine
bodyText ||| attempts at establishing connections from suspicious proc-
bodyText ||| esses targeted at suspicious remote servers. A bot infection
bodyText ||| could be detected similarly, except in some cases the remote
bodyText ||| systems would be initiating the connections. In this sense,
bodyText ||| Sesame goes further than current firewalls, enabling users to
bodyText ||| proactively explore security risks. For example, some phish-
bodyText ||| ing scams could be identified by observing one’s web
bodyText ||| browser connecting to servers that appear unaffiliated with
bodyText ||| the nominal proprietor of the website. We used situations
bodyText ||| like these to evaluate Sesame as described below in our User
bodyText ||| Study section.
subsectionHeader ||| Formative Study
bodyText ||| To get feedback on potential approaches for visual presenta-
bodyText ||| tion and terminology, we conducted a small formative study
bodyText ||| early in our design process. This formative study was in-
bodyText ||| tended to provide feedback on (1) user preferences with
bodyText ||| respect to concrete versus abstract representations of system
bodyText ||| information, (2) ability of users to decipher relationships
bodyText ||| among system information, and (3) preferred terminology for
bodyText ||| technical concepts. We showed three users paper prototypes
bodyText ||| of two designs, one using a concrete, spatial visualization
bodyText ||| similar to that of figure 1, and another using more a more
bodyText ||| abstract presentation. Participants overwhelmingly preferred
bodyText ||| the more concrete representation, and understood many of
bodyText ||| the relationships being conveyed (such as relationships
bodyText ||| between processes and windows) without explanation by the
bodyText ||| experimenters.
bodyText ||| This brief, early study was also helpful in revealing what
bodyText ||| participants did not understand. For example, participants
bodyText ||| had difficulty understanding that a part of the visualization
bodyText ||| represented physically remote computers on the Internet. Our
bodyText ||| discussions with participants also informed a number of
bodyText ||| elements of our final design, such as the use of geographic
bodyText ||| maps to suggest remoteness. Other feedback led to signifi-
bodyText ||| cant changes in the arrangement of processes used in the
bodyText ||| final version of Sesame. Finally, an additional discovery we
bodyText ||| made during the formative study was that the term ‘process’
bodyText ||| caused significant confusion for our non-technical users.
bodyText ||| Based on participant feedback, we chose the term ‘engine’ as
bodyText ||| one that made more sense to them. (We acknowledge,
bodyText ||| however, that using such non-standard terms may confuse
bodyText ||| the more ‘technical’ users.)
sectionHeader ||| SESAME: EXTENDING THE DESKTOP
bodyText ||| In this section we describe how the system level information
bodyText ||| is presented in Sesame, and the controls given to users for
bodyText ||| interacting with the tool.
subsectionHeader ||| Invocation - Getting ‘behind-the-scenes’
bodyText ||| Among the first design choices we faced was deciding where
bodyText ||| to place Sesame in relation to the desktop. Our requirement
bodyText ||| to connect existing elements (such as windows) to Sesame-
bodyText ||| provided elements (such as processes) meant that the tool
bodyText ||| somehow had to be integrated into the desktop. However it
bodyText ||| could not appear to be ‘just another application’ running on
bodyText ||| the desktop, because we needed to convey that Sesame is a
bodyText ||| level of abstraction ‘below’ the conventional GUI.
bodyText ||| To resolve this challenge, users can access Sesame either by
bodyText ||| invoking the always-present “Open Sesame” button on the
bodyText ||| desktop, or through a dialog box that appears when Sesame
bodyText ||| needs to interact with the user—for example, when a process
bodyText ||| requests a connection (the user may ignore the dialog box if
bodyText ||| they do not wish to respond). When Sesame is invoked, the
bodyText ||| user’s desktop GUI rotates about the vertical axis to reveal
bodyText ||| the processes, networks, and other system-level elements
bodyText ||| behind it (Figure 1). To exit from the view, users click the
bodyText ||| exit button at the top of the screen. A benefit of this smooth
bodyText ||| rotation effect is that it provides a continuous transition from
bodyText ||| the desktop interface to Sesame to keep users from becoming
bodyText ||| disoriented.
bodyText ||| Rotating the entire desktop to display the Sesame visualiza-
bodyText ||| tion raises several problems. The first is that a full-screen
bodyText ||| visualization is heavyweight, and may dissuade users from
bodyText ||| invoking it when they do not have to. It further means that
bodyText ||| the user cannot have the Sesame visualization visible while
bodyText ||| performing other tasks. These issues of motivation and
bodyText ||| efficiency may be important to explore in the future, but at
bodyText ||| this stage we are principally concerned with effective infor-
bodyText ||| mation representation. A full screen visualization helps us
bodyText ||| with this by offering conceptual advantages in showing the
bodyText ||| desktop/system-level separation, as well as the practical
bodyText ||| advantages of providing abundant space for the system-level
bodyText ||| components we wish to show.
subsectionHeader ||| Division of Space
bodyText ||| Once behind the desktop, we faced another design challenge.
bodyText ||| The effect of rotating the desktop is intended to suggest that
bodyText ||| the revealed objects are part of the user’s PC. Yet to convey
bodyText ||| abstractions such as remote computers, we also needed to
bodyText ||| represent areas that lie outside the user’s PC. Thus, Sesame
bodyText ||| provides a clean division where one side of the visualization
bodyText ||| (furthest from the rotated desktop) contains all external
bodyText ||| elements such as remote computers, and the other side
bodyText ||| (containing the rotated desktop) represents the internal
bodyText ||| elements of the user’s PC; both regions are labeled and are
bodyText ||| colored differently to emphasize the distinction.
subsectionHeader ||| Visual Elements
bodyText ||| In addition to the rotated desktop, the Sesame visualization
bodyText ||| contains several distinct types of visual elements: proc-
bodyText ||| esses, remote computers and connection requests. As
page ||| 1048
note ||| CHI 2008 Proceedings · Am I Safe	April 5-10, 2008 · Florence, Italy
bodyText ||| shown in Figure 1, blue cubes (representing window-
bodyText ||| owning processes) are connected via arrows to each of the
bodyText ||| windows on the rotated desktop. Directly beneath them are
bodyText ||| the non-window-owning processes, referred to as ‘back-
bodyText ||| ground’ processes. On the right, in the ‘external’ region,
bodyText ||| are representations of remote computers that are connected
bodyText ||| via arrows to the process with which they are communicat-
bodyText ||| ing. However, before the remote computers can connect to
bodyText ||| the user’s system, a connection request is given to the user
bodyText ||| with options to ‘Allow’ or ‘Forbid’ the connection. Also, in
bodyText ||| the lower right corner is a ‘More Info’ space providing
bodyText ||| brief descriptions when the user hovers over the various
bodyText ||| visual elements.
subsubsectionHeader ||| Processes
bodyText ||| Processes are arranged either floating parallel to the rotated
bodyText ||| desktop or lying on the ground, depending on whether they
bodyText ||| own windows (‘foreground’ processes) or not (‘back-
bodyText ||| ground’). To highlight the difference between them, the
bodyText ||| foreground processes are larger and in blue; the back-
bodyText ||| ground processes are smaller and in green. This difference
bodyText ||| in representation was the result of our earlier formative
bodyText ||| user studies: we found that users preferred significant
bodyText ||| visual differences between the process types.
bodyText ||| To avoid deluging users with processes, only certain ones
bodyText ||| are shown: 1) we show all processes that own windows as
bodyText ||| we want to suggest to users that all of their interaction with
bodyText ||| the computer is mediated by processes; 2) we show all
bodyText ||| processes that have ever connected to the network; and 3)
bodyText ||| we cull any process that is a known-safe component of the
bodyText ||| Windows OS, unless it is being controlled by another,
bodyText ||| untrusted process.
bodyText ||| Much of the security-related, system information provided
bodyText ||| is actually conveyed with the process cube. On its face is
bodyText ||| the name of the executable from which it was started.
bodyText ||| There is also a small square, a rectangular bar graph, and a
bodyText ||| gauge (Figure 2a). The colored square indicates whether
bodyText ||| the vendor of the executable could be verified (green for
bodyText ||| yes, yellow for no); the bar graph indicates how long the
bodyText ||| executable has been installed on the user’s system; and the
bodyText ||| gauge indicates both current and average CPU usage.
bodyText ||| These three indicators provide users with a fast way of
bodyText ||| judging if a process is behaving abnormally. Part of Ses-
bodyText ||| ame’s design intent is to help users identify abnormal
bodyText ||| behavior by developing a sense of what normal behavior
bodyText ||| looks like via the three indicators. To augment their ability
bodyText ||| to have a sense of ‘normal’ and in keeping with the safe-
bodyText ||| staging principle [17], we also use in-place semantic
bodyText ||| zooming, allowing users to learn more information when
bodyText ||| they want. When users hover over a process cube with the
bodyText ||| mouse, it expands slightly to show small explanatory text
bodyText ||| labels next to each of the glyphs on the cube’s face (Figure
bodyText ||| 2b). To obtain an even more complete explanation, users
bodyText ||| can click the cube, expanding it to a full-sized representa-
bodyText ||| tion, which also contains an editable list of security policies
bodyText ||| applied to the process (Figure 2c). Consequently, users can
figureCaption ||| Figure 2a: unexpanded	Figure 2b: view of process
figureCaption ||| process	when hovered over
figureCaption ||| Figure 2c: process when clicked upon
figureCaption ||| Figure 3b: Process-to-remote system arrow
bodyText ||| visually determine whether a given process’ characteristics
bodyText ||| are unusual, then zoom in to learn what they actually mean.
bodyText ||| Coming out from the edges of processes are wide arrows
bodyText ||| joining them to the windows they own and the remote
bodyText ||| computers with which they are communicating (Figures 3a,
bodyText ||| 3b). The intention here is to connect—both conceptually
bodyText ||| and diagrammatically—concepts in the Sesame interface
bodyText ||| with familiar related concepts on the user’s desktop and in
bodyText ||| the real world. The arrows are rendered in bright colors
bodyText ||| with an extruded, gradated appearance to draw attention
bodyText ||| and make them feel concrete. We chose double-headed
bodyText ||| arrows to imply that information flows both ways.
subsubsectionHeader ||| Remote Computers
bodyText ||| The remote computers that act as either servers or, less
bodyText ||| likely, clients to the user’s computer are represented as
bodyText ||| stacked rectangular tiles on the right of the screen. In
bodyText ||| earlier versions of Sesame, we tried to depict the remote
bodyText ||| computers as actual concrete renderings of computers; but
bodyText ||| as it was not clear to users that these were separate from
bodyText ||| their PCs. Users tended to feel that a better way to suggest
bodyText ||| distantness would be to use maps, which prompted us to
bodyText ||| render remote computers as abstract map images overlaid
bodyText ||| with pointers to the putative location of the remote system.
bodyText ||| The arrows leading from the processes to the remote
bodyText ||| system tiles terminate over the geography of the remote
bodyText ||| system, and the panels include a textual description (e.g.,
bodyText ||| “Remote computer owned by XYZ Corp”).
bodyText ||| Figure 3a: Process-to-window arrow
page ||| 1049
note ||| CHI 2008 Proceedings · Am I Safe	April 5-10, 2008 · Florence, Italy
figureCaption ||| Figure 4: expanded remote system tile
bodyText ||| As with processes, remote system tiles also allow semantic
bodyText ||| zooming. When the mouse hovers over a tile, it expands to
bodyText ||| reveal the domain, owner, and more precise geographic
bodyText ||| location associated with the remote system; the information
bodyText ||| is obtained via a reverse DNS lookup and query of a WHOIS
bodyText ||| database of domain registrations (Figure 4).
subsubsectionHeader ||| Connection Requests
bodyText ||| When an attempt is made to establish a new incoming or
bodyText ||| outgoing connection, the firewall component of the Sesame
bodyText ||| backend intercepts the request and Sesame asks the user for
bodyText ||| permission. Sesame represents the connection attempt by
bodyText ||| showing a double headed arrow between the local process
bodyText ||| and remote system tile, but the arrow is solid only on the side
bodyText ||| initiating the request, with the other end of the arrow dotted
bodyText ||| (Figure 5). There is a gap between the two ends of the arrow
bodyText ||| to suggest that they could be, but are not yet, connected. To
bodyText ||| make the user’s options more clear, the buttons where the
bodyText ||| user can accept or forbid the request appear at this
bodyText ||| solid/dotted junction. In order to draw the user’s attention to
bodyText ||| the choice, the red border around the buttons flashes for
bodyText ||| several seconds after Sesame is invoked. To ensure that users
bodyText ||| see the process associated with the connection request, a
bodyText ||| border flashes around it as well.
bodyText ||| Like current firewalls, Sesame allows the user to set policies
bodyText ||| for allowing or denying connections; but unlike most fire-
bodyText ||| walls, we try to make changes affecting future policy
bodyText ||| obvious by representing policies concretely, and visually
bodyText ||| associating them with the objects to which they apply. When
bodyText ||| the user selects the ‘accept’ or ‘forbid’ buttons, a policy
bodyText ||| dialog box is shown animating out of the relevant process
bodyText ||| cube and expanding to full size on screen. The user can
bodyText ||| select from four policy choices, allowing or denying connec-
bodyText ||| tions on a one time basis or indefinitely, and with respect to
bodyText ||| any remote computer or just those associated with a particu-
bodyText ||| lar domain. Once the user confirms their policy choice, the
bodyText ||| selected policy (represented as a card) is animated to disap-
bodyText ||| pear directly into the associated process, conveying that the
bodyText ||| policy is ‘inside’ that cube and is later accessible from it.
subsectionHeader ||| Usage Scenarios
bodyText ||| To demonstrate how Sesame might be used, we include two
figureCaption ||| Figure 5: Remote computer requesting connection to local
figureCaption ||| process.
bodyText ||| usage scenarios in which we show similar situations, one
bodyText ||| where the appropriate action is to allow a connection so that
bodyText ||| the user can continue with her task; and one where the
bodyText ||| appropriate action is to deny it in order to fend off an attack.
bodyText ||| In the first, the user is asked to answer an explicit question
bodyText ||| by Sesame about whether to allow access to a remote system.
bodyText ||| In the second, the user invokes Sesame herself to try to
bodyText ||| decide whether a website is fraudulent.
subsubsectionHeader ||| Scenario 1: Should I allow this connection?
bodyText ||| In the first scenario, the user is browsing a web page contain-
bodyText ||| ing an embedded video. Upon selecting the ‘Play’ button in
bodyText ||| the embedded video player, Sesame brings up a dialog box
bodyText ||| indicating a remote computer is trying to initiate communica-
bodyText ||| tion with a local process, and the user is directed to click a
bodyText ||| button in the dialog box to open Sesame. When clicked, the
bodyText ||| user’s screen rotates to reveal that the process, to which the
bodyText ||| remote system is trying to connect, is the same process that is
bodyText ||| running her web browser. Noting the temporal coincidence
bodyText ||| between selecting the ‘Play’ button and the appearance of the
bodyText ||| dialog box, she suspects that the new connection is needed to
bodyText ||| allow the video to play. Unsure if watching the video is
bodyText ||| worth the risk of letting a remote system connect to her
bodyText ||| computer, she hovers over the remote system and observes
bodyText ||| that it is owned by the same company associated with the
bodyText ||| website—a company she is familiar with and feels reasona-
bodyText ||| bly comfortable trusting. She clicks the ‘Allow’ button to
bodyText ||| permit the connection to proceed. However, as she does not
bodyText ||| feel comfortable giving the company free reign to connect to
bodyText ||| her computer, she assigns a permission card allowing the
bodyText ||| connection just once. The yellow connection arrow now
bodyText ||| becomes completely solid and the user clicks the ‘Exit and
bodyText ||| Return to Windows’ button which rotates her desktop back
bodyText ||| to its normal position and the video plays as expected.
subsubsectionHeader ||| Scenario 2: Is this a phishing site?
bodyText ||| In the second scenario, we begin with a user who is directed
bodyText ||| to a website claiming to be affiliated with their bank. When
bodyText ||| the site asks for personal information, the user becomes
bodyText ||| suspicious and invokes Sesame. Sesame shows the rotated
bodyText ||| desktop allowing the user to see which process is connected
bodyText ||| to their web browser window. They notice that the same
bodyText ||| process is connected to one remote computer. The small map
bodyText ||| shows that the remote computer is located in an unfamiliar
bodyText ||| geography and the name of the owner of the remote com-
bodyText ||| puter seems unrelated to the user’s bank. Still uncertain, the
bodyText ||| user moves their mouse to the remote computer to find out
bodyText ||| more information. When the mouse hovers over the remote
bodyText ||| system, it zooms to show it is associated with an unknown
bodyText ||| domain, and located at an address in a distant country. The
bodyText ||| user becomes concerned that they may not really have visited
bodyText ||| their bank’s website, and therefore closes their browser and
bodyText ||| calls the bank.
sectionHeader ||| IMPLEMENTATION
bodyText ||| Sesame is implemented in C++ and runs on unmodified
bodyText ||| Microsoft Windows XP. All screenshots in this paper were
bodyText ||| taken from live execution of the system. The front-end
page ||| 1050
note ||| CHI 2008 Proceedings · Am I Safe	April 5-10, 2008 · Florence, Italy
bodyText ||| interface of the system uses the standard windows GDI to
bodyText ||| render most graphics, with GDI+ used for more complex
bodyText ||| effects, such as the gradient fills on the extruded arrows. The
bodyText ||| front-end also includes a series of hooks allowing it to be
bodyText ||| driven from synthetic data sets, as this capability was neces-
bodyText ||| sary for our user study. In order to modify the datasets in real
bodyText ||| time, Sesame registers several global hotkeys allowing us to
bodyText ||| use a second keyboard to control the data Sesame shows to
bodyText ||| study participants. The Sesame front-end gathers process list
bodyText ||| data; the back-end is used to retrieve network status. It also
bodyText ||| includes a simple open-source firewall that is used to inter-
bodyText ||| cept attempts at initiating network connections, and performs
bodyText ||| reverse-DNS and WHOIS lookups to obtain information
bodyText ||| about remote systems. As we did not need complete func-
bodyText ||| tionality for our evaluations, certain backend features related
bodyText ||| to firewall operations, process culling, CPU usage, and
bodyText ||| vender verification were not fully implemented, but were
bodyText ||| mocked up in the front end.
sectionHeader ||| USER STUDY
bodyText ||| We conducted a study to evaluate how well users could
bodyText ||| judge potential security threats using the visualization
bodyText ||| provided by Sesame. Our primary interest was in how well
bodyText ||| users could cumulatively leverage the concepts presented in
bodyText ||| Sesame to make security-related decisions. We chose to
bodyText ||| evaluate these concepts together rather than piecemeal, as the
bodyText ||| experience of our formative study suggested that the differ-
bodyText ||| ent concepts underlying Sesame are heavily interdependent.
bodyText ||| To perform this cumulative evaluation, we asked users to
bodyText ||| make security decisions in an environment with Sesame, as
bodyText ||| well as a more conventional environment using the
bodyText ||| ZoneAlarm firewall instead. To assess users’ understanding
bodyText ||| of the different ideas in Sesame, we asked various questions
bodyText ||| about different parts of the visualization and about why users
bodyText ||| made particular choices. Note that our focus in this study was
bodyText ||| to understand how the quality of decision-making was
bodyText ||| affected by our visual interface, not on evaluating Sesame’s
bodyText ||| efficiency as a UI (whether it allows faster decision-making),
bodyText ||| or its impact on user motivation (whether it incents people to
bodyText ||| be more active in security management); we leave these as
bodyText ||| future work.
subsectionHeader ||| Participants
bodyText ||| Our study included a total of 20 participants recruited from a
bodyText ||| university campus: 45% female (9 subjects) and 55% male
bodyText ||| (11 subjects). All were undergraduate students; none were
bodyText ||| computer science or computer engineering majors, and none
bodyText ||| considered themselves to be experts in computer operation.
bodyText ||| While those pursuing undergraduate degrees may not ideally
bodyText ||| represent typical users, we found that our participants were
bodyText ||| indeed unfamiliar with basic concepts of computer operation
bodyText ||| such as processes, and security threats such as phishing. We
bodyText ||| therefore felt they were adequately representative. We used
bodyText ||| between-subjects testing, so participants were divided evenly
bodyText ||| between control and experimental groups.
subsectionHeader ||| Security Tasks
bodyText ||| To determine how well participants could identify security
bodyText ||| threats, we gave them several tasks. For each task, they
bodyText ||| effectively had to judge whether a given situation posed a
bodyText ||| security threat. The tasks were based on the types of deci-
bodyText ||| sions users must make in real world use; the first four were
bodyText ||| common personal firewall configuration decisions, the latter
bodyText ||| two required judging the authenticity of websites. The tasks
bodyText ||| included: T1) allow or forbid an incoming connection from
bodyText ||| Microsoft.com after clicking on a video player link; T2)
bodyText ||| allow or forbid an outgoing connection from a spyware
bodyText ||| process named loadsys.exe; T3) allow or forbid an incoming
bodyText ||| connection from a bot server requesting connection with a
bodyText ||| bot process named intmonp.exe; T4) allow or forbid an
bodyText ||| outgoing connection from the process named outlook.exe;
bodyText ||| T5) determine if the website claiming to be Mid America
bodyText ||| Bank is a phishing site; T6) determine if the website claiming
bodyText ||| to be CitiBank is a phishing site. T5 and T6 are intentionally
bodyText ||| similar but whereas T5 represents a threat, T6 does not—this
bodyText ||| allows us to test for false positives as well as false negatives.
bodyText ||| We balanced the tasks between situations that are triggered
bodyText ||| by user activity (T1, T5, and T6) and those with no direct
bodyText ||| relationship to the user’s actions (T2, T3, and T4).
bodyText ||| Participants performed the security tasks in either the control
bodyText ||| or the experimental environment. The control environment
bodyText ||| was made to reflect the most common configuration used by
bodyText ||| non-experts [15], a typical personal computer with the
bodyText ||| ZoneAlarm firewall. In addition to its ubiquity, we used
bodyText ||| ZoneAlarm in the control because, like Sesame, it provides
bodyText ||| firewall functions and therefore offers many of the same
bodyText ||| actionable controls, and asks many of the same questions, as
bodyText ||| Sesame. It also embodies the textual, indirect interaction
bodyText ||| paradigm employed in most end-user security tools. Further,
bodyText ||| the firewall tasks (T1-T4) were derived from actual prompts
bodyText ||| ZoneAlarm presents to users. Also, rather than use a live
bodyText ||| installation of ZoneAlarm, we made an interactive mockup
bodyText ||| using actual screenshots from ZoneAlarm alerts—this was to
bodyText ||| ensure that we could control the timing and exact content of
bodyText ||| the dialog boxes. We integrated interactive widgets into our
bodyText ||| mockup as well so that it would behave, as well as appear,
bodyText ||| virtually identical to the actual tool.
bodyText ||| Participants in the experimental group used the same system
bodyText ||| as those in the control, except that Sesame was provided in
bodyText ||| place of ZoneAlarm. Because Sesame offers an unusual user
bodyText ||| interface, we gave participants about 90 seconds to explore it
bodyText ||| before beginning the tasks. We provided no explanation
bodyText ||| about the meaning of Sesame’s behind-the-desktop visual
bodyText ||| elements; we only demonstrated how one could hover over
bodyText ||| and click on some objects to semantically zoom in on them.
bodyText ||| Similarly to ZoneAlarm and other firewalls, for tasks T1-T4,
bodyText ||| Sesame alerted the user to the security situation by bringing
bodyText ||| up a dialog box. From there the user would click a button to
bodyText ||| enter the Sesame UI. For T5-T6, the experimenter explained
bodyText ||| the situation and asked the user to click the always-present
bodyText ||| “Open Sesame” button to enter the Sesame interface.
subsectionHeader ||| Study Details
bodyText ||| As each participant began the study, they were asked a series
page ||| 1051
note ||| CHI 2008 Proceedings · Am I Safe	April 5-10, 2008 · Florence, Italy
bodyText ||| of background questions to assess their familiarity with
bodyText ||| computers and security tools. Before any tasks were pre-
bodyText ||| sented to them, participants were instructed to think aloud
bodyText ||| about what information they would be using in making their
bodyText ||| decisions. All participants used the same Dell laptop with a
bodyText ||| 15” monitor running Windows XP Home edition. An exter-
bodyText ||| nal keyboard was used by the experimenters to bring up the
bodyText ||| alerts for each security task. The participants were asked to
bodyText ||| make security decisions as if the laptop being used was their
bodyText ||| own.
bodyText ||| As discussed above, for the first security task participants
bodyText ||| were asked to download a video from the Microsoft website
bodyText ||| which caused an alert dialog box from the firewall to pop-up.
bodyText ||| After completing the first task, participants were instructed to
bodyText ||| browse to any website of their choosing. They were then
bodyText ||| presented with the next three tasks while they browsed
bodyText ||| online. Upon the completion of each task, the participant
bodyText ||| continued browsing until the next one was presented to them.
bodyText ||| We were careful during these tasks not to cause a popup to
bodyText ||| appear immediately after the user took an action (e.g.,
bodyText ||| clicking a link) so that they would not erroneously think they
bodyText ||| caused the popup in those cases where they did not. For the
bodyText ||| final two tasks, none of the participants were familiar with
bodyText ||| the term ‘phishing site’ so a brief explanation was given.
bodyText ||| Since we were assessing the intelligibility of the Sesame
bodyText ||| visualization, we declined to answer participant questions
bodyText ||| about the meanings of Sesame’s visual elements. We asked
bodyText ||| them to infer as best they could with the information given.
bodyText ||| Participants were asked to think aloud during their decision
bodyText ||| making process for the six tasks, in order to aid us in under-
bodyText ||| standing their reasoning processes. Upon completion of all
bodyText ||| tasks participants were asked follow-up questions in a semi-
bodyText ||| structured interview regarding the choices they made. We
bodyText ||| asked about the clarity of the decisions they had to make, the
bodyText ||| choices presented to them and the information provided by
bodyText ||| the security tool they used (i.e., Sesame or ZoneAlarm). We
bodyText ||| also asked for suggestions for improving the security tools.
bodyText ||| Each subject participated in the study individually and was
bodyText ||| voice recorded to capture responses to the interview ques-
bodyText ||| tions and the think aloud.
sectionHeader ||| RESULTS
bodyText ||| For each participant, we gathered the following data: 1)
bodyText ||| background information, 2) the participant’s ‘miss-rate’ for
bodyText ||| the six tasks, and 3) responses to follow-up questions regard-
bodyText ||| ing comprehension of the system information provided. We
bodyText ||| define miss-rate to be the number of potential threats the
bodyText ||| participant evaluated erroneously (i.e., judging a threatening
bodyText ||| situation to be safe or vice versa).
bodyText ||| Participant security background: Based on the background
bodyText ||| information gathered, both the control and experimental
bodyText ||| groups were similar in terms of experience with computers
bodyText ||| and security tools. Participants in the control group had an
bodyText ||| average of 10.4 years of experience using the computer and
bodyText ||| only 2 out of 10 participants did not use any security tool
bodyText ||| (e.g. Norton Anti-virus, firewalls or anti-spyware). Similarly,
bodyText ||| participants in the experimental group had an average of 9.2
bodyText ||| years of experience using the computer and 2 out of 10 did
bodyText ||| not use any security tools. Subjects in both groups were
bodyText ||| asked to briefly describe their security practices besides
bodyText ||| using security software.
bodyText ||| Based on the responses in both groups, the majority of the
bodyText ||| participants did not have or could not recall additional
bodyText ||| security practices they performed besides making occasional
bodyText ||| updates to their security software when alerted to do so by
bodyText ||| their tools. Further, it seems that the amount of time spent
bodyText ||| using a computer does not necessarily translate into familiar-
bodyText ||| ity with the system knowledge needed to make security
bodyText ||| decisions. Although participants’ computer usage averaged
bodyText ||| 9-10 years, all were unfamiliar with basic system-level
bodyText ||| concepts, e.g., processes, network connections.
bodyText ||| Security task miss-rate: Since our data were non-parametric,
bodyText ||| discrete, and did not appear to fit a known distribution, we
bodyText ||| used a two-tailed Mann-Whitney test to determine if the
bodyText ||| difference in the miss-rate between the ZoneAlarm (control)
bodyText ||| and Sesame (experimental) groups was statistically signifi-
bodyText ||| cant. In the table below, we summarize the miss rate for both
bodyText ||| groups of participants:
table ||| 	ZoneAlarm group miss- rate (6 males, 4 females)	Sesame group miss-rate (5 males, 5 females)
table ||| Females	45.8%	25% (with outlier* 30%)
table ||| Males	36%	20%
table ||| Miss-rate	40%	22.2% (with outlier* 26.6%)
table ||| *Outlier miss-rate: 66.7%
tableCaption ||| Table 1. Participant miss-rate for security tasks
bodyText ||| Of the 20 participants, we identified one outlier whose miss-
bodyText ||| rate was 66.7%. During the study, this participant expressed
bodyText ||| concern about completing the tasks because s/he was very
bodyText ||| unfamiliar with the Windows environment given that the
bodyText ||| participant’s primary computer was a Macintosh.
bodyText ||| Cumulatively over all of the tasks, the experimental group
bodyText ||| performed significantly better than the control group. Includ-
bodyText ||| ing the outlier, the miss-rate for the group using Sesame is
bodyText ||| 26.6% while the miss-rate is 40% for the control group
bodyText ||| (Z=1.97, P=0.05). (When the outlier is excluded, the Sesame
bodyText ||| group miss-rate is reduced further to 22.2%, Z=2.53,
bodyText ||| P=0.05). Over just the firewall-like tasks (T1-T4), the
bodyText ||| experimental group using Sesame performed 41 % better than
bodyText ||| the control group; but if the outlier is included, the experi-
bodyText ||| mental group performs just 20% better. However, when tasks
bodyText ||| were considered individually or in smaller sets, we did not
bodyText ||| have statistically significant differences between groups due
bodyText ||| to our relatively small sample size. Figure 6 shows the
bodyText ||| success rates by task, including the outlier.
bodyText ||| Information Comprehension: After the completion of the six
bodyText ||| security tasks, we interviewed participants to understand
bodyText ||| their reactions to the tasks they performed and, for the
bodyText ||| experimental group, to assess how much of Sesame they
bodyText ||| understood. Most of the participants in the control group
bodyText ||| stated that they were uncertain how to use the information
page ||| 1052
note ||| CHI 2008 Proceedings · Am I Safe	April 5-10, 2008 · Florence, Italy
figure ||| T1	T2	T3	T4	T5	T6
figure ||| Task (T)
figureCaption ||| Figure 6: Participant hit-rates for security tasks
bodyText ||| provided by ZoneAlarm in making their security decisions.
bodyText ||| Also, many of the participants (seven out of ten) said they
bodyText ||| were following a specific strategy in making allow/deny
bodyText ||| decisions. Five of the seven were either allowing or denying
bodyText ||| every connection request. For example, one participant said
bodyText ||| “I don’t want to read all this stuff so I’m just going to deny
bodyText ||| it. If I allow it, I may have to do something else.” The
bodyText ||| remaining two of the seven allowed or denied based on
bodyText ||| whether they could recognize the process name. Even though
bodyText ||| all the participants had access to a lot of information pro-
bodyText ||| vided by Zone Alarm, only five participants in total looked at
bodyText ||| the process name given to help with their decision. The more
bodyText ||| info button was consistently ignored.
bodyText ||| Cumulatively, as discussed above, the experimental group
bodyText ||| performed significantly better than the control group. One
bodyText ||| contributing factor for this may have been that none of the
bodyText ||| participants reported using a predetermined strategy in
bodyText ||| making decisions. But perhaps more importantly, Sesame
bodyText ||| users appeared to employ more of the information provided
bodyText ||| than the control group in making their allow/deny decisions.
bodyText ||| Sesame users reported using information about the processes
bodyText ||| themselves as well as the remote systems to which they were
bodyText ||| connecting. In contrast, control users tended to rely on
bodyText ||| process names only. We suspect that this may be because
bodyText ||| Sesame provided a more accessible explanation of the
bodyText ||| general significance and specific facts about remote systems.
bodyText ||| For example, five participants found the geography informa-
bodyText ||| tion provided on remote systems to be helpful. Participants
bodyText ||| also reported that the type of language used in Sesame was
bodyText ||| helpful, as well as the permission cards in the allow/deny
bodyText ||| dialog box—though it is not clear that the latter specifically
bodyText ||| aided them in performing the tasks.
bodyText ||| To assess the extent to which participants understood the
bodyText ||| conceptual model Sesame provides, we asked them to
bodyText ||| describe the visualization. We specifically inquired about the
bodyText ||| nature of the visual elements such as processes, and about the
bodyText ||| distinction between areas representing things within the
bodyText ||| computer versus outside of the computer. We found that 8 of
bodyText ||| the 10 users understood the basic significance of the cubes
bodyText ||| representing foreground processes. Background processes
bodyText ||| posed a challenge, with only 2 users understanding their
bodyText ||| purpose. We were surprised by this finding, as we explicitly
bodyText ||| included a textual description of the distinction between the
bodyText ||| two types of processes within the UI. The representations of
bodyText ||| the remote computers were understood well, with 8 partici-
bodyText ||| pants recognizing their meaning. Eight participants also
bodyText ||| understood the basic purpose of the arrows connecting
bodyText ||| processes to the remote computers. Finally, 8 of the 10
bodyText ||| participants were also able to identify the areas of the Sesame
bodyText ||| UI that represented things considered to be within the com-
bodyText ||| puter, versus the areas representing things that were ‘outside’
bodyText ||| the computer.
sectionHeader ||| DISCUSSION AND FUTURE WORK
bodyText ||| The results of our study are encouraging, suggesting that on
bodyText ||| the whole, Sesame’s novel UI helps users make better
bodyText ||| security decisions than with typical security environments
bodyText ||| with a traditional firewall. We were especially pleased that
bodyText ||| our representation could be reasonably well interpreted
bodyText ||| without explanation. E.g., nearly all users understood the
bodyText ||| division between the internal and external regions of the
bodyText ||| design—this was a particular challenge we faced in earlier
bodyText ||| prototypes. The results suggest our basic representational
bodyText ||| approach to be a viable alternative to conventional textual
bodyText ||| approaches; and that novice users seem to rapidly learn a
bodyText ||| system-level structure when it is framed visually and in terms
bodyText ||| of more familiar concepts as was done in Sesame. While
bodyText ||| there is evidence that Sesame’s visual presentation is more
bodyText ||| effective than traditional firewalls, additional, larger studies
bodyText ||| are needed to confirm this.
bodyText ||| Besides the seemingly successful aspects of Sesame, the
bodyText ||| shortcomings of the UI were also informative. A common
bodyText ||| difficulty for participants was inferring causal relationships.
bodyText ||| Many participants felt that actions they took caused Sesame
bodyText ||| to bring up dialog boxes, even in cases where the Sesame
bodyText ||| visualization itself gave indications to the contrary. Addi-
bodyText ||| tionally, participant comments suggested they often had
bodyText ||| difficulty grasping the idea of their computer’s software
bodyText ||| environment as a collection of quasi-independent causal
bodyText ||| agents, instead inferring strong relationships among the
bodyText ||| different processes. These difficulties suggest that future
bodyText ||| versions of Sesame might use metaphors that better suggest
bodyText ||| the agent-causal nature of processes—such as depicting them
bodyText ||| with animated, anthropomorphic figures.
bodyText ||| While we evaluated Sesame as a holistic combination of its
bodyText ||| features, we do believe that there are generalizable design
bodyText ||| principles from our experiences that could be applied to other
bodyText ||| systems.
bodyText ||| First, given our desire to provide a direct manipulation
bodyText ||| interface, swiveling the desktop to show the underlying
bodyText ||| system seemed to be an accessible way to provide context to
bodyText ||| help users understand otherwise hidden features. That there
bodyText ||| are other possible approaches is certain; however, we believe
bodyText ||| that the generalizable principle here is that contextualization
bodyText ||| of new information with familiar, known concepts is a key
bodyText ||| for non-expert use. Our swivel metaphor is one (but not the
bodyText ||| only) way one might accomplish this.
bodyText ||| Second, Sesame’s policy cards provide a persistent visual
bodyText ||| indication of policy settings, allowing them to be easily seen
bodyText ||| and accessed by users in the future. The utility of persistent
bodyText ||| visual indicators —to support awareness of system state, to
figure ||| 120
figure ||| 100
figure ||| 80
figure ||| 60
figure ||| 40
figure ||| 20
figure ||| 0
figure ||| Success Rate By Task
figure ||| Sesame
figure ||| Control
page ||| 1053
note ||| CHI 2008 Proceedings · Am I Safe	April 5-10, 2008 · Florence, Italy
bodyText ||| serve as an affordance for reversibility, and so forth—seems
bodyText ||| particularly important for conveying security state, where re-
bodyText ||| accessibility and intelligibility are especially difficult. We
bodyText ||| believe this to be a severe failing of current firewalls, in
bodyText ||| which settings—once configured—are often difficult to re-
bodyText ||| access.
bodyText ||| Third, we believe that metaphorical 3D models may aid in
bodyText ||| helping non-experts understand system information where
bodyText ||| necessary; particularly when it involves concepts underlying
bodyText ||| the desktop metaphor. Such modeling need not be limited to
bodyText ||| a firewall UI. Like file management models (e.g. two file
bodyText ||| folders with pages transferring from one to the other to show
bodyText ||| the status of copying), other system models can be embedded
bodyText ||| in applications, perhaps with individual components rotating
bodyText ||| aside to reveal relevant underlying system information. Our
bodyText ||| study suggests that security information embedded in such a
bodyText ||| model can be effectively leveraged by end-users.
bodyText ||| Finally, Sesame shows the viability of direct manipulation
bodyText ||| (DM) in low level, security and configuration interfaces,
bodyText ||| whereas DM is traditionally only used for windowing and
bodyText ||| within applications. We believe that this area is ripe for the
bodyText ||| use of other specific design techniques from the HCI com-
bodyText ||| munity, such as the use of 2.5D UI’s to extend the desktop
bodyText ||| metaphor. Our work suggests that users can understand
bodyText ||| relationships between different levels of abstraction through
bodyText ||| such well-proved techniques, even when dealing with the
bodyText ||| complex information necessary for security and system
bodyText ||| decision-making.
sectionHeader ||| CONCLUSION
bodyText ||| Sesame brings a direct manipulation graphical interface to
bodyText ||| end-user security to help non-experts make better informed
bodyText ||| security choices. Most prior work in end-user security tended
bodyText ||| to be highly task or threat-specific; or largely text-based
bodyText ||| and/or designed for experts. There are few tools if any which
bodyText ||| focus explicitly on helping non-expert users to better under-
bodyText ||| stand the technical, system-level concepts needed to make
bodyText ||| security decisions. With Sesame, we investigate an approach
bodyText ||| to providing non-experts with a general, firewall-like tool
bodyText ||| that addresses a wider range of threats independent of
bodyText ||| specific tasks or applications.
bodyText ||| Further, we move toward making system-level concepts
bodyText ||| accessible to non-experts by representing them as concrete
bodyText ||| objects and relating them to more familiar concepts such as
bodyText ||| desktop-level objects and real world abstractions like geo-
bodyText ||| graphic locations. In a controlled study, Sesame users were
bodyText ||| more likely to identify security threats accurately than users
bodyText ||| with more typical software environments. Sesame users were
bodyText ||| further able to understand many of the otherwise unfamiliar
bodyText ||| system-level concepts conveyed, suggesting viability to our
bodyText ||| fundamental interface approach. In the future, we plan to
bodyText ||| conduct further studies and explore how better to convey
bodyText ||| those concepts with which users struggled.
sectionHeader ||| ACKNOWLEDGEMENTS
bodyText ||| We thank our colleagues at Georgia Tech for their helpful
bodyText ||| feedback, in particular, John Stasko and Pixi Lab members;
bodyText ||| and we thank Symantec for their support for this work.
sectionHeader ||| REFERENCES
reference ||| 1. Conti, G., Abdullah, K., Grizzard, J., Stasko, J., Copeland, J.,
reference ||| Ahamad, M., Owen, H., Lee, C. Countering Security Informa-
reference ||| tion Overload through Alert and Pack Visualization. IEEE
reference ||| Computer Graphics (2006).
reference ||| 2. Dhamija, Rachna, Tygar, J.Doug. The Battle Against Phishing:
reference ||| Dynamic Security Skins. Symposium On Usable Privacy and
reference ||| Security, (2005).
reference ||| 3. DiGioia, P., Dourish P. Social Navigation as a Model for
reference ||| Usable Security. Symposium On Usable Privacy and Security
reference ||| (2005).
reference ||| 4. Downs, J. S., Holbrook, M. B., Cranor, L. F. Decision Strate-
reference ||| gies and Susceptibility to Phishing. Symposium On Usable
reference ||| Privacy and Security, (2005).
reference ||| 5. Edwards, W. K., Shehan, E., Stoll, J. Security Automation
reference ||| Considered Harmful? NSPW (2007)
reference ||| 6. Flinn, S.A., Flock of Birds, Safely Staged. DIMACS Workshop
reference ||| on Usable Privacy & Security Software (2005).
reference ||| 7. Foresti, S., Agutter, J. Visual Correlation of Network Alerts.
reference ||| IEEE Computer Graphics (2006).
reference ||| 8. Hutchins, E., Hollan, J., Norman, D. Direct Manipulation
reference ||| Interfaces. Human Computer Interaction, 1985. 1: p. 311-338.
reference ||| 9. Know Your Enemy: Tracking Botnets. Honeynet Project and
reference ||| Research Alliance. honeynet.org/papers/bots (2005).
reference ||| 10. Nielsen, J., Landauer, T. K., A mathematical model of the
reference ||| finding of usability problems. Proceedings of the ACM
reference ||| INTERCHI’93 Conference (1993).
reference ||| 11. Shukla, S., Nah, F., Web Browsing and Spyware Intrusion.
reference ||| Communications of the ACM.Vol. 48, No. 8 (2005).
reference ||| 12. Smetters, D., Grinter, R. Moving from the Design of Usable
reference ||| Security Technologies to the Design of Useful Secure Applica-
reference ||| tions. NSPW (2002).
reference ||| 13. Spyware. NISCC Technical Note. National Infrastructure
reference ||| Security Coordination Centre. (2006).
reference ||| 14. Thorpe, S., Fize, D. & Marlot, C. (1996).Speed of processing
reference ||| in the human visual system. Nature, 381, 520-522.
reference ||| 15. Walker, A. Absolute Beginner’s Guide to Security, Spam,
reference ||| Spyware & Viruses. Que Publishing, © 2006.
reference ||| 16. Whalen, T., Inkpen, K. Techniques for Visual Feedback of
reference ||| Security State. DIMACS Workshop on Usable Privacy and Se-
reference ||| curity Software (2004).
reference ||| 17. Whitten, A., Tygar, J. Safe Security Staging. CHI 2003
reference ||| Workshop on Human-Computer Interaction and Security Sys-
reference ||| tems (2003).
reference ||| 18. Whitten, A., Tygar, J., Why Johnny Can’t Encrypt. Proc. of the
reference ||| 8th USENIX Security Symposium (1999).
reference ||| 19. Wu, M., Miller, R. C., Little, G. Web Wallet: Preventing
reference ||| Phishing Attacks by Revealing User Intentions. Symposium On
reference ||| Usable Privacy and Security, (2006).
reference ||| 20. Wu, M., Miller, R. C., Garfinkel, S., Do Security Toolbars
reference ||| Actually Prevent Phishing Attacks? CHI (2006).
reference ||| 21. Yee, K., Sitaker, K. Passpet: Convenient Password Manage-
reference ||| ment and Phishing Protection. Symposium On Usable Privacy
reference ||| and Security, (2006).
reference ||| 22. www.sysinternals.com/Utilities/
page ||| 1054

note ||| CHI 2008 Proceedings · Am I Safe	April 5-10, 2008 · Florence, Italy
title ||| TALC: Using Desktop Graffiti to Fight
title ||| Software Vulnerability
author ||| Kandha Sankarapandian, Travis Little, W. Keith Edwards
affiliation ||| Georgia Institute of Technology
address ||| 85 Fifth Street NW, Atlanta, GA 30308, USA.
email ||| {kandha, tlittle , keith}@cc.gatech.edu
sectionHeader ||| ABSTRACT
bodyText ||| With the proliferation of computer security threats on the
bodyText ||| Internet, especially threats such as worms that
bodyText ||| automatically exploit software flaws, it is becoming more
bodyText ||| and more important that home users keep their computers
bodyText ||| secure from known software vulnerabilities. Unfortunately,
bodyText ||| keeping software up-to-date is notoriously difficult for
bodyText ||| home users. This paper introduces TALC, a system to
bodyText ||| encourage and help home users patch vulnerable software.
bodyText ||| TALC increases home users’ awareness of software
bodyText ||| vulnerabilities and their motivation to patch their software;
bodyText ||| it does so by detecting unpatched software and then
bodyText ||| drawing graffiti on their computer’s background wallpaper
bodyText ||| image to denote potential vulnerabilities. Users can “clean
bodyText ||| up” the graffiti by applying necessary patches, which
bodyText ||| TALC makes possible by assisting in the software patching
bodyText ||| process
category ||| ACM Classification: H.5.m Information interfaces and
category ||| presentation, H.5.2 User Interfaces, K.6.5 Management of
category ||| Computer and Information Systems: Security and
category ||| Protection, D.4.6 Operating Systems: Security and
category ||| Protection
keyword ||| General terms: Human factors, security, management
keyword ||| Keywords: Usable security, Internet security, home users,
keyword ||| patch management, software vulnerabilities, security
keyword ||| framework, graffiti
sectionHeader ||| INTRODUCTION
bodyText ||| One of the most significant computer security threats faced
bodyText ||| by users today results from vulnerabilities in the operating
bodyText ||| system and application software installed on users’
bodyText ||| computers. Software defects—bugs such as susceptibility
bodyText ||| to buffer overflow attacks [7], cross site scripting [26], and
bodyText ||| so forth—represent vectors through which malware can
copyright ||| Permission to make digital or hard copies of all or part of this work for
copyright ||| personal or classroom use is granted without fee provided that copies are
copyright ||| not made or distributed for profit or commercial advantage and that copies
copyright ||| bear this notice and the full citation on the first page. To copy otherwise,
copyright ||| or republish, to post on servers or to redistribute to lists, requires prior
copyright ||| specific permission and/or a fee.
note ||| CHI 2008, April 5–10, 2008, Florence, Italy.
copyright ||| Copyright 2008 ACM 978-1-60558-011-1/08/04...$5.00
bodyText ||| infect and compromise users’ machines. Once machines
bodyText ||| have been compromised, malicious parties can extract
bodyText ||| personal information from them, or enlist them into botnets
bodyText ||| to serve in further attacks on network resources. The latter
bodyText ||| threat, in particular, has a significant impact on the entire
bodyText ||| Internet community as botnets are the means to Distributed
bodyText ||| Denial of Service (DDoS), spam and phishing attacks [14];
bodyText ||| the exponential increase in size and number of botnets [6]
bodyText ||| is a stark reflection on the number of vulnerable machines
bodyText ||| that exist in the Internet. Ironically, in many cases, patches
bodyText ||| exist to repair these vulnerabilities; however, users are
bodyText ||| often unaware that such patches exist, or are unmotivated to
bodyText ||| install them, or may not know how to install them.
bodyText ||| Numerous reports from both government and industry
bodyText ||| sources highlight the magnitude of the threat posed by
bodyText ||| unpatched software vulnerabilities. For example, statistics
bodyText ||| from the Computer Emergency Response Team
bodyText ||| (CERT/CC) show the rapid increase in reported software
bodyText ||| vulnerabilities since 1995 [5]. NIST's report on the
bodyText ||| economic impacts of inadequate software testing estimates
bodyText ||| damage from attacks exploiting software vulnerabilities at
bodyText ||| US$60 billion/year [25]. Furthermore, testimony from the
bodyText ||| US General Accounting Office notes the importance of
bodyText ||| effective and continual patch management in addressing the
bodyText ||| “staggering” increase in software vulnerabilities [29].
bodyText ||| Industry sources echo these same concerns. The importance
bodyText ||| of routine patching is highlighted in Symantec’s security
bodyText ||| report [28], which notes that after having a firewall and
bodyText ||| antivirus software, the single most important practice for
bodyText ||| consumers to maintain their computer’s security is to stay
bodyText ||| current on software patches. The SAGE report [17] from
bodyText ||| McAfee Avert Labs estimates that known software
bodyText ||| vulnerabilities are increasing at a rate of about 30%
bodyText ||| annually. Microsoft’s LaMacchia [16] also notes that the
bodyText ||| window of time between when new software is released
bodyText ||| and when an exploit has been created has decreased
bodyText ||| considerably (leading to so-called zero day attacks, in
bodyText ||| which exploits are ready to be employed the day new
bodyText ||| software is released).
bodyText ||| Unfortunately, just as the necessity of maintaining up-to-
bodyText ||| date patches is increasing, the complexity of doing so is
bodyText ||| also increasing: users must now be responsible for patching
bodyText ||| not only their operating system software, but also the
page ||| 1055
note ||| CHI 2008 Proceedings · Am I Safe	April 5-10, 2008 · Florence, Italy
bodyText ||| multiplicity of application software on their systems. While
bodyText ||| operating systems have built-in facilities (such as Windows
bodyText ||| Update) to download patches and encourage users to install
bodyText ||| them, other applications use a diverse range of update
bodyText ||| mechanisms, including requiring that users explicitly visit
bodyText ||| vendors’ web sites for newer versions. Worryingly, the
bodyText ||| SAGE report indicates that in the period between
bodyText ||| December 2005 and May 2006, the vulnerabilities targeted
bodyText ||| were moving away from OS attacks, to attacks on other
bodyText ||| software, such as Internet Explorer and Firefox. Thus users
bodyText ||| must now contend with a host of disparate and confusing
bodyText ||| patch systems in order to ensure that all of the software on
bodyText ||| their machines is protected.
bodyText ||| In order to patch vulnerable software, users (1) must know
bodyText ||| that such software exists in the first place, (2) know how to
bodyText ||| go about patching it, and (3) be motivated to do so in a
bodyText ||| timely manner.1 Although there are a number of existing
bodyText ||| systems that address patching in some capacity (described
bodyText ||| below), none of these systems specifically address making
bodyText ||| home users aware of the threats that vulnerable software
bodyText ||| poses to their computer’s security and their privacy, nor do
bodyText ||| they provide a holistic approach to patch management
bodyText ||| across multiple vendors’ applications.
bodyText ||| To address these challenges, we have developed a system
bodyText ||| called TALC (for Threat Awareness, Learning, and
bodyText ||| Control) that aims to augment users’ awareness of
bodyText ||| vulnerabilities posed by unpatched software through
bodyText ||| unobtrusive yet persistent visual reminders, persuade them
bodyText ||| to remedy those vulnerabilities, and provide easier
bodyText ||| mechanisms for patch install ation across a range of
bodyText ||| applications.
bodyText ||| In this paper, we describe TALC, its architecture, and a
bodyText ||| deployment-based user study that we performed to
bodyText ||| determine its overall utility. We conclude with a discussion
bodyText ||| of our approach and directions for future research.
sectionHeader ||| RELATED WORK
bodyText ||| Most of the current work on easier patch management is
bodyText ||| either vendor-specific, or has focused on managed solutions
bodyText ||| for the enterprise environment.
bodyText ||| In the vendor-specific category, tools such as Windows
bodyText ||| Update and Mac OS X Software Update perform automatic
bodyText ||| detection and download of new patches, and single-click
bodyText ||| installation. However, these tools only work for operating
bodyText ||| system components and, as noted above, unpatched
bodyText ||| application software now represents the major source of
bodyText ||| vulnerabilities. Of course, many application vendors
bodyText ||| provide mechanisms for their own products (such as Adobe
bodyText ||| Online’s tools for update of their Creative Suite products).
bodyText ||| However, there is no unified vendor-supported mechanism
footnote ||| 1 Even with systems that include an auto-update mechanism, the response window between
footnote ||| the public disclosure of an exploit and the availability of a software patch is sufficient for a
footnote ||| worm to exploit the vulnerability and achieve significant spread. Usually an advisory on
footnote ||| working around the vulnerable software is released before the actual patch and educating
footnote ||| users with these advisories can be effective in stopping exploits.
bodyText ||| for simple updates of all software on a user’s system,
bodyText ||| requiring users to deal with these on a piecemeal basis,
bodyText ||| when such systems exist at all.
bodyText ||| In the enterprise space, a number of companies have begun
bodyText ||| to focus specifically on patch installation in managed
bodyText ||| networks, as a way for centralized IT organizations to
bodyText ||| protect the corporate network. Enterprise management
bodyText ||| solutions like Marimba Patch Management from BMC
bodyText ||| Software [3], for example, enable deployment of security
bodyText ||| patches on all devices across the enterprise. While
bodyText ||| powerful, these systems are not designed for use by home
bodyText ||| users; they require, for example, a centralized administrator
bodyText ||| who manages patch releases to the corporate network, and
bodyText ||| rely on homogeneous software installations on client
bodyText ||| devices.
bodyText ||| There is a tension between tools like Marimba, which are
bodyText ||| proactive and aim to shield end-users from direct
bodyText ||| involvement with patching, and other tools such as
bodyText ||| Windows Update that take a more interactive approach,
bodyText ||| involving the user in the patch decision process and
bodyText ||| demanding their attention [15].
bodyText ||| While proactive tools are, on the surface, easier to use since
bodyText ||| they do not require direct user involvement, they also do
bodyText ||| not contribute to the user’s learning process: awareness of
bodyText ||| threats is a critical component in managing software
bodyText ||| vulnerabilities given the diversity each user’s individual
bodyText ||| software usage patterns. Further—and perhaps more
bodyText ||| importantly—unless potential software version conflicts
bodyText ||| can be reliably determined in advance, there is a risk that an
bodyText ||| automatically installed patch will break other software on
bodyText ||| the user’s computer. Such a hypothetical, fully-automated
bodyText ||| tool for managing software updates across applications is
bodyText ||| difficult to achieve outside the homogeneity of the
bodyText ||| managed corporate network, meaning that users will likely
bodyText ||| have to be involved in at least some aspects of patch
bodyText ||| decision making for the foreseeable future [10].
bodyText ||| Given these practical realities of automated patch
bodyText ||| management, it is imperative that users be kept informed
bodyText ||| about the potential dangers of an unpatched system, as well
bodyText ||| as the benefits and risks of installing a given patch, if they
bodyText ||| are going to be involved in making patch decisions.
bodyText ||| A challenge, of course, is that highly interactive tools can
bodyText ||| potentially annoy users to the point that they turn off such
bodyText ||| tools completely. This problem has been especially evident
bodyText ||| in security software; most common firewalls, for instance,
bodyText ||| display pop up messages about threats such as port scans.
bodyText ||| Bailey, Konstan, and Carlis [1] report that such
bodyText ||| interruptions increase task completion times, as well as user
bodyText ||| anxiety and frustration. However the suggestion from [1] of
bodyText ||| an “attention manager” that predicts opportunities for
bodyText ||| engaging with the user may not be an optimal solution for a
bodyText ||| security task like patch management that does not require
bodyText ||| an instantaneous allow/deny decision in the way that
bodyText ||| antivirus or firewall alerts do. This suggests that different,
bodyText ||| more subtle and less intrusive approaches than interrupting
bodyText ||| the user may be employed, which allow the user to interact
page ||| 1056
note ||| CHI 2008 Proceedings · Am I Safe	April 5-10, 2008 · Florence, Italy
figureCaption ||| Figure 1: TALC showing graffiti on the user's desktop along with a popup description of the threat.
bodyText ||| with the patch management system as a secondary task, but
bodyText ||| with sufficient persuasion that users do not ignore it
bodyText ||| completely.
bodyText ||| There have also been a number of research efforts intended
bodyText ||| to address the problem of excessive dependence on user
bodyText ||| interaction for security. For example, systems such as the
bodyText ||| Chameleon System for Desktop Security [23] attempt to
bodyText ||| categorize software into activity roles in an effort to reduce
bodyText ||| impinging on the user’s attention. However, most such
bodyText ||| tools are incomplete, or focus on a narrow range of threats.
bodyText ||| For example, Chameleon is a low-fi, paper-based prototype
bodyText ||| intended to address only the threat of malware.
bodyText ||| TALC is designed in response to the need for better patch
bodyText ||| management on end-user systems. It aims to strike a
bodyText ||| balance between proactive and interactive support, in order
bodyText ||| to provide users with awareness and control over security
bodyText ||| risks without excessive attention costs or disruption to their
bodyText ||| workflow. TALC uses “calm” notifications, rather than
bodyText ||| intrusive techniques such as popups, to motivate specific
bodyText ||| user behaviors, and to provide awareness of overall system
bodyText ||| risk from software vulnerabilities. TALC also provides a
bodyText ||| holistic approach to patch management, by assisting with
bodyText ||| patch management across the heterogeneous variety of
bodyText ||| applications and software components that may be installed
bodyText ||| on a user’s machine.
sectionHeader ||| DESCRIPTION
bodyText ||| In this section, we describe how the user sees TALC, as
bodyText ||| well as how TALC detects and assists in repairing software
bodyText ||| vulnerabilities.
bodyText ||| TALC paints graffiti on the user’s desktop to indicate the
bodyText ||| presence of unpatched software on the user’s system (see
bodyText ||| Figure 1). Unlike intrusive techniques such as popups, this
bodyText ||| is meant to be a “low-distraction” technique, designed to
bodyText ||| make users aware of potential problems, while allowing
bodyText ||| them to act on them in their own time. In contrast to
bodyText ||| warning dialogs that interrupt users’ activities (“Your
bodyText ||| patches are out of date!”), this awareness function is
bodyText ||| intended to serve as a constant but gentle reminder,
bodyText ||| allowing users to finish their primary tasks without letting
bodyText ||| them forget about the security maintenance tasks that need
bodyText ||| their attention.
page ||| 1057
note ||| CHI 2008 Proceedings · Am I Safe	April 5-10, 2008 · Florence, Italy
bodyText ||| For each threat found on the user’s machine by TALC a
bodyText ||| single graffiti image is chosen out of a corpus of images,
bodyText ||| and composited into a randomly selected area of the screen.
bodyText ||| TALC uses the size of the graffiti image to convey the
bodyText ||| relative severity of the threat: the graffiti is shown larger
bodyText ||| for severe threats and smaller for more mild threats.
subsectionHeader ||| Why Graffiti?
bodyText ||| We chose the graffiti visualization of software
bodyText ||| vulnerabilities to convey a general sense of “decay” or
bodyText ||| “threat” to the user, suggesting that their machine has
bodyText ||| entered a state of risk. Such notions appear to be broadly
bodyText ||| associated with graffiti in physical environments for many
bodyText ||| people. Numerous studies have confirmed this association
bodyText ||| across a number of cultures and communities; see, for
bodyText ||| example Morin et al.’s study of US public health nursing
bodyText ||| students’ perception of threat in their communities [22],
bodyText ||| Bowling et al.’s study of risk perception in Britain [4] as
bodyText ||| well as others [2, 13].
bodyText ||| We realize that this association may not hold across all
bodyText ||| cultures, or even across individuals within a given culture.
bodyText ||| (See, for instance, sources that reflect the artistic value in
bodyText ||| graffiti such as Susan Farrell’s Art Crimes site,
bodyText ||| http://www.graffiti.org, as well as academic work exploring
bodyText ||| the appropriation of graffiti by various subcultures [11].)
bodyText ||| However, even for those users that may not have negative
bodyText ||| associations with graffiti, we hoped that their personal
bodyText ||| inclinations would be outweighed by the minor annoyance
bodyText ||| of having part of their desktop covered by the graffiti
bodyText ||| (covering a personally selected photo for instance), and
bodyText ||| therefore would still provide motivation to deal with the
bodyText ||| software vulnerabilities.
bodyText ||| Our choice of a real world metaphor for visualizing
bodyText ||| security threats stems from the observations made by
bodyText ||| Redstrom, Skog and Hallnas in their work on informative
bodyText ||| art [27]. We explored a number of other, non-graffiti
bodyText ||| visualization approaches during prototyping, which we also
bodyText ||| believed might convey a sense of risk to the user. These
bodyText ||| included one that used bullet holes in the user’s background
bodyText ||| image (deemed both to be too violent, and to
bodyText ||| inappropriately convey a sense of active attack rather than
bodyText ||| simple decay), and one that rendered increasingly large
bodyText ||| piles of garbage and other debris along the bottom of the
bodyText ||| user’s screen (deemed to appropriately convey a sense of
bodyText ||| decay but perhaps be too easy to ignore). We believe using
bodyText ||| graffiti walks the line between the ambient media and
bodyText ||| diversion categories as described by McCrickard, et.al. in
bodyText ||| their model for notification systems [18].
subsectionHeader ||| Determining and Presenting Vulnerabilities
bodyText ||| TALC determines potential vulnerabilities through a multi-
bodyText ||| step process. First, we perform a periodic system-wide
bodyText ||| audit to identify software versions installed on the user’s
bodyText ||| machine. Next, this data is compared against the online
bodyText ||| NIST National Vulnerability Database (NVD) [24],
bodyText ||| resulting in an up-to-date list of installed software for
bodyText ||| which patches exist.
bodyText ||| When the user’s cursor hovers over a graffiti area, a tooltip
bodyText ||| displays the name of the software that is vulnerable, as well
bodyText ||| as the threats posed by this vulnerability (see Figure 1).
bodyText ||| We parse the NVD at connection time to retrieve patch
bodyText ||| information, as well as the descriptions presented to users,
bodyText ||| as shown in Figure 1 above. The language used in the
bodyText ||| descriptions in the National Vulnerability Database is often
bodyText ||| highly technical, and may be confusing to home users. To
bodyText ||| make the descriptions more palatable, we use a set of
bodyText ||| heuristics to simplify the explanations. For example, an
bodyText ||| NVD threat description such as the following:
construct ||| The do_change_cipher_specfunction in OpenSSL
construct ||| 0.9.6c to 0.9.6k, and 0.9.7a to 0.9.7c, allows remote
construct ||| attackers to cause a denial of service (crash) via a
construct ||| crafted SSL/TLS handshake that triggers a null
construct ||| dereference
bodyText ||| would be presented by TALC as:
construct ||| Denial of service vulnerability that lets a remote
construct ||| attacker slow down/crash your computer.
bodyText ||| The descriptions are scanned for a small set of keywords,
bodyText ||| and predefined descriptions of the problems are presented
bodyText ||| to the user. This provides a more readable description for a
bodyText ||| large number of common classes of vulnerabilities; other
bodyText ||| descriptions that do not match our heuristics are explained
bodyText ||| with a generic message: “Other vulnerability.”
bodyText ||| We did not completely eliminate all information about the
bodyText ||| vulnerability to allow users to learn about common types of
bodyText ||| threats, and—if necessary—communicate such information
bodyText ||| to any people or organizations they trust to help them keep
bodyText ||| their computer safe. Thus, following Zurko [30], TALC
bodyText ||| places emphasis on helping users understand these security
bodyText ||| concepts through its use.
subsectionHeader ||| Repairing Vulnerabilities
bodyText ||| In addition to supporting threat awareness, TALC also
bodyText ||| allows users to take actions that mitigate threats. When the
bodyText ||| user clicks the right mouse button on graffiti, a popup
bodyText ||| context menu appears that allows them to repair the threats
bodyText ||| posed by a vulnerable program. When the user chooses to
bodyText ||| fix the program, TALC downloads and displays the
bodyText ||| webpage that contain patches or workarounds for
bodyText ||| vulnerabilities, and displays the control window shown in
bodyText ||| Figure 2. TALC also shows system information and the
bodyText ||| name and version number of the program with the
bodyText ||| vulnerability.
bodyText ||| Unfortunately, different vendors require different processes
bodyText ||| to acquire patches: some may require that users log in,
bodyText ||| while others require a click-through license agreement, and
bodyText ||| others may simply provide direct access to the patch itself.
bodyText ||| Thus, while TALC automates the process offinding a patch
bodyText ||| for the detected vulnerabilities, it leaves the task of actually
bodyText ||| installing patches to individual users. This is not only
bodyText ||| because of the difficulty involved in automatically dealing
bodyText ||| with multiple vendors’ web sites, but also because users
bodyText ||| must often be involved in the process of deciding whether a
bodyText ||| particular patch is appropriate for them. Security is not
page ||| 1058
note ||| CHI 2008 Proceedings · Am I Safe	April 5-10, 2008 · Florence, Italy
bodyText ||| users’ only concern; they must make security related
bodyText ||| decisions in context, such as knowing whether a new
bodyText ||| software version will break compatibility with other tools.
bodyText ||| For example, Windows XP SP2—while providing
bodyText ||| important security features—broke the functionality of a
bodyText ||| number of network-based tools [21]. Simply installing such
bodyText ||| updates automatically without considering the context of
bodyText ||| other software in use can often lead to such problems.
figureCaption ||| Figure 2: TALC Control window displaying the
figureCaption ||| website with patch information.
sectionHeader ||| IMPLEMENTATION
bodyText ||| TALC uses a modular implementation, with well-defined
bodyText ||| communication interfaces between modules to facilitate
bodyText ||| easy addition and replacement of components. This is
bodyText ||| exposed in the form of an API that allows developers to
bodyText ||| write pluggable modules for TALC. For example, these
bodyText ||| APIs have been used to create the software vulnerability
bodyText ||| detection system described in this paper, but can be
bodyText ||| extended to provide functionality beyond software patch
bodyText ||| management. The extensible nature of TALC is intended to
bodyText ||| be used to visualize and control a large set of security tools
bodyText ||| through a framework similar to the one described by
bodyText ||| Dourish and Redmiles in [9]. For example, information
bodyText ||| sources, sensors and aggregators can be created and
bodyText ||| plugged into TALC, allowing it to be extended to new
bodyText ||| visualizations and to detect new security threats. Our long-
bodyText ||| term goal is for TALC to ultimately serve as an integrated
bodyText ||| security suite along the lines of Internet Security suites
bodyText ||| from Symantec, McAfee and an advanced form of the
bodyText ||| Windows Security Center [20].
bodyText ||| The TALC system is composed of four modules,
bodyText ||| Information Source Module, Correlation Module,
bodyText ||| Visualization Module and Control Module linked together
bodyText ||| by a Communication Manager that allows modules to pass
bodyText ||| messages to each other. Each module exposes hooks and
bodyText ||| registers callback functions with the other modules for
bodyText ||| communication. The Information Source module detects
bodyText ||| events from the host and the network and processes them
bodyText ||| into XML data that can be exchanged with other modules.
bodyText ||| For example, the software vulne rability detection features
bodyText ||| described in this paper are implemented as a custom
bodyText ||| Information Source module, which generates data by using
bodyText ||| Hijackthis [19] (a tool that scans the registry for references
bodyText ||| to installed programs) and a series of other system scans
bodyText ||| (such as programs on the Start Menu, or on the user’s
bodyText ||| desktop) to identify installed software.
bodyText ||| The Correlation module interprets this information by
bodyText ||| aggregating the data from the different Information
bodyText ||| Sources. For the software vulnerability detection
bodyText ||| incarnation of TALC, the Correlation module correlates the
bodyText ||| information from the system scans with data pulled from
bodyText ||| the NVD. The Correlator performs a version match with the
bodyText ||| list of vulnerable software from the NVD database,
bodyText ||| ascertains the severity of the threat (Mild, Medium or
bodyText ||| Severe), and records the website indicated by the NVD to
bodyText ||| contain information necessary to resolve the vulnerability.
bodyText ||| This is fed to the Visualization and Control modules.
bodyText ||| The Visualization module is responsible for information
bodyText ||| presentation. As described earlier, our current visualization
bodyText ||| module presents software vulnerabilities as graffiti
bodyText ||| rendered onto the user’s desktop. Other visualizations are
bodyText ||| possible; for example, one visualization we have explored
bodyText ||| renders vulnerabilities as pieces of garbage piling up along
bodyText ||| the bottom of the user’s screen; one could also create
bodyText ||| visualization modules that use standard pop-up dialog
bodyText ||| boxes to notify the user of threats.
bodyText ||| Finally, the Control module provides the means by which
bodyText ||| the user can act upon the information presented by the
bodyText ||| Visualization module. In our current system the Control
bodyText ||| module opens up websites that lets the user download a
bodyText ||| patch to fix the software vulnerability. The Control module
bodyText ||| can be easily extended to give a user control of different
bodyText ||| security software such as their firewall.
sectionHeader ||| EVALUATION
bodyText ||| We performed a deployment-based study of TALC to
bodyText ||| determine its efficacy in providing better awareness of
bodyText ||| software vulnerabilities, and in incenting users to rectify
bodyText ||| those vulnerabilities. Our study structure consisted of a
bodyText ||| two-week deployment period during which TALC was in
bodyText ||| operation on users’ primary machines. Logging features in
bodyText ||| TALC reported on users’ use of the system so that we
bodyText ||| could collect quantitative data on their actions. We also
bodyText ||| collected data from pre- and post-study questionnaires to
bodyText ||| get qualitative data about users’ perceptions of the
bodyText ||| software.
bodyText ||| Participants were recruited from a non-university context.
bodyText ||| After consent was obtained (but before any other
bodyText ||| participation in the study), users were sent a link to an
bodyText ||| online questionnaire that tested them on their awareness of
bodyText ||| computer security concepts and threats, as well as their
bodyText ||| expertise in general computer usage.
bodyText ||| Once users completed the pre-test questionnaire they were
bodyText ||| emailed a link to the installation file and they were asked to
bodyText ||| download and install TALC. Our participants ran a
bodyText ||| specially instrumented version of TALC on their personal
page ||| 1059
note ||| CHI 2008 Proceedings · Am I Safe	April 5-10, 2008 · Florence, Italy
bodyText ||| computers for two weeks. Every week, TALC would
bodyText ||| upload the data it had collected on how users interacted
bodyText ||| with it.
bodyText ||| When the participants had been running the program for
bodyText ||| two weeks, they were sent a link via email to a post-study
bodyText ||| questionnaire to allow us to get data about their subjective
bodyText ||| experiences of using the software.
subsectionHeader ||| The Participants
bodyText ||| Ten participants finished the study successfully. Seven
bodyText ||| more started the study, but dropped out for a variety of
bodyText ||| reasons, including changing their mind about participating
bodyText ||| in the study before downloading the software, and because
bodyText ||| of installation problems. One participant uninstalled the
bodyText ||| TALC software before the two weeks were completed; we
bodyText ||| include data from this subject in the results presented here:
bodyText ||| one of the things we hoped to discover was whether we had
bodyText ||| correctly adjusted TALC to motivate users without being
bodyText ||| annoying, and so results from users who ceased using the
bodyText ||| software had the potential to be especially illuminating.
bodyText ||| The ages of the participants ranged from twenty-three to
bodyText ||| thirty-five, with an average age of twenty-six. Of those who
bodyText ||| completed the study, four were women and six were men.
bodyText ||| Although the absolute number of participants is smaller
bodyText ||| than would be typical in a controlled lab study, the intent
bodyText ||| with our evaluation was specifically to engage users in a
bodyText ||| real-world deployment of the system over a sustained (half
bodyText ||| month) period of time, a style of evaluation that we believe
bodyText ||| is necessary for ecological validity. While lab-based studies
bodyText ||| can easily engage substantially larger numbers of users,
bodyText ||| these studies have problems in the security context,
bodyText ||| particularly around artificial experimental scenarios that are
bodyText ||| removed from users' day-to-day experiences, and also may
bodyText ||| overly prime subjects’ orientation toward security. We
bodyText ||| therefore believed that a deployment study, on users’ own
bodyText ||| computers, confronting unknown usage contexts and
bodyText ||| uncontrolled software vulnerabilities, was the only
bodyText ||| appropriate way to measure use.
subsectionHeader ||| The Pre-test Questionnaire
bodyText ||| The pre-test questionnaire was administered online, using a
bodyText ||| common online survey vendor. Participants were emailed
bodyText ||| requests to fill out the survey, and provided links to the
bodyText ||| survey site. The survey consisted of three demographic
bodyText ||| questions, eleven questions to determine how comfortable
bodyText ||| the participants felt using computers, and how confident
bodyText ||| they were in their computer’s security. Finally there were
bodyText ||| eight questions in which the user was asked to define
bodyText ||| simple computer security related terms, to gauge their
bodyText ||| general knowledge of computer security concepts.
subsectionHeader ||| The Study
bodyText ||| There were two conditions in the study, to separate
bodyText ||| patching actions incented directly by TALC from other
bodyText ||| patches downloaded merely because users had an increased
bodyText ||| awareness of the security issues as a result of participating
bodyText ||| in the study itself. In all conditions TALC was downloaded
bodyText ||| and installed by the participants. In one condition, however,
bodyText ||| the tool was instrumented to not identify any vulnerabilities
bodyText ||| (and, hence, to not show any graffiti) during the first week;
bodyText ||| in the second condition the tool was instrumented so that it
bodyText ||| did not detect any vulnerabilities (nor show any graffiti) in
bodyText ||| the second week. Through these two conditions we hoped
bodyText ||| to isolate any potentially biasing novelty effects caused
bodyText ||| simply because subjects were participating in the study. In
bodyText ||| both cases, for the week it was active, TALC detected
bodyText ||| vulnerable software on all participants’ computers, and thus
bodyText ||| presented graffiti to all users during the week it was
bodyText ||| activated. During both weeks, for both conditions, TALC
bodyText ||| continued to scan the users’ systems and record
bodyText ||| vulnerabilities as well as how the participants interacted
bodyText ||| with it.
bodyText ||| Participants were randomly assigned to a condition when
bodyText ||| they consented to be a part of the study. They were not
bodyText ||| given a link to the TALC installation file until they had
bodyText ||| completed the pre-test questionnaire. Participants were
bodyText ||| instructed to inform researchers if they had any problems
bodyText ||| installing the software packages; despite this, a number of
bodyText ||| participants did have trouble installing our prototype and
bodyText ||| yet did not contact us, which contributed significantly to
bodyText ||| the drop-out rate.
subsectionHeader ||| The Post-test Questionnaire
bodyText ||| The post-test questionnaire was administered online, again
bodyText ||| using a common online survey vendor, in the same way as
bodyText ||| the pretest questionnaire. Participants were emailed
bodyText ||| requests to fill out the survey, and provided links to the
bodyText ||| survey site, when they had run the TALC software for two
bodyText ||| weeks and their usage data had been uploaded. The survey
bodyText ||| had the same ques tions as the pretest questionnaire, along
bodyText ||| with the addition of thirteen questions to dete rmine the
bodyText ||| participants’ perceptions of using the TALC system over
bodyText ||| the deployment period.
sectionHeader ||| RESULTS
bodyText ||| This section describes the results from our deployment
bodyText ||| study, and from our pre - and post-test questionnaires.
bodyText ||| Events Tracked
bodyText ||| TALC kept logs of the users’ interaction with it, over the
bodyText ||| two week period, and the data was uploaded twice to our
bodyText ||| server: once at the end of each week.
bodyText ||| From the logs we categorized five types of event s:
bodyText ||| Awareness events, Learning events, Control (Fixed) events,
bodyText ||| Control (Ignore) events, and Reappear events. An
bodyText ||| Awareness event was recorded when graffiti for a particular
bodyText ||| threat was shown to the user for the first time. Whenever
bodyText ||| our simplified description of the threat was shown to the
bodyText ||| user or when the user clicked on a graffiti, and the vendor
bodyText ||| website was displayed, it was recorded as a Learning event.
bodyText ||| Whenever users would indicate to the system that a
bodyText ||| vulnerability had been repaired and should be dismissed
bodyText ||| (through clicking the “Already Fixed” button in the TALC
bodyText ||| interface), Control (Fixed) events were recorded. If the
bodyText ||| vulnerability hadn’t actually been fixed, a Reappear event
bodyText ||| would be recorded when the vulnerability was re-detected.
bodyText ||| Finally, if a user chose to not fix a vulnerability by clicking
page ||| 1060
note ||| CHI 2008 Proceedings · Am I Safe	April 5-10, 2008 · Florence, Italy
figureCaption ||| Figure 3: Awareness of new threats reported by
figureCaption ||| TALC to the test participants.
bodyText ||| the Ignore button while viewing a patch website, a Control
bodyText ||| (Ignore) event was written to the log.
bodyText ||| Each line on these graphs represents a single test
bodyText ||| participant. Figure 3 records the distribution of Awareness
bodyText ||| events—each representing a newly detected vulnerability—
bodyText ||| over the TALC active week period. The smaller spike in
bodyText ||| awareness at later stages of test period is a composite of
bodyText ||| two factors—new vulnerabilities released by NVD and new
bodyText ||| program installs by users of the software.
subsectionHeader ||| Usage Patterns
bodyText ||| The majority of user actions were taken within two days
bodyText ||| after graffiti for a particular vulnerability first appeared on
bodyText ||| the desktop: 60% of all vulnerabilities were fixed within a
bodyText ||| two-day period. However, 39% of the remaining
bodyText ||| vulnerabilities that were fixed were patched in the last two
bodyText ||| days of the test, indicating that users were patching,
bodyText ||| ignoring graffiti for a couple of days, and then coming back
bodyText ||| and patching at a later time. This is illustrated in Figure 4
bodyText ||| below.
bodyText ||| Recall that Learning events represent visits by users to a
bodyText ||| patch website through TALC; this figure shows the
bodyText ||| distribution of such visits. Beyond simply exploring
bodyText ||| vulnerabilities through TALC, we believe that the effects of
bodyText ||| making users aware of software vulnerabilities on their
bodyText ||| systems may have resulted in greater sensitivity to patching
bodyText ||| in general: A number of the respondents to our post-test
bodyText ||| survey reported using regular web search engines to find
bodyText ||| out more details about the detected vulnerabilities. While
bodyText ||| we were encouraged by these findings, such events are
bodyText ||| beyond the scope of the instrumentation we had in place for
bodyText ||| TALC and so we only have self-reports of such activities.
bodyText ||| The Fixed and Ignore types of Control events are a good
bodyText ||| reflection of the effectiveness of TALC. When a participant
bodyText ||| applied a software patch, TALC did not immediately
bodyText ||| remove the graffiti; rather, the graffiti was removed during
bodyText ||| the next periodic scan of the user’s system. The TALC user
bodyText ||| interface, however, provided an option to manually invoke
figureCaption ||| Figure 4: Learning events logged by TALC.
bodyText ||| the scan to remove graffiti for threats that had been fixed.
bodyText ||| Another option, which incidentally most users adopted, was
bodyText ||| to use the Control window to mark a threat as “Fixed” so
bodyText ||| that TALC hides the graffiti. Figure 5 shows users’ usage
bodyText ||| patterns of marking threats as fixed.
bodyText ||| A common pattern across all participants is that they tried
bodyText ||| to fix a number of vulnerabilities initially, following which
bodyText ||| there was a lull period with little or no activity; finally,
bodyText ||| several days later, there were more attempts to fix
bodyText ||| vulnerabilities. We believe this pattern indicates favorable
bodyText ||| acceptance on the part of users: rather than becoming
bodyText ||| infuriated with the notifications provided by TALC, users
bodyText ||| were “living with” the notifications for a period of several
bodyText ||| days, and then fixing them at convenient intervals. Users
bodyText ||| were able to put off patching anything for a couple of days,
bodyText ||| but were not allowed to forget about the security task to
bodyText ||| which they needed to attend. This indicates that the graffiti
bodyText ||| notification system worked well in allowing users to push
bodyText ||| back their lower priority (but necessary) security tasks until
bodyText ||| they were convenient, but while still retaining awareness of
bodyText ||| the need to perform these tasks. Furthermore, we believe
bodyText ||| the sudden flurry of activity near the end of the active week
figureCaption ||| Figure 5: Participants marking threats as “Fixed”.
figure ||| Awareness
figure ||| 1	2	3	4	5	6	7
figure ||| 80
figure ||| 70
figure ||| 60
figure ||| 50
figure ||| 40
figure ||| 30
figure ||| 20
figure ||| 10
figure ||| 0
figure ||| Days
figure ||| Learning
figure ||| 1	2	3	4	5	6	7
figure ||| 40
figure ||| 20
figure ||| 90
figure ||| 80
figure ||| 70
figure ||| 60
figure ||| 50
figure ||| 30
figure ||| 10
figure ||| 0
figure ||| Days Graffiti was shown
figure ||| Control (Fixed)
figure ||| 70
figure ||| 60
figure ||| 50
figure ||| 40
figure ||| 30
figure ||| 20
figure ||| 10
figure ||| 0
figure ||| 1	2	3	4	5	6	7
figure ||| Days Graffiti was shown
page ||| 1061
note ||| CHI 2008 Proceedings · Am I Safe	April 5-10, 2008 · Florence, Italy
figureCaption ||| Figure 6: Threats that reappeared after being
bodyText ||| marked as “Fixed” by the participants.
bodyText ||| represents a periodic turn of attention toward patching,
bodyText ||| rather than a desire by participants to “wrap up” patching
bodyText ||| before the end of the study. Much of this activity, for
bodyText ||| example, came from the condition two participants, who
bodyText ||| still had another week to participate in the study.
bodyText ||| In the subsequent scan cycles, TALC logged any of these
bodyText ||| fixed threats that still match the vulnerability description
bodyText ||| from NVD and logs them as a reappearance of a threat,
bodyText ||| shown in Figure 6.
bodyText ||| We should note here that, in our current implementation,
bodyText ||| threats for which the NVD has only an advisory (meaning:
bodyText ||| for which no patch is available) are never detected as fixed
bodyText ||| by TALC. To handle such a scenario, TALC allows the
bodyText ||| user to optionally ignore these threats that have reappeared.
bodyText ||| Threats that have been ignored will not reappear in the
bodyText ||| subsequent scans unless the user explicitly asks TALC to
bodyText ||| include them in the scan. Occurrences of this event are
bodyText ||| plotted in Figure 7. The spike near the start of the test may
bodyText ||| be due to the large number of vulnerabilities detected by
bodyText ||| TALC (see below for details on the number of raw
bodyText ||| vulnerabilities found on users’ systems). These Ignore
bodyText ||| events were also recorded when participants found the
bodyText ||| information provided by the patch website too daunting for
bodyText ||| them, and chose to leave the vulnerability unpatched. We
bodyText ||| discuss some suggestions for how to overcome both these
bodyText ||| shortcomings in the Future Work section.
sectionHeader ||| DISCUSSION
bodyText ||| There are multiple useful metrics for determining what
bodyText ||| constitutes efficacy in a tool such as TALC. One such
bodyText ||| metric is whether the tool increases the perceived safety of
bodyText ||| users; the second is whether it increases their actual safety.
bodyText ||| While we evaluated for both metrics, we believe that the
bodyText ||| latter is actually the more important, since perceptions of
bodyText ||| increased safety are of little value without actually
bodyText ||| increased safety.
bodyText ||| In the sections below we first report on TALC’s efficacy in
bodyText ||| actually repairing system vulnerabilities, and then on users’
bodyText ||| perceptions of its efficacy.
figureCaption ||| Figure 7: Participants asking TALC to Ignore a
figureCaption ||| threat from subsequent scans
subsectionHeader ||| TALC Effectiveness
bodyText ||| We were pleased to find that TALC provided a dramatic
bodyText ||| increase in the safety of users’ systems during its
bodyText ||| deployment, and that TALC’s notifications made a large
bodyText ||| and statistically significant difference in users’ awareness
bodyText ||| and motivation to install patches.
bodyText ||| In the weeks where TALC was dormant—meaning it was
bodyText ||| not drawing graffiti on the users’ desktops—none of the
bodyText ||| users patched any vulnerabilities whatsoever. However, in
bodyText ||| the week when the graffiti was placed on the desktop,
bodyText ||| seventy percent of the users fixed at least one vulnerability,
bodyText ||| with an average of 24.3 vulnerabilities patched per user
bodyText ||| (averaged over all users), and an average of 34.7
bodyText ||| vulnerabilities patched over users who patched at least one
bodyText ||| vulnerability. The number of vulnerabilities patched during
bodyText ||| the active period was found to be statistically significant
bodyText ||| (t(9) = 2.78, p = 0.0216) when compared to the dormant
bodyText ||| state when no vulnerabilities were patched.
bodyText ||| The absolute number of vulnerabilities patched may seem
bodyText ||| artificially high, because it does not necessarily indicate the
bodyText ||| number of fixes downloaded, but rather the number of
bodyText ||| vulnerabilities patched: A single fix downloaded by the
bodyText ||| user may or may not patch multiple vulnerabilities.
bodyText ||| At the beginning of the test, TALC found an average of
bodyText ||| 47.6 vulnerabilities on our participants’ machines. All
bodyText ||| participants’ computers had at least five vulnerabilities,
bodyText ||| with the most having 64 vulnerabilities. These numbers not
bodyText ||| only confirm the threat posed by unpatched software, but
bodyText ||| also users’ lack of awareness about vulnerabilities on their
bodyText ||| systems for which patches exist.
bodyText ||| Although TALC was effective in getting users to fix some
bodyText ||| of the vulnerabilities in their systems, none of the users
bodyText ||| patched their machines completely. Of the 482
bodyText ||| vulnerabilities left unpatched, 208 (43.15%) were
bodyText ||| considered serious threats by the NVD, 88 (18.25%) were
bodyText ||| considered moderate threats by the NVD, and 186
bodyText ||| (38.59%) were considered mild threats. The total number of
bodyText ||| vulnerabilities increased over the test period in part due to
figure ||| Reappearances
figure ||| 2.5
figure ||| 2
figure ||| 1.5
figure ||| 1
figure ||| 0.5
figure ||| 0
figure ||| 1	2	3	4	5	6	7
figure ||| Days Grafitti was shown
figure ||| Control (Ignore)
figure ||| 70
figure ||| 1	2	3	4	5	6	7
figure ||| 40
figure ||| 20
figure ||| 60
figure ||| 50
figure ||| 30
figure ||| 10
figure ||| 0
figure ||| Days Graffiti was shown
page ||| 1062
note ||| CHI 2008 Proceedings · Am I Safe	April 5-10, 2008 · Florence, Italy
bodyText ||| new software being installed by our test subjects, but
bodyText ||| mostly due to updates in the vulnerability listing from the
bodyText ||| NVD. 50% of the users responded that it was very difficult
bodyText ||| to correct the security vulnerabilities reported by TALC,
bodyText ||| which we attribute to the poor usability of many of the web
bodyText ||| pages supplied by the NVD. In addition, sometimes the
bodyText ||| links provided in the NVD data were not valid. Further
bodyText ||| discussion can be found in the Future Work section below.
subsectionHeader ||| User Perce ptions
bodyText ||| One of the goals of TALC was to experiment with gentle
bodyText ||| reminder functions to motivate users to take security
bodyText ||| actions. In the post-test questionnaire, when asked to
bodyText ||| suggest improvements to the program, thirty-three percent
bodyText ||| of the participants suggested various solutions for making
bodyText ||| the graffiti less invasive. However, our goal was to make
bodyText ||| TALC as motivating as possible, without being overly
bodyText ||| annoying (which could have caused users to disable the
bodyText ||| program entirely). A majority (67%) of users raised no
bodyText ||| issue with intrusiveness; further, we find it to be telling that
bodyText ||| the only user who reported disabling the TALC software
bodyText ||| during the test did so because he felt it was slowing his
bodyText ||| system down too much. The implementation of our
bodyText ||| Visualization module uses the default.NET transparency
bodyText ||| effects, which run on the CPU on systems without modern
bodyText ||| graphics cards, so this may have contributed to the
bodyText ||| problem.
bodyText ||| Finally, with regard to the effect of TALC on perceived
bodyText ||| user safety, we found that four of the seven users who
bodyText ||| responded to the post-study questionnaire felt that using
bodyText ||| TALC had improved their ability to protect their computer,
bodyText ||| and that their computer was safer as a result. Although this
bodyText ||| figure does not represent universal success in increasing
bodyText ||| perceived safety, we were delighted to demonstrate any
bodyText ||| increase, since our pre-test questionnaire showed users
bodyText ||| were generally unaware of any vulnerabilities. We believe
bodyText ||| that this sort of awareness of risk is essential for self-
bodyText ||| managed computers (at least given today’s state-of-the-art
bodyText ||| in automated security systems), and points to necessary
bodyText ||| further work in the area of conveying an accurate sense of
bodyText ||| risk or safety to users.
subsectionHeader ||| Future Work
bodyText ||| Our near-term goals concern both expanding the
bodyText ||| capabilities of the TALC framework, as well as evaluating
bodyText ||| with a larger user base on how well our visualization and
bodyText ||| control features motivate and support users to mitigate
bodyText ||| threats.
bodyText ||| One of the common problems encountered by users was the
bodyText ||| complexity of vendors’ update websites. To address this
bodyText ||| issue, we intend to add another level of proactivity in the
bodyText ||| system, to allow TALC to automatically download and
bodyText ||| install patches from a set of “common” websites, the patch
bodyText ||| processes of which can be built into the tool itself. With
bodyText ||| this addition, TALC would only present instructional web
bodyText ||| pages for late-breaking advisories that do not include a
bodyText ||| direct download link to a software patch. This feature can
bodyText ||| be accompanied by an additional layer of abstraction over
bodyText ||| the patch websites that simply asks the user to update their
bodyText ||| software to the latest version without loading the entire
bodyText ||| website containing specific details of the threat.
bodyText ||| To prevent display of “unfixable” problems (such as
bodyText ||| advisories that do not have valid URLs), we intend to filter
bodyText ||| the advisories for common problems, and never show
bodyText ||| graffiti for the vulnerabilities reported.
bodyText ||| We also intend to add several more information sources to
bodyText ||| the program, to exercise the extensibility features described
bodyText ||| in the Implementation section. Most important among these
bodyText ||| are the creation of modules that integrate a number of
bodyText ||| existing security tools, such as NMAP [12] and Nessus [8],
bodyText ||| to extract data about other sorts of system vulnerabilities.
bodyText ||| Specifically, we plan to use NMAP (a port scanning tool)
bodyText ||| to independently audit the user’s firewall, since properly
bodyText ||| configured firewalls are very effective at blocking many
bodyText ||| automated attacks. Nessus is a tool that performs security
bodyText ||| audits by running exploit code against a user’s computer. It
bodyText ||| has an active development base that releases new exploits
bodyText ||| to be used while auditing.
sectionHeader ||| CONCLUSION
bodyText ||| We have presented TALC, a software system that assists
bodyText ||| users in protecting their computers from some of the most
bodyText ||| serious threats on the Internet, software with known
bodyText ||| vulnerabilities. TALC uses a low-intrusion notification
bodyText ||| mechanism for presenting users with information about
bodyText ||| vulnerabilities. Through the use of automated system audits
bodyText ||| and correlation against online databases, we can detect
bodyText ||| potential software vulnerabilities and give users easier
bodyText ||| mechanisms to act to repair those vulnerabilities. The
bodyText ||| extensible architecture of TALC allows it to be used to
bodyText ||| detect, visualize, and mitigate against a wide range of
bodyText ||| threats.
bodyText ||| More generally, we believe that the approach taken by
bodyText ||| TALC may be useful in cases where 1) user motivation for
bodyText ||| a task may be low (as is often the case with security tasks),
bodyText ||| 2) intrusive or disruptive notifications may actually incent
bodyText ||| users to disable the system, and 3) there is not the need for
bodyText ||| immediate action. This combination of factors makes this
bodyText ||| class of tasks somewhat different from others (such as
bodyText ||| firewalls or background email notification) that have been
bodyText ||| widely studied in our community. We believe that the
bodyText ||| strategy of background notifications that strike a balance
bodyText ||| between awareness and annoyance to gently incent the user
bodyText ||| can be profitably applied to this class of problems.
sectionHeader ||| REFERENCES
reference ||| 1. Bailey, B.P., Konstan, J.A. and Carlis, J. V. (2001) The
reference ||| effects of interruptions on task performance,
reference ||| annoyance, and anxiety in the user interface.
reference ||| Proceedings ofINTERACT ’01, pp. 593-601.
reference ||| 2. Bennett, R. and Flavin, J. “Determinants of Fear of
reference ||| Crime: The Effect of Cultural Setting.” Justice
reference ||| Quarterly, 11:3, September 1994, pp. 357-381.
reference ||| 3. BMC Software. Marimba Patch Management
reference ||| Software, http://www.marimba.com/
reference ||| 1063
reference ||| CHI 2008 Proceedings · Am I Safe	April 5-10, 2008 · Florence, Italy
reference ||| 4. Bowling, A., Barber, J., Morris, R., and Ebrahim, S.
reference ||| ÒDo Perceptions of Neighbourhood Environment
reference ||| Influence Health? Baseline Findings from a British
reference ||| Survey of Aging.” Journal of Epidemioogy and
reference ||| Community Health, 60:476-483.2006.
reference ||| 5. Computer Emergency Response Team (CERT), 2006.
reference ||| CERT/CC	Statistics	1988-2006.
reference ||| http://www.cert.org/stats
reference ||| 6. Cooke, E., Jahanian, F., and McPherson, D. The
reference ||| Zombie Roundup: Understanding, Detecting and
reference ||| Disrupting Botnets, in First Workshop on Steps to
reference ||| Reducing Unwanted Traffic on the Internet (SRUTI),
reference ||| 2005.
reference ||| 7. Cowan, C., Wagle, P., and Pu, C. Buffer Overflows:
reference ||| Attacks and Defenses for the Vulnerability of the
reference ||| Decade,	DARPA	Information	Survivability
reference ||| Conference and Expo, 1999.
reference ||| 8. Deraison, R. Nessus - A Comprehensive Vulnerability
reference ||| scanning program, http://www.nessus.org/, 1998.
reference ||| 9. Dourish, P., Redmiles, D. , An approach to usable
reference ||| security based on event monitoring and visualization.
reference ||| In Proceedings of the New Security Paradigms
reference ||| Workshop (NSPW), 2002. pp. 75-81.
reference ||| 10. Edwards, W.K., Poole, E.S., and Stoll, J. Security
reference ||| Automation Considered Harmful? In Proceedings of
reference ||| the New Security Paradigms Workshop (NSPW), White
reference ||| Mountain, New Hampshire. September 18-21, 2007.
reference ||| 11. Ferrell, J. Crimes of Style: Urban Graffiti and the
reference ||| Politics of Criminality. New York: Garland. 1993.
reference ||| 12. Fyodor. Nmap - Free Security Scanner for Network
reference ||| Exploration and Security Audits, Insecure.org, 1997.
reference ||| 13. Geason, S. “Preventing Graffiti and Vandalism.”
reference ||| Proceedings of Designing Out Crime: Crime
reference ||| Prevention through Environmental Design, Sydney,
reference ||| Australia. June 16, 1989.
reference ||| 14. Ianelli, N., and Hackworth, A. Botnets as a Vehicle for
reference ||| Online Crime, CERT, Request for Comments (RFC)
reference ||| 1700, December 2005.
reference ||| 15. Isbell, C. and Pierce, J. An IP Continuum for Adaptive
reference ||| Interface Design. In Proceedings of HCI International,
reference ||| 2005.
reference ||| 16. LaMacchia, B.A. Security Attacks and Defenses, in
reference ||| 47th Meeting of IFIP WG 10.4.2005.
reference ||| 17. McAfee AVERT Labs. SAGE. Security Vision from
reference ||| McAfee AVERT Labs, July 2006.
reference ||| 18. McCrickard, D. S., Chewar, C. M., Somervell, J. P., &
reference ||| Ndiwalana, A. A Model for Notification Systems
reference ||| Evaluation—Assessing User Goals for Multitasking
reference ||| Activity. ACM Transactions on Computer-Human
reference ||| Interaction (TOCHI), 10 (4), 2003.
reference ||| 19. Merijn. HijackThis .
reference ||| http://www.spywareinfo.com/~merijn/programs.php.
reference ||| 20. Microsoft. Manage Your Computer's Security Settings
reference ||| in	One	Place	with	Security	Center,
reference ||| http://www.microsoft.com/windowsxp/using/security/i
reference ||| nternet/sp2_wscintro.mspx.
reference ||| 21. Microsoft. Programs that are known to experience a
reference ||| loss of functionality when they run on a Windows XP
reference ||| Service	Pack	2-based	computer,
reference ||| http://support.microsoft.com/?id=884130.
reference ||| 22. Morin, K., Hayes, E., Carroll, M., and Chamberlain, B.
reference ||| “Selected Factors Associated with Students’
reference ||| Perceptions of Threat in the Community.” Public
reference ||| Health Nursing, 19:6, pp. 451-459, Nov. 2002
reference ||| 23. Moskowitz, C.L.a.C. Simple Desktop Security with
reference ||| Chameleon. in Lorrie Faith Cranor, S.G. ed. Security
reference ||| and Usability, O'Reilly, August 2005.
reference ||| 24. National Institute of Standards and Technology
reference ||| (NIST).	National	Vulnerability	Database,
reference ||| http://nvd.nist.gov.
reference ||| 25. National Institute of Standards and Technology
reference ||| (NIST), 2002. The economic impacts of inadequate
reference ||| infrastructure for software testing. Technical Report
reference ||| 02-3, May 2002. This report estimates damage from
reference ||| attacks exploiting software vulnerabilities at $60
reference ||| billion/year.
reference ||| 26. Rafail, J. Cross-Site Scripting Vulnerabilities, CERT
reference ||| Coordination Center, 2001.
reference ||| 27. Redstrom, J., Skog, T. and Hallnas, L. Informative Art:
reference ||| Using Amplified Artworks as Information Displays, in
reference ||| Proceedings of the Designing Augmented Reality
reference ||| Environments Conference ‘00, (Elsinore Denmark,
reference ||| 2000), 103 Ð114.
reference ||| 28. Symantec Internet Security Threat Report, Volume IX.
reference ||| www.symantec.com/enterprise/threatreport/index.jsp.
reference ||| 29. US General Accounting Office (GAO), 2003.
reference ||| "Effective Patch Management is Critical to Mitigating
reference ||| Software Vulnerabilities." Testimony before the
reference ||| Subcommittee on Technology, Information Policy,
reference ||| Intergovernmental Relations, and the Census.
reference ||| 30. Zurko, M.E. User-Centered Security: Stepping Up to
reference ||| the Grand Challenge ACSAC, 2005.
page ||| 1064

note ||| CHI 2008 Proceedings · Am I Safe	April 5-10, 2008 · Florence, Italy
title ||| You’ve Been Warned: An Empirical Study of the
title ||| Effectiveness of Web Browser Phishing Warnings
author ||| Serge Egelman
affiliation ||| Carnegie Mellon University
email ||| egelman@cs.cmu.edu
author ||| Lorrie Faith Cranor
affiliation ||| Carnegie Mellon University
email ||| lorrie@cs.cmu.edu
author ||| Jason Hong
affiliation ||| Carnegie Mellon University
email ||| jasonh@cs.cmu.edu
sectionHeader ||| ABSTRACT
bodyText ||| Many popular web browsers now include active phishing
bodyText ||| warnings since research has shown that passive warnings
bodyText ||| are often ignored. In this laboratory study we examine the
bodyText ||| effectiveness of these warnings and examine if, how, and
bodyText ||| why they fail users. We simulated a spear phishing attack
bodyText ||| to expose users to browser warnings. We found that 97%
bodyText ||| of our sixty participants fell for at least one of the phishing
bodyText ||| messages that we sent them. However, we also found that
bodyText ||| when presented with the active warnings, 79% of partici-
bodyText ||| pants heeded them, which was not the case for the passive
bodyText ||| warning that we tested—where only one participant heeded
bodyText ||| the warnings. Using a model from the warning sciences we
bodyText ||| analyzed how users perceive warning messages and offer
bodyText ||| suggestions for creating more effective phishing warnings.
sectionHeader ||| Author Keywords
keyword ||| Phishing, warning messages, mental models, usable privacy
keyword ||| and security
sectionHeader ||| ACM Classification Keywords
category ||| H.1.2 User/Machine Systems, H.5.2 User Interfaces, D.4.6
category ||| Security and Protection
sectionHeader ||| INTRODUCTION
bodyText ||| Online security indicators have historically failed users be-
bodyText ||| cause users do not understand or believe them. The preva-
bodyText ||| lence of phishing, a scam to collect personal information
bodyText ||| by mimicking trusted websites, has prompted the design of
bodyText ||| many new online security indicators. Because phishing is a
bodyText ||| semantic attack that relies on confusing people, it is difficult
bodyText ||| to automatically detect these attacks with complete accuracy.
bodyText ||| Thus, anti-phishing tools use warnings to alert users to po-
bodyText ||| tential phishing sites, rather than outright blocking them.
bodyText ||| The question remains, do anti-phishing warnings actually
bodyText ||| help users? Up until recently these tools have relied on pas-
bodyText ||| sive indicators to alert users. A passive indicator indicates
bodyText ||| a potential danger by changing colors, providing textual in-
bodyText ||| formation, or by other means without interrupting the user’s
copyright ||| Permission to make digital or hard copies of all or part of this work for
copyright ||| personal or classroom use is granted without fee provided that copies are
copyright ||| not made or distributed for profit or commercial advantage and that copies
copyright ||| bear this notice and the full citation on the first page. To copy otherwise, or
copyright ||| republish, to post on servers or to redistribute to lists, requires prior specific
copyright ||| permission and/or a fee.
note ||| CHI 2008, April 5 - 10, 2008, Florence, Italy.
copyright ||| Copyright 2008 ACM 978-1-60558-011-1/08/04...$5.00.
figureCaption ||| Figure 1. The active Internet Explorer 7.0 phishing warning.
figureCaption ||| Figure 2. The passive Internet Explorer 7.0 phishing warning.
bodyText ||| task. However, research has shown that passive indicators
bodyText ||| are failing users because users often fail to notice them or do
bodyText ||| not trust them [23].
bodyText ||| The newest web browsers now include active warnings, which
bodyText ||| force users to notice the warnings by interrupting them. Mi-
bodyText ||| crosoft’s Internet Explorer 7 includes both active and passive
bodyText ||| phishing warnings (Figures 1 and 2, respectively). When IE7
bodyText ||| encounters a confirmed phishing website, the browser will
bodyText ||| display an active warning message giving the user the op-
bodyText ||| tion of closing the window (recommended) or displaying the
bodyText ||| website (not recommended). This warning is a full screen
bodyText ||| error, which turns the URL bar red if the user chooses to dis-
bodyText ||| play the website (Figure 1). The passive indicator, a popup
page ||| 1065
note ||| CHI 2008 Proceedings · Am I Safe	April 5-10, 2008 · Florence, Italy
figureCaption ||| Figure 3. The active Firefox 2.0 phishing warning.
bodyText ||| dialog box, is displayed to the user when the browser be-
bodyText ||| lieves a website is suspicious (Figure 2), but that website
bodyText ||| has not been verified as being a phishing website (i.e. it does
bodyText ||| not appear on a blacklist). We consider this warning to be
bodyText ||| more passive because it does not give the user any choices,
bodyText ||| nor does it make any recommendations.
bodyText ||| Firefox 2.0 also includes an active phishing warning, which
bodyText ||| was part of the Google Toolbar extension for previous ver-
bodyText ||| sions of Firefox. When a user encounters a confirmed phish-
bodyText ||| ing website, a non-interactive dimmed version of the web-
bodyText ||| site is displayed with an overlayed dialog box. The user is
bodyText ||| given a choice between continuing to the site or leaving. The
bodyText ||| user may also click the red ‘X’ in the corner of the warning,
bodyText ||| which has the same effect as continuing to the website (Fig-
bodyText ||| ure 3).
bodyText ||| In this study we compared the effectiveness of active and
bodyText ||| passive phishing warnings by analyzing them using a warn-
bodyText ||| ing analysis methodology used by researchers in the warning
bodyText ||| sciences field, called the Communication-Human Informa-
bodyText ||| tion Processing Model (C-HIP) model [21].
bodyText ||| This paper makes three contributions. First, it presents the
bodyText ||| results of a study evaluating the effectiveness of active secu-
bodyText ||| rity indicators in current web browsers. Second, it presents
bodyText ||| an analysis of the results using a model from the warning
bodyText ||| sciences. Third, it presents recommendations for improving
bodyText ||| these security indicators such that fewer users fall victim to
bodyText ||| online fraud.
bodyText ||| We first frame our study within the context of previous phish-
bodyText ||| ing and warning research, and then describe the methodol-
bodyText ||| ogy behind our study. We then discuss the results of our
bodyText ||| user study and how effective we determined each warning
bodyText ||| message to be. Finally, we make recommendations based on
bodyText ||| these results for designing more effective security indicators.
sectionHeader ||| BACKGROUND
bodyText ||| In this section we describe previous work related to users’
bodyText ||| susceptibility to phishing, warning indicators used in web
bodyText ||| browsers, and user perceptions of warning messages.
subsectionHeader ||| Phishing Susceptibility
bodyText ||| Despite growing efforts to educate users and create better
bodyText ||| detection tools, users are still very susceptible to phishing
bodyText ||| attacks. Unfortunately, due to the nature of the attacks, it is
bodyText ||| very difficult to estimate the number of people who actually
bodyText ||| fall victim. A 2006 report by Gartner estimated the costs at
bodyText ||| $1,244 per victim, an increase over the $257 they cited in
bodyText ||| a 2004 report [11]. In 2007 Moore and Clayton estimated
bodyText ||| the number of phishing victims by examining web server
bodyText ||| logs. They estimated that 311,449 people fall for phishing
bodyText ||| scams annually, costing around 350 million dollars [15]. An-
bodyText ||| other study in 2007 by Florencio and Herley estimated that
bodyText ||| roughly 0.4% of the population falls for phishing attacks an-
bodyText ||| nually [9].
bodyText ||| Phishing works because users are willing to trust websites
bodyText ||| that appear to be designed well. In a 2001 study on web-
bodyText ||| site credibility, Fogg et al. found that the “look and feel”
bodyText ||| of a website is often most important for gaining a user’s
bodyText ||| trust [10]. A 2006 phishing study by Dhamija et al. found
bodyText ||| that 90% of the participants were fooled by phishing web-
bodyText ||| sites. The researchers concluded that current security indi-
bodyText ||| cators (i.e. the lock icon, status bar, and address bar) are inef-
bodyText ||| fective because 23% of the participants failed to notice them
bodyText ||| or because they did not understand what they meant [7].
bodyText ||| In a similar study, Downs et al. showed participants eight
bodyText ||| emails, three of which were phishing. They found that the
bodyText ||| number of participants who expressed suspicion varied for
bodyText ||| each email; 47% expressed suspicion over a phishing mes-
bodyText ||| sage from Amazon, whereas 74% expressed suspicion over
bodyText ||| a phishing message from Citibank. Those who had inter-
bodyText ||| acted with certain companies in the past were significantly
bodyText ||| more likely to fall for phishing messages claiming to be from
bodyText ||| these companies. Participants were also likely to ignore or
bodyText ||| misunderstand web browser security cues [8].
subsectionHeader ||| Phishing Indicators
bodyText ||| New research has focused on creating new anti-phishing in-
bodyText ||| dicators because existing security indicators have failed. The
bodyText ||| Passpet system, created by Yee et al. in 2006, uses indicators
bodyText ||| so that users know they are at a previously-trusted website.
bodyText ||| Users can store an animal icon within the web browser for
bodyText ||| each trusted site with which they interact. The system will
bodyText ||| only send a password when the user recognizes that the ani-
bodyText ||| mal icons match. Preliminary user testing suggests that this
bodyText ||| system is easy for users to use [25]. Other proposals have
bodyText ||| also been put forth to modify browser chrome to help users
bodyText ||| detect phishing websites. In one system, “synchronized ran-
bodyText ||| dom dynamic boundaries,” by Ye and Smith, the browser
bodyText ||| chrome is modified to blink at a random rate. If the blink
bodyText ||| rate matches a trusted window’s blink rate, the user knows
bodyText ||| that the window in question has not been spoofed [24]. A
bodyText ||| similar solution using a trusted window was also proposed
bodyText ||| by Dhamija and Tygar in 2005. In their system the chrome
bodyText ||| of the browser window contains a colored pattern that must
bodyText ||| be matched with the trusted window. The user knows to rec-
bodyText ||| ognize the trusted window because it contains a personal im-
bodyText ||| age that the user selected during the initial configuration [6].
bodyText ||| Since all of these proposals require the use of complicated
bodyText ||| third-party tools, it’s unclear how many users will actually
bodyText ||| benefit from them. These proposals have only undergone
bodyText ||| minimal user testing in unrealistic environments. User test-
bodyText ||| ing should be performed under real world conditions before
bodyText ||| any new security indicator is recommended.
page ||| 1066
note ||| CHI 2008 Proceedings · Am I Safe	April 5-10, 2008 · Florence, Italy
bodyText ||| The SiteKey system was introduced in 2005 to simplify au-
bodyText ||| thentication by not forcing the user to install additional soft-
bodyText ||| ware. SiteKey uses a system of visual authentication images
bodyText ||| that are selected by the user at the time of enrollment. When
bodyText ||| the user enters his or her username, the image is displayed.
bodyText ||| If the user recognizes the image as the original shared secret,
bodyText ||| it is safe to enter the password [2]. However, a recent study
bodyText ||| found that 92% of participants still logged in to the website
bodyText ||| using their own credentials when the correct image was not
bodyText ||| present [19]. However, this sample may have been drawn
bodyText ||| from a biased population since others refused to participate,
bodyText ||| citing privacy and security concerns.
bodyText ||| Some argue that the use of extended validation (EV) certifi-
bodyText ||| cates may help users detect phishing websites. An EV cer-
bodyText ||| tificate differs from a standard SSL certificate because the
bodyText ||| website owner must undergo background checks. A regular
bodyText ||| certificate only tells a user that the certificate was granted
bodyText ||| by a particular issuing authority, whereas an EV certificate
bodyText ||| also says that it belongs to a legally recognized company [4].
bodyText ||| The newest version of Microsoft’s Internet Explorer sup-
bodyText ||| ports EV certificates, coloring the URL bar green and dis-
bodyText ||| playing the name of the company. However, a recent study
bodyText ||| found that EV certificates did not make users less likely to
bodyText ||| fall for phishing attacks. The study also found that after
bodyText ||| reading a help file, users were less suspicious of fraudulent
bodyText ||| websites that did not yield warning indicators [13].
bodyText ||| Many web browser extensions for phishing detection cur-
bodyText ||| rently exist. Unfortunately, a recent study on anti-phishing
bodyText ||| toolbar accuracy found that these tools fail to identify a sub-
bodyText ||| stantial proportion of phishing websites [26]. A 2006 study
bodyText ||| by Wu et al. found that the usability of these tools is also
bodyText ||| lacking because many of them use passive indicators. Many
bodyText ||| users fail to notice the indicators, while others often do not
bodyText ||| trust them because they think the sites look trustworthy [23].
sectionHeader ||| A MODEL FOR WARNINGS
bodyText ||| In this paper we will analyze our user study results using
bodyText ||| a model from the warnings sciences. Computer scientists
bodyText ||| can benefit from studies in this field. Many studies have ex-
bodyText ||| amined “hazard matching” and “arousal strength.” Hazard
bodyText ||| matching is defined as accurately using warning messages to
bodyText ||| convey risks—if a warning does not adequately convey risk,
bodyText ||| the user may not take heed of the warning. Arousal strength
bodyText ||| is defined as the perceived urgency of the warning [12].
bodyText ||| To date, few studies have been conducted to evaluate the
bodyText ||| arousal strength of software warnings. In one study of warn-
bodyText ||| ing messages used in Microsoft Windows, researchers found
bodyText ||| that using different combinations of icons and text greatly af-
bodyText ||| fected participants’ risk perceptions. Participants were shown
bodyText ||| a series of dialog boxes with differing text and icons, and
bodyText ||| were instructed to estimate the severity of the warnings us-
bodyText ||| ing a 10-point Likert scale. The choice of icons and words
bodyText ||| greatly affected how each participant ranked the severity.
bodyText ||| The researchers also examined the extent to which individu-
bodyText ||| als will continue to pay attention to a warning after seeing it
bodyText ||| multiple times (“habituation”). They found that users dis-
bodyText ||| missed the warnings without reading them after they had
bodyText ||| seen them multiple times. This behavior continued even
figureCaption ||| Figure 4. Diagram of the different phases of the C-HIP model [21].
bodyText ||| when using a similar but different warning in a different sit-
bodyText ||| uation. The only way of recapturing the user’s attention was
bodyText ||| to increase the arousal strength of the warning [1].
bodyText ||| Wogalter proposed the Communication-Human Information
bodyText ||| Processing Model (C-HIP) for structuring warning research,
bodyText ||| as shown in Figure 4. He suggests that C-HIP be used to
bodyText ||| identify reasons that a particular warning is ineffective [21].
bodyText ||| The C-HIP model begins with a source delivering a warning
bodyText ||| through a channel to a receiver, who receives it along with
bodyText ||| other environmental stimuli that may distract from the mes-
bodyText ||| sage. The receiver goes through five information processing
bodyText ||| steps, which ultimately determine whether the warning re-
bodyText ||| sults in any change in behavior.
bodyText ||| We can ask the following questions to examine the different
bodyText ||| steps in Wogalter’s model [5]:
listItem ||| 1. Attention Switch and Maintenance — Do users notice the
listItem ||| indicators?
listItem ||| 2. Comprehension/Memory — Do users know what the indi-
listItem ||| cators mean?
listItem ||| 3. Comprehension/Memory — Do users know what they are
listItem ||| supposed to do when they see the indicators?
listItem ||| 4. Attitudes/Beliefs — Do they believe the indicators?
listItem ||| 5. Motivation — Are they motivated to take the recommended
listItem ||| actions?
listItem ||| 6. Behavior — Will they actually perform those actions?
listItem ||| 7. Environmental Stimuli — How do the indicators interact
listItem ||| with other indicators and other stimuli?
bodyText ||| Observing users as they complete a task while thinking aloud
bodyText ||| provides insights into most of the above questions. Alterna-
bodyText ||| tively, users can complete tasks and then fill out post-task
bodyText ||| questionnaires or participate in interviews, although these
bodyText ||| require users to remember why they did something and re-
bodyText ||| port it afterwards, and users sometimes say what they think
figure ||| Environmental
figure ||| Stimuli
figure ||| Comprehension
figure ||| Memory
figure ||| Attention
figure ||| Maintenance
figure ||| Motivation
figure ||| Attention
figure ||| Switch
figure ||| Attitudes
figure ||| Beliefs
figure ||| Behavior
figure ||| Channel
figure ||| Delivery
figure ||| Source
page ||| 1067
note ||| CHI 2008 Proceedings · Am I Safe	April 5-10, 2008 · Florence, Italy
bodyText ||| the researcher wants to hear. In our study of active phishing
bodyText ||| indicators we performed a think-alound experiment followed
bodyText ||| by a post-task questionnaire. We then used the C-HIP model
bodyText ||| to analyze our data.
sectionHeader ||| METHODOLOGY
bodyText ||| In this study participants made online purchases and then
bodyText ||| were told to check their email, whereupon they encountered
bodyText ||| phishing messages we had sent them. We observed partic-
bodyText ||| ipants visit the URLs in these phishing messages, at which
bodyText ||| point the participants were exposed to the web browser warn-
bodyText ||| ing messages. We took note of whether participants read
bodyText ||| these warnings and how they chose to proceed. Finally, par-
bodyText ||| ticipants were given an exit survey.
bodyText ||| The primary purpose of this study was to examine the effec-
bodyText ||| tiveness of phishing warnings found in current web browsers.
bodyText ||| These warnings serve as the last line of defense against a user
bodyText ||| divulging his or her sensitive information to a con artist. In
bodyText ||| other words, prior to these warnings being displayed, it is
bodyText ||| likely that users believe they are visiting legitimate websites.
bodyText ||| Thus, we needed users to fall for the phishing messages we
bodyText ||| sent them during our study so that they would be in a similar
bodyText ||| state of mind when they encountered the warnings. At the
bodyText ||| same time, we needed our attack to be plausible. Thus, we
bodyText ||| simulated a spear phishing attack. Spear phishing “involves
bodyText ||| personalized emails or emails sent to a specifically targeted
bodyText ||| group, such as employees of a particular organization” [8].
bodyText ||| For instance, a phisher might send a message to email ad-
bodyText ||| dresses at aol.com announcing account changes impacting
bodyText ||| AOL users. Since all the recipients are AOL users, this scam
bodyText ||| may have increased credibility because users believe it to be
bodyText ||| relevant to them. In our study, if participants did not believe
bodyText ||| our phishing messages to be credible, they would be less
bodyText ||| likely to follow the links and thus would not see the browser
bodyText ||| warning messages.
bodyText ||| We framed our study as an “online shopping study”—items
bodyText ||| were purchased online, and then we sent the participants
bodyText ||| phishing messages claiming to be from those shopping web-
bodyText ||| sites. Participants were told that we were examining how
bodyText ||| they interact with shopping websites and that they needed to
bodyText ||| think aloud during their purchases. After the first purchase
bodyText ||| was made, participants checked their email to confirm that
bodyText ||| the order was going to be shipped, thereby encountering the
bodyText ||| first phishing message. Once the participants were confi-
bodyText ||| dent that the first purchase had been completed, instructions
bodyText ||| were provided for the second purchase. This purchase was
bodyText ||| then made using a different website, and a different phishing
bodyText ||| message was sent. Participants in the experimental condi-
bodyText ||| tions were given an exit survey before leaving. In this sec-
bodyText ||| tion we will provide the details of our recruitment process
bodyText ||| and the study design.
subsectionHeader ||| Recruitment
bodyText ||| This study was designed as a between-subjects study, with
bodyText ||| four different conditions using the Internet Explorer 7.0 and
bodyText ||| Firefox 2.0 web browsers: participants were shown either
bodyText ||| the Firefox warning (Figure 3), the active IE warning (Fig-
bodyText ||| ure 1), the passive IE warning (Figure 2), or no warning at
bodyText ||| all. As of June 2007, users of Internet Explorer and Firefox
bodyText ||| comprised 58.5% and 34.0% of all Internet users, respec-
bodyText ||| tively [18]. Additionally, both browsers have automatic up-
bodyText ||| date features. Thus, it is only a matter of time before most
bodyText ||| users will be using the newest versions of these browsers
bodyText ||| which contain these phishing warnings. We began recruiting
bodyText ||| participants in May of 2007.
bodyText ||| We did not tell participants that we were studying online se-
bodyText ||| curity because we wanted to simulate a natural environment
bodyText ||| by not priming them to security concerns. We recruited par-
bodyText ||| ticipants from all over Pittsburgh in order to make our re-
bodyText ||| sults generalizable. We attached flyers to telephone posts,
bodyText ||| bus stops, and community bulletin boards. We also posted
bodyText ||| online to Craigslist and a CMU website for recruiting study
bodyText ||| participants. We constructed a screening survey to screen out
bodyText ||| technically savvy individuals, users of certain web browsers,
bodyText ||| participants in previous phishing studies, and users of certain
bodyText ||| email providers. We also used this survey to glean some ba-
bodyText ||| sic demographic information from participants, such as age,
bodyText ||| gender, occupation, prior online shopping experience, etc.
bodyText ||| Participants who contacted us after seeing a recruitment flyer
bodyText ||| were directed to our online screening survey. Since we were
bodyText ||| examining the newest versions of Firefox (2.0) and IE (7.0)
bodyText ||| to include the active warnings, we made sure that all par-
bodyText ||| ticipants in the experimental conditions already used one of
bodyText ||| these browser versions. Thus the screening survey included
bodyText ||| a question about current browser version (with graphics de-
bodyText ||| picting how to determine the version) to screen out users of
bodyText ||| other web browsers.
bodyText ||| Since our lab has conducted previous studies on phishing,
bodyText ||| we were concerned about the potential for priming of prior
bodyText ||| participants. Thus we disqualified anyone who had previ-
bodyText ||| ously participated in a phishing-related study. We were also
bodyText ||| concerned that savvy users would not believe the emails, and
bodyText ||| thus not be exposed to the warnings. We asked four ques-
bodyText ||| tions to gauge each participant’s experience:
listItem ||| •	Have you ever designed a website?
listItem ||| •	Have you ever registered a domain name?
listItem ||| •	Have you ever used SSH?
listItem ||| •	Have you ever configured a firewall?
bodyText ||| In our pilot we discovered that participants who answered
bodyText ||| yes to all four questions were just as likely to believe the
bodyText ||| phishing emails as all other participants. Thus, we decided
bodyText ||| not to disqualify participants based on these questions.
bodyText ||| We tried to make our scenarios as realistic as possible by
bodyText ||| requiring participants to use their own email accounts and
bodyText ||| financial information for the purchases. The screening sur-
bodyText ||| vey explicitly asked whether or not they could check their
bodyText ||| email using a web browser on a foreign computer. We also
bodyText ||| asked them to enter their email addresses so that we could
bodyText ||| contact them as well as to determine which email provider
bodyText ||| they were using. We initially found that some of the larger
bodyText ||| free email providers were detecting our phishing messages
bodyText ||| and filtering them out. We minimized this problem by im-
bodyText ||| plementing DKIM and SPF on our outgoing mail server to
bodyText ||| help recipient mail servers verify the message sender. 1,2
footnote ||| 1http://www.dkim.org/
footnote ||| 2http://www.openspf.org/
page ||| 1068
note ||| CHI 2008 Proceedings · Am I Safe	April 5-10, 2008 · Florence, Italy
bodyText ||| Of the 282 individuals who completed our screening sur-
bodyText ||| vey, only 70 qualified and showed up. Despite our efforts
bodyText ||| to screen out individuals who used email providers that were
bodyText ||| likely to filter out our messages, we still found that we could
bodyText ||| not collect data from ten participants because they did not re-
bodyText ||| ceive either of our phishing messages. These ten participants
bodyText ||| were not included in our results.
bodyText ||| Based on the browser versions that they indicated in the
bodyText ||| screening survey, participants were placed in one of the four
bodyText ||| conditions. The average age of participants was 28 (σ =
bodyText ||| 10.58), and there was no significant difference between the
bodyText ||| groups in terms of age or gender. The Firefox condition con-
bodyText ||| sisted of 20 users of Firefox 2.0, while the other two exper-
bodyText ||| imental conditions consisted of users of Internet Explorer
bodyText ||| 7 (20 participants in the active IE condition and 10 partic-
bodyText ||| ipants in the passive IE condition). The ten participants in
bodyText ||| the control group all used an older version of one of the two
bodyText ||| browsers. The control group was used to determine whether
bodyText ||| or not participants were willing to enter information into our
bodyText ||| phishing websites in the absence of any warning messages.
bodyText ||| This told us whether the warning was affecting phishing sus-
bodyText ||| ceptibility or if it could be attributed to some other factor.
bodyText ||| The group sizes were chosen based on a power analysis per-
bodyText ||| formed prior to recruitment.
bodyText ||| We were initially concerned that the self-selected nature of
bodyText ||| the groups (based on web browser preference) may have bi-
bodyText ||| ased our study. However, we found no statistical differences
bodyText ||| between the average number of hours participants in each
bodyText ||| group claimed to use the Internet, nor with regard to the av-
bodyText ||| erage number of email messages participants claimed to re-
bodyText ||| ceive. In each of the active warning groups, exactly seven
bodyText ||| participants answered “no” to all of the questions used to
bodyText ||| gauge technical prowess. Thus, there were equal numbers of
bodyText ||| novices in each group.
subsectionHeader ||| Scenarios
bodyText ||| We decided to spoof Amazon and eBay since they were the
bodyText ||| most commonly phished non-bank websites [17]. Thus, re-
bodyText ||| gardless of familiarity with the real websites, it is likely that
bodyText ||| participants have previously encountered phishing messages
bodyText ||| claiming to be from these websites. Our spoofed websites
bodyText ||| consisted of login forms for usernames and passwords. To
bodyText ||| make these websites look authentic, we registered two do-
bodyText ||| main names: ebay-login.net and amazonaccounts.net. The
bodyText ||| websites were designed to mimic the login pages of the orig-
bodyText ||| inal websites. We created two spoof URLs at each domain
bodyText ||| name.
bodyText ||| We took steps to ensure our phishing websites triggered the
bodyText ||| warnings in each web browser. Firefox downloads its lo-
bodyText ||| cally stored blacklist from Google, so we modified it locally
bodyText ||| to include our URLs [16]. Microsoft agreed to add our spoof
bodyText ||| URLs to their remote blacklists, causing those URLs to trig-
bodyText ||| ger the IE phishing warnings.
bodyText ||| We copied two common phishing emails spoofing Amazon
bodyText ||| and eBay and changed the content to fit our study. The
bodyText ||| message claiming to be from Amazon was sent out in plain
bodyText ||| text and informed the recipient that the order was delayed
bodyText ||| and would be cancelled unless the recipient clicked the in-
bodyText ||| cluded URL. The message claiming to be from eBay was in
bodyText ||| HTML and informed the recipient that all international or-
bodyText ||| ders needed to be confirmed by visiting a URL contained
bodyText ||| within the message. Both messages contained random or-
bodyText ||| der numbers to help convince the recipients of their legit-
bodyText ||| imacy, though no information specific to the recipients was
bodyText ||| included in these messages in order to make our attacks real-
bodyText ||| istic. The scenario was such that it would have been entirely
bodyText ||| possible for a person to have just completed a purchase from
bodyText ||| one of these websites and then received a generic phishing
bodyText ||| message spoofing that same website. It is also possible for
bodyText ||| a phisher to monitor wireless Internet traffic and conduct a
bodyText ||| similar phishing attack after detecting a purchase. We be-
bodyText ||| lieve that the coincidental nature of this attack was the reason
bodyText ||| why many more participants fell for our attacks than what
bodyText ||| has been found in similar studies [8, 7, 19, 14, 20]. Previous
bodyText ||| phishing studies have spoofed companies with whom vic-
bodyText ||| tims had relationships. However we are unaware of any user
bodyText ||| studies that have used phishing messages timed to coincide
bodyText ||| with a transaction with the spoofed brand.
bodyText ||| Participants arrived at our laboratory and were told that they
bodyText ||| would be purchasing two items online from Amazon and
bodyText ||| eBay. We randomized the order in which the purchases were
bodyText ||| made. We also informed participants that we were recording
bodyText ||| them, so they needed to think aloud about everything they
bodyText ||| were doing. Participants did the study individually with the
bodyText ||| experimenter sitting behind them in the laboratory.
bodyText ||| We were concerned that if we allowed participants to pur-
bodyText ||| chase whatever they wanted, they might take too long to de-
bodyText ||| cide, and that other factors might confound our results. We
bodyText ||| also wanted participants to focus on buying cheap items so
bodyText ||| that we could reimburse them for both purchases while still
bodyText ||| giving them enough additional money for their time. We lim-
bodyText ||| ited the scope of the purchases by asking them to purchase a
bodyText ||| box of paper clips from Amazon, which cost roughly $0.50,
bodyText ||| plus around $6 in shipping (the exact prices changed with
bodyText ||| each order since all participants did not purchase the same
bodyText ||| paperclips). We asked participants to make their eBay pur-
bodyText ||| chases from a cheap electronics store based in Hong Kong
bodyText ||| that sold a variety of items for around $5-$10, including
bodyText ||| shipping. Participants were compensated $35 for their time
bodyText ||| and the purchases, which were made using their personal
bodyText ||| credit cards.
bodyText ||| After each purchase, participants received a sheet of five
bodyText ||| questions relating to shopping. These questions were part
bodyText ||| of an unrelated study on shopping behaviors, but helped our
bodyText ||| study by convincing participants that this was indeed a shop-
bodyText ||| ping study. While the participant answered these questions,
bodyText ||| the experimenter sent them a phishing message. We con-
bodyText ||| structed a web interface for the study, so that the experi-
bodyText ||| menter only needed to enter an email address, the brand to
bodyText ||| spoof, and the experimental condition.
bodyText ||| After the written questions were completed, the experimenter
bodyText ||| told the participant to “check your email to make sure that
bodyText ||| the order is confirmed and ready to ship so we can move
bodyText ||| on.” When participants checked their email, they encoun-
bodyText ||| tered legitimate messages relating to their orders as well as
bodyText ||| a phishing message. After examining (and reacting) to all of
page ||| 1069
note ||| CHI 2008 Proceedings · Am I Safe	April 5-10, 2008 · Florence, Italy
table ||| Condition Name	Size	Clicked	Phished
table ||| Firefox	20	20(100%)	0(0%)
table ||| Active IE	20	19(95%)	9(45%)
table ||| Passive IE	10	10(100%)	9(90%)
table ||| Control	10	9(90%)	9(90%)
tableCaption ||| Table 1. An overview depicting the number of participants in each
tableCaption ||| condition, the number who clicked at least one phishing URL, and
tableCaption ||| the number who entered personal information on at least one phishing
tableCaption ||| website. For instance, nine of the control group participants clicked at
tableCaption ||| least one phishing URL. Of these, all nine participants entered personal
tableCaption ||| information on at least one of the phishing websites.
bodyText ||| the messages, participants received a set of instructions for
bodyText ||| the second purchase. After participants checked their email
bodyText ||| after the second purchase (thereby encountering the second
bodyText ||| phishing message), an exit survey was administered. This
bodyText ||| online exit survey contained questions about participants’ re-
bodyText ||| actions to the warning messages. The experimenter observed
bodyText ||| participants fill this out and asked followup questions if any
bodyText ||| of the responses were too terse or did not seem to follow
bodyText ||| the behaviors exhibited during the experiment. Those in the
bodyText ||| control group were not asked to complete an exit survey as
bodyText ||| they had not seen any warnings. Participants took an aver-
bodyText ||| age of forty minutes to complete all the tasks and were given
bodyText ||| $35 in cash before leaving.
bodyText ||| We were initially concerned that since participants did not
bodyText ||| explicitly want the items, the results might be skewed in fa-
bodyText ||| vor of participants acting more cautious. However, we be-
bodyText ||| lieve their desire to complete the study negated this. Thus,
bodyText ||| the desire to buy the items to complete the study was likely
bodyText ||| just as strong as if the participant were at home purchasing
bodyText ||| a desired item. Additionally, we do not believe that the cost
bodyText ||| of the items played any role since an attacker could use the
bodyText ||| stolen account credentials to make any number of larger pur-
bodyText ||| chases.
sectionHeader ||| RESULTS AND ANALYSIS
bodyText ||| Overall we found that participants were highly susceptible
bodyText ||| to our spear phishing attack. However, users of the active
bodyText ||| phishing warnings were largely protected, since 79% chose
bodyText ||| to heed them. We found a significant difference between
bodyText ||| the active IE and Firefox warnings (p < 0.0004 for Fisher’s
bodyText ||| exact test) as well as no significant difference between the
bodyText ||| passive IE warning and the control group (i.e. significantly
bodyText ||| more users were helped by the active Firefox warning than
bodyText ||| the active IE warning, while the passive IE warning is no dif-
bodyText ||| ferent than not displaying any warning). We also found sig-
bodyText ||| nificant differences between the active IE warning and the
bodyText ||| control group (p < 0.01) demonstrating that the active IE
bodyText ||| warning is still significantly better than not displaying any
bodyText ||| warning. Table 1 depicts these results. In this section we ex-
bodyText ||| amine how participants reacted to the initial phishing mes-
bodyText ||| sages, and then we use the C-HIP model to analyze why
bodyText ||| certain warnings performed better than others.
subsectionHeader ||| Phishing Susceptibility
bodyText ||| Our simulated spear phishing attack was highly effective:
bodyText ||| of the 106 phishing messages that reached participants’ in-
bodyText ||| boxes, participants clicked the URLs of 94 of them (89%).
bodyText ||| While all participants made purchases from both Amazon
bodyText ||| and eBay, not every participant received both of our phish-
bodyText ||| ing messages due to email filtering. Only two participants
bodyText ||| (3%) did not attempt to visit any of the phishing URLs. Of
bodyText ||| the 46 participants who received both phishing messages, 43
bodyText ||| clicked the Amazon link and 37 clicked the eBay link. How-
bodyText ||| ever this difference was not statistically significant, nor were
bodyText ||| there any significant correlations based on which phishing
bodyText ||| message was viewed first. It should also be noted that every
bodyText ||| participant in the control group who followed a link from an
bodyText ||| email message also submitted information to the phishing
bodyText ||| websites (Table 1). Thus, in the absence of security indica-
bodyText ||| tors, it is likely that this type of phishing attack could have a
bodyText ||| success rate of at least 89%.
bodyText ||| With regard to the technical questions mentioned in the Re-
bodyText ||| cruitment section, we noticed a negative trend between tech-
bodyText ||| nical experience and obeying the warnings among Internet
bodyText ||| Explorer users (i.e. users with more technical experience
bodyText ||| were more likely to ignore the warnings). With Firefox,
bodyText ||| technical experience played no role: all users obeyed the
bodyText ||| warnings regardless of their technical experience.
bodyText ||| We did not actually collect any information entered into the
bodyText ||| phishing websites. Instead the experimenter observed each
bodyText ||| participant and noted when they submitted information. Thus
bodyText ||| we cannot conclusively say whether all participants entered
bodyText ||| their correct information. However, the experimenter did
bodyText ||| note that all usernames were entered correctly, and no partic-
bodyText ||| ipants denied entering their correct information when asked
bodyText ||| in the exit survey.
bodyText ||| We found that participants had very inaccurate mental mod-
bodyText ||| els of phishing. Both of our phishing messages contained
bodyText ||| language that said the orders would be cancelled if they did
bodyText ||| not visit the URLs. Thirty-two percent of the participants
bodyText ||| who heeded the warnings and left the phishing websites be-
bodyText ||| lieved that their orders would be cancelled as a result—they
bodyText ||| believed that the emails were really sent from eBay and Ama-
bodyText ||| zon. We asked 25 of the participants how they believed
bodyText ||| the fraudulent URLs came to them, and only three recog-
bodyText ||| nized that the emails had been sent by someone not affiliated
bodyText ||| with either eBay or Amazon (we added this question halfway
bodyText ||| through the study). Thus, there seems to be some cognitive
bodyText ||| dissonance between recognizing a fraudulent website and
bodyText ||| the fraudulent email that spread it. This raises grave con-
bodyText ||| cerns about Internet users’ susceptibility to phishing. Highly
bodyText ||| targeted phishing attacks will continue to be very effective as
bodyText ||| long as users do not understand how easy it is to forge email.
bodyText ||| At the same time, effective browser warnings may mitigate
bodyText ||| the need for user education, as we will now show.
subsectionHeader ||| Attention Switch and Maintenance
bodyText ||| The first stage in the C-HIP model is “attention switch.” If
bodyText ||| a warning is unable to capture the user’s attention, the warn-
bodyText ||| ing will not be noticed and thus be rendered useless. Unlike
bodyText ||| the passive indicators examined by Wu et al. [23], the ac-
bodyText ||| tive warnings in Firefox and Internet Explorer get the user’s
bodyText ||| attention by interrupting their task—the user is forced to
bodyText ||| choose one of the options presented by the warning.
page ||| 1070
note ||| CHI 2008 Proceedings · Am I Safe	April 5-10, 2008 · Florence, Italy
table ||| Firefox	20	20	13	4	17	19
table ||| Active IE	20	19	10	10	10	12
table ||| Passive IE	10	8	3	5	3	5
tableCaption ||| Table 2. This table depicts the number of participants in each experi-
bodyText ||| mental condition, the number who saw at least one warning, the num-
bodyText ||| ber who completely read at least one warning, the number who recog-
bodyText ||| nized the warnings, the number who correctly understood the warn-
bodyText ||| ings, and the number who understood the choices that the warnings
bodyText ||| presented.
bodyText ||| This was not the case with the passive warning in IE (Figure
bodyText ||| 2). This warning is a single dialog box with only the op-
bodyText ||| tion to dismiss it. We observed that it could take up to five
bodyText ||| seconds for this warning to appear. If a user starts typing
bodyText ||| during this period, the user’s keystrokes will inadvertently
bodyText ||| dismiss the warning. Six of the ten participants in this con-
bodyText ||| dition never noticed the warning because their focus was on
bodyText ||| either the keyboard or the input box. Two of these partic-
bodyText ||| ipants had this happen on both phishing websites, so they
bodyText ||| had no idea they were ever exposed to any warnings. We
bodyText ||| found no statistical significance between this condition and
bodyText ||| the control group. Thus, this type of warning is effectively
bodyText ||| useless.
bodyText ||| Effective warnings must also cause attention maintenance—
bodyText ||| they must grab the users’ attention long enough for them to
bodyText ||| attempt comprehension. We examined the number of partici-
bodyText ||| pants who read the warnings (as determined by self-reporting
bodyText ||| and confirmed by the observations of the experimenter) in
bodyText ||| order to determine their effectiveness at attention mainte-
bodyText ||| nance. Table 2 shows the number of warnings read and the
bodyText ||| number of participants who claimed to have seen the warn-
bodyText ||| ings prior to this study, for each experimental condition.
bodyText ||| Not counting the two participants who failed to notice the
bodyText ||| warnings entirely, and the participant in the active IE condi-
bodyText ||| tion who did not click on the URLs, we found that twenty-six
bodyText ||| of the remaining forty-seven (55%) claimed to have com-
bodyText ||| pletely read at least one of the warnings that were displayed.
bodyText ||| When asked, twenty-two of these twenty-six (85%) said they
bodyText ||| decided to read the warning because it appeared to warn
bodyText ||| about some sort of negative consequences.
bodyText ||| Upon seeing the warnings, two participants in the active IE
bodyText ||| condition immediately closed the window. They went back
bodyText ||| to the emails and clicked the links, were presented with the
bodyText ||| same warnings, and then closed the windows again. They
bodyText ||| repeated this process four or five times before giving up,
bodyText ||| though never bothered to read the warnings. Both said that
bodyText ||| the websites were not working. Despite not reading or un-
bodyText ||| derstanding the warnings, both were protected because the
bodyText ||| warnings “failed safely.” Thus, if users do not read or under-
bodyText ||| stand the warnings, the warnings can still be designed such
bodyText ||| that the user is likely to take the recommended action.
bodyText ||| Nineteen participants claimed to have previously seen these
bodyText ||| particular warnings. A significantly higher proportion of
bodyText ||| participants in the active IE condition (50%) claimed to have
bodyText ||| recognized the warnings as compared to participants in the
bodyText ||| Firefox condition (20%; p < 0.048 for Fisher’s exact test).
bodyText ||| Many of the participants who encountered the active IE warn-
bodyText ||| ing said that they had previously seen the same warning on
bodyText ||| websites which they trusted, and thus they ignored it. It is
bodyText ||| likely that they did not read this phishing warning because
bodyText ||| IE uses a similar warning when it encounters an expired or
bodyText ||| self-signed SSL certificate. Therefore they did not notice
bodyText ||| that this was a slightly different and more serious warning.
bodyText ||| We found a significant negative Pearson correlation between
bodyText ||| participants recognizing a warning message and their will-
bodyText ||| ingness to completely read it (r = —0.309, p < 0.03).
bodyText ||| This implies that if a warning is recognized, a user is sig-
bodyText ||| nificantly less likely to bother to read it completely (i.e. ha-
bodyText ||| bituation). Thus, very serious warnings should be designed
bodyText ||| differently than less serious warnings in order to increase the
bodyText ||| likelihood that users will read them. This was also the basis
bodyText ||| for Brustoloni and Villamar´ın-Salom´on’s work on dynamic
bodyText ||| warnings [3].
subsectionHeader ||| Warning Comprehension
bodyText ||| A well-designed warning must convey a sense of danger and
bodyText ||| present suggested actions. In this study we asked partici-
bodyText ||| pants what they believed each warning meant. Twenty-seven
bodyText ||| of the 47 participants (57%) who saw at least one of the
bodyText ||| warnings correctly said they believed that they had some-
bodyText ||| thing to do with giving information to fraudulent websites
bodyText ||| (Table 2). Of the 20 participants who did not understand the
bodyText ||| meaning of the warnings, one said that she did not see it long
bodyText ||| enough to have any idea, while the others had widely varying
bodyText ||| answers. Examples include: “someone got my password,”
bodyText ||| “[it] was not very serious like most window[s] warning[s],”
bodyText ||| and “there was a lot of security because the items were cheap
bodyText ||| and because they were international.”
bodyText ||| Using Fisher’s exact test, we found that those using Firefox
bodyText ||| understood the meaning of the warnings significantly more
bodyText ||| than those exposed to the active IE warnings (p < 0.041)
bodyText ||| and the passive IE warnings (p < 0.005), though we found
bodyText ||| no significant difference between the active and passive IE
bodyText ||| warnings. We found a significant Pearson correlation be-
bodyText ||| tween completely reading a warning and understanding its
bodyText ||| meaning for the active IE warning (r = 0.478, p < 0.039),
bodyText ||| but not for Firefox. Since all but one Firefox user correctly
bodyText ||| understood what the warning wanted them to do, this im-
bodyText ||| plies that users did not need to completely read it to know
bodyText ||| the appropriate actions to take.
bodyText ||| Overall, 31 of the 47 participants who noticed the warnings
bodyText ||| mentioned that they thought they were supposed to leave
bodyText ||| the website or refrain from entering personal information.
bodyText ||| Those who did not understand the warnings provided re-
bodyText ||| sponses such as “panic and cancel my accounts,” “confirm
bodyText ||| information about the orders,” and “put in my account infor-
bodyText ||| mation so that they could track it and use it for themselves.”
page ||| 1071
note ||| CHI 2008 Proceedings · Am I Safe	April 5-10, 2008 · Florence, Italy
subsectionHeader ||| Attitudes and Beliefs
bodyText ||| We asked participants how their attitudes and beliefs influ-
bodyText ||| enced their perceptions and found a highly significant corre-
bodyText ||| lation between trusting and obeying the warnings (i.e. users
bodyText ||| who did not trust the warnings were likely to ignore them;
bodyText ||| r = 0.76, p < 0.0001). More telling, all but three partic-
bodyText ||| ipants who ignored a warning said it was because they did
bodyText ||| not trust the warning. Two of the participants who ignored
bodyText ||| the warnings in the active IE group said they did so because
bodyText ||| they trusted them but thought the warnings were not very se-
bodyText ||| vere (“since it gave me the option of still proceeding to the
bodyText ||| website, I figured it couldn’t be that bad”). The other par-
bodyText ||| ticipant who trusted the warning yet ignored it was in the
bodyText ||| passive IE group and blamed habituation (“my own PC con-
bodyText ||| stantly bombards me with similar messages”). All three of
bodyText ||| these participants questioned the likelihood of the risks, and
bodyText ||| thus were more interested in completing the primary task.
bodyText ||| We found a significant correlation between recognizing and
bodyText ||| ignoring a warning (r = 0.506, p < 0.0003). This fur-
bodyText ||| ther implies that habituation was to blame when participants
bodyText ||| ignored warnings: they confused them with similar look-
bodyText ||| ing, but less serious warnings, and thus did not understand
bodyText ||| the level of risk that these warnings were trying to convey.
bodyText ||| This was only a problem for the warnings used by IE, as
bodyText ||| all the Firefox users obeyed the warnings (though only 20%
bodyText ||| claimed to have seen them before, compared to the 50% with
bodyText ||| IE). The IE users who ignored the warnings made comments
bodyText ||| such as:
listItem ||| •	“Oh, I always ignore those”
listItem ||| •	“Looked like warnings I see at work which I know to ig-
listItem ||| nore”
listItem ||| •	“Have seen this warning before and [it] was in all cases
listItem ||| [a] false positive”
listItem ||| •	“I’ve already seen such warnings pop up for some other
listItem ||| CMU web pages as well”
listItem ||| •	“I see them daily”
listItem ||| •	“I thought that the warnings were some usual ones dis-
listItem ||| played by IE”
bodyText ||| A warning should not require domain knowledge for a user
bodyText ||| to understand it. In order to examine whether prior knowl-
bodyText ||| edge of phishing impacted user attitudes towards the warn-
bodyText ||| ings, we asked them to define the term “phishing.” Twenty-
bodyText ||| six of the forty-seven participants who noticed the warn-
bodyText ||| ings were able to correctly say they had something to do
bodyText ||| with using fraudulent websites to steal personal information.
bodyText ||| We calculated Pearson’s correlation coefficient and found
bodyText ||| a significant correlation between knowing what phishing is
bodyText ||| and both reading (r = 0.487, p < 0.0005) and heeding
bodyText ||| (r = 0.406, p < 0.005) the warnings. Thus, if a user does
bodyText ||| not understand what phishing is, they are less likely to be
bodyText ||| concerned with the consequences, and thus less likely to pay
bodyText ||| attention to the warning.
subsectionHeader ||| Motivation and Warning Behaviors
bodyText ||| Table 1 depicts the number of participants from each condi-
bodyText ||| tion who fell for at least one phishing message. Some partic-
bodyText ||| ipants only clicked on one of the two phishing messages, and
bodyText ||| in other cases some participants only received one phishing
bodyText ||| message due to email filtering.
bodyText ||| Overall we found that active phishing warnings were signifi-
bodyText ||| cantly more effective than passive warnings (p < 0.0002 for
bodyText ||| Fisher’s exact test). We showed the passive Internet Explorer
bodyText ||| warning to ten different participants, but only one participant
bodyText ||| heeded it and closed the website, whereas the other times
bodyText ||| participants dismissed it and submitted personal information
bodyText ||| to the phishing websites (in two of these cases participants
bodyText ||| failed to notice the warnings altogether). We found that this
bodyText ||| passive warning did not perform significantly different than
bodyText ||| the control group (p < 1.0 for Fisher’s exact test). The ac-
bodyText ||| tive IE warning was ignored by nine participants, while in
bodyText ||| the Firefox condition every participant heeded the warning
bodyText ||| and navigated away from the phishing websites. This was a
bodyText ||| highly significant difference (p < 0.0004, for Fisher’s exact
bodyText ||| test), however the active IE warning still performed signifi-
bodyText ||| cantly better than the control condition (p < 0.01) and the
bodyText ||| passive IE warning (p < 0.044).
bodyText ||| Qualitatively, we examined why participants were motivated
bodyText ||| to heed or ignore the warnings. A total of thirty-one partic-
bodyText ||| ipants chose to heed the warnings, and in twenty-three of
bodyText ||| these cases participants said that the warnings made them
bodyText ||| think about risks:
listItem ||| •	“I didn’t want to get burned”
listItem ||| •	“...it is not necessary to run the risk of letting other poten-
listItem ||| tially dangerous sites to get my information”
listItem ||| •	“I chose to heed the warning since I don’t like to gamble
listItem ||| with the little money I have”
listItem ||| •	“I felt it better to be safe than sorry”
listItem ||| •	“I heeded the warning because it seemed less risky than
listItem ||| ignoring it”
bodyText ||| Participants who chose to submit information said that they
bodyText ||| did so because they were unaware of the risks (i.e. they did
bodyText ||| not read the warnings), were used to ignoring similarly de-
bodyText ||| signed warnings (i.e. habituation), or they did not under-
bodyText ||| stand the choices that the warnings presented.
subsectionHeader ||| Environmental Stimuli
bodyText ||| In the passive IE condition, three of the participants who ig-
bodyText ||| nored the warnings said they did so because they incorrectly
bodyText ||| placed some degree of trust in the phishing website because
bodyText ||| of stimuli other than the warning messages. When asked
bodyText ||| why they chose to ignore the warnings, one participant said
bodyText ||| she had “confidence in the website.” Another participant
bodyText ||| ignored the warning “because I trust the website that I am
bodyText ||| doing the online purchase at.” These answers corroborate
bodyText ||| Fogg’s work, showing that the look and feel of a website
bodyText ||| is often the biggest trust factor [10]. Participants who ig-
bodyText ||| nored the active IE warning provided similar answers, and
bodyText ||| also said that they ignored the warnings because they trusted
bodyText ||| the brands that the emails had spoofed.
bodyText ||| We also found that when some participants saw the warn-
bodyText ||| ings, they examined other security context information be-
bodyText ||| fore making a decision. One Firefox user reexamined the
bodyText ||| original phishing email and noticed the lack of any person-
bodyText ||| alized information. She then decided to “back out and log
bodyText ||| in from the root domain to check.” After seeing the warn-
bodyText ||| ings, ten other Firefox users also examined either the URL
bodyText ||| bar or the email headers. Some observations included: “The
page ||| 1072
note ||| CHI 2008 Proceedings · Am I Safe	April 5-10, 2008 · Florence, Italy
bodyText ||| URL did not match the usual eBay URL and so it could be
bodyText ||| fraudulent;” “I did look at the URL that I opened from the
bodyText ||| email, and the sender of the email, to confirm that they did
bodyText ||| look suspicious;” and “it made me look at the web address
bodyText ||| which was wrong.” One participant in the passive IE con-
bodyText ||| dition and three in the active IE condition incorrectly used
bodyText ||| this information to fall for the phishing attacks. Some of
bodyText ||| the comments included: “The address in the browser was
bodyText ||| of amazonaccounts.com which is a genuine address” and “I
bodyText ||| looked at the URL and it looked okay.”
bodyText ||| Finally, at least four participants claimed that the timing of
bodyText ||| the phishing emails with the purchases contributed to them
bodyText ||| ignoring the warnings. It is unclear how susceptible these
bodyText ||| participants would have been to a broader phishing attack,
bodyText ||| rather than the targeted attack that we examined.
sectionHeader ||| DISCUSSION
bodyText ||| In this section we provide some recommendations for im-
bodyText ||| proving the design of phishing indicators based on the results
bodyText ||| of our study.
bodyText ||| Interrupting the primary task — Phishing indicators need
bodyText ||| to be designed to interrupt the user’s task. We found that the
bodyText ||| passive indicator, which did not interrupt the user’s task, was
bodyText ||| not significantly different than not providing any warning.
bodyText ||| The active warnings were effective because they facilitated
bodyText ||| attention switch and maintenance.
bodyText ||| Providing clear choices — Phishing indicators need to pro-
bodyText ||| vide the user with clear options on how to proceed, rather
bodyText ||| than simply displaying a block of text. The users that no-
bodyText ||| ticed the passive Internet Explorer warning, read it but ig-
bodyText ||| nored it because they did not understand what they were sup-
bodyText ||| posed to do. They understood it had something to do with
bodyText ||| security, but they did not know how to proceed. In contrast,
bodyText ||| the active warnings presented choices and recommendations
bodyText ||| which were largely heeded. Wu found similar results with
bodyText ||| regard to providing users with clear choices [22].
bodyText ||| Failing safely — Phishing indicators must be designed such
bodyText ||| that one can only proceed to the phishing website after read-
bodyText ||| ing the warning message. Users of the active Internet Ex-
bodyText ||| plorer warning who did not read the warning or choices could
bodyText ||| only close the window to get rid of the message. This pre-
bodyText ||| vented them from accessing the page without reviewing the
bodyText ||| warning’s recommendations. However, users of the passive
bodyText ||| Internet Explorer warning had the option of clicking the fa-
bodyText ||| miliar ‘X’ in the corner to dismiss it without reading it, and
bodyText ||| accessing the page anyway.
bodyText ||| Preventing habituation — Phishing indicators need to be
bodyText ||| distinguishable from less serious warnings and used only
bodyText ||| when there is a clear danger. Users ignored the passive in-
bodyText ||| dicators because they looked like many other warnings that
bodyText ||| users have ignored without consequences, thus they appear
bodyText ||| to be “crying wolf.” Even the active Internet Explorer warn-
bodyText ||| ing was not read in a few cases because users mistook it for
bodyText ||| other IE warnings. More people read the Firefox warnings
bodyText ||| because they are designed unlike any other warnings. Dy-
bodyText ||| namic warning messages may help prevent habituation [3].
bodyText ||| Altering the phishing website — Phishing indicators need to
bodyText ||| distort the look and feel of the website such that the user does
bodyText ||| not place trust in it. This can be accomplished by altering its
bodyText ||| look or simply not displaying it at all. The overall look and
bodyText ||| feel of a website is usually the primary factor when users
bodyText ||| make trust decisions [10]. When the website was displayed
bodyText ||| alongside the passive indicators, users ignored the warnings
bodyText ||| because they said that they trusted the look of the website.
sectionHeader ||| CONCLUSION
bodyText ||| This study has given us insights into creating effective se-
bodyText ||| curity indicators within the context of phishing. Such in-
bodyText ||| dicators are clearly needed as 97% of participants believed
bodyText ||| the phishing emails enough to visit the URLs. Of the par-
bodyText ||| ticipants who saw the active warnings, 79% chose to heed
bodyText ||| them and close the phishing websites, whereas only 13% of
bodyText ||| those who saw the passive warnings obeyed them. Without
bodyText ||| the active warning indicators, it is likely that most partici-
bodyText ||| pants would have entered personal information. However,
bodyText ||| the active indicators did not perform equally: the indica-
bodyText ||| tors used by Firefox performed significantly better than the
bodyText ||| active warnings used by IE, though both performed signif-
bodyText ||| icantly better than the passive IE warnings (which was not
bodyText ||| significantly different from not showing any warnings in the
bodyText ||| control group).
bodyText ||| As phishing attacks continue to evolve, it is likely that highly
bodyText ||| targeted attacks will become more prevalent. Future indica-
bodyText ||| tors within the phishing context need to be designed such
bodyText ||| that they interrupt the user’s primary task, clearly convey the
bodyText ||| recommended actions to take, fail in a secure manner if the
bodyText ||| user does not understand or ignores them, draw trust away
bodyText ||| from the suspected phishing website, and prevent the user
bodyText ||| from becoming habituated.
sectionHeader ||| ACKNOWLEDGMENTS
bodyText ||| Thanks to the members of the Supporting Trust Decisions
bodyText ||| project for their feedback, and Matthew Williams for his as-
bodyText ||| sistance. This work was supported in part by the National
bodyText ||| Science Foundation under grant CCF-0524189. The views
bodyText ||| and conclusions contained in this document are those of the
bodyText ||| authors and should not be interpreted as representing the of-
bodyText ||| ficial policies, either expressed or implied, of the National
bodyText ||| Science Foundation or the U.S. government.
sectionHeader ||| REFERENCES
reference ||| 1. AMER, T. S., AND MARIS, J. B. Signal words and
reference ||| signal icons in application control and information
reference ||| technology exception messages – hazard matching and
reference ||| habituation effects. Tech. Rep. Working Paper
reference ||| Series–06-05, Northern Arizona University, Flagstaff,
reference ||| AZ, October 2006.
reference ||| 2. BANK OF AMERICA. How Bank of America SiteKey
reference ||| Works for Online Banking Security.
reference ||| http://www.bankofamerica.com/privacy/sitekey/, 2007.
reference ||| 3. BRUSTOLONI, J. C., AND VILLAMAR´IN-SALOM´ON,
reference ||| R. Improving security decisions with polymorphic and
reference ||| audited dialogs. In SOUPS ’07: Proceedings of the 3rd
reference ||| symposium on Usable privacy and security (New York,
reference ||| NY, USA, 2007), ACM Press, pp. 76–85.
page ||| 1073
note ||| CHI 2008 Proceedings · Am I Safe	April 5-10, 2008 · Florence, Italy
reference ||| 4. CERTIFICATION AUTHORITY/BROWSER FORUM.
reference ||| Extended validation ssl certificates, Accessed: July 27,
reference ||| 2007. http://cabforum.org/.
reference ||| 5. CRANOR, L. F. What do they “indicate?”: Evaluating
reference ||| security and privacy indicators. Interactions 13, 3
reference ||| (2006),45–47.
reference ||| 6. DHAMIJA, R., AND TYGAR, J. D. The battle against
reference ||| phishing: Dynamic security skins. In Proceedings of
reference ||| the 2005 Symposium on Usable Privacy and Security
reference ||| (New York, NY, USA, July 6-8 2005), ACM Press.
reference ||| 7. DHAMIJA, R., TYGAR, J. D., AND HEARST, M. Why
reference ||| phishing works. In CHI ’06: Proceedings of the
reference ||| SIGCHI conference on Human Factors in computing
reference ||| systems (New York, NY, USA, 2006), ACM Press,
reference ||| pp. 581–590.
reference ||| 8. DOWNS, J. S., HOLBROOK, M., AND CRANOR, L.
reference ||| Decision Strategies and Susceptibility to Phishing. In
reference ||| Proceedings of The 2006 Symposium on Usable
reference ||| Privacy and Security (Pittsburgh, PA, July 12-14,
reference ||| 2006).
reference ||| 9. FLORENCIO, D., AND HERLEY, C. A large-scale study
reference ||| of web password habits. In WWW ’07: Proceedings of
reference ||| the 16th international conference on World Wide Web
reference ||| (New York, NY, USA, 2007), ACM Press, pp. 657–666.
reference ||| 10. FOGG, B., MARSHALL, J., LARAKI, O., OSIPOVICH,
reference ||| A., VARMA, C., FANG, N., PAUL, J., RANGEKAR,
reference ||| A., SHON, J., SWANI, P., AND TREINEN, M. What
reference ||| Makes Web Sites Credible? A Report on a Large
reference ||| Quantitative Study. In Proceedings of the ACM
reference ||| Computer-Human Interaction Conference (Seattle,
reference ||| WA, March 31 - April 4, 2001), ACM.
reference ||| 11. GARTNER, INC. Gartner Says Number of Phishing
reference ||| E-Mails Sent to U.S. Adults Nearly Doubles in Just
reference ||| Two Years.
reference ||| http://www.gartner.com/it/page.jsp?id--498245,
reference ||| November 9 2006.
reference ||| 12. HELLIER, E., WRIGHT, D. B., EDWORTHY, J., AND
reference ||| NEWSTEAD, S. On the stability of the arousal strength
reference ||| of warning signal words. Applied Cognitive Psychology
reference ||| 14 (2000), 577–592.
reference ||| 13. JACKSON, C., SIMON, D., TAN, D., AND BARTH, A.
reference ||| An evaluation of extended validation and
reference ||| picture-in-picture phishing atttacks. In Proceedings of
reference ||| the 2007 Usable Security (USEC’07) Workshop
reference ||| (February 2007).
reference ||| http://www.usablesecurity.org/papers/jackson.pdf.
reference ||| 14. KUMARAGURU, P., RHEE, Y., ACQUISTI, A.,
reference ||| CRANOR, L. F., HONG, J., AND NUNGE, E.
reference ||| Protecting people from phishing: the design and
reference ||| evaluation of an embedded training email system. In
reference ||| CHI ’07: Proceedings of the SIGCHI conference on
reference ||| Human factors in computing systems (New York, NY,
reference ||| USA, 2007), ACM Press, pp. 905–914.
reference ||| 15. MOORE, T., AND CLAYTON, R. An empirical analysis
reference ||| of the current state of phishing attack and defence. In
reference ||| Proceedings of the 2007 Workshop on The Economics
reference ||| of Information Security (WEIS2007) (May 2007).
reference ||| http://www.cl.cam.ac.uk/ twm29/weis07-phishing.pdf.
reference ||| 16. OBERHEIDE, J. Google safe browsing, November 6
reference ||| 2006. http://jon.oberheide.org/blog/2006/11/13/google-
reference ||| safe-browsing/.
reference ||| 17. OPENDNS. PhishTank Annual Report.
reference ||| http://www.phishtank.com/, October 2007.
reference ||| 18. REFSNES DATA. Browser statistics, Accessed: April 4,
reference ||| 2007.
reference ||| http://www.w3schools.com/browsers/browsers stats.asp.
reference ||| 19. SCHECHTER, S. E., DHAMIJA, R., OZMENT, A.,
reference ||| AND FISCHER, I. The emperor’s new security
reference ||| indicators. In Proceedings of the 2007 IEEE
reference ||| Symposium on Security and Privacy (May 2007).
reference ||| 20. SHENG, S., MAGNIEN, B., KUMARAGURU, P.,
reference ||| ACQUISTI, A., CRANOR, L., HONG, J., AND NUNGE,
reference ||| E. Anti-phishing phil: The design and evaluation of a
reference ||| game that teaches people not to fall for phish. In
reference ||| Proceedings of the 2007 Symposium On Usable
reference ||| Privacy and Security (Pittsburgh, PA, July 18-20,
reference ||| 2007), ACM Press.
reference ||| 21. WOGALTER, M. S. Communication-Human
reference ||| Information Processing (C-HIP) Model. In Handbook
reference ||| of Warnings, M. S. Wogalter, Ed. Lawrence Erlbaum
reference ||| Associates, 2006, pp. 51–61.
reference ||| 22. WU, M. Fighting Phishing at the User Interface. PhD
reference ||| thesis, Massachusetts Institute of Technology, August
reference ||| 2006.
reference ||| 23. WU, M., MILLER, R. C., AND GARFINKEL, S. L. Do
reference ||| Security Toolbars Actually Prevent Phishing Attacks?
reference ||| In Proceedings of the SIGCHI Conference on Human
reference ||| Factors in Computing Systems Held in Montreal
reference ||| (2006), ACM Press, pp. 601–610.
reference ||| 24. YE, Z. E., AND SMITH, S. Trusted paths for browsers.
reference ||| In Proceedings of the 11 th USENIX Security
reference ||| Symposium (2002), pp. 263–279.
reference ||| 25. YEE, K.-P., AND SITAKER, K. Passpet: Convenient
reference ||| password management and phishing protection. In
reference ||| SOUPS ’06: Proceedings of the Second Symposium on
reference ||| Usable Privacy and Security (New York, NY, USA,
reference ||| 2006), ACM Press, pp. 32–43.
reference ||| 26. ZHANG, Y., EGELMAN, S., CRANOR, L. F., AND
reference ||| HONG, J. Phinding phish: Evaluating anti-phishing
reference ||| tools. In Proceedings of the 14th Annual Network &
reference ||| Distributed System Security Symposium (NDSS 2007)
reference ||| (28th February - 2nd March, 2007).
reference ||| http://lorrie.cranor.org/pubs/toolbars.html.
page ||| 1074

note ||| CHI 2008 Proceedings · Search	April 5-10, 2008 · Florence, Italy
title ||| The Adaptation of Visual Search Strategy to Expected
title ||| Information Gain
author ||| Yuan-Chi Tseng
affiliation ||| The University of Manchester
address ||| MBS Crawford House 2.30, Booth Street West,
address ||| Manchester, M15 6PB, UK
email ||| yuan-chi.tseng@postgrad.manchester.ac.uk
sectionHeader ||| ABSTRACT
bodyText ||| An important question for Human-Computer Interaction is
bodyText ||| to understand how and why visual search strategy is
bodyText ||| adapted to the demands imposed by the task of searching
bodyText ||| the results of a search engine. There is emerging evidence
bodyText ||| that a key part of the answer concerns the expected
bodyText ||| information gain of each of the set of available information
bodyText ||| gathering actions. We build on previous research to show
bodyText ||| that people are acutely sensitive to differences in the density
bodyText ||| and in the number of items returned by the search engine.
bodyText ||| These factors cause shifts in the efficiency of the available
bodyText ||| information gathering actions. We focus on an image
bodyText ||| browsing task, and show that, as a consequence of changes
bodyText ||| to the efficiency of available actions, people make small but
bodyText ||| significant changes to eye-movement strategy.
sectionHeader ||| Author Keywords
keyword ||| Visual Search, Visual Exploration, Strategy, Cognitive
keyword ||| Models, Decision Making, Image Search Results,
keyword ||| Thumbnails, Eye Movement, Density, Spacing
sectionHeader ||| ACM Classification Keywords
category ||| H.5.2 Information Interfaces and Presentation: User
category ||| Interfaces – Theory and methods; H.1.2 Models and
category ||| Principles: User/Machine Systems – Human Information
category ||| Processing; H.3.3 Information Storage and Retrieval:
category ||| Information Search and Retrieval – Selection process
sectionHeader ||| INTRODUCTION
bodyText ||| An important question for Human-Computer Interaction
bodyText ||| (HCI) is how to design the presentation of search results to
bodyText ||| facilitate visual search behaviour [9,20,35]. Researchers
bodyText ||| have proposed many alternatives to the standard list of
bodyText ||| results. They include Space-filling thumbnails of text [7],
bodyText ||| Tabular interface [36], Faceted category interface [42], and
bodyText ||| Textually-enhanced thumbnails [41].
copyright ||| Permission to make digital or hard copies of all or part of this work for
copyright ||| personal or classroom use is granted without fee provided that copies are
copyright ||| not made or distributed for profit or commercial advantage and that copies
copyright ||| bear this notice and the full citation on the first page. To copy otherwise,
copyright ||| or republish, to post on servers or to redistribute to lists, requires prior
copyright ||| specific permission and/or a fee.
note ||| CHI 2008, April 5–10, 2008, Florence, Italy.
copyright ||| Copyright 2008 ACM 978-1-60558-011-1/08/04...$5.00.
author ||| Andrew Howes
affiliation ||| The University of Manchester
address ||| MBS East F31, Booth Street West, Manchester,
address ||| M15 6PB, UK
email ||| howesa@manchester.ac.uk
bodyText ||| The number of proposals is, in part, a reflection of the scale
bodyText ||| of the design space. Identifying which of the potentially
bodyText ||| hundreds of interesting points in this space is best might be
bodyText ||| informed by a theory of how people choose to search
bodyText ||| through results, e.g. an ACT-R or EPIC theory of the
bodyText ||| cognitive, motor, and perceptual processing required to
bodyText ||| achieve the task [2,18,22,23]. Recent efforts to understand,
bodyText ||| what Payne, Howes and Reader [28] call interactive search
bodyText ||| tasks, have included [5,6,8,13,31]. However, it is
bodyText ||| sometimes difficult to ascertain which interface will be best
bodyText ||| when the details of the strategy that people will use given a
bodyText ||| particular task environment are unclear [10,14,17,19]. In
bodyText ||| this paper we are interested in the strategy choices that
bodyText ||| people make about visual search, i.e. how they choose to
bodyText ||| look at search results. Our focus is on the assumption that
bodyText ||| people attempt to maximise expected utility given the
bodyText ||| constraints of the human visual system [8,39] and that
bodyText ||| design changes which change the efficiency of information
bodyText ||| gathering actions will lead to changes in observed
bodyText ||| behaviour.
bodyText ||| There is some evidence in the visual perception and
bodyText ||| cognition literature that visual search strategy is adapted to
bodyText ||| the demands imposed by particular task environments
bodyText ||| [4,26,40]. It appears that people seek to maximise the
bodyText ||| efficiency of visual search in the context of the particular
bodyText ||| display layout. For example, longer fixations enable more
bodyText ||| information to be gathered from fovea and peripheral
bodyText ||| vision, although longer fixations can only be effective if the
bodyText ||| information is available within the perceptual span [26].
bodyText ||| Moreover, people need to manage the trade-off between the
bodyText ||| increased information gain of longer fixations and the effort
bodyText ||| and time cost of holding a fixation.
bodyText ||| Some evidence that people adapt their strategy to the task
bodyText ||| can also be found in the HCI literature. For example, trade-
bodyText ||| offs in the use of wide versus narrow spacing between icons
bodyText ||| [11], in more but smaller text versus fewer but bigger text
bodyText ||| in the same space [15] and in the use of Hyperbolic browser
bodyText ||| versus standard browser [30]. Even in a standard results
bodyText ||| layout, such as a simple list of links, there is evidence that
bodyText ||| search strategy is affected by the context in which the
bodyText ||| relevance of items is assessed [5,6,8,13]. The position of a
bodyText ||| target item in a list and relationship between the relevance
bodyText ||| of this target and distractor items affects search behaviour
page ||| 1075
note ||| CHI 2008 Proceedings · Search	April 5-10, 2008 · Florence, Italy
bodyText ||| [5,6,13]. These finding support the view that search and
bodyText ||| selection is guided by maximising the expected information
bodyText ||| gain [8]. Strikingly there is evidence that maximising
bodyText ||| expected gain can involve fixating on every other item in a
bodyText ||| list, rather than fixating on contiguous items [5,6],
bodyText ||| particularly in contexts where good results have already
bodyText ||| been encountered.
bodyText ||| In a number of respects people appear to be sensitive to the
bodyText ||| expected information gain of information gathering actions.
bodyText ||| In the following section we review in more detail the
bodyText ||| literature on the trade-offs that contribute toward the
bodyText ||| efficiency of information gathering actions during visual
bodyText ||| search. We are interested in the broad class of interactive
bodyText ||| search tasks [28] but our particular focus is on the visual
bodyText ||| search strategies and decision-making processes that people
bodyText ||| use when looking through items returned by an image
bodyText ||| search engine such as Flickr or Google. Further, we are
bodyText ||| interested in everyday tasks with somewhat underspecified
bodyText ||| target criteria, e.g. look for attractive images of the city
bodyText ||| Florence. In what follows we consider the relevance of the
bodyText ||| visual search and HCI literature to understanding these
bodyText ||| kinds of task.
sectionHeader ||| RELATED WORK
subsectionHeader ||| Visual Search in HCI
bodyText ||| Researchers in HCI have suggested that the details of
bodyText ||| interface design affect visual search strategy (e.g.,
bodyText ||| [11,15,30]). Everett and Byrne [11], for example, suggested
bodyText ||| a small difference of 1.6 degrees of visual angle between
bodyText ||| items can result in participants either fixating on an icon or
bodyText ||| not. Similarly, Halverson and Hornof [15] provided
bodyText ||| evidence that low density, task-meaningless large words
bodyText ||| could lead participants to use fewer and shorter fixations
bodyText ||| and so shorter overall search time than when given high
bodyText ||| density, small, task-meaningless, words. Similarly, Pirolli,
bodyText ||| Card, and Van Der Wege [30] found that participants used
bodyText ||| more but shorter fixations when using a Hyperbolic browser
bodyText ||| than when using a standard browser, especially in areas of
bodyText ||| the Hyperbolic browser in which small, low information
bodyText ||| scent items, were grouped closely together.
subsectionHeader ||| Visual Search in Experimental Psychology
bodyText ||| In the visual search literature, there is compelling evidence
bodyText ||| that the density of items on the display has consequences
bodyText ||| for search strategy. Ojanpää, Näsänen and Kojo [26] found
bodyText ||| that decreased spacing in a vertical list of words (common
bodyText ||| Finnish verbs, nouns and adjectives) resulted in longer but
bodyText ||| fewer numerous fixations. Vlaskamp, Over and Hooge [40]
bodyText ||| found that the fixation duration, number of fixation and
bodyText ||| search time increased dramatically with decreasing item
bodyText ||| spacing, as the range of spacing smaller than 1.5° visual
bodyText ||| angle. On the other hand, their data showed that at wide
bodyText ||| spacing range between 1.5° to 7.1° fixation duration,
bodyText ||| number of fixations and search time increased slightly as
bodyText ||| the spacing increased. Bertera and Rayner [4] found that as
bodyText ||| the item spacing increased the number of fixations and
bodyText ||| fixation duration increased.
bodyText ||| Although allowing a high degree of experimental control
bodyText ||| the tasks [4,26,40] lack ecological validity. For example,
bodyText ||| Vlaskamp, Over and Hooge [40] used abstract shapes (e.g.,
bodyText ||| squares) in their search task, and, Bertera and Rayner [4]
bodyText ||| used an unstructured alphanumeric array. Ojanpää, Näsänen
bodyText ||| and Kojo [26]) used common-words, which reduced the
bodyText ||| task to a simple visual pattern match, rather than a match of
bodyText ||| information scent but it is known that search behaviour is
bodyText ||| contingent on label relevance [5,6]. The different materials
bodyText ||| may account for the different effects. Both tasks are far
bodyText ||| from the real HCI task in which the stimuli are more
bodyText ||| heterogeneous and complicated.
subsectionHeader ||| Strategy Change during Search
bodyText ||| Visual search strategies are also known to change during
bodyText ||| the course of a search [27,33]. Over, Hooge, Vlaskamp and
bodyText ||| Erkelens [27] found that fixation duration increased and the
bodyText ||| amplitude of saccade decreased gradually as search
bodyText ||| progressed. They called this is a coarse-to-fine strategy.
bodyText ||| Rao, Zelinsky, Hayhoe and Ballard [33] used a coarse-to-
bodyText ||| fine matching mechanism to model the skipping saccades
bodyText ||| because it could increase the probability of an early match.
bodyText ||| In contrast, Brumby and Howes [6] found a fine-to-coarse
bodyText ||| search strategy. People increased saccade amplitude once
bodyText ||| they had found, but not committed to, a highly relevant
bodyText ||| target suggesting that although it is known that strategy can
bodyText ||| change, the reasons for change are not always clear.
bodyText ||| Also, it is known that people spend more time examining
bodyText ||| items that are presented nearer to the top of the returned
bodyText ||| search results [9,13], presumably, and in part, because
bodyText ||| search engines tend to rank order results. However, what is
bodyText ||| not clear is whether people change visual search strategy as
bodyText ||| they examine links further from the top of the results list.
bodyText ||| For example, they may be more likely to skip i.e. fixate
bodyText ||| alternate, non-adjacent, items once a potential hit has been
bodyText ||| found, as was observed in [6].
sectionHeader ||| THEORY
bodyText ||| We assume that people make strategic adaptations in order
bodyText ||| to improve the efficiency of visual search, that is that they
bodyText ||| rationally adapt the strategy, given cognitive, perceptual,
bodyText ||| and motor constraints, to maximise benefits while
bodyText ||| minimising costs [1,8,17,28,29]. More specifically, people
bodyText ||| adapt their eye movement strategy to maximise the
bodyText ||| expected gain of task-relevant information and minimise the
bodyText ||| neural resources devoted to memory [25] and cognitive and
bodyText ||| attentional load [3]. In this paper, we take an “active vision”
bodyText ||| approach [12] to understanding the complex interactive
bodyText ||| behaviours that people exhibit when searching for
bodyText ||| information. Understanding these behaviours requires
bodyText ||| bridging between theories of visual search, visual
bodyText ||| exploration, and decision-making.
bodyText ||| Following Cox and Young [8] we assumed that people are
bodyText ||| sensitive to the prior probabilities that any particular item
bodyText ||| will be the target item. Cox and Young operationalised this
bodyText ||| assumption by assuming that prior probabilities were
page ||| 1076
note ||| CHI 2008 Proceedings · Search	April 5-10, 2008 · Florence, Italy
bodyText ||| normalized over the set of potential targets. More search
bodyText ||| items implies lower initial priors.
bodyText ||| Following Ojanpää, Näsänen and Kojo [26] we assumed
bodyText ||| that the information that can be gathered given the
bodyText ||| perceptual span is (1) contingent on the item density, (2)
bodyText ||| contingent on the duration of fixation.
bodyText ||| Combining the theories of Cox and Young [8] and Ojanpää,
bodyText ||| Näsänen and Kojo [26] we assume that the visual search
bodyText ||| strategy is rationally adapted to the information that can be
bodyText ||| gained from the perceptual span. On this basis we made
bodyText ||| two predictions:
bodyText ||| (1) that packing items together more closely (high density)
bodyText ||| would allow more information to be harvested from the
bodyText ||| perceptual span given sufficient time. We predicate that
bodyText ||| people would therefore increase the duration spent looking
bodyText ||| at any one item, and reduce the number of items directly
bodyText ||| fixated. That is, they would take advantage of the fact that
bodyText ||| more information was available for each fixation.
bodyText ||| (2) if there are more search items then the gaze durations
bodyText ||| and the rate of number of items directly fixated in a trial
bodyText ||| should decrease because the prior probability of any one
bodyText ||| item being the target item is decreased [8]. In other words,
bodyText ||| when there are more results returned we expect people to
bodyText ||| give each result less time, presumably reducing the quality
bodyText ||| of each evaluation in order to conduct more evaluations.
bodyText ||| The eye movement strategy should switch to a lower cost
bodyText ||| strategy, involving more item skipping [6].
sectionHeader ||| EXPERIMENT
subsectionHeader ||| Method
bodyText ||| This study investigates the consequences of expected
bodyText ||| information gain for the visual search strategy that people
bodyText ||| use given pages of thumbnails returned by a search engine.
bodyText ||| Participants were asked to imagine that they were choosing
bodyText ||| where to go on holiday, and that they were using the web to
bodyText ||| gather information about various places that they could visit.
bodyText ||| In particular, their goal was to use a particular image search
bodyText ||| engine site to find an image of a visually attractive
bodyText ||| destination.
subsubsectionHeader ||| Stimuli and Design
bodyText ||| There were 180 unique sets of images. Each set included
bodyText ||| image thumbnails about a place, such as a resort, city or
bodyText ||| country. These image thumbnails were selected from the
bodyText ||| search results responding to keywords or search phrases
bodyText ||| input in an image search engine of Flickr, a photo sharing
bodyText ||| website. Moreover, each set at least contains 1,000 photo
bodyText ||| results matching the name of the place. For example, Flickr
bodyText ||| found 423,166 up-to-date results for photos matching
bodyText ||| Florence. We filtered out the tourists’ poor quality self-
bodyText ||| portrait, maps and pictures with special effect, such as High
bodyText ||| Dynamic Range (HDR) images which is not clear in the
bodyText ||| task thumbnail size. Finally, we selected 180 photo
bodyText ||| thumbnails for each set. So, totally, we had unique 32,400
bodyText ||| thumbnails (180 sets × 180 thumbnails). At the eye-to-
figureCaption ||| Figure 1: an example of search task with high density
figureCaption ||| layout and one number of pages condition.
figureCaption ||| Figure 2: A sample trial of low density layout and 5 pages
figureCaption ||| set size. This shows the thumbnails on page 3.
bodyText ||| screen distance of 60 centimeters used in the experiment,
bodyText ||| the size of thumbnails (75 × 75 pixels) subtended a visual
bodyText ||| angle of 2.15°.
bodyText ||| The experiment was a within-subjects design and had two
bodyText ||| independent variables. These were thumbnail density and
bodyText ||| number of pages (set size). Density had two levels with
bodyText ||| narrow or wide spacing between items displayed in the
bodyText ||| search task. Figure 1 shows a sample display from one high
bodyText ||| density trial. The edge-to-edge item spacings were 3 pixels
bodyText ||| (visual angle = 0.085°) in high density layout. Figure 2
page ||| 1077
note ||| CHI 2008 Proceedings · Search	April 5-10, 2008 · Florence, Italy
bodyText ||| shows one low density trial. The edge-to-edge item
bodyText ||| spacings were 30 pixels (visual angle = 0.85°) in low
bodyText ||| density display. Unlike in Halverson and Hornof [15] and
bodyText ||| Pirolli, Card, and Van Der Wege [30] the size of thumbnails
bodyText ||| was held constant, so that density was manipulated by
bodyText ||| changing proximity only.
bodyText ||| Number of pages had three levels: 1-page, 2-pages and 5-
bodyText ||| pages. Each page consisted of exactly 36 thumbnails (6 × 6
bodyText ||| square layout). In the 1-page condition, there were 36
bodyText ||| thumbnails in total and the first 36 of 180 thumbnails of
bodyText ||| sets were used. In 2-pages condition, 1st to 36th thumbnails
bodyText ||| were used in the first page; 37th to 72nd thumbnails were
bodyText ||| used in the second page and there were 72 thumbnails in
bodyText ||| total. In the 5-pages condition, all 180 thumbnails were
bodyText ||| used sequentially. There were page links below thumbnails
bodyText ||| in any page. It appeared all the time (see figure 1 and 2).
bodyText ||| Participants could click these links to switch between pages
bodyText ||| during a trial. So, when Participants searched in the first
bodyText ||| page, they also gained the information about how many
bodyText ||| pages in this task.
bodyText ||| In total, there were 6 conditions (2 densities × 3 number of
bodyText ||| pages). Each condition had 30 trials. The total number of
bodyText ||| trials was 180. Each set of thumbnails could be arranged
bodyText ||| into one of six conditions. The presentations of each set of
bodyText ||| thumbnails were counterbalanced across subjects.
subsubsectionHeader ||| Apparatus
bodyText ||| The experiment was performed with a Tobii 1750 eye
bodyText ||| tracker. The eyetracker is embodied in a 17” monitor. The
bodyText ||| eye tracker has a tracking rate or the frame rate of 50 Hz.
bodyText ||| The temporal resolution of 20 ms is sufficient for
bodyText ||| monitoring long fixation and eye movements in our task.
bodyText ||| Although low temporal resolution could cause noise in
bodyText ||| signal sampling, noise was reduced by averaging several
bodyText ||| gazes per page and by testing 30 trials per condition. The
bodyText ||| screen resolutions were set at 1024×768 pixels.
subsubsectionHeader ||| Participants
bodyText ||| Participants were twenty four students from University of
bodyText ||| Manchester who received 5-10 pounds depending on their
bodyText ||| time for their volunteer. All participants were between 18
bodyText ||| and 28 years old and have normal vision or corrected-to-
bodyText ||| normal vision.
subsubsectionHeader ||| Procedure
bodyText ||| Participants were presented with instructions and then a
bodyText ||| practice block allowed them to become familiar with the
bodyText ||| task. After the practice block, the eye tracker system was
bodyText ||| calibrated. And then participants completed all 180 trials.
bodyText ||| The whole Experiment took between 40 minutes and 70
bodyText ||| minutes depending on different participants. The variation
bodyText ||| in time was because we didn’t give our participants any
bodyText ||| time limitation. Some participants were faster than others.
bodyText ||| The participant looked at a place label then clicked on the
bodyText ||| search button to make thumbnail search results appear. The
bodyText ||| participant was instructed to move the cursor to a thumbnail
bodyText ||| of a visually attractive destination and click on it to finish a
bodyText ||| trial. The trial process and interface are shown in Figure 1.
subsectionHeader ||| Results
bodyText ||| Normally, eye movement studies analysed participants’
bodyText ||| search time, number of fixations and fixation duration.
bodyText ||| When we observed the participants’ search behaviour, we
bodyText ||| also found the gaze transitions were not always from one
bodyText ||| item to the next adjacent item; instead, participants skipped
bodyText ||| one or more items during their saccade. We calculated how
bodyText ||| many gaze transitions were not between spatially adjacent
bodyText ||| thumbnails. Therefore, in this study, we were interested in
bodyText ||| visual search performance, particularly in how (1) search
bodyText ||| time and (2) number of item gazes (all contiguous fixations
bodyText ||| on an item were combined to be a single gaze), (3) gaze
bodyText ||| duration (the sum of all fixation durations on a thumbnail
bodyText ||| prior to moving to another thumbnail), and (4) the
bodyText ||| proportion of skipping gaze transitions (the total number of
bodyText ||| gaze transitions divided by the number of skipping gaze
bodyText ||| transitions), are affected by the thumbnails density and
bodyText ||| number of pages. The data in the revisited page were not
bodyText ||| included. These four measures might reveal the adaptation
bodyText ||| of search strategy while participants interact with different
bodyText ||| item densities and number of items.
bodyText ||| We predicted that when the thumbnails were displayed
bodyText ||| close together, participants would spend longer in a gaze,
bodyText ||| and be more likely to skip thumbnails during search in the
bodyText ||| display, than when thumbnails were displayed further apart.
bodyText ||| In addition, page links below the thumbnails indicated that
bodyText ||| the number of pages and total items in the task. We
bodyText ||| predicted that when there are more pages and thumbnails,
bodyText ||| people would adopt a different strategy which would be
bodyText ||| revealed by these four measures.
subsubsectionHeader ||| Overall Performance
bodyText ||| Figure 3 illustrates the overall performance. There were
bodyText ||| significant main density effect on total search time (F(1,23)
bodyText ||| = 23.43, p < 0.001), number of gazes (F(1,23) = 15.87,
bodyText ||| p=0.001), gaze duration (F(1,23) = 17.34, p < 0.001), and
bodyText ||| proportion of skipping gaze transitions (F(1,23) = 35.04,
bodyText ||| p<0.001). The results showed that participant spent less
bodyText ||| time (M = 12,709 ms vs 14,044 ms, figure 3a), fewer gazes
bodyText ||| (M = 8.16 vs 9.28, figure 3b), longer gaze (M = 407 ms vs
bodyText ||| 387 ms, figure 3c) and skipped more often (M = 72.4% vs
bodyText ||| 67.7%, figure 3d) in high versus low density.
bodyText ||| There were significant main number of pages effects on
bodyText ||| total search time (F(2,46) = 136.54, p < 0.001), number of
bodyText ||| gazes (F(2,46) = 73.18, p < 0.001), gaze duration (F(2,46) =
bodyText ||| 10.16, p < 0.001), and proportion of skipping gaze
bodyText ||| transitions (F(2,46) = 8.37, p=0.001). A Bonferroni test
bodyText ||| revealed that every pairwise comparison was significantly
bodyText ||| different (p < 0.05). According to the pairwise comparison,
bodyText ||| participants spent significantly less time (1-page: M = 7,514
bodyText ||| ms, 2-pages: M = 11,482 ms and 5-pages: M = 21,132 ms),
bodyText ||| gazed less (1-page: M = 10.96, 2-pages: M = 15.8 and 5-
bodyText ||| pages: M = 28.02), and skipped less often (1-page: M =
bodyText ||| 66.5%, 2-pages: M = 70.7% and 5-pages: M = 72.9%), in
page ||| 1078
note ||| CHI 2008 Proceedings · Search	April 5-10, 2008 · Florence, Italy
figureCaption ||| Figure 3: four measures of overall search performance per
figureCaption ||| density and number of page condition. (a) mean response
figureCaption ||| times; (b) mean number of gazes; (c) mean gaze duration
figureCaption ||| and (d) proportion of skipping gaze transitions for high
figureCaption ||| density (white bars) and low density (grey bars) in each
figureCaption ||| page set size. Error bars indicate 95% confidence intervals
figureCaption ||| and also in all figures below.
bodyText ||| the fewer page condition. Also, pairwise comparison
bodyText ||| showed that they spent longer gaze duration in the 1-page
bodyText ||| condition (M = 401 ms) than 5-page condition (M = 369
bodyText ||| ms), although 2-pages is not significant different to 1-page
bodyText ||| and 5-pages condition. There were no significant
bodyText ||| interactions on total search time, number of gazes and gaze
bodyText ||| duration, except proportion of skipping gaze transitions,
bodyText ||| F(2,46) = 3.73, p < 0.05.
bodyText ||| Moreover, following Reiman, Young and Howes [34], we
bodyText ||| analysed the revisiting. Figure 4a shows the number of
bodyText ||| items that were visited at least once and revisited (i.e.
bodyText ||| visited at least twice) for each experimental condition.
bodyText ||| Participant revisited around 22% to 27% of visited items for
bodyText ||| each condition. Density and number of pages had similar
bodyText ||| effects on the number of visited and the number of revisited
bodyText ||| items. Participants visited and revisited more items in low
bodyText ||| density (all p’s < 0.01) and when there were more pages (a
bodyText ||| Bonferroni test for analysing three page levels showed
bodyText ||| every pair was significantly different, p < 0.001). In
bodyText ||| number of pages
figureCaption ||| Figure 4: (a) mean number of items visited at least once
figureCaption ||| (bars with solid pattern) and items visited at least twice
figureCaption ||| (bars with line pattern) and (b) mean duration of an item
figureCaption ||| visited at the first time visit (bars with solid pattern) and
figureCaption ||| at the second time visit (bars with line pattern).
bodyText ||| addition, figure 4b shows that our participants spent more
bodyText ||| time on an item when they revisited it than when they
bodyText ||| visited it the fist time, F(1,20) = 99.788, P < 0.001.
bodyText ||| Performance in the First Page
bodyText ||| We analysed data in more detail. In this section we contrast
bodyText ||| performance in the first page of each condition. (Not all
bodyText ||| conditions had subsequent pages so the first page provides
bodyText ||| the critical test. In addition, it is the first page behaviour
bodyText ||| that should be affected by information about the number of
bodyText ||| pages, rather than by the quality of the additional items.)
bodyText ||| We analysed our four measures (search time, number of
bodyText ||| gazes, gaze duration and skipping rate) taken from the first
bodyText ||| page of search results. We conducted a 2 × 3 (density ×
bodyText ||| number of pages) repeated-measure ANOVA for each
bodyText ||| measure separately.
bodyText ||| Duration on a page was defined as the total time from the
bodyText ||| display onset to the time leaving the first page by click a
bodyText ||| page number link, or from the onset to the start of
bodyText ||| participants’ last fixation on the clicked target.
bodyText ||| As expected, there was a main effect of density on mean
bodyText ||| search time in the first page, F(1,23) = 28.27, p < 0.001.
bodyText ||| The search performance in the fist page was quicker in high
bodyText ||| density (M = 6082.24 ms) than low density (M = 6742.9
bodyText ||| ms). There was also a main effect of number of pages on
bodyText ||| search time of the first page, F(2,46) = 15.82,p < 0.001.
figure ||| 1	2	5	(a)
figure ||| 25
figure ||| 20
figure ||| 35
figure ||| 30
figure ||| 15
figure ||| 10
figure ||| 5
figure ||| 0
figure ||| 1	2	5	(b)
figure ||| 450
figure ||| 430
figure ||| 410
figure ||| 390
figure ||| 370
figure ||| 350
figure ||| 1	2	5	(c)
figure ||| 100%
figure ||| 90%
figure ||| 80%
figure ||| 70%
figure ||| 60%
figure ||| 50%
figure ||| 1	2	5	(d)
figure ||| number of pages
figure ||| 30000
figure ||| 25000
figure ||| 20000
figure ||| 15000
figure ||| 10000
figure ||| 5000
figure ||| high density
figure ||| low density
figure ||| 1	2	5	(a
figure ||| 1	2	5	(b)
figure ||| 35
figure ||| 30
figure ||| 25
figure ||| 20
figure ||| 15
figure ||| 10
figure ||| 5
figure ||| 0
figure ||| at least once, high density
figure ||| at least tw ice, high density
figure ||| at least once, low density
figure ||| at least twice, low density
figure ||| first time visit, high density
figure ||| second time visit, high density
figure ||| first time visit, low density
figure ||| second time visit, low density
figure ||| 700
figure ||| 600
figure ||| 500
figure ||| 400
figure ||| 300
figure ||| 200
page ||| 1079
note ||| CHI 2008 Proceedings · Search	April 5-10, 2008 · Florence, Italy
bodyText ||| Figure 5c illustrates mean first page gaze duration.
bodyText ||| Participants’ mean gaze duration in the first page was
bodyText ||| longer in the high density (M = 407 ms) than low density
bodyText ||| layout (M = 387.259 ms), F(1,23) = 22.414, p < 0.001. The
bodyText ||| main effect of number of pages was not significant. There
bodyText ||| was no interaction between density and number of pages.
bodyText ||| Figure 5d shows the data of mean proportion of first page
bodyText ||| skipping gaze transitions. The density had significant effect,
bodyText ||| F (1, 23) = 46.72, p < 0.001. It was found that that
bodyText ||| participants were more likely to skip thumbnails in the high
bodyText ||| density (M = 72%) than in the low density layout (M =
bodyText ||| 67.2%). The main effect of number of pages was also
bodyText ||| significant, F (2, 46) = 15.00, p < 0.001. Every pairwise
bodyText ||| comparison of number of pages condition was significantly
bodyText ||| different (p < 0.01). It showed that our participants skipped
bodyText ||| more often in 5-pages condition (M = 66.5%), than they did
bodyText ||| in 2-pages condition (M = 70.3%), which in turn was more
bodyText ||| often than in the 1-page condition (M = 71.8%). There was
bodyText ||| no interaction between density and number of pages.
figure ||| 15
figure ||| 12
figure ||| 9
figure ||| 6
figure ||| 3
figure ||| 1	2	5	(b
figure ||| high density
figure ||| low density
figure ||| 1	2	5
figure ||| (a
figure ||| 12500
figure ||| 10500
figure ||| 8500
figure ||| 6500
figure ||| 4500
figure ||| 2500
figure ||| 1	2	5
figure ||| (c
figure ||| 450
figure ||| 430
figure ||| 410
figure ||| 390
figure ||| 370
figure ||| 350
figureCaption ||| Figure 5: the four measures of mean search performance in
figureCaption ||| the first page per density condition and number of page
figureCaption ||| condition. (a) mean duration of first page; (b) mean number
figureCaption ||| of first page gazes; (c) mean first page gaze duration and (d)
figureCaption ||| mean proportion of first page skipping gaze transitions.
figure ||| 100%
figure ||| 90%
figure ||| 80%
figure ||| 70%
figure ||| 60%
figure ||| 50%
figure ||| 1	2	5
figure ||| number of pages
figure ||| (d)
figure ||| 10000
figure ||| 8000
figure ||| 6000
figure ||| 4000
figure ||| 2000
figure ||| 15
figure ||| 12
figure ||| 9
figure ||| 6
figure ||| 3
figure ||| 1 page: p.1	2 pages: pp.1-2	5 pages: pp.1-5
figure ||| p.1	p.2	p.3	p.4	p.5
figure ||| (a)
bodyText ||| Every pair comparison of number of pages condition with
bodyText ||| Bonferroni method was significantly different (p < 0.01). It
bodyText ||| was found that time spent in the first page was more in the
bodyText ||| fewer page condition (1-page: M = 7514.54 ms, 2-pages: M
bodyText ||| = 6117.07 ms and 5-pages: M = 5606.10 ms). The
bodyText ||| interaction between density and number of pages was not
bodyText ||| significant. Results are summarized in Figure 5a.
bodyText ||| Figure 5b shows the data of mean number of gazes in the
bodyText ||| first page. Number of gazes was approximate one fewer in
bodyText ||| the high density (M = 8.16) than low density (M = 9.29),
bodyText ||| F(1,23) = 24.65, p < 0.001. There was also a main effect of
bodyText ||| number of pages, F(2,46) = 24.9, p < 0.001. Every pair
bodyText ||| comparison of number of pages condition with Bonferroni
bodyText ||| method was significantly different (p < 0.001). It showed
bodyText ||| that participants spent greater number of gazes in fewer
bodyText ||| page conditions (1-page: M = 10.96, 2-pages: M = 8.07 and
bodyText ||| 5-pages condition: M = 7.11). In addition, the interaction of
bodyText ||| density and number of pages was also significant, F(2,46) =
bodyText ||| 4.48, p = 0.017. The fewest number of gazes were made in
bodyText ||| the first page of the high density display when there were 5-
bodyText ||| pages of items.
figure ||| 1 page: p.1	2 pages: pp.1-2	5 pages: pp.1-5 (b)
figure ||| 1 page: p.1	2 pages: pp.1-2	5 pages: pp.1-5 (d)
figure ||| number of pages
figureCaption ||| Figure 6: the four measures of mean search performance
figureCaption ||| per page. Page 1, page 1 to 2 and page 1 to 5 of 1-page, 2-
figureCaption ||| pages and 5-pages condition, respectively in high density
figureCaption ||| condition. (a) mean search time per page; (b) mean
figureCaption ||| number of gazes per page; (c) mean gaze duration per
figureCaption ||| page and (d) mean proportion of skipping gaze
figureCaption ||| transitions per page.
figure ||| 	500 450 400 350 300
figure ||| 1 page: p.1	2 pages: pp.1-2	5 pages: pp.1-5 (c)
figure ||| 	100% 90% 80% 70% 60% 50%
page ||| 1080
note ||| CHI 2008 Proceedings · Search	April 5-10, 2008 · Florence, Italy
subsubsectionHeader ||| Performance per Page
bodyText ||| Figure 6 summarises the mean performance of our eighteen
bodyText ||| participants’ eye movement behaviour in the high density
bodyText ||| condition. (All results of the low density condition has the
bodyText ||| same trend as in the high density condition) Figure 6a
bodyText ||| shows mean search duration per page, figure 6b shows
bodyText ||| mean number of gazes per page, figure 6c shows mean gaze
bodyText ||| duration per page and figure 6d shows the proportion of
bodyText ||| skipping gaze transitions in number of pages condition.
bodyText ||| Each bar within a page condition shows the performance on
bodyText ||| each page of that condition. For example, the only bar in the
bodyText ||| 1-page condition shows performance in the 1-page
bodyText ||| condition, the two bars in 2-pages condition show each
bodyText ||| performance in page 1 and 2 and the five bars in 5-page
bodyText ||| condition show each performance from page 1 to page 5,
bodyText ||| from left to right respectively.
bodyText ||| When we examined whether participants adopted different
bodyText ||| strategies in different pages in a search course, the values of
bodyText ||| four measures of search performance were taken from each
bodyText ||| page.
bodyText ||| Because there were four participants who didn’t have data
bodyText ||| in all five pages in the 5-page condition, we took out these
bodyText ||| four participants. Then, we arbitrarily selected and removed
bodyText ||| another two participants from the analysis to keep the
bodyText ||| counterbalanced design. Therefore, in this section, the
bodyText ||| results were from analysing eighteen participants’ data. The
bodyText ||| following analyses were conducted in 2-pages and 5-pages
bodyText ||| condition separately.
bodyText ||| In the 2-pages condition, every measure of four search
bodyText ||| performance of participants was not significantly different
bodyText ||| in page 1 and page2. it indicated that the search strategy did
bodyText ||| not vary in the first and second page, when participants
bodyText ||| search in a 2-pages display (see Figure 6a, b, c, d, 2-pages
bodyText ||| condition).
bodyText ||| In 5-pages condition, the results of a 5×2 repeated-measure
bodyText ||| ANOVA (page number: page 1, 2, 3, 4 and 5 × density:
bodyText ||| high and low) showed there were main effect of page
bodyText ||| number and density on every measure of search
bodyText ||| performance our participants’ performance (see Figure 6 a,
bodyText ||| b, c, d, 5-pages condition). The results of search
bodyText ||| performance per page in the 5-pages condition are
bodyText ||| summarized in Table 1. In general, search performance was
bodyText ||| in page number 1 is different to other pages.
bodyText ||| pairwise comparisons of page number with Bonferroni
bodyText ||| method in search duration, number of gazes, and proportion
bodyText ||| of skipping gaze transitions showed that the measures in
bodyText ||| page 1 were different from those in page 2 to page 5 (pair
bodyText ||| between page 1 and any other page was significant, p<0.01
bodyText ||| and pair between page 2 to page 5 were not significant
bodyText ||| different). There was a significant difference between page
bodyText ||| 1 and page 3 in gaze duration. Although any other pair does
bodyText ||| not reach significant, there was a trend for people to take
bodyText ||| longer gaze on page 1 than on pages 2, 3, 4, or 5. This
bodyText ||| indicated that participants search in the first page more
bodyText ||| carefully than other pages.
sectionHeader ||| DISCUSSION
bodyText ||| The results support the claim that visual search strategy is
bodyText ||| guided by expected information gain when people search
bodyText ||| results returned by an image search engine:
bodyText ||| 1. Participants were observed to adjust the duration that
bodyText ||| they attended to each item to the item density. When more
table ||| 		search duration (ms)	number of gazes		gaze duration (ms)	proportion of skipping gaze
table ||| 						transitions
table ||| 		mean	SD	mean	SD	mean	SD	mean	SD
table ||| page number
table ||| 	p. 1	5,238.64a	2,048.75	6.83 a	3.49	406.8 1b	55.64	74.64%a	0.08
table ||| 	p. 2	4,004.51	1,494.82	5.35	2.72	388.18	37.58	79.33%	0.08
table ||| high density	p. 3	3,796.32	1,295.97	5.27	2.30	377.32 c	39.58	79.36%	0.06
table ||| 	p. 4	3,781.66	1,359.42	5.13	2.41	380.30	34.42	77.55%	0.08
table ||| 	p. 5	3,999.54	1,653.50	5.50	2.88	381.00	36.14	77.86%	0.06
table ||| 	p. 1	5,810.45a	2,240.65	7.95 a	4.01	399.47 b	57.47	69.53%a	0.08
table ||| 	p. 2	4,176.94	1,853.84	5.64	3.20	365.01	37.52	77.33%	0.07
table ||| low density	p. 3	4,164.26	1,624.12	5.82	2.97	365.20 c	38.85	76.84%	0.09
table ||| 	p. 4	4,282.31	1,828.08	5.98	3.14	378.27	55.09	74.17%	0.08
table ||| 	p. 5	4,346.20	1,540.77	5.91	2.53	381.86	36.53	74.66%	0.06
table ||| repeated-measures	spacing	F	MSE	p	F	MSE	p	F	MSE	p	F	MSE	p
table ||| ANOVA
table ||| 		14.32	4.83E+05 0.001	9.54	1.942	0.007	4.56	757.26	0.048	13.73	0.003	0.002
table ||| 	page	29.63	5.21E+05 <0.001	17.06	1.397	<0.001	5.4	998.24	0.001	9.70	0.002	<0.001
tableCaption ||| Table 1. Search duration, number of gazes, gaze duration and proportion of skipping gaze transitions across per page in the 5-
tableCaption ||| pages condition and per density condition. (Note. p. = page number. asearch performance is significant different to all other pages in the same
tableCaption ||| density condition. b,csearch performance is significant different to each other in the same density condition)
page ||| 1081
note ||| CHI 2008 Proceedings · Search	April 5-10, 2008 · Florence, Italy
bodyText ||| items were available within the perceptual span (higher
bodyText ||| density), longer item visits were used, and when fewer
bodyText ||| items were available (lower density), shorter item visits
bodyText ||| were used. Longer visits were only used when they were
bodyText ||| efficient, i.e. when expected information gain was high.
bodyText ||| 2. Longer visits to items were combined with skipping.
bodyText ||| Participants in the high density conditions skipped items
bodyText ||| more often, visited fewer items, and spent less time
bodyText ||| searching overall.	In other words, when the potential
bodyText ||| information gain for longer visits was high, people made
bodyText ||| more use of longer visits and reduced the number of items
bodyText ||| that they directly fixated. They made more use of the
bodyText ||| perceptual span when it was rational given the constraints
bodyText ||| of the visual system to do so, and gained an overall
bodyText ||| reduction in the required search time.
bodyText ||| 3. Participants were observed to reduce the number of items
bodyText ||| that they visited, i.e. they skipped, when there was a larger
bodyText ||| number of items (Figure 5d) but without increasing the
bodyText ||| duration spent attending to each item (Figure 5c). These
bodyText ||| findings suggest that skipping was sensitive to the prior
bodyText ||| probability that any one item would be attractive enough to
bodyText ||| be selected but that gaze duration was not.
bodyText ||| 4. Participants spent more time on an item, when they
bodyText ||| revisited it than when they visited it for the first time. this
bodyText ||| findings indicates that people may use an iterative
bodyText ||| deepening of attention [34]. This strategy may help
bodyText ||| participants to parse large amounts of information quickly
bodyText ||| using lower tolerance to rule out poor quality items and
bodyText ||| then focus effort on a smaller set. The difference between
bodyText ||| [34] and our study is that our participants didn’t sample all
bodyText ||| items before they started to revisit, especially in conditions
bodyText ||| with more pages (Figure 4b). This finding suggests that the
bodyText ||| set size of potential items may be constrained by the
bodyText ||| capacity limitation in memory. We also observed
bodyText ||| participants select an item at the first time visit before
bodyText ||| sampling all items. This indicated that people also picked
bodyText ||| an item immediately when the value of the item currently
bodyText ||| visited is beyond their satisficing criteria [38]. Adopting the
bodyText ||| coarse-to-fine strategy [27,33] and employing satisficing
bodyText ||| [38] could save lots of visual processing cost for sampling
bodyText ||| out poor items quickly and gain an item with satisficing
bodyText ||| value or gain a revisited item with acceptable value.
bodyText ||| In sum, the results support the view that people adjusted
bodyText ||| their visual search strategy to their expectations of
bodyText ||| information gain, and that these expectations were
bodyText ||| contingent on (a) the density of items, and (b) the prior
bodyText ||| likelihood that an item is the one that they will want to
bodyText ||| select. In the remainder of the Discussion we first offer
bodyText ||| further explanations for the details of the findings, we then
bodyText ||| discuss some design implications.
subsectionHeader ||| Further Explanations
bodyText ||| Why, for some designs, is it more efficient to use fewer
bodyText ||| longer gazes than more, shorter, ones? Essentially, because
bodyText ||| planning and executing gaze transitions, saccades, is
bodyText ||| expensive. Planning and executing a new gaze so as to
bodyText ||| bring a foveal fixation to a new place requires effort, both
bodyText ||| mental and physical effort. Neurophysiological evidence
bodyText ||| indicates that making a saccade involves high cost neural
bodyText ||| processes to keep the visual scene stable (see [37] review).
bodyText ||| Therefore, to prolong an old gaze to gain information about
bodyText ||| an adjacent item can cost less than to plan and execute a
bodyText ||| new gaze. For example, in our experiment a new item visit
bodyText ||| took an extra 400 ms, but a longer gaze took only about 20
bodyText ||| ms more. Although each longer gaze takes more time, fewer
bodyText ||| gazes are required, reducing the overall visual search time.
bodyText ||| Why was it not possible for participants to increase
bodyText ||| perceptual span to cover adjacent items in lower density
bodyText ||| displays? Findings reported by Hooge, Vlaskamp and Over
bodyText ||| [16] suggest that information can be gathered from a wider
bodyText ||| area of a display as gaze durations increase, i.e. it is
bodyText ||| possible that perceptual span is itself contingent on duration
bodyText ||| of fixation. However, there are clearly limits [4], and it
bodyText ||| appears as though the reduction in the rate that information
bodyText ||| can be acquired caused by the lower densities in our
bodyText ||| experiment pushed participants beyond this limit.
bodyText ||| Will the findings generalise to other types of search result
bodyText ||| items? There is some evidence that the finding would
bodyText ||| generalise to word items. For example, Pollatsek, Perea
bodyText ||| and Binder [32] found that fixation duration is longer when
bodyText ||| a word with more neighbours than few neighbours. Longer
bodyText ||| fixation duration in a more dense display suggests that more
bodyText ||| information within the perceptual span is required to be
bodyText ||| processed serially. In contrast, Motter and Belky [24]
bodyText ||| showed that fixation duration didn’t change as the number
bodyText ||| of items within a 4° constant area and assumed that this
bodyText ||| result is because items surrounding a fixation are processed
bodyText ||| in parallel (number of items surrounded the fixation will not
bodyText ||| affect the fixation duration). These contrary results could be
bodyText ||| because of the relative complexities of stimuli in these two
bodyText ||| tasks are so different. Simple items, e.g. symbols, adjacent
bodyText ||| to a fixation can be processed in parallel, but complex items
bodyText ||| such photographic thumbnails in our task have to be
bodyText ||| processed in series and result in longer durations.
bodyText ||| Why do the findings differ from previous research? The
bodyText ||| importance of ecological validity. The observed density
bodyText ||| effect on gaze duration and number of gazes are consistent
bodyText ||| with some previous studies [26], but contrary to others
bodyText ||| [4,15]. Unlike most of the previous studies, our target was
bodyText ||| not defined by only one or two visual features (color, shape,
bodyText ||| and orientation et al.) or non-words (non-words without
bodyText ||| semantic meaning can be searched by their shape or the
bodyText ||| order of characters), but was, instead, informed by the
bodyText ||| semantic description of a place. In contrast to these
bodyText ||| previous studies, participants in our study had to search a
bodyText ||| target based on aesthetic judgment. They spent longer gaze
bodyText ||| duration in our task than normal visual search task. These
bodyText ||| differences in the task environment may lead to the
bodyText ||| different results of the effect on search performance.
bodyText ||| Ecological validity is therefore crucial to understanding the
bodyText ||| constraints on visual search strategy.
page ||| 1082
note ||| CHI 2008 Proceedings · Search	April 5-10, 2008 · Florence, Italy
bodyText ||| On the other hand, we have chosen to control some
bodyText ||| variables that are confounded in studies of potential new
bodyText ||| designs. For example, in studies of hyperbolic browsers
bodyText ||| [30] item size and item density are confounded, i.e. items
bodyText ||| that are close together are also smaller than items that are
bodyText ||| further apart. Although this is perhaps, a natural confound
bodyText ||| for systems like hyperbolic browsers, failing to isolate what
bodyText ||| are otherwise independent factors will limit the generality
bodyText ||| of conclusions drawn from the data.
bodyText ||| A downside of our effort to engage our participants in a
bodyText ||| meaningful task -- looking for attractive images of potential
bodyText ||| destinations -- was that there was a weak criterion for
bodyText ||| successful trial completion. The trial was over when
bodyText ||| participants indicated that they had found an attractive
bodyText ||| thumbnail but some participants may have used radically
bodyText ||| different thresholds for ‘attractive’ than others. In contrast,
bodyText ||| experiments in which participants were asked to find a
bodyText ||| particular item have a strong and measurable criterion for
bodyText ||| trial completion and moreover participants can make errors.
bodyText ||| Although we claim that our design reflects some part of the
bodyText ||| natural task ecology, it also reduces the strength of the
bodyText ||| conclusions that we can draw from the fact that participants
bodyText ||| took less time, overall, when items were presented with a
bodyText ||| higher density.
subsectionHeader ||| Design Implications
bodyText ||| A persistent problem for HCI is that the exploration of new
bodyText ||| designs in the absence of adequate empirically grounded
bodyText ||| theory might lead to the rejection of the design on the basis
bodyText ||| of false negatives. Hyperbolic or other fish-eye view
bodyText ||| projections have, for example, had no impact on the way
bodyText ||| that most people use computer systems, despite the huge
bodyText ||| research investment over many years. It is tempting to take
bodyText ||| this fact as evidence that hyperbolic browsers are not fit for
bodyText ||| purpose. However, an alternative reason for their failure to
bodyText ||| find a role might be that the particular design instances are
bodyText ||| not tuned to the detailed constraints and adaptive capability
bodyText ||| of the human visual system. Hyperbolic browsers that fail
bodyText ||| to let people adapt to the constraints and capabilities
bodyText ||| imposed by their visual system are unlikely to succeed.
bodyText ||| Careful empirical investigation in response to well-formed
bodyText ||| theory and motivated by the ecology of user’s real task
bodyText ||| environments may have the potential to address this
bodyText ||| problem.
bodyText ||| For example, although users might adapt their search
bodyText ||| strategy to achieve the highest payoff given a particular
bodyText ||| thumbnail density, some layout designs are better for
bodyText ||| decreasing of total search time and manual response time.
bodyText ||| The results reported above suggest the high density (3
bodyText ||| pixels gap between thumbnails) can facilitate search.
bodyText ||| Interestingly, even higher densities than we have explored
bodyText ||| in this paper are unlikely to produce further gains. Previous
bodyText ||| work [21] has suggested that when the spacing between
bodyText ||| icons is zero pixels search becomes more difficult.
bodyText ||| Thumbnails require at least some space for visual search,
bodyText ||| which perhaps reflects common intuitions.
sectionHeader ||| ACKNOWLEDGMENTS
bodyText ||| This research is supported by an Overseas Scholarship
bodyText ||| Scheme (OSS) Award from the University of Manchester
bodyText ||| and a Manchester Business School Award to Yuan-Chi
bodyText ||| Tseng and Office of Naval Research grant (N00014-03-1-
bodyText ||| 0087) to Andrew Howes.
sectionHeader ||| REFERENCES
reference ||| 1. Anderson, J.R. The Adaptive Character of Thought.
reference ||| Lawrence Erlbaum Associates, 1990.
reference ||| 2. Anderson, J.R., Bothell, D., Byrne, M.D., Douglass, S.,
reference ||| Lebiere, C., and Qin, Y. An integrated theory of the
reference ||| mind. Psychological Review 111, 4 (2004), 1036-1060.
reference ||| 3. Araujo, C.C., Kowler, E.E., and Pavel, M.M. Eye
reference ||| movements during visual search: the costs of choosing
reference ||| the optimal path. Vision Research 41, 25-26 (2001),
reference ||| 3613-3625.
reference ||| 4. Bertera, J.H. and Rayner, K. Eye movements and the
reference ||| span of the effective visual stimulus in visual search.
reference ||| Perception & Psychophysics 62 (2000), 576-585.
reference ||| 5. Brumby, D.P. and Howes, A. Good enough but I’ll just
reference ||| check: Web-page search as attentional refocusing. In
reference ||| Proc. ICCM 2004, Lawrence Erlbaum Associates
reference ||| (2004).
reference ||| 6. Brumby, D.P. and Howes, A. Strategies for guiding
reference ||| interactive search: An empirical investigation into the
reference ||| consequences of label relevance for assessment and
reference ||| selection. Human-Computer Interaction (in press).
reference ||| 7. Cockburn, A., Gutwin, C., and Alexander, J. Faster
reference ||| document navigation with space-filling thumbnails. In
reference ||| Proc. CHI 2006, ACM Press (2006), 1-10.
reference ||| 8. Cox, A.L. and Young, R.M. A Rational Model of the
reference ||| Effect of Information Scent on the Exploration of
reference ||| Menus. In Proc. ICCM 2004, Lawrence Erlbaum
reference ||| Associates (2004).
reference ||| 9. Cutrell, E. and Guan, Z. What are you looking for? An
reference ||| eye-tracking study of information usage in Web search.
reference ||| In Proc. CHI 2007, ACM Press (2007).
reference ||| 10.Eng, K., Lewis, R.L., Tollinger, I., Chu, A., Howes, A.,
reference ||| and Vera, A. Generating automated predictions of
reference ||| behavior strategically adapted to specific performance
reference ||| objectives. In Proc. CHI 2006, ACM Press (2006), 621-
reference ||| 630.
reference ||| 11.Everett, S.P. and Byrne, M.D. Unintended effects:
reference ||| Varying icon spacing changes users' visual search
reference ||| strategy. In Proc. CHI 2004, ACM Press (2004), 695-
reference ||| 702.
reference ||| 12.Findlay, J.M. and Gilchrist, I.D. Active vision-the
reference ||| psychology of looking and seeing. Oxford University
reference ||| Press, 2003.
reference ||| 13.Fu, W.-T. and Pirolli, P. SNIF-ACT: A Cognitive
reference ||| Model of User Navigation on the World Wide Web.
reference ||| Human-Computer Interaction 22 (2007).
page ||| 1083
note ||| CHI 2008 Proceedings · Search	April 5-10, 2008 · Florence, Italy
reference ||| 14.Gray, W.D. and Boehm-Davis, D.A. Milliseconds
reference ||| Matter: An introduction to microstrategies and to their
reference ||| use in describing and predicting interactive behavior.
reference ||| Journal of Experiment Psychology: Applied 6, 4 (2000),
reference ||| 322-335.
reference ||| 15.Halverson, T. and Hornof, A.J. Explaining eye
reference ||| movements in the visual search of varying density
reference ||| layouts. In Proc. ICCM 2004, Lawrence Erlbaum
reference ||| Associates (2004), 124-129.
reference ||| 16.Hooge, I.T.C., Vlaskamp, B.N.S., and Over, E.A.B.
reference ||| Saccadic search: the relation between fixation duration
reference ||| and saccade amplitude. Perception 31, ECVP Abstract
reference ||| Supplement (2002).
reference ||| 17.Howes, A., Vera, A., and Lewis, R.L. Bounding rational
reference ||| analysis: Constraints on asymptotic performance. In
reference ||| W.D. Gray (Ed.), Integrated Models of Cognitive
reference ||| Systems, Oxford University Press (2006).
reference ||| 18.Kieras, D.E. and Meyer, D.E. An overview of the EPIC
reference ||| architecture for cognition and performance with
reference ||| application to human-computer interaction. Human-
reference ||| Computer Interaction 12 (1997), 391-438.
reference ||| 19.Kieras, D.E. and Meyer, D.E. The role of cognitive task
reference ||| analysis in the application of predictive models of
reference ||| human performance. In J.M. Schraagen and S.F.
reference ||| Chipman (Eds.), Cognitive task analysis (2000), 237-
reference ||| 260.
reference ||| 20.Klöckner, K., Wirschum, N., and Jameson, A. Depth
reference ||| and breadth-first processing of search result lists. In Ext.
reference ||| Abstracts CHI 2004, ACM Press (2004), 1539-1539.
reference ||| 21.Lindberg, T. and Nasanen, R. The effect of icon spacing
reference ||| and size on the speed of icon processing in the human
reference ||| visual system. Displays 24, 3 (2003), 111-120.
reference ||| 22.Meyer, D.E. and Kieras, D.E. A computational theory of
reference ||| executive control processes and human multiple-task
reference ||| performance: Part 1. Basic Mechanisms. Psychological
reference ||| Review 104 (1997), 3-65.
reference ||| 23.Meyer, D.E. and Kieras, D.E. A computational theory of
reference ||| executive control processes and human multiple-task
reference ||| performance: Part 2. Accounts of Psychological
reference ||| Refractory-Period Phenomena. Psychological Review
reference ||| 104 (1997), 749-791.
reference ||| 24.Motter, B.C. and Belky, E.J. The zone of focal attention
reference ||| during active visual search. Vision Research 38 (1998),
reference ||| 1007-1022.
reference ||| 25.Najemnik, J. and Geisler, W.S. Optimal eye movement
reference ||| strategy in visual search. Nature 434 (2005), 387-391.
reference ||| 26.Ojanpää, H., Näsänen, R., and Kojo, I. Eye movements
reference ||| in the visual search of word lists. Vision Research 42, 12
reference ||| (2002), 1499-1512.
reference ||| 27.Over, E.A.B., Hooge, I.T.C., Vlaskamp, B.N.S., and
reference ||| Erkelens, C.J. Coarse-to-fine eye movement strategy in
reference ||| visual search. Vision Research 47 (2007), 2272-2280.
reference ||| 28.Payne, S.J., Howes, A., and Reader, W.R. Adaptively
reference ||| distributing cognition: a decision-making perspective on
reference ||| human-computer interaction. Behaviour and Information
reference ||| Technology 20, 5 (2001), 339-346.
reference ||| 29.Pirolli, P. and Card, S.K. Information foraging.
reference ||| Psychological Review 106, 4 (1999), 643-675.
reference ||| 30.Pirolli, P., Card, S.K., and Van Der Wege, M. The
reference ||| effects of information scent on visual search in the
reference ||| hyperbolic tree browser. ACM Transactions on
reference ||| Computer Human Interaction 10, 1 (2003), 20-53.
reference ||| 31.Pirolli, P. and Fu, W.-T. SNIF-ACT: a model of
reference ||| information foraging on the world wide web. In Proc.
reference ||| Ninth International Conference on User Modeling,
reference ||| Springer (2003).
reference ||| 32.Pollatsek, A., Perea, M., and Binder, K.S. The Effecs of
reference ||| Neighborhood Size in Reading and Lexical Decision.
reference ||| Journal of Experimental Psychology: Human Perception
reference ||| and Performance 25, 4 (1999), 1142-1158.
reference ||| 33.Rao, R.P.N., Zelinsky, G., Hayhoe, M.M., and Ballard,
reference ||| D.H. Eye movements in iconic visual search. Vision
reference ||| Research 42, 11 (2002), 1447-1463.
reference ||| 34.Reiman, J., Young, M., and Howes, A. A dual-space
reference ||| model of interatively deepening exploratory learning.
reference ||| International Journal of Human-Computer Studies 44
reference ||| (1996), 743-775.
reference ||| 35.Rele, R.S. and Duchowski, A.T. Using eye tracking to
reference ||| evaluate alternate search results interfaces. In Proc.
reference ||| HFES 49th Annual Conference (2005).
reference ||| 36.Resnick, M.L., Maldonado, C.A., Santos, J.M., and
reference ||| Lergier, R. Modeling On-line Search Behavior Using
reference ||| Alternative Output Structures. In Proc. HFES 45th
reference ||| Annual Conference (2001), 1166-1171.
reference ||| 37.Ross, J., Morrone, M.C., Goldberg, M.E., and Burr,
reference ||| D.C. Changes in visual perception at the time of
reference ||| saccades. Trends in Neurosciences 24, 2 (2001), 113-
reference ||| 121.
reference ||| 38.Simon, H.A. A behavioral model of rational choice.
reference ||| Quarterly Journal of Economics 69 (1955), 99-118.
reference ||| 39.Sperling, G. and Dosher, B.A. Strategy and optimization
reference ||| in human information processing. In K.R. Boff, L.
reference ||| Kaufman, and J.P. Thomas (Eds.), Handbook of
reference ||| perception and human performance, Vol. I, Sensory
reference ||| processes and perception, Wiley (1986).
reference ||| 40.Vlaskamp, B.N.S., Over, E.A.B., and Hooge, I.T.C.
reference ||| Saccadic search performance: the effect of element
reference ||| spacing. Experimental Brain Research 3 (2005), 1-14.
reference ||| 41.Woodruff, A., Faulring, A., Rosenholtz, R., Morrison,
reference ||| J., and Pirolli, P. Using Thumbnails to Search the Web.
reference ||| In Proc. CHI 2001, ACM Press (2001), 198-205.
reference ||| 42.Yee, K.P., Swearingen, K., Li, K., and Hearst, M.
reference ||| Faceted metadata for image search and browsing. In
reference ||| Proc. CHI 2003, ACM Press (2003), 401-408.
page ||| 1084

note ||| CHI 2008 Proceedings · Shared Authoring	April 5-10, 2008 · Florence, Italy
title ||| Don’t Look Now, But We’ve Created a Bureaucracy:
title ||| The Nature and Roles of Policies and Rules
title ||| in Wikipedia
author ||| Brian Butler
affiliation ||| Katz Graduate School of
affiliation ||| Business, University of
affiliation ||| Pittsburgh
email ||| bbutler@katz.pitt.edu
author ||| Elisabeth Joyce
affiliation ||| Edinboro University of
affiliation ||| Pennsylvania
email ||| ejoyce@edinboro.edu
author ||| Jacqueline Pike
affiliation ||| Katz Graduate School of
affiliation ||| Business, University of
affiliation ||| Pittsburgh
email ||| jpike@katz.pitt.edu
sectionHeader ||| ABSTRACT
bodyText ||| Wikis are sites that support the development of emergent,
bodyText ||| collective infrastructures that are highly flexible and open,
bodyText ||| suggesting that the systems that use them will be
bodyText ||| egalitarian, free, and unstructured. Yet it is apparent that
bodyText ||| the flexible infrastructure of wikis allows the development
bodyText ||| and deployment of a wide range of structures. However, we
bodyText ||| find that the policies in Wikipedia and the systems and
bodyText ||| mechanisms that operate around them are multi-faceted. In
bodyText ||| this descriptive study, we draw on prior work on rules and
bodyText ||| policies in organizations to propose and apply a conceptual
bodyText ||| framework for understanding the natures and roles of
bodyText ||| policies in wikis. We conclude that wikis are capable of
bodyText ||| supporting a broader range of structures and activities than
bodyText ||| other collaborative platforms. Wikis allow for and, in fact,
bodyText ||| facilitate the creation of policies that serve a wide variety of
bodyText ||| functions.
sectionHeader ||| Author Keywords
keyword ||| Wikis, Wikipedia, community, collaboration, policy,
keyword ||| policies, rules, dynamics.
sectionHeader ||| ACM Classification Keywords
category ||| K.4.3. [Computers and Society]: Organizational Impact –
category ||| Computer-supported collaborative work, H.5.3
category ||| [Information Interfaces]: Group and Organization Interfaces
category ||| - Collaborative computing, Web-based interaction,
category ||| Computer-supported cooperative work, H.3.5 [Information
category ||| Storage and Retrieval]: Online Information Systems.
sectionHeader ||| INTRODUCTION
construct ||| “The Wikipedia online encyclopedia — written by
construct ||| thousands of individuals working without a boss – shows
construct ||| the way... ” [28]
bodyText ||| Wikipedia is characterized by many as emergent, complex,
copyright ||| Permission to make digital or hard copies of all or part of this work for
copyright ||| personal or classroom use is granted without fee provided that copies are
copyright ||| not made or distributed for profit or commercial advantage and that copies
copyright ||| bear this notice and the full citation on the first page. To copy otherwise,
copyright ||| or republish, to post on servers or to redistribute to lists, requires prior
copyright ||| specific permission and/or a fee.
note ||| CHI 2008, April 5–10, 2008, Florence, Italy.
copyright ||| Copyright 2008 ACM 978-1-60558-011-1/08/04...$5.00
bodyText ||| messy, informal, popularly uncontrolled, non-
bodyText ||| organizational, and radically different from traditional
bodyText ||| organizations [5, 11, 22, 42, 52, 53]. Consistent with this
bodyText ||| characterization, one of the founding principles of
bodyText ||| Wikipedia is “Ignore all rules,” which states that if a rule
bodyText ||| inhibits developing Wikipedia, the contributor should
bodyText ||| ignore it [45].
bodyText ||| Yet examination of the administrative structures of
bodyText ||| Wikipedia reveals a complex structure of rules, processes,
bodyText ||| policies, and roles. There are 44 wiki pages in the
bodyText ||| “Wikipedia Official Policy” category as of September
bodyText ||| 20071. There are 248 wiki pages categorized as “Wikipedia
bodyText ||| guidelines” which are organized into at least eight
bodyText ||| subcategories. In addition, these do not seem to be
bodyText ||| sufficient, since there are 45 pending proposals for
bodyText ||| guidelines and policies, not to mention the 200 rejected
bodyText ||| proposals for guidelines and policies.
bodyText ||| Even the principle of “Ignore all rules,” labeled as one of
bodyText ||| the official Wikipedia policies, is not immune from such
bodyText ||| “development” [45]. While the “Ignore all rules” policy
bodyText ||| itself is only sixteen words long, the page explaining what
bodyText ||| the policy means contains over 500 words, refers readers to
bodyText ||| seven other documents, has generated over 8,000 words of
bodyText ||| discussion, and has been changed over 100 times in less
bodyText ||| than a year.
bodyText ||| Studies of Wikipedia activities [5, 11, 42, 43] and
bodyText ||| anecdotal discussions among participants [49] suggest that
bodyText ||| these policies, rules, and guidelines play an important part
bodyText ||| in both the day-to-day operations and overall success of
bodyText ||| Wikipedia. These arguments are consistent with findings
bodyText ||| and arguments made with regard to other types of online
bodyText ||| collective action, such as online communities [19, 24, 32],
bodyText ||| open source development [15, 16, 26, 41, 44], and virtual
bodyText ||| organizations [1].
bodyText ||| The purpose of this study is to propose a conceptual
bodyText ||| framework for understanding the nature and role of policies
bodyText ||| and rules within wikis. Drawing from prior studies of rules
footnote ||| 1 All references to Wikipedia content are based on data
footnote ||| exported from the site in September 2007. Since the
footnote ||| policies undergo perpetual re-editing and reconfiguring, the
footnote ||| data presented here represents a snap-shot.
page ||| 1101
note ||| CHI 2008 Proceedings · Shared Authoring	April 5-10, 2008 · Florence, Italy
bodyText ||| and policies in a variety of contexts, including teams,
bodyText ||| traditional organizations, and legal systems [29], different
bodyText ||| images of rules and policies are considered. In each case,
bodyText ||| examples and evidence are drawn from Wikipedia to
bodyText ||| illustrate that view of rules and policies. Following this we
bodyText ||| discuss the implications of the framework for understanding
bodyText ||| both the potential and likely outcomes of wiki efforts and
bodyText ||| design implications of the different perspectives for both
bodyText ||| wiki implementation and development of infrastructures for
bodyText ||| supporting wiki-like initiatives.
sectionHeader ||| RULES, POLICIES AND GUIDELINES
bodyText ||| In the broadest scope, terms like rules, policies, and
bodyText ||| guidelines all refer to the “explicit and implicit norms,
bodyText ||| regulations, and expectations that regulate the behavior of
bodyText ||| individuals and interactions between them” [29 p. 5].
bodyText ||| Taken in its most general sense, this definition can also be
bodyText ||| seen as including informal or implicit norms and constraints
bodyText ||| that can significantly affect behavior and interaction, even
bodyText ||| though they are not formally recognized or recorded.
bodyText ||| Given the widely discussed importance of informal norms
bodyText ||| in contexts such as open source projects [35, 41] and other
bodyText ||| online social settings [3, 4], it may be beneficial to equate
bodyText ||| formal and informal rules. In particular this approach
bodyText ||| suggests that insights and results from the study of explicit,
bodyText ||| formal rules and policies may be useful for understanding
bodyText ||| the development, application, and impact of informal rules
bodyText ||| and norms. However, in this study we focus on formal, or
bodyText ||| written, policies, rules, and guidelines.
bodyText ||| We use the terms rules, policies, and guidelines
bodyText ||| interchangeably. While there are some contexts in which
bodyText ||| these are clearly conceptually distinguishable, the
bodyText ||| difference between and application of the terms vary from
bodyText ||| context to context. This suggests that while some aspects
bodyText ||| require distinguishing them from each other, there is not
bodyText ||| ready agreement on what they are or how the terms should
bodyText ||| be used. Furthermore, and for our purposes perhaps more
bodyText ||| importantly, this conceptual equivalence is reflected in the
bodyText ||| Wikipedia definitions which state:
construct ||| “A guideline is any page that is: (1) actionable (i.e. it
construct ||| recommends, or recommends against, an action to be taken
construct ||| by editors) and (2) authorized by consensus. Guidelines are
construct ||| not set in stone and should be treated with common sense
construct ||| and the occasional exception.
construct ||| A policy is similar to a guideline, only more official and
construct ||| less likely to have exceptions.” [48]
bodyText ||| This study focuses on formal written policies for both
bodyText ||| practical and conceptual reasons. Practically, formal rules
bodyText ||| are ideal for study because of the relative ease of
bodyText ||| determining what the policy is, when it was put in place,
bodyText ||| who participated in creating it, when it was referenced, and,
bodyText ||| in some cases, when it was removed. This is particularly
bodyText ||| true in the context of a wiki because of its facilities for
bodyText ||| archiving and managing collaborative documents.
bodyText ||| However, beyond the practical issues, formal written rules
bodyText ||| and policies are significant because of their role as
bodyText ||| boundary objects [33, 34], or as specifications of how the
bodyText ||| content will be used and communication will occur. They
bodyText ||| can serve a variety of purposes by virtue of the fact that
bodyText ||| they are explicit and external. Because they are explicit and
bodyText ||| visible, though, written policies and rules are often sites of
bodyText ||| conflict [29 p. 18]. These same characteristics also mean
bodyText ||| that written policies have greater potential as levers for
bodyText ||| developers, designers, and managers to affect a community
bodyText ||| or collaborative effort [10, 19].
bodyText ||| Hence, while it may be the case that informal norms are
bodyText ||| important, it makes sense to focus on the nature and role of
bodyText ||| formal written rules and policies in the operation of a
bodyText ||| distributed collaborative effort like Wikipedia.
sectionHeader ||| IMAGES AND ROLES OF RULES AND POLICIES
bodyText ||| Because of their centrality in so many aspects of society
bodyText ||| and organizational and individual behaviors, rules and
bodyText ||| policies have been studied by scholars in a wide variety of
bodyText ||| fields, including law, sociology, political science,
bodyText ||| economics, management science, anthropology, linguistics,
bodyText ||| and organizational studies. While these scholars typically
bodyText ||| adopt definitions similar to those described above, the
bodyText ||| assumptions they make about the source, nature, and
bodyText ||| implications of rules and policies can vary significantly.
bodyText ||| While this lack of consensus can present challenges, it also
bodyText ||| provides a basis for characterizing the multifaceted nature
bodyText ||| of rules, policies, and guidelines.
bodyText ||| In particular, prior work provides several perspectives
bodyText ||| which can be used to view rules and policies, including
bodyText ||| rules and policies as:
listItem ||| •	Rational efforts to organize and coordinate
listItem ||| •	Evolving, competing entities
listItem ||| •	Constructions of meaning & identity
listItem ||| •	External signals
listItem ||| •	Internal signals
listItem ||| •	Negotiated settlements and trophies
listItem ||| •	Control mechanisms
bodyText ||| In the following sections, we consider each of these
bodyText ||| perspectives. For each one we begin with a discussion of
bodyText ||| the core assumptions that are made about the nature and
bodyText ||| implications of policies playing this role with reference to
bodyText ||| principles and examples drawn from studies of rules in
bodyText ||| traditional organizational and social contexts. We then
bodyText ||| consider examples from Wikipedia that illustrate how the
bodyText ||| policies and guidelines there are consistent with the
bodyText ||| perspective.
bodyText ||| The purpose of these discussions and examples is to
bodyText ||| illustrate how the guidelines and policies in Wikipedia, and
bodyText ||| the systems and mechanisms that operate around them, are
bodyText ||| multi-faceted. As such, these perspectives should not be
page ||| 1102
note ||| CHI 2008 Proceedings · Shared Authoring	April 5-10, 2008 · Florence, Italy
figureCaption ||| Figure 2. Wikipedia
figureCaption ||| Guideline Box
bodyText ||| treated as a set of mutually exclusive categories, but rather
bodyText ||| as a set of potentially overlapping lenses, each of which
bodyText ||| highlights different aspects of the policies and guidelines
bodyText ||| that exist within Wikipedia.
subsectionHeader ||| Rules and Policies as Rational Efforts to Organize or
subsectionHeader ||| Coordinate
bodyText ||| All groups are faced with challenges created by
bodyText ||| communication and coordination problems which must be
bodyText ||| solved if the shared objectives are to be achieved [7, 13, 14,
bodyText ||| 21, 38, 41]. In this view rules are conscious, intentional
bodyText ||| actions put in place for the purpose of improving collective
bodyText ||| performance. Rules and policies address, or at least
bodyText ||| substantially increase the chance of addressing, the
bodyText ||| problems of communication and coordination by creating a
bodyText ||| context in which distributed actions are taken in reliable
bodyText ||| and consistent ways [27]. In other words, rules and policies
bodyText ||| are means of solving communication and coordination
bodyText ||| problems by increasing the reliability and consistency of
bodyText ||| action (i.e., eliminating the need to explicitly communicate
bodyText ||| and coordinate) [29]. Rules in this role assume that all
bodyText ||| parties have the same motivations and goals.
bodyText ||| Rules and policies for coordination and communication
bodyText ||| have been identified as particularly important in contexts
bodyText ||| where there is high turnover (people coming and going on a
bodyText ||| regular basis), where there is substantial autonomy of
bodyText ||| action, and where explicit coordination is costly and yet
bodyText ||| important to success of the activity [9, 25].
subsubsectionHeader ||| Rational Efforts to Organize or Coordinate in Wikipedia
bodyText ||| Wikipedia has high turnover in that a large majority of the
bodyText ||| editors make only a few changes once, the editors are
bodyText ||| distributed globally, and coordination is necessary in order
bodyText ||| to continuously provide a functioning product (i.e., an
bodyText ||| encyclopedia) on demand.
bodyText ||| For Wikipedia, this perspective
bodyText ||| on rules and policies suggests
bodyText ||| that policies and guidelines are
bodyText ||| being put in place to achieve
bodyText ||| consistency and reliability in
bodyText ||| terms of how things are
bodyText ||| handled and coordinate efforts
bodyText ||| [23], but also to confirm the
bodyText ||| authority of those most likely
bodyText ||| to implement the policies: the
bodyText ||| administrators. For example, a
bodyText ||| policy was created which
bodyText ||| outlines the process which
bodyText ||| should be taken to block a user
bodyText ||| or delete an entry in
bodyText ||| Wikipedia. The 48 policies
bodyText ||| under consideration on the
bodyText ||| Wikipedia Policy proposals
bodyText ||| indicate the administrators’ continual need to reinforce their
bodyText ||| limited power over the dispersed population of this
bodyText ||| community.
bodyText ||| Because of the decentralized
bodyText ||| nature of the role of user (i.e.,
bodyText ||| editor) in Wikipedia and the high
bodyText ||| turnover, more written policies
bodyText ||| and guidelines are needed to
bodyText ||| facilitate the transfer of
bodyText ||| knowledge [40] from one user to
bodyText ||| the next and maintain
bodyText ||| consistency during the editing.
bodyText ||| Alternatively, fewer policies will
bodyText ||| be specified for administrators
bodyText ||| than users. There are more
bodyText ||| rules, therefore, for editors, since
bodyText ||| their population experiences
bodyText ||| greater turnover and their
bodyText ||| activities are more dispersed
bodyText ||| than those of the administrators
bodyText ||| [13, 14]. Also, since this
bodyText ||| population gains members more
bodyText ||| frequently than the
bodyText ||| administrators, written policies
bodyText ||| assist new people by lending
bodyText ||| them direction with their
bodyText ||| contributions, in a similar
bodyText ||| fashion as Frequently asked
bodyText ||| questions pages in online
bodyText ||| communities [6].
bodyText ||| Most policy and guideline pages
bodyText ||| provide a box with general
bodyText ||| information about Wikipedia
bodyText ||| policy or guidelines,
bodyText ||| respectively, in the prominent
bodyText ||| upper right hand corner, as
bodyText ||| shown in Figures 1 and 2. The
bodyText ||| policies selected for emphasis
bodyText ||| are divided into two sections:
bodyText ||| one discussing procedures for
bodyText ||| editing articles and the other
bodyText ||| reminding users about
bodyText ||| behavioral standards.
bodyText ||| These boxes serve to introduce first time participants to the
bodyText ||| norms of the hybrid community/document paradigm and
bodyText ||| remind more experienced and committed members about
bodyText ||| the essential rules. After all, according to the Wikipedia
bodyText ||| contributors, these policies and guidelines help make
bodyText ||| Wikipedia successful [48]. Also, since the items in these
bodyText ||| lists are links, they point readily to the written document for
bodyText ||| each of these policies.
bodyText ||| Wikipedia editors suggest that policy is often enacted after
bodyText ||| it has been used in practice and recognized as important
bodyText ||| [48], such as to increase the speed, efficiency, or reduce the
bodyText ||| cost of administering the encyclopedia. These enactments
bodyText ||| embody the rational efforts of this role of a policy or
bodyText ||| guideline.
figureCaption ||| Figure 1. Wikipedia
figureCaption ||| Policy Box
page ||| 1103
note ||| CHI 2008 Proceedings · Shared Authoring	April 5-10, 2008 · Florence, Italy
bodyText ||| A case where a process was “policy-fied” to accomplish
bodyText ||| these goals is the policy outlining the Criteria for Speedy
bodyText ||| Deletion [50]. The deletion policy is written exclusively for
bodyText ||| administrators, for they are the only community members
bodyText ||| empowered to determine what pages should remain in
bodyText ||| Wikipedia and what pages should be removed. This policy
bodyText ||| is written in extensive form and with multiple categorized
bodyText ||| subsections to accommodate the autonomy of the
bodyText ||| administrators and to support consistency in their decision
bodyText ||| making. Written policies of this sort ensure coordination
bodyText ||| among administrators and prevent arbitrary decisions.
bodyText ||| Additionally, written policies establish guidelines for
bodyText ||| behavior so that each decision does not require the endless
bodyText ||| time expense of lengthy discussion and consensus
bodyText ||| development.
subsubsectionHeader ||| Implications for Rational Efforts to Organize or Coordinate
bodyText ||| Wikipedia policies and guidelines can be seen as intentional
bodyText ||| efforts to solve coordination and communication problems
bodyText ||| by either eliminating the need for direct coordination or
bodyText ||| communication or significantly reducing the costs of such
bodyText ||| communication. Reduction of costs is often achieved by
bodyText ||| codifying the interaction, and hence, reducing the effort
bodyText ||| needed to engage in the exchanges. These mechanisms
bodyText ||| remain important even though communication and
bodyText ||| coordination costs are lower (at least theoretically) because
bodyText ||| of the technology infrastructure due to issues such as
bodyText ||| information overload [17]. At least for large scale wikis,
bodyText ||| such as Wikipedia, the need for organizational mechanisms
bodyText ||| to reduce communication and coordination cost remains.
bodyText ||| Rules and Policies as Evolving, Competing, Self-
bodyText ||| propagating Entities
subsectionHeader ||| Rules can be seen as self-propagating entities that are the
bodyText ||| result of an evolving, competitive process. This perspective
bodyText ||| rejects the idea of intention, design, and agency as the
bodyText ||| primary drivers of policy development, largely because of
bodyText ||| the bounded rationality of individuals and high levels of
bodyText ||| complexity in the organizational system. Instead it is
bodyText ||| argued that rules are the result of competition for shifting
bodyText ||| attention. This results in systems of policies in which
bodyText ||| dynamics of rule development have the following features:
listItem ||| •	Rules generate more rules (either exponentially, linearly,
listItem ||| or at a declining rate)
listItem ||| •	Areas or problems can be saturated, so modification or
listItem ||| adaptation of rules will drop off as the space gets
listItem ||| “populated”
listItem ||| •	Developing manner rules in one area will draw attention
listItem ||| and people from other areas [29]
subsubsectionHeader ||| Evolving, Competing, Self-propagating Entities in Wikipedia
bodyText ||| For Wikipedia, the basic conditions of this perspective
bodyText ||| definitely apply. Wikipedia is an extremely complex system
bodyText ||| of documents, people, roles, policies and guidelines, yet
bodyText ||| individuals possess bounded rationality [39]. This suggests
bodyText ||| that we should see these kinds of dynamics of rules in the
bodyText ||| formation and modifications of the policies and guidelines
bodyText ||| in Wikipedia, and the archives bear this out.
bodyText ||| One useful measure of increased complexity is the change
bodyText ||| in lengths in terms of word count alone of the policies from
bodyText ||| the first version to most current. All policies studied grew
bodyText ||| enormously.
listItem ||| •	Copyrights: 341 words 4 3200 words: 938%
listItem ||| •	What Wikipedia is not: 541 words 4 5031 words: 929%
listItem ||| •	Civility: 1741 words 4 2131 words: 124%
listItem ||| •	Consensus: 132 words 4 2054 words: 1557%
listItem ||| •	Deletion: 405 words 4 2349 words: 580%
listItem ||| •	Ignore all rules: exceptional case
bodyText ||| The first version of the Ignore all rules policy is only 23
bodyText ||| words long, stating, “If rules make you nervous and
bodyText ||| depressed, and not desirous of participating in the Wiki,
bodyText ||| then ignore them and go about your business” [45]. The
bodyText ||| current version is actually shorter, only 16 words, and says,
bodyText ||| “If a rule prevents you from working with others to improve
bodyText ||| or maintain Wikipedia, ignore it” [45]. However, as
bodyText ||| suggested earlier in this paper, while the actual wording of
bodyText ||| this policy declined 69% and it appears on the surface to be
bodyText ||| the least bureaucratic of the policies, the supplemental page
bodyText ||| directly linked to this policy contains 579 words, indicating
bodyText ||| that the policy swelled over 3600% [45].
bodyText ||| The Deletion policy appears to grow less than most of the
bodyText ||| other policies, but this statistic is misleading as the deletion
bodyText ||| policy is continually broken down into smaller
bodyText ||| subcategories in order to prevent discussion of particular
bodyText ||| instances of deletion decisions from appearing on the
bodyText ||| general policy page. The Deletion policy, therefore, is a
bodyText ||| policy of tremendous proliferation and complication.
bodyText ||| Increased complexity is apparent in the Copyrights policy,
bodyText ||| among others, where the diction and syntax emulate that of
bodyText ||| legal documents. The first version of the policy, for
bodyText ||| instance, starts with: “The goal of Wikipedia is to create
bodyText ||| information that is available to everyone.” The current
bodyText ||| version, starting after a disclaimer note, begins: “The
bodyText ||| license Wikipedia uses grants free access to our content in
bodyText ||| the same sense as free software is licensed freely.” The
bodyText ||| earlier version uses simple sentence construction and
bodyText ||| vernacular diction. The current one relies on words from the
bodyText ||| legal profession, such as license, grants, access, and later in
bodyText ||| the policy, permission, obligation, rights.
subsubsectionHeader ||| Implications for Evolving, Competing, Self-propagating
subsubsectionHeader ||| Entities
bodyText ||| This role of rules and policies is necessary because it
bodyText ||| attempts to take the complex system that is Wikipedia and
bodyText ||| make it manageable. The evolutionary aspect of this role
bodyText ||| also promotes the continuous updating and modification of
bodyText ||| rules, which is needed in this type of dynamic environment.
subsubsectionHeader ||| Rules and Policies as Constructions of Meaning and
subsubsectionHeader ||| Identity
bodyText ||| Rules and policies answer questions about “who we are”
bodyText ||| [29]. They also indicate the way things “should be” (i.e.,
bodyText ||| ideals). Lastly they serve to define and exemplify the “talk”
page ||| 1104
note ||| CHI 2008 Proceedings · Shared Authoring	April 5-10, 2008 · Florence, Italy
bodyText ||| of the place. Previous work has looked at the role of shared
bodyText ||| group and community identity [2, 12, 14] and individual
bodyText ||| identity [18, 30, 37] construction.
subsubsectionHeader ||| Constructions of Meaning and Identity in Wikipedia
bodyText ||| For Wikipedia this includes policies that serve the purpose
bodyText ||| of defining what Wikipedia is and is not, either explicitly
bodyText ||| (e.g., What Wikipedia is not page) or through the
bodyText ||| articulation of policy pages on community principles (e.g.,
bodyText ||| Ignore all rules page).
bodyText ||| Meaning and identity are also likely to be reflected in
bodyText ||| discussions of policy changes that center on whether or not
bodyText ||| something is consistent with the “core principles” of
bodyText ||| Wikipedia. An example of these discussions is that which
bodyText ||| centers around the Neutral Point of View policy. This
bodyText ||| policy contains detailed definitions of bias, carefully
bodyText ||| organized guidelines for how to maintain neutrality in an
bodyText ||| article, and specifically outlined procedures for handling
bodyText ||| conflicts [51]. The archived discussion pages on this policy
bodyText ||| are so voluminous that many of them contain the
bodyText ||| discussions held within only one or two days [51].
bodyText ||| The What Wikipedia is not policy sets up a clear sense of
bodyText ||| identity, but less through a description or definition of it
bodyText ||| (i.e., what we are) than through a negative approach. This
bodyText ||| policy is divided into three sections: Style and Format,
bodyText ||| Content, and Community. The first section differentiates
bodyText ||| Wikipedia from printed and published encyclopedias that
bodyText ||| are written by paid experts. The second section defines the
bodyText ||| term encyclopedia. The third one is perhaps the most
bodyText ||| illustrative of the identity of the group, however, for it lays
bodyText ||| out explicitly norms for community behavior, and for the
bodyText ||| purposes of this paper, “Wikipedia is not a bureaucracy” is
bodyText ||| the section most directed towards policy. Interestingly, it
bodyText ||| denies the bureaucratic nature of this organization:
bodyText ||| “Wikipedia is not a moot court, and rules are not the
bodyText ||| purpose of the community. Instruction creep should be
bodyText ||| avoided. A perceived procedural error made in posting
bodyText ||| anything, such as an idea or nomination, is not grounds for
bodyText ||| invalidating that post. Follow the spirit, not the letter, of
bodyText ||| any rules, policies and guidelines if you feel they conflict. If
bodyText ||| the rules prevent you from improving the encyclopedia, you
bodyText ||| should ignore them. Disagreements should be resolved
bodyText ||| through consensus-based discussion, rather than through
bodyText ||| tightly sticking to rules and procedures.”
bodyText ||| The irony of this statement is that discussion surrounding
bodyText ||| policy development and modification turns to policy for
bodyText ||| support on a regular basis. The Three-revert rule policy, for
bodyText ||| instance, refers to the Copyrights, Spamming, Non-free
bodyText ||| content, Biographies of living persons, Blocking, and
bodyText ||| Consensus policies in its statement alone, with reference to
bodyText ||| those and other policies and guidelines proliferating
bodyText ||| through the discussion pages.
subsubsectionHeader ||| Implications for Constructions of Meaning and Identity
bodyText ||| Rules in this role allow the wiki and its users to develop a
bodyText ||| sense of identity and meaning, which can be viewed,
bodyText ||| literally and figuratively, by new and current editors. These
bodyText ||| editors can then measure their fit with the community and
bodyText ||| decide on their intended level of participation. For
bodyText ||| example, someone looking for a wiki focused on social
bodyText ||| interaction may not be satisfied with one which focuses on
bodyText ||| purely identity formation [36]. In a volitional environment,
bodyText ||| such statement of meaning, values, and identity can become
bodyText ||| highly influential and rallying.
subsectionHeader ||| Rules and Policies as External Signals
bodyText ||| Sometimes rules are ways of indicating to outside
bodyText ||| stakeholders or concerned parties that things that they care
bodyText ||| about are being attended to. The rules can be symbolic; can
bodyText ||| reflect action, or both. It is possible to discern these
bodyText ||| responses through media coverage of Wikipedia that
bodyText ||| provoked changes in policies or the creation of new ones.
subsubsectionHeader ||| External Signals in Wikipedia
bodyText ||| For Wikipedia, the Copyrights policy illustrates a rule
bodyText ||| acting as an external signal. Based on an analysis of the
bodyText ||| Copyrights guidelines, it appears they were developed in
bodyText ||| response to external complaints or concerns about the
bodyText ||| unpermitted use of protected material [47]. It is perhaps
bodyText ||| because of this external stimulant that this policy’s
bodyText ||| discussion pages, while devoted extensively to copyright
bodyText ||| rules in general, often devolve into discussions of particular
bodyText ||| cases, especially those concerning images [47]. Also,
bodyText ||| perhaps because of the need to signal recognition of an
bodyText ||| issue by Wikipedia, this page developed from a simply
bodyText ||| stated list of rules into a more extensively organized but
bodyText ||| also more linguistically complicated treatise, as mentioned
bodyText ||| above. The language evolved from simple sentence
bodyText ||| structures and vernacular style into the more complicated
bodyText ||| grammars and dictions of the legal profession, possibly due
bodyText ||| to the hiring of general counsel [8], but also as the need for
bodyText ||| greater credibility and as a reflection of the community’s
bodyText ||| pressures to protect itself and its reputation from outside
bodyText ||| attacks or influences.
bodyText ||| Another example of a policy acting as an external signal, or
bodyText ||| at least being heavily oriented toward external stakeholders,
bodyText ||| is the Biographies of living persons policy [46]. Notable
bodyText ||| characteristics of this policy include:
listItem ||| •	It includes full contact information for Jimmy Wales as
listItem ||| the “Designated Agent” (which references specific
listItem ||| requirement of US Law) unlike the other policies. It also
listItem ||| includes a link to the Wikimedia Foundations Board of
listItem ||| Trustees in a related readings section.
listItem ||| •	It explicitly references external legal structures
listItem ||| requirements (“Such material requires a high degree of
listItem ||| sensitivity, and must adhere strictly to the law in Florida,
listItem ||| United States and to our content policies”). The other
page ||| 1105
note ||| CHI 2008 Proceedings · Shared Authoring	April 5-10, 2008 · Florence, Italy
listItem ||| policy that turns to this type of language is the Copyrights
listItem ||| policy.
listItem ||| •	It uses very insistent language (“Editors must take
listItem ||| particular care...”, “...must adhere strictly to...”
listItem ||| (emphasis in original), or “We must get the article right”
listItem ||| (emphasis in original)).
listItem ||| •	In internal discussions, explanations for the policy and
listItem ||| changes to the policy are described in the third person
listItem ||| (they, them, he, her) not first person (we, us, I, me).
listItem ||| •	External attention triggers changes to the policy and
listItem ||| concerns of the external stakeholders are one of the
listItem ||| factors referenced in discussions of the policy, such as a
listItem ||| comment on the Biographies of living person page
listItem ||| stating, “I started this due to the Daniel Brandt situation.”
listItem ||| •	The policy is referenced in statements to external
listItem ||| stakeholders and media.
bodyText ||| While the Biography of living persons policy is an extreme
bodyText ||| case, which came about because of a very high level of
bodyText ||| external attention to a particular aspect of Wikipedia, other
bodyText ||| examples do exist, such as the sock-puppeting of external
bodyText ||| organizations that edit the content of the entries on them or
bodyText ||| the revelations that editors were not as qualified as they
bodyText ||| claimed.
subsectionHeader ||| Implications for External Signals
bodyText ||| External signals serve the role of demonstrating that the
bodyText ||| wiki and its members recognize an issue as important or
bodyText ||| significant. However, doing this too often can weaken the
bodyText ||| impact or message that an external signal sends to the
bodyText ||| external audience. It is important to note that rules which
bodyText ||| act as external signals speak to external audiences and are
bodyText ||| not necessarily meant for internal audiences, or members.
bodyText ||| Theoretically, a rule which serves only as an external signal
bodyText ||| could be removes and not change the internal dynamic of
bodyText ||| the community.
subsectionHeader ||| Rules and Policies as Internal Signals
bodyText ||| Policies and rules can be used to signal to the community
bodyText ||| what the community finds important, such as creating a
bodyText ||| policy about a particular issue or behavior which is
bodyText ||| significant to the community.
subsubsectionHeader ||| Internal Signals in Wikipedia
bodyText ||| An example of a policy developed as an internal signal is
bodyText ||| the Civility policy. Its function is to promote polite
bodyText ||| interactions between members of the community, rather
bodyText ||| than to recognize or call significance to an issue for an
bodyText ||| external audience. Perhaps as a result of its role, this
bodyText ||| policy’s current form differs from its original form the least
bodyText ||| of all the policies and generates the fewest discussions or
bodyText ||| dissensions. Policies fitting into this category are not
bodyText ||| threatened by outside forces, so their language can remain
bodyText ||| less formal in contrast to rules acting as external signals. As
bodyText ||| such, they also will not serve as the foci of editorial
bodyText ||| pressures faced by those responding to external signals.
bodyText ||| This policy also acts as an internal signal via its prominent
bodyText ||| placement on the list of policies for first-time users [48].
subsubsectionHeader ||| Implications for Internal Signals
bodyText ||| Internal signals demonstrate values and identity to internal
bodyText ||| stakeholders. It is significant to note that while internal
bodyText ||| signals speak to the internal stakeholders, they can be
bodyText ||| triggered by either internal members (e.g. via complaints or
bodyText ||| problematic events) or external viewers.
subsectionHeader ||| Rules and Policies as Negotiated Settlements and
subsectionHeader ||| Trophies
bodyText ||| People have different interests or perspectives. Rules and
bodyText ||| policies are negotiated settlements or trophies. Settlements
bodyText ||| are creating to avoid the cost of continued conflict, while
bodyText ||| trophies are created to give credibility and influence to the
bodyText ||| “winner” in future discussions.
subsubsectionHeader ||| Negotiated Settlements and Trophies in Wikipedia
bodyText ||| In Wikipedia, references to “that has already been decided”
bodyText ||| or references to policy changes as having been determined
bodyText ||| in one side’s favor or another reflect this perspective. An
bodyText ||| example of this “trophy” type situation occurs in the
bodyText ||| Consensus policy. As mentioned previously, extensive
figureCaption ||| Figure 3. Wikipedia consensus flowchart
page ||| 1106
note ||| CHI 2008 Proceedings · Shared Authoring	April 5-10, 2008 · Florence, Italy
bodyText ||| discussion surrounds the development of written guidelines
bodyText ||| to assist smooth negotiations and to achieve acceptable
bodyText ||| compromises. For the Consensus policy, this type of
bodyText ||| discussion focuses on whether to use specific numbers for
bodyText ||| confirmation of consensus or not. That is, should the group
bodyText ||| need 80% or 75% of the population’s approval? Or should
bodyText ||| the policy simply state that general agreement is all that is
bodyText ||| required for consensus? An active member wants polling
bodyText ||| results to determine consensus, but he “loses” this effort in
bodyText ||| 2005; consensus is explained through the organizational
bodyText ||| structure of the flowchart in Figure 3. In July 2007,
bodyText ||| someone starts adding the numbers requirement back into
bodyText ||| the Consensus policy, and the administrators talk about it
bodyText ||| and remove it each time. In August, there is more
bodyText ||| discussion of consensus versus the supermajority, and then
bodyText ||| it appears that it might be the original participant who lost
bodyText ||| the battle who is adding the numbers back to the policy, and
bodyText ||| even if it is not, he is actively participating in discussions to
bodyText ||| bring back the “numbers” [49].
bodyText ||| As an example of the discussion leading away from
bodyText ||| decisions through polling, one administrator says, “for all
bodyText ||| but uncontroversial trivial propositions, it is unusual for
bodyText ||| decisions on Wikipedia talk pages to operate on a true
bodyText ||| consensus. Instead they operate on a rough consensus
bodyText ||| where it is recognised that a minority are in opposition. The
bodyText ||| question then arises is how large must the majority be to
bodyText ||| ignore the opinions of a minority?” [49].
bodyText ||| When the policy is revised to respect the majority of
bodyText ||| decision makers, the discussion is titled, “The numbers
bodyText ||| came back again.” The first comment reads, “So I removed
bodyText ||| them.” The response to it, by the “losing” contestant says,
bodyText ||| “Did you not read the section above? There is not
bodyText ||| consensus to remove them,” in an assertion that previous
bodyText ||| decisions support this, but the response to this remark is: “I
bodyText ||| have read the section above. There is clearly no consensus
bodyText ||| to include them. Stop adding them,” reinforcing the
bodyText ||| community’s adherence to “rough consensus” as opposed to
bodyText ||| numerically-based decision-making.
subsubsectionHeader ||| Implications for Negotiated Settlements and Trophies
bodyText ||| Policies, therefore, reflect a continuous process of battles
bodyText ||| engaged in and won or lost, so that no conclusion is
bodyText ||| achieved. Much discussion of these policies includes a
bodyText ||| continuous recycling of old fights and unresolved
bodyText ||| contentions.
subsectionHeader ||| Rules and Policies as Control Mechanisms
bodyText ||| To complete tasks and meet goals, rules and policies are
bodyText ||| often written to act as control mechanisms. Control is
bodyText ||| defined as any effort made to ensure appropriate action
bodyText ||| [31]. In the systems development literature, control has
bodyText ||| been defined more specifically from the behavioral sense as
bodyText ||| attempts to ensure that individuals on a project team act in
bodyText ||| accordance with a previously agreed-upon strategy to
bodyText ||| accomplish desired goals and objectives [21]. Control
bodyText ||| mechanisms are “devices used by controllers to ensure
bodyText ||| proper controllee behavior” [20]. Both formal and informal
bodyText ||| control modes rely on control mechanisms to influence
bodyText ||| behavior, but formal modes control via performance
bodyText ||| evaluation and rewards while informal modes control via
bodyText ||| socialization to reduce goal differences [20]. Wikis draw
bodyText ||| upon informal modes of control by writing policies which
bodyText ||| describe ideal work output or behavior.
bodyText ||| Explicitly highlighting this role of rules and policies also
bodyText ||| allows for consideration of ways that rules are used to
bodyText ||| manage divergence of individual and organizational goals, a
bodyText ||| phenomenon that is an important element of organizational
bodyText ||| evolution.
subsubsectionHeader ||| Control Mechanisms in Wikipedia
bodyText ||| Wikipedia’s hierarchy of roles creates a class of people who
bodyText ||| apply the control mechanisms for the group: the
bodyText ||| administrators. Though, it is sometimes claimed that this
bodyText ||| hierarchy does not exist. Administrators are the only ones
bodyText ||| who can, as the Wikipedia site suggests, “protect and delete
bodyText ||| pages, block other editors, and undo these actions as well.”
bodyText ||| Also, in its categories of policies, Wikipedia devotes an
bodyText ||| entire section to what it calls, “enforcement,” a term for
bodyText ||| controlling the behavior of others. Two in this section that
bodyText ||| require administrator participation are Deletion and
bodyText ||| Blocking. Since control mechanisms ensure consistency
bodyText ||| between the goals and actions of the individual and those of
bodyText ||| the community, and since the goals of individuals are
bodyText ||| sometimes destructive, such as vandalism, a policy like
bodyText ||| Blocking prevents chronic disrupters from damaging the
bodyText ||| group or its efforts. Blocking is the term for the prevention
bodyText ||| of editing rights for those participants who refuse to support
bodyText ||| the goals of the organization. An interesting feature of the
bodyText ||| Blocking policy ameliorates its punitive approach: it is not
bodyText ||| meant for “retaliation,” but instead for “encouraging”
bodyText ||| appropriate behavior. A control mechanism of this sort,
bodyText ||| therefore, guides normative behavior rather than punishes
bodyText ||| deviance.
bodyText ||| The Three-Revert Rule (called a “rule” but considered a
bodyText ||| “policy” by Wikipedia) is a community-specific control
bodyText ||| mechanism. It states that an editor may not make more than
bodyText ||| three changes to an encyclopedia page within a twenty-four
bodyText ||| hour period. The stated purpose for this policy is to prevent
bodyText ||| what the group calls “edit wars," or conflicts between two
bodyText ||| or more editors over an entry that result in the constant
bodyText ||| effort to assert the validity of one version of it over another.
bodyText ||| Administrators established this rule because, as Wikipedia
bodyText ||| founder Jimbo Wales says, “revert warring has become an
bodyText ||| absurd drain on us.” This control mechanism, therefore,
bodyText ||| protects the administrators from overload created by editors
bodyText ||| who refuse to negotiate about the contents of an entry.
subsubsectionHeader ||| Implications for Control Mechanisms
bodyText ||| Where coordination assumes that all participants in a
bodyText ||| community have the same motives and merely need to
bodyText ||| understand how to get something done in terms of sequence
bodyText ||| or procedure, control suggests to the community what not to
bodyText ||| do and establishes rules of prevention of behaviors that will
bodyText ||| disrupt the process of the organization. These mechanisms
page ||| 1107
note ||| CHI 2008 Proceedings · Shared Authoring	April 5-10, 2008 · Florence, Italy
bodyText ||| are exceptional, for they can largely be applied only by
bodyText ||| administrators, by those with power acceded to them by the
bodyText ||| group through their demonstrated degree of participation in
bodyText ||| editing and through the acknowledgement of those efforts
bodyText ||| by the other power holders and wielders in the system.
sectionHeader ||| IMPLICATIONS FOR CREATION OF WIKI-BASED
sectionHeader ||| SYSTEMS AND DESIGN OF PLATFORMS
bodyText ||| We suggest, therefore, that pursuing the “policyless” ideal
bodyText ||| that wikis represent is a pipedream. Policy creation and
bodyText ||| maintenance is an important aspect of the work that must be
bodyText ||| done to keep the community running
bodyText ||| Providing tools and infrastructure mechanisms that support
bodyText ||| the development and management of policies is an
bodyText ||| important part of creating social computing systems that
bodyText ||| work. For example, work has been done on policy
bodyText ||| extraction that focuses on identifying rules which can be
bodyText ||| embedded in the infrastructure to support coordination and
bodyText ||| organization. This study suggests that policies vary in their
bodyText ||| intention to support coordination and organization, thus the
bodyText ||| application of the work on policy extraction is narrowed.
bodyText ||| For example, a rule acting as an external signal has less
bodyText ||| intention for coordination and organization. As a result, it
bodyText ||| may not be appropriate for it to be embedded in the
bodyText ||| infrastructure to support coordination and organization.
bodyText ||| Looking at the language used in writing the policy may
bodyText ||| signal its intention to support coordination and organization
bodyText ||| and, subsequently, whether it is a candidate for embedding
bodyText ||| in the infrastructure. More detailed systematic studies can
bodyText ||| provide insight into a policies candidacy for embedding in
bodyText ||| the infrastructure.
bodyText ||| While there is something to be said about treating policies
bodyText ||| as coordination mechanisms that are automated or at least
bodyText ||| embedded directly in the technology, that approach is not
bodyText ||| without its pitfalls. Since policies can also be highly
bodyText ||| symbolic or meaning-filled, embedding them or automating
bodyText ||| them may not work because it could remove this function or
bodyText ||| make it less effective for this purpose. Furthermore, it may
bodyText ||| be possible that different rules playing different roles have
bodyText ||| varying importance for the success of the wiki at specific
bodyText ||| phases in the wiki lifecycle.
bodyText ||| This work raises important questions for organizations
bodyText ||| implementing wikis and collaborative technologies for
bodyText ||| internal use. When organizations invest in these
bodyText ||| technologies, such as Lotus Notes and Microsoft
bodyText ||| Sharepoint, their first step is often to put in place a
bodyText ||| collection of policies and guidelines regarding their use.
bodyText ||| However, less attention is given to the policies and
bodyText ||| guidelines created by the groups that use these systems –
bodyText ||| which are often left to “emerge” spontaneously. The
bodyText ||| examples and concepts described in this paper highlight the
bodyText ||| complexity of rule formation and suggest that support
bodyText ||| should be provided to help collaborating groups create and
bodyText ||| maintain effective rulespaces.
bodyText ||| Lastly, the Wikipedia archives suggest that facilitating,
bodyText ||| supporting, and managing this system of rules may not be
bodyText ||| simply a matter of data collection. Rather, serving this
bodyText ||| system well is a matter of promoting situational awareness
bodyText ||| and strategic intervention in a complex, evolving system.
sectionHeader ||| CONCLUSIONS
bodyText ||| Wikis have captured the imagination of many because as a
bodyText ||| technology they support unencumbered, highly flexible,
bodyText ||| very visible, and accessible collaboration [5, 11, 22, 42, 52,
bodyText ||| 53]. These features have led many commentators and
bodyText ||| authors to wax eloquently about the possibility of new types
bodyText ||| of work and organization which are peer-based, non-
bodyText ||| hierarchical, non-bureaucratic, emergent, complex, and
bodyText ||| communal.
bodyText ||| While it may be the case that wikis do in fact provide a
bodyText ||| basis for this type of work arrangement, the study reported
bodyText ||| here suggests that the true power of wikis lies in the fact
bodyText ||| that they are a platform that provides affordances which
bodyText ||| allow for a wide variety of rich, multifaceted organizational
bodyText ||| structures. Rather than assuming that rules, policies, and
bodyText ||| guidelines are operating in only one fashion, wikis allow
bodyText ||| for, and in fact facilitate, the creation of policies and
bodyText ||| procedures that serve a wide variety of functions – and as a
bodyText ||| result they are capable of truly supporting a much broader
bodyText ||| range of structures and activities than many of the other
bodyText ||| more structured, collaborative platforms.
bodyText ||| This suggests that not only are wikis a platform that has
bodyText ||| greater potential in organizational and public use, but also
bodyText ||| that, from a design perspective, they provide a valuable
bodyText ||| opportunity for using the “sidewalk design strategy” of
bodyText ||| providing a field of grass and watching where and how the
bodyText ||| users walk, or so-called desire paths. This study provides a
bodyText ||| basis for describing these paths. Future studies in particular
bodyText ||| applications would do well to ask how these issues are
bodyText ||| addressed, capabilities are used, and how the activities and
bodyText ||| mechanisms that come into play can be helpfully reinforced
bodyText ||| or supported through the interface and infrastructure.
sectionHeader ||| ACKNOWLEDGEMENTS
bodyText ||| The authors would like to thank the members of the Online
bodyText ||| Community Research Group at Carnegie Mellon University
bodyText ||| and especially Bob Kraut and John Levine.
sectionHeader ||| REFERENCES
reference ||| 1. Ahuja, M.K. and K.M. Carley, Network structure in
reference ||| virtual organizations. Organization Science, 1999.
reference ||| 10(6): p. 741-757.
reference ||| 2. Barreto, M. and N. Ellemers, The impact of anonymity
reference ||| and group identification on progroup behavior in
reference ||| computer-mediated groups. Small Group Research,
reference ||| 2002. 33(5): p. 590-610.
reference ||| 3. Baym, N., Interpreting soap operas and creating
reference ||| community: Inside a computer-mediate fan culture.
reference ||| Journal of Folklore Research, 1993. 30: p. 143-176.
reference ||| 4. Baym, N.K., Tune in, log on: Soaps, fandom, and
reference ||| online community. 2000, Thousand Oaks, CA: Sage
reference ||| Publications.
reference ||| 5. Bryant, S.L., A. Forte, and A. Bruckman, Becoming
reference ||| wikipedia: Transformation of participation in a
page ||| 1108
note ||| CHI 2008 Proceedings · Shared Authoring	April 5-10, 2008 · Florence, Italy
reference ||| collaborative online encyclopedia, in GROUP. 2005:
reference ||| Sanibel Island, FL.
reference ||| 6. Burnett, G. and L. Bonnici, Beyond the faq: Explicit
reference ||| and implicit norms in usenet newsgroups. Library &
reference ||| Information Science Research, 2003. 25(3): p. 333.
reference ||| 7. Chidambaram, L. and L.L. Tung, Is out of sight, out of
reference ||| mind? An empirical study of social loafing in
reference ||| technology-supported groups. Information Systems
reference ||| Research, 2005. 16(2): p. 149-168.
reference ||| 8. Cohen, N., Defending wikipedia's impolite side, in The
reference ||| New York TImes. 2007, The New York Times
reference ||| Company: New York, NY.
reference ||| 9. Connelly, T. and B.K. Thorn, Discretionary databases:
reference ||| Theory, data, and implications, in Organizations and
reference ||| communication technology, J. Fulk and C. Steinfield,
reference ||| Editors. 1990, Sage Publications: Newbury Park, CA.
reference ||| p. 219-233.
reference ||| 10. Fogel, K., Producing open source software: How to
reference ||| run a successful free software project 2005,
reference ||| Sebastopol, CA O'Reilly Media, Inc.
reference ||| 11. Forte, A. and A. Bruckman, Why do people write for
reference ||| wikipedia? Incentives to contribute to open-content
reference ||| publishing, in Group 2005 Workshop - Sustaining
reference ||| Community: The role and design of incentive
reference ||| mechanisms in online systems. 2005: Sanibel Island,
reference ||| FL.
reference ||| 12. Galegher, J., L. Sproull, and S. Kiesler, Legitimacy,
reference ||| authority, and community in electronic support groups.
reference ||| Written Communication, 1998. 15(4): p. 493-530.
reference ||| 13. Hinds, P.J. and D.E. Bailey, Out of sight, out of sync:
reference ||| Understanding conflict in distributed teams.
reference ||| Organization Science, 2003. 14(6): p. 515-632.
reference ||| 14. Hinds, P.J. and M. Mortensen, Understanding conflict
reference ||| in geographically distributed teams: The moderating
reference ||| effects of shared identity, shared context, and
reference ||| spontaneous communication. Organization Science,
reference ||| 2005. 16(3): p. 290-307.
reference ||| 15. Jensen, C. and W. Scacchi. Collaboration, leadership,
reference ||| control, and conflict negotiation in the netbeans.Org
reference ||| software development community. in Proceedings of
reference ||| the 38th Hawaii International Conference on System
reference ||| Sciences. 2005. Waikola Village, HI.
reference ||| 16. Jensen, C. and W. Scacchi. Role migration and
reference ||| advancement processes in ossd projects: A
reference ||| comparative case study. in Proceedings of the 27th
reference ||| International Conference on Software Engineerring.
reference ||| 2007. Minneapolis, MN.
reference ||| 17. Jones, Q., G. Ravid, and S. Rafaeli, Information
reference ||| overload and the message dynamics of online
reference ||| interaction spaces: A theoretical model and empirical
reference ||| exploration. Information Systems Research, 2004.
reference ||| 15(2): p. 194-210.
reference ||| 18. Kennedy, H., Beyond anonymity, or future directions
reference ||| for internet identity research. New Media & Society,
reference ||| 2006. 8(6): p. 859-876.
reference ||| 19. Kim, A.J., Community building on the web: Secret
reference ||| strategies for successful online communities. 1 ed.
reference ||| 2000, Berkeley, CA Peachpit Press.
reference ||| 20. Kirsch, L.J., Portfolios of control modes and is project
reference ||| management. Information Systems Research, 1997.
reference ||| 8(3): p. 215-239.
reference ||| 21. Kirsch, L.J., et al., Controlling information systems
reference ||| development projects: The view from the client.
reference ||| Management Science, 2002. 48(4): p. 484-498.
reference ||| 22. Kittur, A., et al., Power of the few vs. Wisdom of the
reference ||| crowd: Wikipedia and the rise of the bourgeoisie, in
reference ||| Conference on Human Factors in Computing Systems
reference ||| (CHI). 2007: San Jose, CA.
reference ||| 23. Kittur, A., et al., He says, she says: Conflict and
reference ||| coordination in wikipedia, in Conference on Human
reference ||| Factors in Computing Systems (CHI). 2007: San Jose,
reference ||| CA.
reference ||| 24. Kollock, P. and M. Smith, Managing the virtual
reference ||| commons: Cooperation and conflict in computer
reference ||| communities, in Computer-mediated communication:
reference ||| Linguistic, social and cross-cultural perspectives, S.
reference ||| Herring, Editor. 1996, John Benjamins: Amsterdam. p.
reference ||| 109-128.
reference ||| 25. Kuechler, W.L. and C. Vaishnavi, So, talk to me: The
reference ||| effect of explicit goals on the comprehension of
reference ||| business process narratives. MIS Quarterly, 2006.
reference ||| 30(4): p. 961-A16.
reference ||| 26. Lakhani, K.R. and E. von Hippel, How open source
reference ||| software works: "Free" User-to-user assistance.
reference ||| Research Policy, 2003. 32(6): p. 923-943.
reference ||| 27. Malone, T., W. and K. Crowston, The interdisciplinary
reference ||| study of coordination. ACM Computing Surveys, 1994.
reference ||| 26(1): p. 87-119.
reference ||| 28. Maney, K., Mass collaboration could change way
reference ||| companies operate, in USA Today. 2006.
reference ||| 29. March, J.G., M. Schulz, and X. Zhou, The dynamics of
reference ||| rules: Change in written organizational codes. 2000,
reference ||| Stanford, CA: Stanford University Press.
reference ||| 30. McKenna, K.Y.A. and J.A. Bargh, Coming out in the
reference ||| age of the internet: Identity "Demarginalization"
reference ||| Through virtual group participation. Journal of
reference ||| Personality & Social Psychology. 75(3): p. 681.
reference ||| 31. Nidumolu, S.R. and M.R. Subramani, The matrix of
reference ||| control: Combining process and structure approaches
reference ||| to managing software development. Journal of
reference ||| Management Information Systems, 2003. 20(Issue 3):
reference ||| p. 159.
reference ||| 32. Ostrom, E., Collective action and the evolution of
reference ||| social norms. Journal of Economic Perspectives, 2000.
reference ||| 14(3): p. 137-158.
reference ||| 33. Petronio, S., The boundaries of privacy: Praxis of
reference ||| everyday life, in Balancing the secrets of private
reference ||| disclosures, S. Petronio, Editor. 2000, Lawrence
reference ||| Erlbaum Associates: Mahwah, N. J. p. 37-50.
reference ||| 34. Petronio, S., et al., (mis)communicating across
reference ||| boundaries. Communication Research, 1998: p. 571-
reference ||| 595.
page ||| 1109
note ||| CHI 2008 Proceedings · Shared Authoring	April 5-10, 2008 · Florence, Italy
reference ||| 35. Raymond, E., The cathedral and the bazaar.
reference ||| Knowledge and Policy, 1999. 12(3).
reference ||| 36. Ren, Y., R.E. Kraut, and S. Kiesler, Applying common
reference ||| identity and bond theory to the design of online
reference ||| communities. In press, 2006.
reference ||| 37. Riva, G. and C. Galimberti, Computer-mediated
reference ||| communication: Identity and social interaction in an
reference ||| electronic environment. Genetic, Social & General
reference ||| Psychology Monographs, 1998. 124(4): p. 434-463.
reference ||| 38. Roberts, J.A., I.-H. Hann, and S.A. Slaughter,
reference ||| Understanding the motivations, participation, and
reference ||| performance of open source software developers: A
reference ||| longitudinal study of the apache projects. Management
reference ||| Science, 2006. 52(7): p. 984-999.
reference ||| 39. Simon, H., Bounded rationality and organizational
reference ||| learning. Organization Science, 1991. 2(1): p. 125-134.
reference ||| 40. Slaughter, S.A. and L.J. Kirsch, The effectiveness of
reference ||| knowledge transfer portfolios on software process
reference ||| improvement: A field study. Information Systems
reference ||| Research, 2006. 17(3): p. 301-320.
reference ||| 41. Stewart, K.J. and S. Gosain, The impact of ideology on
reference ||| effectiveness in open source software development
reference ||| teams. MIS Quarterly, 2006. 30(2): p. 291-314.
reference ||| 42. Viegas, F., M. Wattenberg, and K. Dave, Studying
reference ||| cooperation and conflict between authors with history
reference ||| flow visualizations, in Conference on Human Factors
reference ||| in Computing Systems (CHI). 2004: Vienna, Austria.
reference ||| 43. Viegas, F.B., et al. Talk before you type: Coordination
reference ||| in wikipedia. in Proceedings of the 40th Hawaii
reference ||| International Conference on System Sciences. 2007.
reference ||| Big Island, HI.
reference ||| 44. von Krogh, G., S. Spaeth, and K.R. Lakhani,
reference ||| Community, joining, and specialization in open source
reference ||| software innovation: A case study. Research Policy,
reference ||| 2003. 32(7): p. 1217-1241.
reference ||| 45. Wikipedia contributors, Ignore all rules. 2006,
reference ||| Wikipedia, The Free Encyclopedia.
reference ||| 46. Wikipedia contributors, Wikipedia talk:Biographies of
reference ||| living persons 2007, Wikipedia, The Free
reference ||| Encyclopedia.
reference ||| 47. Wikipedia contributors, Wikipedia talk: Copyrights
reference ||| 2007, Wikipedia, The Free Encyclopedia.
reference ||| 48. Wikipedia contributors, Wikipedia: Policies and
reference ||| guidelines. 2007, Wikipedia, The Free Encyclopedia.
reference ||| 49. Wikipedia contributors, Wikipedia: Consensus. 2007,
reference ||| Wikipedia, The Free Encyclopedia.
reference ||| 50. Wikipedia contributors, Wikipedia: Criteria for speedy
reference ||| deletion. 2007, Wikipedia, The Free Encyclopedia.
reference ||| 51. Wikipedia contributors, Wikipedia:Neutral point of
reference ||| view. 2007, Wikipedia, The Free Encyclopedia.
reference ||| 52. Zhang, X.M. and F. Zhu, Intrinsic motivation of open
reference ||| content contributors: The case of wikipedia, in
reference ||| Workshop on Information Systems and Economics.
reference ||| 2006: Evanston, IL.
reference ||| 53. Zlatić, V., et al., Wikipedias: Collaborative web-based
reference ||| encyclopedias as complex networks. Physical Review,
reference ||| 2006. 74(016115).
page ||| 1110

note ||| CHI 2008 Proceedings · Shared Authoring	April 5-10, 2008 · Florence, Italy
title ||| Exploring the Role of the Reader in the Activity of
title ||| Blogging
author ||| Eric Baumer	Mark Sueyoshi	Bill Tomlinson
affiliation ||| Department of Informatics	Int’l Studies / East Asian Cultures	Department of Informatics
affiliation ||| U of California, Irvine, USA	U of California, Irvine, USA	U of California, Irvine, USA
email ||| ebaumer@ics.uci.edu	msueyosh@uci.edu	wmt@uci.edu
sectionHeader ||| ABSTRACT
bodyText ||| Within the last decade, blogs have become an important
bodyText ||| element of popular culture, mass media, and the daily lives
bodyText ||| of countless Internet users. Despite the medium’s
bodyText ||| interactive nature, most research on blogs focuses on either
bodyText ||| the blog itself or the blogger, rarely if at all focusing on the
bodyText ||| reader’s impact. In order to gain a better understanding of
bodyText ||| the social practice of blogging, we must take into account
bodyText ||| the role, contributions, and significance of the reader. This
bodyText ||| paper presents the findings of a qualitative study of blog
bodyText ||| readers, including common blog reading practices, some of
bodyText ||| the dimensions along which reading practices vary,
bodyText ||| relationships between identity presentation and perception,
bodyText ||| the interpretation of temporality, and the ways in which
bodyText ||| readers feel that they are a part of the blogs they read. It
bodyText ||| also describes similarities to, and discrepancies with,
bodyText ||| previous work, and suggests a number of directions and
bodyText ||| implications for future work on blogging.
sectionHeader ||| Author Keywords
keyword ||| Blogging, blog readers.
sectionHeader ||| ACM Classification Keywords
category ||| H.5.m. Information interfaces and presentation (e.g., HCI):
category ||| Miscellaneous; K.4.m. Computers and Society:
category ||| Miscellaneous.
sectionHeader ||| INTRODUCTION
bodyText ||| By most indications, blogs are proliferating at an ever-
bodyText ||| increasing rate. Although specific figures vary among
bodyText ||| different sources [16,25] there is consensus that blogs have
bodyText ||| become an important, active, and influential part of online
bodyText ||| media. Research on blogging, e.g., [11,15,21], has revealed
bodyText ||| important insights about the activity of blogging, the
bodyText ||| attitudes of bloggers, and the practices surrounding blogs.
bodyText ||| However, blogging is not a solo activity. While work has
bodyText ||| been done in areas such as analyzing conversations between
copyright ||| Permission to make digital or hard copies of all or part of this work for
copyright ||| personal or classroom use is granted without fee provided that copies are
copyright ||| not made or distributed for profit or commercial advantage and that copies
copyright ||| bear this notice and the full citation on the first page. To copy otherwise,
copyright ||| or republish, to post on servers or to redistribute to lists, requires prior
copyright ||| specific permission and/or a fee.
note ||| CHI 2008, April 5–10, 2008, Florence, Italy.
copyright ||| Copyright 2008 ACM 978-1-60558-011-1/08/04...$5.00.
bodyText ||| blogs, e.g., [7,10], and applying social network analysis to
bodyText ||| blogs, e.g., [8,19], little work has been done examining the
bodyText ||| role of the reader in the blogging process. This gap is
bodyText ||| surprising, considering Nardi et al.’s prediction that “future
bodyText ||| research is sure to pay attention to blog readers” [21:231].
bodyText ||| Furthermore, according to Lenhart and Fox [16], as of July
bodyText ||| 2006, 57 million American adults read blogs, over a third of
bodyText ||| the 147 million who use the Internet. Sifry [25] puts the
bodyText ||| number of unique Technorati visitors at over 9 million in
bodyText ||| March 2007, up by over 50% from February 2007. Clearly,
bodyText ||| not only is the number of blogs increasing, but also the
bodyText ||| number of blog readers. The role of this ever increasing
bodyText ||| population of blog readers presents a promising and
bodyText ||| important, yet little-explored, area of research.
bodyText ||| This paper is not the first call for a focus on readers. In the
bodyText ||| 1960’s and 1970’s, a shift occurred in literary theory from
bodyText ||| focusing primarily on the literary object itself to including
bodyText ||| the reader’s response to the literature. Reader-response
bodyText ||| theory, or reader-response criticism, cf. [3,17], focuses not
bodyText ||| on the literature itself but rather on the audience’s response
bodyText ||| to, and interpretation of, the text. The reader is not a passive
bodyText ||| recipient of content, this critique argues, but rather engages
bodyText ||| in an active process of interpretation. Reality and meaning
bodyText ||| exist neither solely in the text nor solely in the reader, but
bodyText ||| are constructed through the dialectic interactions between
bodyText ||| the two. Similarly, the reality and meaning of a blog exists
bodyText ||| neither solely in the blog itself nor solely in the reader, but
bodyText ||| rather in the reader’s active interpretation of, and
bodyText ||| interaction with, the blog. Furthermore, technologies and
bodyText ||| practices such as commenting, linking, tagging, and
bodyText ||| trackbacks enable a level of explicit interaction with both
bodyText ||| the text and the author not available in previous textual
bodyText ||| media. This paper argues for a shift in the study of blogging
bodyText ||| similar to that in literary criticism represented by reader-
bodyText ||| response theory. This shift to emphasize the interactional
bodyText ||| aspects of blogging also fits into a larger trend in HCI
bodyText ||| research of moving from the user as information processor,
bodyText ||| to human actor, to embodied experiencer [5]. In order to
bodyText ||| understand the myriad contexts in which human-computer
bodyText ||| interaction takes place, researchers have adopted different
bodyText ||| stances toward users and taken different perspectives on
bodyText ||| HCI systems. Similarly, in order to understand fully the
bodyText ||| activity of blogging, we must study not only bloggers and
bodyText ||| the blogs they produce, but also the readers of those blogs
bodyText ||| and their interactions with the blog and the blogger.
page ||| 1111
note ||| CHI 2008 Proceedings · Shared Authoring	April 5-10, 2008 · Florence, Italy
bodyText ||| This paper reports on the results of a qualitative study into
bodyText ||| the practices and culture of blog readers. How do readers
bodyText ||| contribute to and help shape the various blogs they read?
bodyText ||| When, why, and how do readers choose to comment? How
bodyText ||| do readers perceive the identity of the blogger? Do readers
bodyText ||| feel overwhelmed by the amount of information available
bodyText ||| through blogs? What habits do readers follow? While this
bodyText ||| paper cannot address these questions in their entirety, it is a
bodyText ||| first step toward understanding the role, contributions, and
bodyText ||| significance of the reader in the activity of blogging.
sectionHeader ||| RELATED WORK
bodyText ||| Recent work on blogging covers a wide range of topics (see
bodyText ||| [24] for an overview). This section highlights work that
bodyText ||| helps inform this study. Nardi [21] examined the social
bodyText ||| nature of blogging activity, illustrating that blogs are quite
bodyText ||| unlike a personal diary. Lenhart’s [15] work pointed to the
bodyText ||| slow development of norms given the decentralized and
bodyText ||| non-standardized activities that occur on and off blogs.
bodyText ||| Herring et al. [11] provide a genre analysis of weblogs.
bodyText ||| Within the emerging medium of blogs, boyd [1] addressed
bodyText ||| the need for self-awareness tools to manage the fluidity of
bodyText ||| identity presentation in blogs. Some have applied existing
bodyText ||| analytic tools, such as social network analysis, e.g., [8, 19],
bodyText ||| to show that blogs are not highly interconnected in a
bodyText ||| decentralized fashion, but rather grouped in numerous
bodyText ||| clusters of blogs with limited links between clusters.
bodyText ||| Studies using conversation analysis have suggested that
bodyText ||| conversations across blogs and amongst bloggers are
bodyText ||| limited to a small number of “A-list” blogs [10].
bodyText ||| Here, our focus is the audience. In Lenhart’s examination of
bodyText ||| norm formation in blogging [15], she discusses the
bodyText ||| anonymity of the blog audience and their occasional
bodyText ||| terrifying effect on bloggers. Similarly, Reed [23] illustrates
bodyText ||| blogger self-censorship due to an audience made up of
bodyText ||| certain friends and family. boyd [2] describes the
bodyText ||| expectations that bloggers feel are placed on them by their
bodyText ||| audience and how bloggers negotiate the formation and
bodyText ||| fulfillment of these expectations. Nardi suggests that
bodyText ||| “readers create blogs as much as writers” [21:225], giving
bodyText ||| them an equal role in the activity of blogging. Despite
bodyText ||| acknowledging the presence and impact of an audience, no
bodyText ||| previous blogging research has made blog readers the
bodyText ||| primary focus. This paper aims to fill that gap.
bodyText ||| The position of the blog reader is often an ambiguous one.
bodyText ||| Most research on blogs adopts the view that readers,
bodyText ||| commenters, and participants are also bloggers themselves,
bodyText ||| e.g., [8]. However, according to the statistics cited above,
bodyText ||| there is obviously a large discrepancy between bloggers and
bodyText ||| people who read blogs – not every reader is a blogger. The
bodyText ||| question becomes, when does one move from being a blog
bodyText ||| reader to a blogger? Is simply owning a blog enough, or
bodyText ||| must there be regular updates? What is the requisite update
bodyText ||| frequency? Despite indications to the contrary, are there
bodyText ||| any bloggers who do not read other blogs? It is be argued
bodyText ||| below that, rather than attempting to split individuals into
bodyText ||| either the category of blogger or the category of reader, it
bodyText ||| might be more useful to consider the question in terms of
bodyText ||| degree of membership, where an individual may be both a
bodyText ||| blogger and a reader to varying and independent degrees.
bodyText ||| For the purposes of this study, we focus on those who have
bodyText ||| a high enough degree of readership to self-identify as a blog
bodyText ||| reader, regardless of their degree of bloggership.
sectionHeader ||| THEORY
bodyText ||| In examining the activities that surround blog reading, this
bodyText ||| study is partially informed by ideas from reader-response
bodyText ||| theory [3,17], which help provide a general framework with
bodyText ||| which to analyze the act of reading blogs. This section
bodyText ||| provides a brief introduction to reader-response theory,
bodyText ||| situating it in the context of literary criticism, and describes
bodyText ||| how the theory is applied in this paper.
bodyText ||| Despite the general inclination to situate reader-response
bodyText ||| theory in opposition to formalism, which posits that only
bodyText ||| the materiality of the text is significant, it actually
bodyText ||| developed from within formalism itself (Tompkins, cited in
bodyText ||| [3]). In the 1950’s, reader-response theory branched out
bodyText ||| from formalist discourse under the auspices of Gibson’s
bodyText ||| “mock reader” – the persona a reader should adopt to
bodyText ||| understand the text [3]. Thus a slight variation within
bodyText ||| formalism became the seed from which the reader and her
bodyText ||| or his interpretation gained significance.
bodyText ||| Later reader-response theorists, such as Crosman [3],
bodyText ||| argued specifically that the “construction of meaning
bodyText ||| ultimately resides in the auspices of readers, who approach
bodyText ||| literary texts... from their own subjective perspectives”
bodyText ||| [3:66]. This view is reminiscent of Nardi et al.’s [21]
bodyText ||| assertion that the reader and writer both participate in co-
bodyText ||| creating the blog, as well as Dourish’s [5] emphasis on
bodyText ||| viewing the user as a situated, embodied actor that actively
bodyText ||| engages with a system in context. As an extension of
bodyText ||| Crosman’s approach, Lewis [17] presents an alternate
bodyText ||| method of performing a literary critique. He suggests rather
bodyText ||| than judging books as good or bad and making assertions
bodyText ||| about someone’s tastes based on the books he or she reads,
bodyText ||| “let us try to discover how far it might be plausible to
bodyText ||| define a good book as a book which is read in one way, and
bodyText ||| a bad book as a book which is read in another way” [16:1].
bodyText ||| He argues that “good literature [is] that which permits,
bodyText ||| invites, or even compels good reading” [16:104], and that
bodyText ||| examining the type of reading that a given work permits,
bodyText ||| invites, or compels can tell you about the merits of that
bodyText ||| work. While there may be questions as to what constitutes
bodyText ||| good reading, the purpose at hand is not to separate good
bodyText ||| blogs from bad. Rather, it is to explore the extent to which
bodyText ||| we may understand a blog not by features of its content,
bodyText ||| structure, or technological aspects, but rather by the type of
bodyText ||| reading practices in which readers of the blog engage.
sectionHeader ||| METHODS
bodyText ||| The authors chose to employ qualitative and ethnographic
bodyText ||| methods in order to gain an understanding of the subjective
page ||| 1112
note ||| CHI 2008 Proceedings · Shared Authoring	April 5-10, 2008 · Florence, Italy
bodyText ||| experience of reading blogs. Participants were recruited
bodyText ||| through physical fliers posted on community bulletin
bodyText ||| boards and in public posting areas, as well as through
bodyText ||| online bulletin boards for the local community. The posted
bodyText ||| criteria were that respondents read at least 5 different blogs
bodyText ||| at least 2 to 3 times per week. In total, 23 individuals
bodyText ||| replied to these advertisements: 21 responded to the
bodyText ||| physical fliers, and 2 replied to the online postings. Of
bodyText ||| those, 19 fit our criteria (18 from the physical fliers and 1
bodyText ||| from the online postings). Some potential subjects decided
bodyText ||| not to participate or stopped responding, resulting in a total
bodyText ||| of 15 respondents. All participants were compensated up to
bodyText ||| $20 US depending on the extent of their participation.
bodyText ||| Participant names used in this paper are pseudonyms.
bodyText ||| Three main data-gathering techniques were used: two semi-
bodyText ||| structured interviews with each participant, logging
bodyText ||| software to track reading patterns, and a survey to gather
bodyText ||| some basic data, such as demographics. Since there is little
bodyText ||| focus on blog readers in the existing literature, the first set
bodyText ||| of interviews were largely exploratory and generative;
bodyText ||| although there were specific themes on which this study
bodyText ||| was to focus, the first interview was also used to find other
bodyText ||| interesting themes or issues in our respondents’ blog
bodyText ||| reading practices. During the second interviews,
bodyText ||| participants were asked to discuss further some of the
bodyText ||| specific themes that emerged during the first round of
bodyText ||| interviews. Participants were also solicited to complete their
bodyText ||| second interview as a group interview. Four participants
bodyText ||| expressed interest in group interviews, but due to logistic
bodyText ||| constraints only one pair of participants completed the
bodyText ||| second interview as a group. One participant, Connie was
bodyText ||| unable to complete the second interview, and another, Jill,
bodyText ||| had to answer questions for the second interview via email.
bodyText ||| During both interviews, all participants spent time reading
bodyText ||| blogs as they normally would, showing and describing
bodyText ||| items of interest and parts of their blog-reading routines to
bodyText ||| the interviewer. All interviews and notes were transcribed
bodyText ||| and coded, initially using open coding and then
bodyText ||| transitioning to axial coding (see [18]). Coding was an
bodyText ||| iterative process during which two of the authors
bodyText ||| independently coded each interview transcript and then
bodyText ||| exchanged the transcripts to confer on the codes used and
bodyText ||| the themes they represented. The initial coding began after
bodyText ||| the completion of the first interviews, so that results from
bodyText ||| analysis of the first set of interviews helped inform and
bodyText ||| direct the second set. The axial codes form the basis for the
bodyText ||| findings reported below.
bodyText ||| Participants were also asked to install logging software on
bodyText ||| their computers to track their blog reading. The logger was
bodyText ||| implemented as a plugin for IBM’s Web Intermediaries
bodyText ||| infrastructure [28], which recorded a series of time-stamped
bodyText ||| URLs. Unfortunately, most participants either elected not to
bodyText ||| install the logger or ran into technical difficulties. Since
bodyText ||| only five participants successfully ran the logger, an
bodyText ||| analysis of those logs is not presented here, but it was used
bodyText ||| to generate questions for some of the second interviews.
sectionHeader ||| FINDINGS AND DISCUSSION
bodyText ||| Table 1 presents a profile of our respondents. Because
bodyText ||| subjects were recruited from the geographical area around a
bodyText ||| university, many are students or recent graduates. That said,
bodyText ||| they represent a diverse set of blog reading habits and
bodyText ||| practices. The data presented in this table were collected
bodyText ||| through an online survey completed by all but one of the
bodyText ||| participants (Connie). “Regular blogs” is the number of
bodyText ||| blogs the participant reads on a regular basis as determined
bodyText ||| by the participant, “example blogs” are a selection of
bodyText ||| representative examples from the blogs she or he reads, and
bodyText ||| “tools” describes the technology the participant uses to find
bodyText ||| and to read blogs. Since the purpose of these data is not to
bodyText ||| make statistical inferences about blog readers but rather to
bodyText ||| help create a picture of the various participants, and since
bodyText ||| the sample is not sufficiently large to generate statistically
bodyText ||| significant results, no quantitative analysis is performed.
bodyText ||| For statistics about blog readers, see [16].
bodyText ||| This section includes a description of blog reading practices
bodyText ||| that were common among most of our participants, along
bodyText ||| with some of the factors that influence the myriad
bodyText ||| differences in approaches to reading blogs. Drawing on this
bodyText ||| diversity in blog reading practices, the section then
bodyText ||| addresses the question “what is a blog?” from readers’
bodyText ||| perspectives; discusses the presentation and perception of
bodyText ||| online identity, noting important similarities and differences
bodyText ||| with previous work; and describes ways in which readers
bodyText ||| can feel that they are “a part” of the blogs they read.
subsectionHeader ||| Common Blog Reading Practices
bodyText ||| While reader-response theory helps make sense of the
bodyText ||| significant variations of the data, some aspects of our
bodyText ||| participants’ reading practices are fairly consistent. Thirteen
bodyText ||| explicitly stated that blog reading is a form of “chilling
bodyText ||| out”, “wasting time”, “brain candy”, or “doing nothing”,
bodyText ||| similar to the pottering activities described by Wyche et al.
bodyText ||| [27]. The other two later indicated on the survey that blog
bodyText ||| reading was “sometimes” an activity during periods of
bodyText ||| boredom. Similar to some instances of pottering, blog
bodyText ||| reading can also have a habitual nature. When Fern reads
bodyText ||| blogs, she adheres to a self-prescribed system, despite her
bodyText ||| lack of interest in the content of some posts she reads.
bodyText ||| Lillian indicated that reading blogs became part of her
bodyText ||| morning routine. When we asked Charles if he looked
bodyText ||| forward to reading blogs everyday he responded:
construct ||| I don’t know if I look forward to [reading blogs]... I don’t
construct ||| really look forward to cigarettes anymore, but it’s something
construct ||| that happens through the course of the day that I feel like I
construct ||| might need to do. It just becomes habit, I guess.
bodyText ||| Though in all likelihood most blog readers do not share
bodyText ||| Charles’s outlook on the intensity of blog reading’s
bodyText ||| addictiveness, blog reading often becomes habitual. For
bodyText ||| Krish, who has only been reading blogs for eight months,
bodyText ||| “checking blogs is like checking one’s email,” which is
bodyText ||| similar to the habitualness described by nine other
bodyText ||| participants. For many, checking email is a routine, almost
page ||| 1113
note ||| CHI 2008 Proceedings · Shared Authoring	April 5-10, 2008 · Florence, Italy
table ||| Pseudonym	Age	Gender	Occupation	Regular Blogs	Frequency	Example Blogs	Years Reading	Tools
table ||| Connie	22	F	--	--	Every Day	--	--	--
table ||| Fern	19	F	Student	1-2	Every Other Day	xanga.com, blogspot.com, livejournal.com	5-6 Years	4, 5, AIM Profiles
table ||| Selena	18	F	Student	6-10	2-3 Times a Week	greatestjournal.com, myspace.com, xanga.com, asianave.com	6-7 Years	1, 4, 5
table ||| Charles	24	M	Admin. Assistant	6-10	Several Times a Day	dailykos.com, boingboing.net, blogspot.com, slashdot.org, poplicks.com	6-7 Years	1, 4
table ||| Lillian	33	F	Graduate Student	20+	Every Day	blogspot.com, indigirl.com/blog, carrieoke.net, doggedknits.com	4.5 Years	2
table ||| Judith	20	F	Student	3-5	Every Other Day	myspace.com, xanga.com, facebook.com	3 Years	4
table ||| Jill	20	F	Student	6-10	Several Times a Day	livejournal.com, flickfilosopher.com/blog, ingliseast.typepad.com/ingliseast	5-6 Years	1
table ||| Cindy	19	F	Student	1-2	Several Times a Day	xanga.com, livejournal.com	5 Years	4
table ||| Patricia	20	F	Student	1-2	2-3 Times a Week	sibol.in, mochix.com	4 Years	1, 2, 5
table ||| Natalie	25	F	Legal Assistant	11-20	Every Other Day	perezhilton.com, blogspot.com, myspace.com, livejournal.com	10 Years	1, 4, 5
table ||| Tony	31	M	Graduate Student	3-5	Every Day	slashdot.org, fark.com, treehugger.com, somethingawful.com	6 Years	1, 3, iGoogle
table ||| Matthew	26	M	Graduate Student	11-20	Several Times a Day	blogspot.com, firejoemorgan.com, kugelmass.wordpress.com, sadlyno.com	6 Years	1, 2
table ||| Laura	27	F	Admin. Assistant	3-5	2-3 Times a Week	mypapercrane.com, blogspot.com, livejournal.com, bloesem.blogs.com	2 Years	1, 4
table ||| Cheryl	24	F	Graduate Student	3-5	2-3 Times a Week	fourfour.typepad.com,	2-3 Years	1
table ||| 						2manadvantage.com, nydailynews.com/blogs/mets
table ||| Krish	22	M	Student	3-5	Every Day	metblogs.com, kiruba.com, blogspot.com, aparnasblog.wordpress.com	8 Months	1
tableCaption ||| Table 1 – Profile of participants. For tools, 1 is web browser, 2 is RSS aggregator, 3 is email client, 4 is blogging website, 5 is
tableCaption ||| links from reader’s blog. Participants listed specific regular blogs, from which the authors generalized and chose examples.
bodyText ||| quintessential part of going online. Whether one expects an
bodyText ||| email or not is unimportant, because one will check her or
bodyText ||| his email account not with the expectation of receiving
bodyText ||| email but rather as part of an Internet ritual.
bodyText ||| Much work in information retrieval, search technologies,
bodyText ||| and related fields is based on the premise that the sheer
bodyText ||| volume of information available is simply overwhelming,
bodyText ||| often referred to as “information overload,” and that users
bodyText ||| feel compelled to try and stay on top of the ever increasing
bodyText ||| amount of available information. This attitude dates at least
bodyText ||| as far back as Barnaby Rich’s assertion, in 1613, that “one
bodyText ||| of the diseases of this age is the multiplicity of books; they
bodyText ||| doth so overcharge the world that it is not able to digest the
bodyText ||| abundance of idle matter that is every day hatched and
bodyText ||| brought forth into the world” (quoted in [4:63]). However,
bodyText ||| such a sense of information overload with respect to blogs
bodyText ||| was not common among our respondents. Only two of the
bodyText ||| fifteen, Charles and Lillian, expressed feeling overwhelmed
bodyText ||| by the potential information available through blogs. The
bodyText ||| other participants indicated that they are not bothered when
bodyText ||| they cannot stay current with the newest posts for the blogs
bodyText ||| they frequent. Some would eventually catch up on old posts
bodyText ||| when the time suited them, while others simply choose the
bodyText ||| most recent or most interesting posts to read, skipping the
bodyText ||| rest. Laura reveals, “I don’t kill myself over it, because it’s
bodyText ||| not like I can’t always go back and see, ‘okay what
bodyText ||| happened two weeks ago’ ... I know what’s there and I
bodyText ||| know where to find it when I need it.” This attitude
bodyText ||| challenges the commonly accepted notion that users feel
bodyText ||| overwhelmed with staying constantly up to date.
bodyText ||| It also raises interesting issues of synchronicity. Computer
bodyText ||| mediated communication is often considered either
bodyText ||| synchronous, e.g., live video or audio chat; near
bodyText ||| synchronous, e.g., instant messaging; or asynchronous, e.g.,
bodyText ||| email. Clearly, there are not fine distinctions but rather a
bodyText ||| gradient from synchronous to asynchronous, and blogs are
bodyText ||| generally placed closer to the asynchronous end of the
bodyText ||| spectrum [21]. However, based on our participants’
bodyText ||| descriptions, they do not read blogs in a temporally situated
bodyText ||| manner. When returning to a blog that has not been visited
bodyText ||| recently, it does not matter if the most recent three posts
bodyText ||| occurred in the past week, in the past day, or in the past
bodyText ||| hour. What matters is the order in which posts appear on the
bodyText ||| blog. The most recent post on one blog, even if it is several
page ||| 1114
note ||| CHI 2008 Proceedings · Shared Authoring	April 5-10, 2008 · Florence, Italy
bodyText ||| days old, is more likely to be read than the fourth post down
bodyText ||| on another blog, even if that post is from the previous day.
bodyText ||| This is somewhat similar to instant messaging
bodyText ||| conversations where time lapses between turns do not
bodyText ||| necessarily have an impact on the conversation [22]. Here,
bodyText ||| we introduce the term non-chronous to describe practices
bodyText ||| where individual events in one context, here a single blog,
bodyText ||| are considered in the temporal order in which they
bodyText ||| occurred, but not with regard to the specific time at which
bodyText ||| they occurred. This non-chronous approach does not mean
bodyText ||| that time-date stamps are utterly ineffectual, but they
bodyText ||| become much less important, especially with the advent of
bodyText ||| RSS aggregators, email clients, blog-host subscription lists,
bodyText ||| etc. For example, when Matthew falls behind on his regular
bodyText ||| blogs, he reads the five or so most recent posts in his RSS
bodyText ||| reader and his friends’ blogs. Patricia notes the time-
bodyText ||| stamp’s existence in passing, but does not take it into
bodyText ||| account while reading. Generally, participants in this study
bodyText ||| do not see themselves as struggling to handle a deluge of
bodyText ||| information streaming through blogs–a missed post is not
bodyText ||| usually a missed opportunity.
bodyText ||| Stepping back from the details of common blog reading
bodyText ||| practices, there are dramatic differences in how blog
bodyText ||| readers understand the visible object of their activity. When
bodyText ||| asked about motivations for reading blogs, participants said
bodyText ||| they visit blogs for information, inspiration, entertainment,
bodyText ||| and to a certain extent because it is just what they have
bodyText ||| always done. However, when asked the deceptively simple
bodyText ||| question, “what is a blog?” the responses were far more
bodyText ||| vague and varied. Patricia responded canonically, “well
bodyText ||| there’s the technical term and my own definition.” How
bodyText ||| does she determine which definition to use at what time?
subsectionHeader ||| “It Depends”
bodyText ||| Among our respondents, the manner of reading and
bodyText ||| interacting with a blog depends on myriad factors
bodyText ||| including, among others, the content of the blog, the intent
bodyText ||| of the reader, the perceived intent of the blogger, and the
bodyText ||| relationship of the reader to the blogger. We argue that part
bodyText ||| of the reason for the great diversity in approaches to blog
bodyText ||| reading is the great diversity of blogs. Previous work, e.g.,
bodyText ||| [11,21], has tried to classify blogs as a genre with certain
bodyText ||| structural and content-based divisions into sub-genres.
bodyText ||| However, our findings align more closely with boyd’s
bodyText ||| argument [2] that blogs are a medium, and that a variety of
bodyText ||| different activities and interactions can occur in and through
bodyText ||| that medium. Furthermore, drawing on reader-response
bodyText ||| theory [17], we argue that, in order to distinguish between
bodyText ||| different types of blogs, it may be less useful to look at the
bodyText ||| structure or content of the blog and more informative to
bodyText ||| follow the ways that readers read and interact with the blog.
bodyText ||| The analysis presented here focuses on the following
bodyText ||| themes as dimensions along which approaches to blog
bodyText ||| reading may vary: the concept of a blog, perception and
bodyText ||| presentation of blogs, and “being a part” of blogs. From an
bodyText ||| analytic standpoint, uncovering data based on a consistent
bodyText ||| definition of blogs seems to make intuitive sense, but given
bodyText ||| the fluid character of blogs it may be misleading to do so.
bodyText ||| Rather than trying to impose a definition of what counts or
bodyText ||| does not count as a blog, the authors strove for a more
bodyText ||| authentic, emic perspective by allowing our blog reader
bodyText ||| participants to decide what constitutes a blog. The styles of
bodyText ||| blogs that our participants read varied as much as the
bodyText ||| specific reading practices. These practices depend in large
bodyText ||| part on the reader’s approach towards, and perception of, a
bodyText ||| blog, which shape and reshape the activity of blogging
bodyText ||| itself. An example of this iterative process is Krish’s
bodyText ||| approach toward blogs; he generally views blogs as just
bodyText ||| another thing to do on the Internet when he’s bored. He
bodyText ||| calls himself a passive reader of blogs, unlikely to search
bodyText ||| out a new set of blogs despite his disappointment in the lack
bodyText ||| of content in the blogs he reads. However, during his blog
bodyText ||| reading activity Krish began to note points of interest in his
bodyText ||| hometown that were described in a blog. Now, when Krish
bodyText ||| returns home, he applies the knowledge he acquired online
bodyText ||| to his experience offline. Although Krish’s initial
bodyText ||| motivation for reading blogs shaped his self-labeled
bodyText ||| “passive reading” of blogs, his Internet-only experience
bodyText ||| reshaped itself into an activity with offline implications.
bodyText ||| Reader-response theory directs us to note the ways that
bodyText ||| individual readers read different blogs differently. While a
bodyText ||| blog reader may feel fine lurking on popular blogs, she or
bodyText ||| he may feel obligated to interact on the blogs of friends.
bodyText ||| Although examining format and content in order to
bodyText ||| categorize a blog may reveal a general understanding of a
bodyText ||| blog, this approach is likely to neglect the audience for
bodyText ||| whom the blog is, at least in part, intended.
subsectionHeader ||| What is a Blog?
bodyText ||| Definitions of the term “blog” cited in the academic
bodyText ||| literature often resemble Herring et al.’s, “frequently
bodyText ||| modified web pages in which dated entries are listed in
bodyText ||| reverse chronological order” [10:1]. boyd [2] provides a
bodyText ||| survey of various definitions from dictionaries, researchers,
bodyText ||| mass media, and bloggers themselves. When we asked our
bodyText ||| participants, “what is a blog?” the responses were a mixture
bodyText ||| that pointed to updates, commenting capabilities,
bodyText ||| authorship, RSS feeds, personal content, etc. Unlike the
bodyText ||| bloggers boyd describes, there is little or no uniformity of
bodyText ||| definition among readers. For example Judith considered
bodyText ||| the notes on facebook.com and the blog option on
bodyText ||| myspace.com examples of blogs while many others did not
bodyText ||| agree. When asked to define a blog some participants did
bodyText ||| refer to the frequency of modifications, but there was no
bodyText ||| mention of dated entries or reverse chronological order.
bodyText ||| Rather than structural features, thirteen participants
bodyText ||| discussed interactional attributes. For many bloggers, a blog
bodyText ||| is not something you have, blogging is something you do
bodyText ||| [2]. However, among our participants, there was not such a
bodyText ||| clear distinction. For example, Patricia emphasizes the
bodyText ||| conversational nature of blogging:
construct ||| A blog is something that’s still going on, that still has a
construct ||| conversation going on, that has people commenting, [it]
page ||| 1115
note ||| CHI 2008 Proceedings · Shared Authoring	April 5-10, 2008 · Florence, Italy
construct ||| doesn’t have to be all the time, but it does have this dialogue
construct ||| between the person who’s posting and the people who are
construct ||| reading, yeah that’s a blog.... [When the conversation stops],
construct ||| by my definition, yeah it’s a dead site.
bodyText ||| However, not all participants stressed conversational
bodyText ||| interaction. Providing another perspective, Natalie suggests
bodyText ||| that “a blog is a journal, like an electronic journal where
bodyText ||| people can express whatever they want, you know, and let
bodyText ||| everyone read it I guess.... it could be anything I guess.”
bodyText ||| Many respondents referred to “getting” a Xanga or
bodyText ||| “having” a blog, which foregrounds the blog as a
bodyText ||| possession and backgrounds the interactivity and process of
bodyText ||| blogging. Eight participants varied in their usage of the
bodyText ||| term “blog”: sometimes it would refer to an individual blog,
bodyText ||| an individual post, e.g., “I write a lot of blogs,” or even an
bodyText ||| entire blog-hosting site, such as when participants include
bodyText ||| LiveJournal in the blogs they frequently read.
bodyText ||| In Patricia’s definition, the interaction that occurs makes it
bodyText ||| a blog, while in Natalie’s definition the content makes it a
bodyText ||| blog. “It could be anything” demonstrates just how fluid the
bodyText ||| notion of blog can be. Another respondent, Tony, listed a
bodyText ||| series of technical requirements, including commenting and
bodyText ||| RSS, when asked if a particular website was a blog or not:
construct ||| That website is [a blog], yeah, but it doesn’t have live
construct ||| comments from people who read it. It has message boards that
construct ||| are associated with it, but they’re not as directly linked with
construct ||| different page articles, I don’t know. It’s not a static page, I
construct ||| mean every week you go to it, it will have different articles,
construct ||| but it’s not exactly the same format as a blog, it does have an
construct ||| RSS feed though so you can see what’s new on it.
bodyText ||| If readers and writers are both involved in the co-
bodyText ||| construction of the blog [21], how do differences in
bodyText ||| definitions impact this process?
bodyText ||| As with boyd’s [2] respondents, many readers used
bodyText ||| metaphors to define the term blog, and the metaphors with
bodyText ||| which they attempt to make sense of blogs in turn affect
bodyText ||| their understanding of, perception of, and interaction with
bodyText ||| blogs. Seven of the fifteen participants referred to blogs as a
bodyText ||| newspaper or magazine, and ten of the fifteen used the term
bodyText ||| diary or journal to describe at least one blog they read.
bodyText ||| These data point to the problematic nature of basing
bodyText ||| research on blogging activity upon the traditional format-
bodyText ||| oriented definition of blogs. Although a blog’s format may
bodyText ||| invite a certain reading, reader-response theory helps us
bodyText ||| understand the actual interaction or lack of interaction that
bodyText ||| occurs between the blog reader and the blogger. Although
bodyText ||| definitions found in the research literature [11,21] can be
bodyText ||| useful from an analytic standpoint, they may be less useful
bodyText ||| or even misleading when trying to understand how the
bodyText ||| bloggers and readers themselves approach blogging. When
bodyText ||| seeking to understand blogging from the blogger’s or the
bodyText ||| reader’s perspective, the authors found it more useful and
bodyText ||| informative to consider blogs not in terms of academic
bodyText ||| definitions, but rather in the terms of those involved in the
bodyText ||| activity of blogging.
subsectionHeader ||| Presentation and Perception
bodyText ||| Previous work [1,2,15,23] has explored how bloggers use
bodyText ||| blogs as a means of presentation of self (see [9]) online.
bodyText ||| This section explores the other half of that phenomenon,
bodyText ||| that is, how readers perceive the self that bloggers present.
bodyText ||| In some respects, these results align with previous findings.
bodyText ||| However, findings about our respondents also differ in a
bodyText ||| number of important ways from previous assertions about
bodyText ||| audience and perception in blogging.
subsubsectionHeader ||| Agreement with Previous Findings
bodyText ||| Past work on authenticity, one aspect of bloggers’
bodyText ||| presentation of self, illustrates that audiences of blogs hope
bodyText ||| and expect authenticity, and that without it readership will
bodyText ||| be lost (McNeil in [15]). For blogs, authenticity does not
bodyText ||| hinge upon the accuracy of information they present, but
bodyText ||| rather upon their interpretability. (Langellier and Peterson
bodyText ||| in [15]). Lenhart bases her conclusion on Langellier and
bodyText ||| Peterson’s examination of the persistent interpretability of
bodyText ||| narratives. Arguing that blogs are a form of narrative, she
bodyText ||| posits that the blog is perceived “as one person’s ‘take’ on
bodyText ||| an issue, one person’s perspective on a story, left open to
bodyText ||| the interpretation of, and evaluation by, the reader, rather
bodyText ||| than as an unbiased source of information” [15:58-59].
bodyText ||| Among our participants, eleven described the blogs they
bodyText ||| read regularly as feeling authentic. Connie “definitely [gets]
bodyText ||| an inside look at their lives”, while Natalie feels like she is
bodyText ||| traveling alongside the bloggers who write about their
bodyText ||| travels. All thirteen of our participants who read single-
bodyText ||| authored blogs recognize that posts of the blogs they read
bodyText ||| regularly were either opinion or personal narratives, which
bodyText ||| are important components of the perception of authenticity.
bodyText ||| Blogs are generally considered a one-to-many medium, but
bodyText ||| are often experienced by bloggers as one-to-one [15]. In
bodyText ||| this study, eight participants have experienced blogs as one-
bodyText ||| to-one communication between them and the blogger.
bodyText ||| Selena says, “for like some people..., I guess sometimes I
bodyText ||| feel like they’re writing to me.”
bodyText ||| This study also shows that negotiations between online and
bodyText ||| offline identity for blog readers are similar to those of
bodyText ||| bloggers. Early research into online identity, e.g., [26],
bodyText ||| argued that people used online worlds to create alternate
bodyText ||| identities or to explore certain facets of their personality
bodyText ||| that were not as prominent. However, more recent work,
bodyText ||| e.g., [1,20], has pointed to the ways in which a person’s
bodyText ||| online identity is a part or an extension of their offline
bodyText ||| identity, such as the way that Trinidadians use the Internet
bodyText ||| as just another way of being “Trini” [20], and that
bodyText ||| attempting to sever the two can be misleading and
bodyText ||| confusing. Similarly, while blogs and “real life”
bodyText ||| experiences are still distinct realms for readers, there is a
bodyText ||| relatively tight coupling between readers’ online and offline
bodyText ||| identities. Describing one of her friends, Fern says that “the
bodyText ||| way he types is the way he talks and thinks,” and Lillian
bodyText ||| hesitates to refer to only her offline friends as her “real”
bodyText ||| friends. Were there a connection with Patricia’s online and
bodyText ||| offline life, she says, “I [would be] a little bit surprised and
page ||| 1116
note ||| CHI 2008 Proceedings · Shared Authoring	April 5-10, 2008 · Florence, Italy
bodyText ||| a little bit happy that there was this link between my online
bodyText ||| life that I publish online with just a typical school day that it
bodyText ||| could be considered that I’m still the same... my screen
bodyText ||| name versus me.” However, she is also wary of creating too
bodyText ||| strong a link between her online and offline identities. “I
bodyText ||| don’t want my dad to find me because there was this whole
bodyText ||| breakup thing [between my mom and dad] and he wasn’t
bodyText ||| such a good person.” While Lillian was initially cautious
bodyText ||| about linking her knit-blogging with her life as a graduate
bodyText ||| student, and she still does not give out her full name online,
bodyText ||| she also feels that her blogging activities are “a part of [her]
bodyText ||| and it’s not worth hiding it.” This sort of ambivalence was
bodyText ||| common among participants; they do not view the set of
bodyText ||| identities they construct through blog reading as identical to
bodyText ||| their set of offline identities, but they also do not view the
bodyText ||| two sets as totally disjoint; most of them continuously
bodyText ||| negotiate and redefine the relationship between the two.
subsubsectionHeader ||| Differences from Previous Findings
bodyText ||| Previous work on blogs has overlooked several elements of
bodyText ||| presentation and perception, possibly due to its focus on
bodyText ||| bloggers as both producers and consumers of blogs. Blog
bodyText ||| readers are often perceived by bloggers as an unnerving and
bodyText ||| anonymous group of lurkers or instigators [15], placing
bodyText ||| expectations on the blogger, creating awkward social
bodyText ||| situations, or sometimes presenting an unwanted, invading
bodyText ||| presence [2]. However, blog readers often approach
bodyText ||| different blogs differently, and may contribute differently in
bodyText ||| different contexts. Each participant shared that she or he
bodyText ||| would variously comment, lurk, or instigate, depending on
bodyText ||| the blog. As for commenting, eleven respondents stated that
bodyText ||| they would semi-regularly encounter statements or
bodyText ||| sentiments with which they disagreed, but only four
bodyText ||| participants shared instances where their views differed
bodyText ||| significantly and decided to express their disagreement
bodyText ||| through comments. However, only one of these four would
bodyText ||| make comments with the aim of instigating an awkward
bodyText ||| situation or invading the blogger’s space. Lillian is of the
bodyText ||| opinion that “it’s not worth being negative.” She strives to
bodyText ||| ensure that “whatever comes out of [her] mouth... or what
bodyText ||| comes out of [her] fingers is positive.” Kirsh, though, said
bodyText ||| that he enjoys bashing on bloggers or simply kindling
bodyText ||| “flame wars” of nearly unfounded, ruthless arguments.
bodyText ||| While previous research has described the expectations
bodyText ||| readers place on bloggers, readers feel that there are certain
bodyText ||| expectations of them, as well. According to Patricia, “a
bodyText ||| good post deserves a reply from the audience,” and Jill sees
bodyText ||| “[commenting] as a courtesy.” Furthermore, while some
bodyText ||| comments are used as simple, lo-fi communication or
bodyText ||| notification mechanisms (discussed further below), many
bodyText ||| readers spend a significant amount of time formulating their
bodyText ||| comments in order for them to be coherent and insightful.
bodyText ||| In the rare event that Charles comments, he needs “time to
bodyText ||| sit down and plot out a cogent response.” While bloggers
bodyText ||| feel pressures about the content and identity they present,
bodyText ||| readers feel pressures about ensuring that their comments
bodyText ||| make a significant contribution. Similarly, while bloggers
bodyText ||| may feel pressured to update, ten of our participants felt
bodyText ||| obligated to read or comment, particularly on friends’ blogs
bodyText ||| or blogs of which they felt that they were “a part” (see next
bodyText ||| section). Selena “admits” that there are some posts, even on
bodyText ||| blogs of close friends, that she does not read. Lillian was
bodyText ||| relieved to learn that other readers did not follow every
bodyText ||| single post and skimmed many. However, while a reader
bodyText ||| can “get away” with not reading every post without much
bodyText ||| notice, it is more obvious when there are lapses on the part
bodyText ||| of the blogger. Though expectations and obligations may
bodyText ||| not be symmetrical, the activity of blogging nevertheless
bodyText ||| exerts social pressures on both bloggers and readers.
bodyText ||| However, the situation with respect to readers’ expectations
bodyText ||| is somewhat more complex still. Thirteen respondents
bodyText ||| expressed expectations with regard to update frequency,
bodyText ||| visual style, navigability, responsiveness, appropriateness,
bodyText ||| and other aspects. However, just as readers read different
bodyText ||| blogs differently, they have different expectations of
bodyText ||| different blogs. Expectations are often more lax for friends’
bodyText ||| blogs and greater for more popular “big” blogs. On the
bodyText ||| other hand, for example, when readers comment on these
bodyText ||| big blogs, they rarely expect a response, while a comment
bodyText ||| on a friend’s blog almost demands reciprocation. Natalie is
bodyText ||| interested in travel, and so often reads and comments on
bodyText ||| travel blogs. She does not expect the blogger to respond to
bodyText ||| her questions, but is pleasantly surprised when it happens.
bodyText ||| Differences in expectations of blogger and reader are not
bodyText ||| split only along the lines of friend blogs vs. big blogs. For
bodyText ||| example, on knit blogs, Lillian comments, answers
bodyText ||| questions, and provides positive feedback, but she is
bodyText ||| unwilling to do the same on other blogs she reads, such as a
bodyText ||| science blog that relates to her graduate studies.
bodyText ||| Many of these differences—in expectations, in
bodyText ||| commenting, in other regards—can be traced to the reader’s
bodyText ||| perception of the blogger or blog, and to the reader’s
bodyText ||| motivation for reading. Lillian views the knit and craft
bodyText ||| blogs as a community and often attributes certain
bodyText ||| characteristics of the community to its primarily female
bodyText ||| composition. Tony accounts for his commenting practices
bodyText ||| as something he enjoys doing as an engineer. Charles reads
bodyText ||| blogs as a routine that helps him obtain information. Judith
bodyText ||| reads primarily to keep in contact with friends. It is not only
bodyText ||| the way the blogger presents herself or himself that affects
bodyText ||| the readers perception of the blogger, but also the purpose
bodyText ||| for which the reader is reading.
bodyText ||| Although this paper focuses on blog readers, only three of
bodyText ||| the fifteen participants do not have their own blog. Despite
bodyText ||| the fact that many of our participants are also bloggers, at
bodyText ||| least nominally, the findings presented here are still
bodyText ||| applicable to blog readers, because, as argued above, there
bodyText ||| is no evidence in the literature that there exist bloggers who
bodyText ||| do not read blogs. However, one difference is the tendency
bodyText ||| for the non-bloggers to read only popular, highly trafficked
bodyText ||| blogs, whereas, of the twelve blog readers with blogs, ten
bodyText ||| used their blogs to keep up with friends. Ultimately, though,
page ||| 1117
note ||| CHI 2008 Proceedings · Shared Authoring	April 5-10, 2008 · Florence, Italy
bodyText ||| the activity of blog reading is neither a dichotomy of
bodyText ||| blogger versus reader nor a set of transactions that are
bodyText ||| confined to the materiality of the blog. “It depends”
bodyText ||| describes how the experience of blog reading is highly
bodyText ||| contingent on the individual reader and not solely the blog.
subsectionHeader ||| “Being a Part”
bodyText ||| When discussions with respondents turned to themes of
bodyText ||| participation in, and contribution to, the blogs they read,
bodyText ||| eleven of them described feeling that they were a “part” of
bodyText ||| a blog in some way. This is distinct from the feeling of
bodyText ||| membership or belonging in a community [6,12]. Some
bodyText ||| respondents felt that they were part of a blog without ever
bodyText ||| making their individual presence known to the blogger or
bodyText ||| other readers. Being part of a blog is more than consistent
bodyText ||| readership, a sense of community, or a feeling of
bodyText ||| connectedness, although it includes all those things.
bodyText ||| Readership is one component to being a part of a blog.
bodyText ||| Connie stated that, “just by reading I feel like I’m
bodyText ||| participating.” Nevertheless, a few question if they are part
bodyText ||| of any of the blogs that they read. For Charles, the idea of a
bodyText ||| community is a central component to the definition of a
bodyText ||| blog, and thus he does not feel part of a blog because he
bodyText ||| does not consistently contribute as he might expect a
bodyText ||| community-member to do. Importantly, Charles reads
bodyText ||| mostly “big” blogs—ones that are relatively popular,
bodyText ||| generate a high volume of traffic, and receive copious
bodyText ||| comments—and while other participants could be a part of
bodyText ||| a big blog without commenting, some sort of interaction
bodyText ||| was necessary for Charles. While an important component
bodyText ||| of being a part, readership alone is often not sufficient.
bodyText ||| Six of the fifteen participants said specifically that they felt
bodyText ||| “connected” to a blog or blogger. Kuwabara et al.’s
bodyText ||| examination of FaintPop [14] revealed that the ability to
bodyText ||| express things that might not be considered an important
bodyText ||| topic of conversation, such as moods, help construct a
bodyText ||| feeling of connectedness. In the blogosphere, such
bodyText ||| examples are lo-fi comments, ones that are short, do not
bodyText ||| convey much content-wise, and are relatively generic.
bodyText ||| These comments also share certain aspects with the
bodyText ||| communication afforded by the Virtual Intimate Object
bodyText ||| (VIO) [13], in that they are relatively low bandwidth
bodyText ||| communication but carry a high degree of meaning and
bodyText ||| value for both reader and blogger. However, of the
bodyText ||| participants who expressed a feeling of connectedness, only
bodyText ||| Natalie described a feeling of presence similar to FaintPop
bodyText ||| or the VIO. When reading travel blogs she feels as if she is
bodyText ||| traveling with the blogger, sharing the blogger’s
bodyText ||| experiences, supporting her or his travels. Furthermore,
bodyText ||| though lo-fi comments are not the exception, they are not
bodyText ||| the rule, either. Although Cheryl feels connected to one of
bodyText ||| the sports-fan blogs she reads, she has yet to feel the need
bodyText ||| to leave comments of any sort. On the one hand, there is an
bodyText ||| argument that the readers who do not comment are not
bodyText ||| really connected, or that those who comment are more
bodyText ||| connected. Drawing on reader response theory, this paper
bodyText ||| argues instead that connectedness is constituted differently
bodyText ||| in different contexts; being a part of a blog looks different
bodyText ||| for different readers, and connectedness, even when
bodyText ||| achieved by different means, is still connectedness.
bodyText ||| Connectedness does not always entail feeling connected to
bodyText ||| the blogger as a person. Despite the distinctive personal
bodyText ||| style and presentation of self in many blogs, not all readers
bodyText ||| visit blogs for the blogger. Instead, they are more interested
bodyText ||| in the content or information presented on the blog. Among
bodyText ||| our respondents, ten of fifteen read certain blogs because
bodyText ||| they know or are familiar with the blogger in person, while
bodyText ||| eleven of fifteen read certain blogs because they want
bodyText ||| information about a particular topic. However, motivations
bodyText ||| can change over time. During the interviews, eleven
bodyText ||| participants described situations where they began reading
bodyText ||| blogs for information purposes, but continued reading
bodyText ||| because they developed a connection with the blogger.
bodyText ||| Cheryl reads fourfour, a blog with pop culture news and
bodyText ||| commentary. Initially, she started reading for the blogger’s
bodyText ||| witty and insightful entries about hip hop and “snarky
bodyText ||| commentary” about reality TV shows. However, the
bodyText ||| blogger would also occasionally post about his cats.
construct ||| At first, when he was posting pictures about his cat, not that I
construct ||| thought it was a little nutty, but it was like, ‘what’s the sense
construct ||| in doing this?’, but then I would read the entries and they
construct ||| would be really cute or hilarious pictures so then I became
construct ||| even a fan of the cat postings then I was like, ‘oh my god, this
construct ||| is so petty’.... he’s a charismatic person so pretty much any
construct ||| topic you’ll get some sort of satisfaction or chuckle...
bodyText ||| Even though Cheryl was initially drawn to the blog for the
bodyText ||| content, she ended up feeling connected with the blogger
bodyText ||| due in part to the personal information with which he
bodyText ||| supplemented his posts. In contrast, there were no instances
bodyText ||| where a blog reader began reading a blog for the blogger,
bodyText ||| and despite a falling out or loss of feeling connected
bodyText ||| continued to read for the content. This pattern suggests that,
bodyText ||| contrary to previous findings [2,23], it is important not to
bodyText ||| conflate the blogger with the content of the blog when
bodyText ||| considering the perspective of the reader.
sectionHeader ||| SUMMARY AND IMPLICATIONS
bodyText ||| This section highlights salient themes from the above
bodyText ||| findings as well as potential implications. These include not
bodyText ||| only design implications, but also more broadly future
bodyText ||| research directions and societal implications.
bodyText ||| Routine – All of our participants mentioned in some way
bodyText ||| the habitual nature of blog reading. Charles’ statement that
bodyText ||| reading blogs is “something that happens” frames the reader
bodyText ||| as passive, neither self-aware nor reflective about their
bodyText ||| reading. While some participants were conscious of why
bodyText ||| they read blogs, few were reflective of how they read. For
bodyText ||| example, participants rarely reflected on the routine or
bodyText ||| time-consuming nature of blog reading prior to
bodyText ||| participation in this study. This finding suggests that
bodyText ||| designing tools to raise self-awareness and encourage
bodyText ||| reflection could be valuable in transforming routinized blog
page ||| 1118
note ||| CHI 2008 Proceedings · Shared Authoring	April 5-10, 2008 · Florence, Italy
bodyText ||| reading into a more engaging, fulfilling experience. Future
bodyText ||| work should also compare blog reading to other routine
bodyText ||| media use, such as watching television, checking email,
bodyText ||| reading the newspaper, or listening to the radio.
bodyText ||| Not Information Overload – Research on information
bodyText ||| retrieval (IR) and related areas often asserts that the copious
bodyText ||| quantity of information available leads to information
bodyText ||| overload, wherein overwhelmed users are unable to find
bodyText ||| relevant or important information in the ever-growing
bodyText ||| deluge. However, among this study’s participants, only two
bodyText ||| feel overwhelmed by the information content available to
bodyText ||| them. These readers do not feel the need to be constantly up
bodyText ||| to date with everything posted in the blogs they read. More
bodyText ||| studies should explore information overload, or lack
bodyText ||| thereof, from users’ perspectives in other contexts, so as not
bodyText ||| to spend research time developing IR algorithms that
bodyText ||| alleviate a problem not actually experienced by users.
bodyText ||| Non-chronous – While readers experience blog posts in
bodyText ||| temporal order, the exact times of the posts does not
bodyText ||| significantly impact the reading activity. The recency of a
bodyText ||| post has more to do with the number of other posts that
bodyText ||| have occurred since the post in question than with the
bodyText ||| amount of time that has passed. Not only does this finding
bodyText ||| have implications for the design of blog reading tools with
bodyText ||| respect to determining what content users/readers will find
bodyText ||| important, but it also points to the ways in which
bodyText ||| technologies such as blogs influence perceptions of
bodyText ||| temporality. The passage of time here is marked by the
bodyText ||| occurrence of certain events, i.e., posts, such that the
bodyText ||| significance of a period of time and even the perception of
bodyText ||| how much time has elapsed are influenced by how much
bodyText ||| happens in that period, i.e., how many posts occur. Future
bodyText ||| studies should pay attention to the ways in which the design
bodyText ||| and use of other technologies and communication media,
bodyText ||| such as instant messaging, email, or Twitter, influence how
bodyText ||| users perceive and constitute the passage of time.
bodyText ||| Identity– This paper builds on previous studies of online
bodyText ||| identity by exploring readers’ perceptions of bloggers’
bodyText ||| identities. The findings here agree with previous ones, for
bodyText ||| example, that online and offline identities are not
bodyText ||| completely separate and distinct from one another [2,20],
bodyText ||| but there are also differences. For example, while previous
bodyText ||| work has looked at the obligations the blogger feels from
bodyText ||| his or her audience, this paper looked also at the obligations
bodyText ||| readers feel toward the blogger. Also, these findings
bodyText ||| indicate disconnects between the pressures felt by bloggers
bodyText ||| and the expectations of readers. While these findings
bodyText ||| provide future directions for exploring identity perception
bodyText ||| and presentation in social media and its connection to other
bodyText ||| aspects of interaction, such as privacy, appropriateness, and
bodyText ||| authority, they also suggest a design space for tools to allow
bodyText ||| more nuanced interactions between bloggers and readers.
bodyText ||| “Being a Part” – Being a part of a blog involves regular
bodyText ||| reading, a feeling of community, and a sense of
bodyText ||| connectedness, though these aspects are neither necessary
bodyText ||| nor sufficient. What it takes to be a part of a blog varies
bodyText ||| depending on the individual reader and the specific blog,
bodyText ||| especially whether it is a “big” popular blog or a personal
bodyText ||| friend’s blog. Based on these varied interactions between
bodyText ||| reader and blog, readership is defined and constituted
bodyText ||| differently in different contexts. Future work should
bodyText ||| examine the feeling of “being a part” both in different
bodyText ||| social media, such as YouTube or Wikipedia, as well as in
bodyText ||| instances where the division between authors and readers is
bodyText ||| more nebulous or even nonexistent, such as social
bodyText ||| networking sites or Twitter. Furthermore, it will be
bodyText ||| important to examine how participation in these and other
bodyText ||| online interactions impacts our definition of what it means
bodyText ||| to be a member of a community, both online and offline.
bodyText ||| Interactional Approach – drawing on reader response
bodyText ||| theory [3,17] and recent trends in HCI research [5], the
bodyText ||| research presented here takes an interactional approach to
bodyText ||| studying blog reading, shifting the focus from structural,
bodyText ||| technical, or content-oriented aspects of blogs to the
bodyText ||| reader’s experiences with them. This approach leads to
bodyText ||| novel, reader-centered definitions of the term “blog” based
bodyText ||| on the types of reading and interaction it allows and
bodyText ||| encourages. Focusing on interaction also foregrounds the
bodyText ||| ways in which blogs are not a genre but a medium for
bodyText ||| multi-directional communication among bloggers and
bodyText ||| readers. Previous work focused predominantly on the
bodyText ||| blogger, and this paper focuses mostly on readers. Future
bodyText ||| work should take an integrative approach, looking at the
bodyText ||| same interaction from both the blogger’s and the reader’s
bodyText ||| perspectives, as well as looking at interactions between
bodyText ||| blog readers in specific contexts, such as political blogs,
bodyText ||| religious blogs, or mommy blogs. What interactional
bodyText ||| aspects of blogging, including both blogger and reader, are
bodyText ||| unique to each of these communities? What aspects
bodyText ||| transcend individual communities to characterize blogging
bodyText ||| in general? How do common practices from blogging
bodyText ||| impact social interaction in other contexts beyond blogs?
sectionHeader ||| CONCLUSION
bodyText ||| In examining the increasingly common social activity of
bodyText ||| blogging, we must consider the experiences, roles, and
bodyText ||| contributions of readers, even when less readily apparent
bodyText ||| than those of bloggers. This paper presents a qualitative
bodyText ||| study that focuses on blog readers, their reading practices,
bodyText ||| their perceptions of blogs and bloggers, and what it means
bodyText ||| to be a part of a blog. The findings presented here indicate
bodyText ||| that the activity of blogging, of which readers are an
bodyText ||| integral part, is far more heterogeneous and multifaceted
bodyText ||| than previously suggested. Even though ten of our fifteen
bodyText ||| participants are between 18-25 years old and eleven of
bodyText ||| fifteen are students, the ways in which they read blogs, and
bodyText ||| even their definitions of what constitutes a blog, are
bodyText ||| dramatically different. The analysis here draws on reader-
bodyText ||| response theory to argue that, rather than using structural or
bodyText ||| content-based features in order to classify blogs, it may be
bodyText ||| more informative to consider them in terms of interactional
bodyText ||| features and readers’ experiences. This focus resonates with
page ||| 1119
note ||| CHI 2008 Proceedings · Shared Authoring	April 5-10, 2008 · Florence, Italy
bodyText ||| current trends in HCI, such as embodied interaction [5].
bodyText ||| This paper describes various ways in which blog reading is
bodyText ||| more than just reading. It leads the reader to form complex
bodyText ||| definitions of the term “blog,” each of which differs to
bodyText ||| varying degrees from the definitions used by bloggers. The
bodyText ||| paper also offers a view into the perception of the digital
bodyText ||| presentation of self in blogs. Blog reading allows for widely
bodyText ||| varied means of “being a part,” giving rise to new notions
bodyText ||| of community and belonging. This paper outlines the role of
bodyText ||| the reader in the activity of blogging, laying a general
bodyText ||| foundation for future work.
sectionHeader ||| ACKNOWLEDGMENTS
bodyText ||| Thanks to the California Institute for Telecommunications
bodyText ||| and Information Technology, the Summer Undergraduate
bodyText ||| Research Fellowship in Information Technologies Program,
bodyText ||| the Emulex Corporation, and the Donald Bren School of
bodyText ||| Information and Computer Sciences for their support.
bodyText ||| Thanks also to Bonnie Nardi for comments on an earlier
bodyText ||| draft, to Peter Krapp and Nathaniel Pope for discussions
bodyText ||| about blogs and blogging, and to the anonymous reviewers
bodyText ||| for their valuable feedback and suggestions.
sectionHeader ||| REFERENCES
reference ||| 1. boyd, d. Faceted id/entity: Managing representation in a
reference ||| digital world. Masters Thesis, Massachusetts Institute of
reference ||| Technology, Cambridge, MA, 2002
reference ||| 2. boyd, d. A blogger's blog: Exploring the definition of a
reference ||| medium Reconstruction 10, 4 (2006).
reference ||| 3. Davis, T.F. and Womack, K. Formalist Criticism and
reference ||| Reader-Response Theory. Palgrave, New York, 2002.
reference ||| 4. de Solla Price, D.J. Little Science, Big Science.
reference ||| Columbia University Press, New York, 1963.
reference ||| 5. Dourish, P. Where the action is. MIT Press, Cambridge,
reference ||| MA, 2001.
reference ||| 6. Driskell, R.B. and Lyon, L. Are virtual communities
reference ||| true communities? Examining the environments and
reference ||| elements of community. City & Community 1, 4 (2002).
reference ||| 373-390.
reference ||| 7. Efimova, L. and Moor, A.d., Beyond personal
reference ||| webpublishing: An exploratory study of conversational
reference ||| blogging practices. in HI Int’l Conf on Sys Sci, (2005),
reference ||| IEEE Computer Society.
reference ||| 8. Furukawa, T., Matsuo, Y., Ohmukai, I., Uchiyama, K.
reference ||| and Ishizuka, M., Social Networks and Reading
reference ||| Behavior in Blogosphere. in Int’l Conf on Weblogs and
reference ||| Social Media, (2007).
reference ||| 9. Goffman, E. The presentation of self in everyday life.
reference ||| Doubleday, New York, 1959.
reference ||| 10. Herring, S.C., Kouper, I., Paolillo, J.C., Scheidt, L.A.,
reference ||| Tyworth, M., Welsch, P., Wright, E. and Yu, N.,
reference ||| Conversations in the blogosphere: An analysis "from the
reference ||| bottom up." in HI Int’l Conf on Sys Sci, (2005), IEEE
reference ||| Computer Society.
reference ||| 11. Herring, S.C., Scheidt, L.A., Bonus, S. and Wright, E.,
reference ||| Bridging the gap: A genre analysis of weblogs. in HI
reference ||| Int’l Conf on Sys Sci, (2004), IEEE Computer Society.
reference ||| 12. Hillery, G. Definitions of community. Rural Sociology
reference ||| 20, (1955), 779-791.
reference ||| 13. Kaye, J., I just clicked to say I love you: Rich
reference ||| evaluations of minimal communication. in CHI
reference ||| Extended Abstracts, (2006), ACM Press, 363-368.
reference ||| 14. Kuwabara, K., Watanabe, T., Ohguro, T., Itoh, Y. and
reference ||| Maeda, Y., Connectedness oriented communication
reference ||| fostering a sense of connectedness to augment social
reference ||| relationships. in SAINT, (2002), Computer Society.
reference ||| 15. Lenhart, A.B. Unstable Texts: An Ethnographic Look at
reference ||| How Bloggers and Their Audience Negotiate Self-
reference ||| Presentation, Authenticity, and Norm Formation,
reference ||| Masters Thesis, Georgetown University, Washington,
reference ||| D.C., 2005.
reference ||| 16. Lenhart, A.B. and Fox, S. Bloggers: A portrait of the
reference ||| Internet's new storytellers, Pew Internet & American
reference ||| Life Project, 2006.
reference ||| 17. Lewis, C.S. An experiment in criticism. Cambridge
reference ||| University Press, 1992.
reference ||| 18. Lofland, J. and Lofland, L. Analyzing social settings: A
reference ||| guide to qualitative observation and analysis.
reference ||| Wadsworth, Belmont, CA, 1995.
reference ||| 19. Marlow, C., Audience, Structure, and Authority in the
reference ||| Weblog Community. in Int’l Comm Assoc Conf, (2004).
reference ||| 20. Miller, D. and Slater, D. Chapter One - Conclusions. in
reference ||| The Internet: An Ethnographic Approach, Berg, Oxford,
reference ||| 2000.
reference ||| 21. Nardi, B.A., Schiano, D.J. and Gumbrecht, M.,
reference ||| Blogging as social activity, or, would you let 900
reference ||| million people read your diary? in ACM CSCW, (2004),
reference ||| ACM Press, 222-231.
reference ||| 22. Nardi, B.A., Whittaker, S. and Bradner, E., Interaction
reference ||| and outeraction: instant messaging in action. in ACM
reference ||| CSCW, (2000), ACM Press, 79--88.
reference ||| 23. Reed, A. 'My blog is me': Texts and person in UK
reference ||| online journal culture (and anthropology). Ethnos 70, 2
reference ||| (2005).
reference ||| 24. Schmidt, J. Blogging practices: An analytical
reference ||| framework. Journal of CMC 12, 4, (2007).
reference ||| 25. Sifry, D. The State of the Live Web, Technorati, 2007,
reference ||| accessed September 4, 2007, from
reference ||| http://www.sifry.com/alerts/archives/000493.html.
reference ||| 26. Turkle, S. Life on the Screen. Simon and Schuster, New
reference ||| York, 1995.
reference ||| 27. www.almaden.ibm.com/cs/wbi. Accessed July 2007.
reference ||| 28. Wyche, S.P., Taylor, A. and Kaye, J., Pottering: A
reference ||| design-oriented investigation. in CHI Extended
reference ||| Abstracts, (2007), ACM Press, 1893-1898.
page ||| 1120

